{
 "cells": [
  {
   "cell_type": "code",
   "id": "899284166d0cc91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:41:58.346319Z",
     "start_time": "2024-05-06T14:41:56.078881Z"
    }
   },
   "source": [
    "%pip install influxdb_client"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb_client in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (1.42.0)\r\n",
      "Requirement already satisfied: reactivex>=4.0.4 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (4.0.4)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (2.8.2)\r\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (68.0.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (1.26.16)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from reactivex>=4.0.4->influxdb_client) (4.7.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9063ec07cd2ed7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:41:58.518877Z",
     "start_time": "2024-05-06T14:41:58.348542Z"
    }
   },
   "source": [
    "import os\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from influxdb_client import InfluxDBClient\n",
    "\n",
    "# 디바이스 ID와 위치를 매핑\n",
    "location_mapping = {\n",
    "    '24e124126d152919': 'indoor',\n",
    "    '24e124126d152969': 'bottom_right_corner',\n",
    "    '24e124128c067999': 'indoor',\n",
    "    '24e124785c389818': 'bottom_left_corner',\n",
    "    '24e124785c421885': 'top_right_corner'\n",
    "}\n",
    "\n",
    "# InfluxDB 설정 정보\n",
    "url = \"http://133.186.144.22:8086\"\n",
    "token = \"r3Ecro-rJQ82UpyNScnHXYDZ3KaE45AzweCXz6QIv2jeo7eOP4hL4-A9uKvkAVQDg_xavWorGUGZn7MI_sPCwg==\"\n",
    "org = \"smoothing\"\n",
    "\n",
    "def create_client(url, token, org):\n",
    "    \"\"\"\n",
    "    Influx DB 연결 Client를 생성합니다.\n",
    "    \n",
    "    :param url: InfluxDB 연결 주소\n",
    "    :param token: InfluxDB 토큰\n",
    "    :param org:  InfluxDB 조직\n",
    "    :return: InfluxDBClient\n",
    "    \"\"\"\n",
    "    return InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "def query_to_dataframe(client, query, field = \"location\"):\n",
    "    \"\"\"\n",
    "    구성된 쿼리를 실행하고 전달받은 데이터를 Dataframe으로 만듭니다.\n",
    "    \n",
    "    :param field: 기본값 location\n",
    "    :param client: InfluxDBClient\n",
    "    :param query: 요청할 쿼리\n",
    "    :return: DataFrame \n",
    "    \"\"\"\n",
    "    result = client.query_api().query(query=query)\n",
    "    results = []\n",
    "\n",
    "    for table in result:\n",
    "        for record in table.records:\n",
    "            results.append({\n",
    "                \"time\": record.get_time(),\n",
    "                \"value\": record.get_value(),\n",
    "                \"place\": record.values.get(\"place\"),\n",
    "                \"location\": record.values.get(field),\n",
    "                \"device\": record.values.get(\"device\")\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df['time'] = df['time'].astype(str).str.replace(r'\\+00:00$', '', regex=True)\n",
    "    return df\n",
    "\n",
    "def save_csv(df, file_pattern, directory):\n",
    "\n",
    "    \"\"\"\n",
    "    DataFrame을 CSV로 변환하여 저장합니다.\n",
    "    \n",
    "    :param df: DataFrame\n",
    "    :param file_pattern: 파일 이름 패턴\n",
    "    :param directory: 저장할 위치\n",
    "    \"\"\"\n",
    "    # 파일 경로를 확인 하고 없다면 생성 합니다.\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "    previous_date = datetime.now() - timedelta(days=1)\n",
    "    filename = f\"{directory}{previous_date.strftime(file_pattern)}\"\n",
    "    df.to_csv(filename, index=False)\n",
    "\n",
    "def update_location(df):\n",
    "    \"\"\"\n",
    "    환경 센서 Data에서 Device ID를 확인 하여 'location' 열을 업데이트 합니다.\n",
    "    \n",
    "    :param df: 환경 센서 DataFrame\n",
    "    :return: 'location' 열을 업데이트한 DataFrame\n",
    "    \"\"\"\n",
    "    df['location'] = df['device'].map(location_mapping)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "id": "fc77d40ce74c9c09",
   "metadata": {},
   "source": [
    "### 쿼리 사용하여 조회"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb3854c3e4e0ad2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T15:01:08.584102Z",
     "start_time": "2024-05-04T15:01:08.474830Z"
    }
   },
   "source": [
    "# 클라이언트 생성 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 한국 시간대 설정\n",
    "korea_tz = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# 사용자로부터 입력받은 날짜와 시간\n",
    "input_date_str = \"2024-05-02 00:00:00\"\n",
    "input_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "sensor_name = \"counter\"\n",
    "\n",
    "# 입력 날짜를 datetime 객체로 변환\n",
    "input_datetime = datetime.strptime(input_date_str, input_format)\n",
    "\n",
    "# 한국 시간대로 localize\n",
    "localized_kst = korea_tz.localize(input_datetime)\n",
    "\n",
    "# UTC로 변환\n",
    "start_time_utc = localized_kst.astimezone(pytz.utc)\n",
    "end_time_utc = start_time_utc + timedelta(days=1)  # 24시간 후\n",
    "\n",
    "query_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"{sensor_name}\")\n",
    "  |> aggregateWindow(every: 1h, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# CSV 변환\n",
    "df_sensor_data = query_to_dataframe(client, query_data)\n",
    "df_sensor_data_fix = update_location(df_sensor_data)\n",
    "print(df_sensor_data_fix.head())\n",
    "save_csv(df_sensor_data_fix, input_datetime.strftime(\"%m_%d\")+\"_\"+sensor_name+\"_data.csv\", \"all_data/\"+sensor_name+\"/\")\n",
    "\n",
    "# client 종료\n",
    "client.close()"
   ],
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3621\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3620\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcasted_key\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:136\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_libs/index.pyx:163\u001B[0m, in \u001B[0;36mpandas._libs.index.IndexEngine.get_loc\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5198\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "File \u001B[0;32mpandas/_libs/hashtable_class_helper.pxi:5206\u001B[0m, in \u001B[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mKeyError\u001B[0m: 'time'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[124], line 34\u001B[0m\n\u001B[1;32m     22\u001B[0m query_data \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m     23\u001B[0m \u001B[38;5;124mimport \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mexperimental\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m     24\u001B[0m \u001B[38;5;124mfrom(bucket: \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124menvironmentalsensors_data\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m)\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;124m  |> keep(columns: [\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_time\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m_value\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mplace\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mlocation\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m])\u001B[39m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;124m'''\u001B[39m\n\u001B[1;32m     33\u001B[0m \u001B[38;5;66;03m# CSV 변환\u001B[39;00m\n\u001B[0;32m---> 34\u001B[0m df_sensor_data \u001B[38;5;241m=\u001B[39m \u001B[43mquery_to_dataframe\u001B[49m\u001B[43m(\u001B[49m\u001B[43mclient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mquery_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     35\u001B[0m df_sensor_data_fix \u001B[38;5;241m=\u001B[39m update_location(df_sensor_data, location_mapping)\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28mprint\u001B[39m(df_sensor_data_fix\u001B[38;5;241m.\u001B[39mhead())\n",
      "Cell \u001B[0;32mIn[123], line 55\u001B[0m, in \u001B[0;36mquery_to_dataframe\u001B[0;34m(client, query, field)\u001B[0m\n\u001B[1;32m     46\u001B[0m         results\u001B[38;5;241m.\u001B[39mappend({\n\u001B[1;32m     47\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m\"\u001B[39m: record\u001B[38;5;241m.\u001B[39mget_time(),\n\u001B[1;32m     48\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalue\u001B[39m\u001B[38;5;124m\"\u001B[39m: record\u001B[38;5;241m.\u001B[39mget_value(),\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     51\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m\"\u001B[39m: record\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdevice\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     52\u001B[0m         })\n\u001B[1;32m     54\u001B[0m df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame(results)\n\u001B[0;32m---> 55\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtime\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m \u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mtime\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mstr\u001B[39m)\u001B[38;5;241m.\u001B[39mstr\u001B[38;5;241m.\u001B[39mreplace(\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m\\\u001B[39m\u001B[38;5;124m+00:00$\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, regex\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m df\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:3505\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3503\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m   3504\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[0;32m-> 3505\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   3506\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[1;32m   3507\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:3623\u001B[0m, in \u001B[0;36mIndex.get_loc\u001B[0;34m(self, key, method, tolerance)\u001B[0m\n\u001B[1;32m   3621\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine\u001B[38;5;241m.\u001B[39mget_loc(casted_key)\n\u001B[1;32m   3622\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m err:\n\u001B[0;32m-> 3623\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01merr\u001B[39;00m\n\u001B[1;32m   3624\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m:\n\u001B[1;32m   3625\u001B[0m     \u001B[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001B[39;00m\n\u001B[1;32m   3626\u001B[0m     \u001B[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001B[39;00m\n\u001B[1;32m   3627\u001B[0m     \u001B[38;5;66;03m#  the TypeError.\u001B[39;00m\n\u001B[1;32m   3628\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n",
      "\u001B[0;31mKeyError\u001B[0m: 'time'"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-06T14:43:50.760493Z",
     "start_time": "2024-05-06T14:43:49.779621Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 클라이언트 생성 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 한국 시간대 설정\n",
    "korea_tz = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# 사용자로부터 입력받은 날짜와 시간\n",
    "input_date_str = \"2024-05-05 00:00:00\"\n",
    "input_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "# 입력 날짜를 datetime 객체로 변환\n",
    "input_datetime = datetime.strptime(input_date_str, input_format)\n",
    "\n",
    "# 한국 시간대로 localize\n",
    "localized_kst = korea_tz.localize(input_datetime)\n",
    "\n",
    "# UTC로 변환\n",
    "start_time_utc = localized_kst.astimezone(pytz.utc)\n",
    "end_time_utc = start_time_utc + timedelta(days=1)  # 24시간 후\n",
    "\n",
    "# 전력(W) 조회 (class a : 콘센트)\n",
    "query_power_socket_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"total\")\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"w\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"office\")\n",
    "  |> filter(fn: (r) => r[\"location\"] == \"class_a_floor_heating_1\" or r[\"location\"] == \"class_a_floor_heating_2\")\n",
    "  |> aggregateWindow(every: 1m, fn: last, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 전력 CSV 생성(콘센트)\n",
    "df_power_socket = query_to_dataframe(client, query_power_socket_data)\n",
    "print(df_power_socket.head(2))\n",
    "save_csv(df_power_socket, input_datetime.strftime(\"%m_%d\")+\"_power_socket_data.csv\", \"all_data/power/socket/\")\n",
    "\n",
    "# 전력 사용량 조회 (class a : 콘센트)\n",
    "query_power_usage_socket_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"kwh\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"office\")\n",
    "  |> filter(fn: (r) => r[\"location\"] == \"class_a_floor_heating_1\" or r[\"location\"] == \"class_a_floor_heating_2\")\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"sum\")\n",
    "  |> aggregateWindow(every: 1m, fn: last, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 전력 사용량 CSV 생성(콘센트)\n",
    "df_power_usage_socket = query_to_dataframe(client, query_power_usage_socket_data)\n",
    "print(df_power_usage_socket.head(2))\n",
    "save_csv(df_power_usage_socket, input_datetime.strftime(\"%m_%d\")+\"_power_usage_socket_data.csv\", \"all_data/power_usage/socket/\")\n",
    "\n",
    "# client 종료\n",
    "client.close()"
   ],
   "id": "ea77b892872779e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time  value   place                 location     device\n",
      "0  2024-05-05 00:01:00   28.0  office  class_a_floor_heating_1  gems-3500\n",
      "1  2024-05-05 00:02:00   28.0  office  class_a_floor_heating_1  gems-3500\n",
      "                  time  value   place                 location     device\n",
      "0  2024-05-05 00:01:00  141.2  office  class_a_floor_heating_1  gems-3500\n",
      "1  2024-05-05 00:02:00  141.2  office  class_a_floor_heating_1  gems-3500\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# 클라이언트 생성 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 한국 시간대 설정\n",
    "korea_tz = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# 사용자로부터 입력받은 날짜와 시간\n",
    "input_date_str = \"2024-05-03 00:00:00\"\n",
    "input_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "# 입력 날짜를 datetime 객체로 변환\n",
    "input_datetime = datetime.strptime(input_date_str, input_format)\n",
    "\n",
    "# 한국 시간대로 localize\n",
    "localized_kst = korea_tz.localize(input_datetime)\n",
    "\n",
    "# UTC로 변환\n",
    "start_time_utc = localized_kst.astimezone(pytz.utc)\n",
    "end_time_utc = start_time_utc + timedelta(days=1)  # 24시간 후\n",
    "\n",
    "# 이동 감지 카운터 조회 Flux 쿼리\n",
    "query_counter_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"milesight\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"line_periodic_data_1_out\" or r[\"_field\"] == \"line_periodic_data_1_in\")\n",
    "  |> aggregateWindow(every: 1m, fn: last, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"_field\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 이동 감지 카운터 CSV 생성\n",
    "df_counter = query_to_dataframe(client, query_counter_data, \"_field\")\n",
    "print(df_counter.head(2))\n",
    "save_csv(df_counter, input_datetime.strftime(\"%m_%d\")+\"_counter_data.csv\", \"all_data/counter/total/\")"
   ],
   "id": "9d71ec64a054b9d1",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoothing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
