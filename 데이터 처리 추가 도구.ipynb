{
 "cells": [
  {
   "cell_type": "code",
   "id": "899284166d0cc91f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:17:47.419687Z",
     "start_time": "2024-05-02T04:17:42.461292Z"
    }
   },
   "source": [
    "%pip install influxdb_client"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: influxdb_client in c:\\users\\김재혁\\appdata\\roaming\\python\\python311\\site-packages (1.42.0)\n",
      "Requirement already satisfied: reactivex>=4.0.4 in c:\\users\\김재혁\\appdata\\roaming\\python\\python311\\site-packages (from influxdb_client) (4.0.4)\n",
      "Requirement already satisfied: certifi>=14.05.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from influxdb_client) (2024.2.2)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from influxdb_client) (2.8.2)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from influxdb_client) (68.2.2)\n",
      "Requirement already satisfied: urllib3>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from influxdb_client) (2.0.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from reactivex>=4.0.4->influxdb_client) (4.9.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "9063ec07cd2ed7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:34:03.428813Z",
     "start_time": "2024-05-02T04:34:03.406622Z"
    }
   },
   "source": [
    "import os\n",
    "import pytz\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "from influxdb_client import InfluxDBClient\n",
    "\n",
    "# 디바이스 ID와 위치를 매핑\n",
    "location_mapping = {\n",
    "    '24e124126d152919': 'indoor',\n",
    "    '24e124126d152969': 'bottom_right_corner',\n",
    "    '24e124128c067999': 'indoor',\n",
    "    '24e124785c389818': 'bottom_left_corner',\n",
    "    '24e124785c421885': 'top_right_corner'\n",
    "}\n",
    "\n",
    "# InfluxDB 설정 정보\n",
    "url = \"http://133.186.144.22:8086\"\n",
    "token = \"BPJ1pnKvoaov4Tte971t0zpRSTUXNZvrshU7u3UPheAIsBeUJEFfbKjfsZjtwZmugkHJEGRW17lH4bR9ybanNQ==\"\n",
    "org = \"smoothing\"\n",
    "\n",
    "# InfluxDB 클라이언트 생성\n",
    "def create_client(url, token, org):\n",
    "    return InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "# 쿼리 실행 및 DataFrame으로 변환\n",
    "def query_to_dataframe(client, query):\n",
    "    result = client.query_api().query(query=query)\n",
    "    results = []\n",
    "    \n",
    "    for table in result:\n",
    "        for record in table.records:\n",
    "            results.append({\n",
    "                \"time\": record.get_time(),\n",
    "                \"value\": record.get_value(),\n",
    "                \"place\": record.values.get(\"place\"),\n",
    "                \"location\": record.values.get(\"location\"),\n",
    "                \"device\": record.values.get(\"device\")\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['time'] = df['time'].astype(str).str.replace(r'\\+00:00$', '', regex=True)\n",
    "    df = df.round(2) # 반올림 추가\n",
    "    return df\n",
    "\n",
    "# 데이터를 날짜를 지정하여 CSV 파일로 저장\n",
    "def save_csv(df, file_pattern, directory):\n",
    "    # 반올림 추가 \n",
    "    df = df.round(2)\n",
    "    # 경로가 존재하는지 확인하고, 없다면 생성\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    current_date = datetime.now()\n",
    "    previous_date = current_date - timedelta(days=1)\n",
    "    filename = f\"{directory}{previous_date.strftime(file_pattern)}\"\n",
    "    df.to_csv(filename, index=False)\n",
    "    \n",
    "# 온도 Data에서 'device' 열에 따라 'location' 열을 업데이트    \n",
    "def update_location(df, location_mapping):\n",
    "    df['location'] = df['device'].map(location_mapping)\n",
    "    return df"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "fc77d40ce74c9c09",
   "metadata": {},
   "source": [
    "### 쿼리 사용하여 조회"
   ]
  },
  {
   "cell_type": "code",
   "id": "cb3854c3e4e0ad2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:31:20.229878Z",
     "start_time": "2024-05-02T04:31:19.470575Z"
    }
   },
   "source": [
    "# 클라이언트 생성 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 한국 시간대 설정\n",
    "korea_tz = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# 사용자로부터 입력받은 날짜와 시간\n",
    "input_date_str = \"2024-04-15 00:00:00\"\n",
    "input_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "sensor_name = \"temperature\"\n",
    "\n",
    "# 입력 날짜를 datetime 객체로 변환\n",
    "input_datetime = datetime.strptime(input_date_str, input_format)\n",
    "\n",
    "# 한국 시간대로 localize\n",
    "localized_kst = korea_tz.localize(input_datetime)\n",
    "\n",
    "# UTC로 변환\n",
    "start_time_utc = localized_kst.astimezone(pytz.utc)\n",
    "end_time_utc = start_time_utc + timedelta(days=1)  # 24시간 후\n",
    "\n",
    "query_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"{sensor_name}\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# CSV 변환\n",
    "df_sensor_data = query_to_dataframe(client, query_data)\n",
    "df_sensor_data_fix = update_location(df_sensor_data, location_mapping)\n",
    "print(df_sensor_data_fix.head())\n",
    "save_csv(df_sensor_data_fix, input_datetime.strftime(\"%m_%d\")+\"_\"+sensor_name+\"_data.csv\", \"all_data/\"+sensor_name+\"/\")\n",
    "\n",
    "# client 종료\n",
    "client.close()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time  value    place             location            device\n",
      "0  2024-04-15 00:02:00   24.0  class_a  bottom_right_corner  24e124126d152969\n",
      "1  2024-04-15 00:04:00   24.0  class_a  bottom_right_corner  24e124126d152969\n",
      "2  2024-04-15 00:06:00   24.0  class_a  bottom_right_corner  24e124126d152969\n",
      "3  2024-04-15 00:08:00   23.8  class_a  bottom_right_corner  24e124126d152969\n",
      "4  2024-04-15 00:10:00   23.8  class_a  bottom_right_corner  24e124126d152969\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T04:50:38.157919Z",
     "start_time": "2024-05-02T04:50:37.322763Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 클라이언트 생성 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 한국 시간대 설정\n",
    "korea_tz = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# 사용자로부터 입력받은 날짜와 시간\n",
    "input_date_str = \"2024-04-30 00:00:00\"\n",
    "input_format = \"%Y-%m-%d %H:%M:%S\"\n",
    "\n",
    "# 입력 날짜를 datetime 객체로 변환\n",
    "input_datetime = datetime.strptime(input_date_str, input_format)\n",
    "\n",
    "# 한국 시간대로 localize\n",
    "localized_kst = korea_tz.localize(input_datetime)\n",
    "\n",
    "# UTC로 변환\n",
    "start_time_utc = localized_kst.astimezone(pytz.utc)\n",
    "end_time_utc = start_time_utc + timedelta(days=1)  # 24시간 후\n",
    "\n",
    "# 전력(W) 조회(class a : main) Flux 쿼리\n",
    "query_power_device_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"total\")\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"w\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"location\"] != \"main\" and r[\"location\"] != \"outdoor_unit_room_light\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 전력 CSV 생성\n",
    "df_power = query_to_dataframe(client, query_power_device_data)\n",
    "print(df_power.head(2))\n",
    "save_csv(df_power, input_datetime.strftime(\"%m_%d\")+\"_power_device_data.csv\", \"all_data/power/device/\")\n",
    "\n",
    "# 전력 사용량 조회(class a : main) Flux 쿼리\n",
    "query_power_usage_device_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"kwh\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"sum\")\n",
    "  |> filter(fn: (r) => r[\"location\"] != \"main\" and r[\"location\"] != \"outdoor_unit_room_light\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 전력 사용량 CSV 생성\n",
    "df_power_usage = query_to_dataframe(client, query_power_usage_device_data)\n",
    "save_csv(df_power_usage, input_datetime.strftime(\"%m_%d\")+\"_power_usage_device_data.csv\", \"all_data/power_usage/device/\")\n",
    "print(df_power_usage.head(2))\n",
    "\n",
    "# client 종료\n",
    "client.close()"
   ],
   "id": "ea77b892872779e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  time  value    place        location     device\n",
      "0  2024-04-30 00:02:00   77.5  class_a  ac_indoor_unit  gems-3500\n",
      "1  2024-04-30 00:04:00   79.0  class_a  ac_indoor_unit  gems-3500\n",
      "                  time  value    place        location     device\n",
      "0  2024-04-30 00:02:00   38.7  class_a  ac_indoor_unit  gems-3500\n",
      "1  2024-04-30 00:04:00   38.7  class_a  ac_indoor_unit  gems-3500\n"
     ]
    }
   ],
   "execution_count": 36
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoothing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
