2024-05-08 15:29:32,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-08 15:29:32,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-08 15:29:32,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-08 15:29:32,533:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-08 15:34:19,658:INFO:PyCaret RegressionExperiment
2024-05-08 15:34:19,658:INFO:Logging name: reg-default-name
2024-05-08 15:34:19,658:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-08 15:34:19,658:INFO:version 3.3.2
2024-05-08 15:34:19,658:INFO:Initializing setup()
2024-05-08 15:34:19,658:INFO:self.USI: dd16
2024-05-08 15:34:19,658:INFO:self._variable_keys: {'y_train', 'X_test', 'seed', 'exp_name_log', 'X', 'y_test', '_ml_usecase', 'log_plots_param', 'idx', '_available_plots', 'html_param', 'exp_id', 'pipeline', 'n_jobs_param', 'data', 'fold_generator', 'transform_target_param', 'X_train', 'fold_groups_param', 'logging_param', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'fold_shuffle_param', 'target_param', 'memory', 'y'}
2024-05-08 15:34:19,658:INFO:Checking environment
2024-05-08 15:34:19,658:INFO:python_version: 3.9.18
2024-05-08 15:34:19,658:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-08 15:34:19,658:INFO:machine: x86_64
2024-05-08 15:34:19,658:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 15:34:19,658:INFO:Memory: svmem(total=16429801472, available=5248856064, percent=68.1, used=10066296832, free=281853952, active=8507265024, inactive=6456459264, buffers=176152576, cached=5905498112, shared=768069632, slab=699281408)
2024-05-08 15:34:19,659:INFO:Physical Core: 12
2024-05-08 15:34:19,659:INFO:Logical Core: 16
2024-05-08 15:34:19,659:INFO:Checking libraries
2024-05-08 15:34:19,659:INFO:System:
2024-05-08 15:34:19,659:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-08 15:34:19,659:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-08 15:34:19,659:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 15:34:19,659:INFO:PyCaret required dependencies:
2024-05-08 15:34:20,023:INFO:                 pip: 23.2.1
2024-05-08 15:34:20,023:INFO:          setuptools: 68.0.0
2024-05-08 15:34:20,023:INFO:             pycaret: 3.3.2
2024-05-08 15:34:20,023:INFO:             IPython: 8.15.0
2024-05-08 15:34:20,023:INFO:          ipywidgets: 8.0.4
2024-05-08 15:34:20,023:INFO:                tqdm: 4.65.0
2024-05-08 15:34:20,023:INFO:               numpy: 1.24.3
2024-05-08 15:34:20,023:INFO:              pandas: 1.4.2
2024-05-08 15:34:20,023:INFO:              jinja2: 3.1.4
2024-05-08 15:34:20,023:INFO:               scipy: 1.11.3
2024-05-08 15:34:20,023:INFO:              joblib: 1.2.0
2024-05-08 15:34:20,023:INFO:             sklearn: 1.4.2
2024-05-08 15:34:20,023:INFO:                pyod: 1.1.3
2024-05-08 15:34:20,023:INFO:            imblearn: 0.12.2
2024-05-08 15:34:20,023:INFO:   category_encoders: 2.6.3
2024-05-08 15:34:20,023:INFO:            lightgbm: 4.3.0
2024-05-08 15:34:20,023:INFO:               numba: 0.58.0
2024-05-08 15:34:20,023:INFO:            requests: 2.31.0
2024-05-08 15:34:20,023:INFO:          matplotlib: 3.7.2
2024-05-08 15:34:20,023:INFO:          scikitplot: 0.3.7
2024-05-08 15:34:20,023:INFO:         yellowbrick: 1.5
2024-05-08 15:34:20,023:INFO:              plotly: 5.22.0
2024-05-08 15:34:20,023:INFO:    plotly-resampler: Not installed
2024-05-08 15:34:20,023:INFO:             kaleido: 0.2.1
2024-05-08 15:34:20,023:INFO:           schemdraw: 0.15
2024-05-08 15:34:20,023:INFO:         statsmodels: 0.14.0
2024-05-08 15:34:20,023:INFO:              sktime: 0.26.0
2024-05-08 15:34:20,023:INFO:               tbats: 1.1.3
2024-05-08 15:34:20,023:INFO:            pmdarima: 2.0.4
2024-05-08 15:34:20,023:INFO:              psutil: 5.9.0
2024-05-08 15:34:20,023:INFO:          markupsafe: 2.0.1
2024-05-08 15:34:20,023:INFO:             pickle5: Not installed
2024-05-08 15:34:20,023:INFO:         cloudpickle: 2.2.1
2024-05-08 15:34:20,023:INFO:         deprecation: 2.1.0
2024-05-08 15:34:20,023:INFO:              xxhash: 2.0.2
2024-05-08 15:34:20,023:INFO:           wurlitzer: 3.0.2
2024-05-08 15:34:20,023:INFO:PyCaret optional dependencies:
2024-05-08 15:34:20,033:INFO:                shap: Not installed
2024-05-08 15:34:20,033:INFO:           interpret: Not installed
2024-05-08 15:34:20,033:INFO:                umap: Not installed
2024-05-08 15:34:20,033:INFO:     ydata_profiling: Not installed
2024-05-08 15:34:20,033:INFO:  explainerdashboard: Not installed
2024-05-08 15:34:20,033:INFO:             autoviz: Not installed
2024-05-08 15:34:20,033:INFO:           fairlearn: Not installed
2024-05-08 15:34:20,033:INFO:          deepchecks: Not installed
2024-05-08 15:34:20,033:INFO:             xgboost: Not installed
2024-05-08 15:34:20,033:INFO:            catboost: Not installed
2024-05-08 15:34:20,033:INFO:              kmodes: Not installed
2024-05-08 15:34:20,033:INFO:             mlxtend: Not installed
2024-05-08 15:34:20,033:INFO:       statsforecast: Not installed
2024-05-08 15:34:20,033:INFO:        tune_sklearn: Not installed
2024-05-08 15:34:20,033:INFO:                 ray: Not installed
2024-05-08 15:34:20,033:INFO:            hyperopt: Not installed
2024-05-08 15:34:20,033:INFO:              optuna: Not installed
2024-05-08 15:34:20,033:INFO:               skopt: Not installed
2024-05-08 15:34:20,033:INFO:              mlflow: Not installed
2024-05-08 15:34:20,033:INFO:              gradio: Not installed
2024-05-08 15:34:20,033:INFO:             fastapi: Not installed
2024-05-08 15:34:20,033:INFO:             uvicorn: Not installed
2024-05-08 15:34:20,033:INFO:              m2cgen: Not installed
2024-05-08 15:34:20,033:INFO:           evidently: Not installed
2024-05-08 15:34:20,033:INFO:               fugue: Not installed
2024-05-08 15:34:20,033:INFO:           streamlit: Not installed
2024-05-08 15:34:20,033:INFO:             prophet: Not installed
2024-05-08 15:34:20,033:INFO:None
2024-05-08 15:34:20,034:INFO:Set up data.
2024-05-08 15:35:19,795:WARNING:/tmp/ipykernel_19548/3230173932.py:107: FutureWarning: Treating datetime data as categorical rather than numeric in `.describe` is deprecated and will be removed in a future version of pandas. Specify `datetime_is_numeric=True` to silence this warning and adopt the future behavior now.
  described_ = table.describe(percentiles=[.05, .25, .5, .75, .95],

2024-05-08 15:43:22,979:WARNING:/tmp/ipykernel_19548/3014180543.py:5: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-08 15:43:42,202:INFO:PyCaret RegressionExperiment
2024-05-08 15:43:42,203:INFO:Logging name: reg-default-name
2024-05-08 15:43:42,203:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-08 15:43:42,203:INFO:version 3.3.2
2024-05-08 15:43:42,203:INFO:Initializing setup()
2024-05-08 15:43:42,203:INFO:self.USI: 1eb6
2024-05-08 15:43:42,203:INFO:self._variable_keys: {'y_train', 'X_test', 'seed', 'exp_name_log', 'X', 'y_test', '_ml_usecase', 'log_plots_param', 'idx', '_available_plots', 'html_param', 'exp_id', 'pipeline', 'n_jobs_param', 'data', 'fold_generator', 'transform_target_param', 'X_train', 'fold_groups_param', 'logging_param', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'fold_shuffle_param', 'target_param', 'memory', 'y'}
2024-05-08 15:43:42,203:INFO:Checking environment
2024-05-08 15:43:42,203:INFO:python_version: 3.9.18
2024-05-08 15:43:42,203:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-08 15:43:42,203:INFO:machine: x86_64
2024-05-08 15:43:42,203:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 15:43:42,203:INFO:Memory: svmem(total=16429801472, available=5204492288, percent=68.3, used=10119147520, free=341692416, active=8557129728, inactive=6348120064, buffers=175710208, cached=5793251328, shared=734412800, slab=699834368)
2024-05-08 15:43:42,204:INFO:Physical Core: 12
2024-05-08 15:43:42,204:INFO:Logical Core: 16
2024-05-08 15:43:42,204:INFO:Checking libraries
2024-05-08 15:43:42,204:INFO:System:
2024-05-08 15:43:42,204:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-08 15:43:42,204:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-08 15:43:42,204:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 15:43:42,204:INFO:PyCaret required dependencies:
2024-05-08 15:43:42,205:INFO:                 pip: 23.2.1
2024-05-08 15:43:42,205:INFO:          setuptools: 68.0.0
2024-05-08 15:43:42,205:INFO:             pycaret: 3.3.2
2024-05-08 15:43:42,205:INFO:             IPython: 8.15.0
2024-05-08 15:43:42,205:INFO:          ipywidgets: 8.0.4
2024-05-08 15:43:42,205:INFO:                tqdm: 4.65.0
2024-05-08 15:43:42,205:INFO:               numpy: 1.24.3
2024-05-08 15:43:42,205:INFO:              pandas: 1.4.2
2024-05-08 15:43:42,205:INFO:              jinja2: 3.1.4
2024-05-08 15:43:42,205:INFO:               scipy: 1.11.3
2024-05-08 15:43:42,205:INFO:              joblib: 1.2.0
2024-05-08 15:43:42,205:INFO:             sklearn: 1.4.2
2024-05-08 15:43:42,205:INFO:                pyod: 1.1.3
2024-05-08 15:43:42,205:INFO:            imblearn: 0.12.2
2024-05-08 15:43:42,205:INFO:   category_encoders: 2.6.3
2024-05-08 15:43:42,205:INFO:            lightgbm: 4.3.0
2024-05-08 15:43:42,205:INFO:               numba: 0.58.0
2024-05-08 15:43:42,205:INFO:            requests: 2.31.0
2024-05-08 15:43:42,205:INFO:          matplotlib: 3.7.2
2024-05-08 15:43:42,205:INFO:          scikitplot: 0.3.7
2024-05-08 15:43:42,205:INFO:         yellowbrick: 1.5
2024-05-08 15:43:42,205:INFO:              plotly: 5.22.0
2024-05-08 15:43:42,205:INFO:    plotly-resampler: Not installed
2024-05-08 15:43:42,205:INFO:             kaleido: 0.2.1
2024-05-08 15:43:42,205:INFO:           schemdraw: 0.15
2024-05-08 15:43:42,205:INFO:         statsmodels: 0.14.0
2024-05-08 15:43:42,205:INFO:              sktime: 0.26.0
2024-05-08 15:43:42,205:INFO:               tbats: 1.1.3
2024-05-08 15:43:42,205:INFO:            pmdarima: 2.0.4
2024-05-08 15:43:42,205:INFO:              psutil: 5.9.0
2024-05-08 15:43:42,205:INFO:          markupsafe: 2.0.1
2024-05-08 15:43:42,205:INFO:             pickle5: Not installed
2024-05-08 15:43:42,205:INFO:         cloudpickle: 2.2.1
2024-05-08 15:43:42,205:INFO:         deprecation: 2.1.0
2024-05-08 15:43:42,205:INFO:              xxhash: 2.0.2
2024-05-08 15:43:42,205:INFO:           wurlitzer: 3.0.2
2024-05-08 15:43:42,205:INFO:PyCaret optional dependencies:
2024-05-08 15:43:42,205:INFO:                shap: Not installed
2024-05-08 15:43:42,205:INFO:           interpret: Not installed
2024-05-08 15:43:42,206:INFO:                umap: Not installed
2024-05-08 15:43:42,206:INFO:     ydata_profiling: Not installed
2024-05-08 15:43:42,206:INFO:  explainerdashboard: Not installed
2024-05-08 15:43:42,206:INFO:             autoviz: Not installed
2024-05-08 15:43:42,206:INFO:           fairlearn: Not installed
2024-05-08 15:43:42,206:INFO:          deepchecks: Not installed
2024-05-08 15:43:42,206:INFO:             xgboost: Not installed
2024-05-08 15:43:42,206:INFO:            catboost: Not installed
2024-05-08 15:43:42,206:INFO:              kmodes: Not installed
2024-05-08 15:43:42,206:INFO:             mlxtend: Not installed
2024-05-08 15:43:42,206:INFO:       statsforecast: Not installed
2024-05-08 15:43:42,206:INFO:        tune_sklearn: Not installed
2024-05-08 15:43:42,206:INFO:                 ray: Not installed
2024-05-08 15:43:42,206:INFO:            hyperopt: Not installed
2024-05-08 15:43:42,206:INFO:              optuna: Not installed
2024-05-08 15:43:42,206:INFO:               skopt: Not installed
2024-05-08 15:43:42,206:INFO:              mlflow: Not installed
2024-05-08 15:43:42,206:INFO:              gradio: Not installed
2024-05-08 15:43:42,206:INFO:             fastapi: Not installed
2024-05-08 15:43:42,206:INFO:             uvicorn: Not installed
2024-05-08 15:43:42,206:INFO:              m2cgen: Not installed
2024-05-08 15:43:42,206:INFO:           evidently: Not installed
2024-05-08 15:43:42,206:INFO:               fugue: Not installed
2024-05-08 15:43:42,206:INFO:           streamlit: Not installed
2024-05-08 15:43:42,206:INFO:             prophet: Not installed
2024-05-08 15:43:42,206:INFO:None
2024-05-08 15:43:42,206:INFO:Set up data.
2024-05-08 15:43:42,213:INFO:Set up folding strategy.
2024-05-08 15:43:42,214:INFO:Set up train/test split.
2024-05-08 15:43:42,218:INFO:Set up index.
2024-05-08 15:43:42,218:INFO:Assigning column types.
2024-05-08 15:43:42,221:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-08 15:43:42,221:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,227:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,236:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,295:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,323:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,324:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,324:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,328:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,331:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,386:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,387:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-08 15:43:42,389:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,391:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,436:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,438:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,440:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,465:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,486:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,486:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,487:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-08 15:43:42,491:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,522:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,543:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,543:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,543:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,548:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,574:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,593:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,593:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,593:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,593:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-08 15:43:42,625:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,650:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,650:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,683:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,702:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,703:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-08 15:43:42,734:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,754:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,754:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,784:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 15:43:42,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,805:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-08 15:43:42,858:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,908:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,909:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:42,909:INFO:Preparing preprocessing pipeline...
2024-05-08 15:43:42,909:INFO:Set up target transformation.
2024-05-08 15:43:42,909:INFO:Set up date feature engineering.
2024-05-08 15:43:42,910:INFO:Set up simple imputation.
2024-05-08 15:43:42,910:INFO:Set up polynomial features.
2024-05-08 15:43:42,910:INFO:Set up feature normalization.
2024-05-08 15:43:42,910:INFO:Set up column name cleaning.
2024-05-08 15:43:42,924:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:42,950:INFO:Finished creating preprocessing pipeline.
2024-05-08 15:43:42,956:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['cumulati...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-08 15:43:42,956:INFO:Creating final display dataframe.
2024-05-08 15:43:43,041:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape         (590, 10)
4        Transformed data shape         (590, 78)
5   Transformed train set shape         (413, 78)
6    Transformed test set shape         (177, 78)
7              Numeric features                 8
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13          Polynomial features              True
14            Polynomial degree                 2
15                    Normalize              True
16             Normalize method            zscore
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              1eb6
2024-05-08 15:43:43,107:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:43,107:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:43,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:43,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 15:43:43,176:INFO:setup() successfully completed in 0.98s...............
2024-05-08 15:43:43,176:INFO:Initializing compare_models()
2024-05-08 15:43:43,176:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-08 15:43:43,176:INFO:Checking exceptions
2024-05-08 15:43:43,177:INFO:Preparing display monitor
2024-05-08 15:43:43,199:INFO:Initializing Linear Regression
2024-05-08 15:43:43,200:INFO:Total runtime is 4.951159159342448e-06 minutes
2024-05-08 15:43:43,203:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:43,203:INFO:Initializing create_model()
2024-05-08 15:43:43,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:43,203:INFO:Checking exceptions
2024-05-08 15:43:43,203:INFO:Importing libraries
2024-05-08 15:43:43,203:INFO:Copying training dataset
2024-05-08 15:43:43,205:INFO:Defining folds
2024-05-08 15:43:43,205:INFO:Declaring metric variables
2024-05-08 15:43:43,210:INFO:Importing untrained model
2024-05-08 15:43:43,213:INFO:Linear Regression Imported successfully
2024-05-08 15:43:43,220:INFO:Starting cross validation
2024-05-08 15:43:43,224:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:47,133:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,133:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,135:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,138:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,157:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,168:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,169:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,171:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,173:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,277:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:47,278:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:47,279:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:47,279:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:47,279:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:47,279:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:47,282:INFO:Calculating mean and std
2024-05-08 15:43:47,285:INFO:Creating metrics dataframe
2024-05-08 15:43:47,293:INFO:Uploading results into container
2024-05-08 15:43:47,303:INFO:Uploading model into container now
2024-05-08 15:43:47,305:INFO:_master_model_container: 1
2024-05-08 15:43:47,305:INFO:_display_container: 2
2024-05-08 15:43:47,306:INFO:LinearRegression(n_jobs=-1)
2024-05-08 15:43:47,306:INFO:create_model() successfully completed......................................
2024-05-08 15:43:47,466:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:47,466:INFO:Creating metrics dataframe
2024-05-08 15:43:47,471:INFO:Initializing Lasso Regression
2024-05-08 15:43:47,471:INFO:Total runtime is 0.07118643919626871 minutes
2024-05-08 15:43:47,472:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:47,473:INFO:Initializing create_model()
2024-05-08 15:43:47,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:47,473:INFO:Checking exceptions
2024-05-08 15:43:47,473:INFO:Importing libraries
2024-05-08 15:43:47,473:INFO:Copying training dataset
2024-05-08 15:43:47,475:INFO:Defining folds
2024-05-08 15:43:47,475:INFO:Declaring metric variables
2024-05-08 15:43:47,477:INFO:Importing untrained model
2024-05-08 15:43:47,480:INFO:Lasso Regression Imported successfully
2024-05-08 15:43:47,487:INFO:Starting cross validation
2024-05-08 15:43:47,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:47,529:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,532:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:47,541:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:51,406:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:53,101:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:53,106:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:53,565:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:53,779:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,171:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,237:INFO:Calculating mean and std
2024-05-08 15:43:54,237:INFO:Creating metrics dataframe
2024-05-08 15:43:54,239:INFO:Uploading results into container
2024-05-08 15:43:54,240:INFO:Uploading model into container now
2024-05-08 15:43:54,240:INFO:_master_model_container: 2
2024-05-08 15:43:54,240:INFO:_display_container: 2
2024-05-08 15:43:54,241:INFO:Lasso(random_state=123)
2024-05-08 15:43:54,241:INFO:create_model() successfully completed......................................
2024-05-08 15:43:54,327:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:54,327:INFO:Creating metrics dataframe
2024-05-08 15:43:54,332:INFO:Initializing Ridge Regression
2024-05-08 15:43:54,332:INFO:Total runtime is 0.18554043769836426 minutes
2024-05-08 15:43:54,334:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:54,334:INFO:Initializing create_model()
2024-05-08 15:43:54,334:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:54,334:INFO:Checking exceptions
2024-05-08 15:43:54,334:INFO:Importing libraries
2024-05-08 15:43:54,334:INFO:Copying training dataset
2024-05-08 15:43:54,337:INFO:Defining folds
2024-05-08 15:43:54,338:INFO:Declaring metric variables
2024-05-08 15:43:54,340:INFO:Importing untrained model
2024-05-08 15:43:54,343:INFO:Ridge Regression Imported successfully
2024-05-08 15:43:54,347:INFO:Starting cross validation
2024-05-08 15:43:54,348:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:54,365:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,369:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,374:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,378:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,382:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,384:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,390:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,395:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,404:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,476:INFO:Calculating mean and std
2024-05-08 15:43:54,476:INFO:Creating metrics dataframe
2024-05-08 15:43:54,478:INFO:Uploading results into container
2024-05-08 15:43:54,479:INFO:Uploading model into container now
2024-05-08 15:43:54,479:INFO:_master_model_container: 3
2024-05-08 15:43:54,479:INFO:_display_container: 2
2024-05-08 15:43:54,479:INFO:Ridge(random_state=123)
2024-05-08 15:43:54,480:INFO:create_model() successfully completed......................................
2024-05-08 15:43:54,572:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:54,572:INFO:Creating metrics dataframe
2024-05-08 15:43:54,578:INFO:Initializing Elastic Net
2024-05-08 15:43:54,579:INFO:Total runtime is 0.18965238332748413 minutes
2024-05-08 15:43:54,581:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:54,581:INFO:Initializing create_model()
2024-05-08 15:43:54,581:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:54,581:INFO:Checking exceptions
2024-05-08 15:43:54,581:INFO:Importing libraries
2024-05-08 15:43:54,581:INFO:Copying training dataset
2024-05-08 15:43:54,584:INFO:Defining folds
2024-05-08 15:43:54,584:INFO:Declaring metric variables
2024-05-08 15:43:54,588:INFO:Importing untrained model
2024-05-08 15:43:54,591:INFO:Elastic Net Imported successfully
2024-05-08 15:43:54,596:INFO:Starting cross validation
2024-05-08 15:43:54,597:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:54,615:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,618:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,622:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,624:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,628:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,630:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,632:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,635:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,641:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,731:INFO:Calculating mean and std
2024-05-08 15:43:54,732:INFO:Creating metrics dataframe
2024-05-08 15:43:54,735:INFO:Uploading results into container
2024-05-08 15:43:54,736:INFO:Uploading model into container now
2024-05-08 15:43:54,736:INFO:_master_model_container: 4
2024-05-08 15:43:54,736:INFO:_display_container: 2
2024-05-08 15:43:54,736:INFO:ElasticNet(random_state=123)
2024-05-08 15:43:54,736:INFO:create_model() successfully completed......................................
2024-05-08 15:43:54,863:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:54,863:INFO:Creating metrics dataframe
2024-05-08 15:43:54,870:INFO:Initializing Least Angle Regression
2024-05-08 15:43:54,870:INFO:Total runtime is 0.19451771179835 minutes
2024-05-08 15:43:54,873:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:54,873:INFO:Initializing create_model()
2024-05-08 15:43:54,873:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:54,873:INFO:Checking exceptions
2024-05-08 15:43:54,873:INFO:Importing libraries
2024-05-08 15:43:54,873:INFO:Copying training dataset
2024-05-08 15:43:54,878:INFO:Defining folds
2024-05-08 15:43:54,878:INFO:Declaring metric variables
2024-05-08 15:43:54,881:INFO:Importing untrained model
2024-05-08 15:43:54,884:INFO:Least Angle Regression Imported successfully
2024-05-08 15:43:54,889:INFO:Starting cross validation
2024-05-08 15:43:54,891:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:54,910:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,915:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,918:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,920:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,922:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,925:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,928:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,930:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,937:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:54,967:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=5.986e-01, with an active set of 43 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,969:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=2.844e-01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,970:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=2.206e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,970:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=4.271e+00, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,970:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=3.171e+00, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,970:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.330e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,970:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=3.293e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,971:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 87 iterations, i.e. alpha=1.656e+00, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,971:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 108 iterations, i.e. alpha=1.219e-01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,971:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 88 iterations, i.e. alpha=1.618e+00, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,971:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.066e+00, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,972:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=7.990e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,972:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=6.051e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,972:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 92 iterations, i.e. alpha=5.765e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,972:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=5.417e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,972:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=3.665e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,972:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=3.064e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,973:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=2.848e-01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,973:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.130e-02, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,973:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=1.591e-02, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,973:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=9.431e-03, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,973:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=3.060e+01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,974:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 118 iterations, i.e. alpha=1.241e+03, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,975:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 120 iterations, i.e. alpha=1.133e+03, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,976:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=1.502e+03, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,976:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=8.993e+02, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,977:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=8.799e-01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,978:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=1.137e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,979:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=6.411e-01, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,980:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 69 iterations, i.e. alpha=6.078e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,980:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=4.753e-01, with an active set of 57 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,980:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.980e-01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=2.877e-01, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.527e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=2.522e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,982:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=2.044e-01, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,982:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.705e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,982:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=1.378e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,982:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=5.494e-02, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,983:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=3.581e-02, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,983:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=6.202e-01, with an active set of 71 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,985:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=7.843e-01, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,985:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 67 iterations, i.e. alpha=7.599e-01, with an active set of 52 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,986:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.235e+00, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,987:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 84 iterations, i.e. alpha=1.028e+00, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,988:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 66 iterations, i.e. alpha=1.056e+00, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,988:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=8.124e-01, with an active set of 59 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,989:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.017e+00, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,990:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=6.529e-01, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,990:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.622e+00, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,990:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.441e+00, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,990:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=5.578e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,990:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=1.363e+00, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,990:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 74 iterations, i.e. alpha=3.911e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,991:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=6.580e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,992:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.211e+00, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,992:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=7.988e-01, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,993:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.287e-01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,993:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.110e-01, with an active set of 63 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,994:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=9.272e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,994:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=8.302e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,995:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=5.520e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,995:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.338e-01, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,996:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 96 iterations, i.e. alpha=1.417e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,998:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=1.091e-01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:54,999:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 107 iterations, i.e. alpha=3.283e+00, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 15:43:55,024:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/preprocessing/_data.py:3386: RuntimeWarning: overflow encountered in power
  x_inv[pos] = np.power(x[pos] * lmbda + 1, 1 / lmbda) - 1

2024-05-08 15:43:55,027:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2024-05-08 15:43:55,027:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2024-05-08 15:43:55,028:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2024-05-08 15:43:55,028:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2024-05-08 15:43:55,028:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2024-05-08 15:43:55,028:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains infinity or a value too large for dtype('float64').

  warnings.warn(

2024-05-08 15:43:55,040:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:55,040:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:55,041:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:55,041:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:55,041:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:55,041:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:55,043:INFO:Calculating mean and std
2024-05-08 15:43:55,044:INFO:Creating metrics dataframe
2024-05-08 15:43:55,047:INFO:Uploading results into container
2024-05-08 15:43:55,047:INFO:Uploading model into container now
2024-05-08 15:43:55,048:INFO:_master_model_container: 5
2024-05-08 15:43:55,048:INFO:_display_container: 2
2024-05-08 15:43:55,048:INFO:Lars(random_state=123)
2024-05-08 15:43:55,048:INFO:create_model() successfully completed......................................
2024-05-08 15:43:55,189:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:55,189:INFO:Creating metrics dataframe
2024-05-08 15:43:55,195:INFO:Initializing Lasso Least Angle Regression
2024-05-08 15:43:55,195:INFO:Total runtime is 0.1999265710512797 minutes
2024-05-08 15:43:55,198:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:55,198:INFO:Initializing create_model()
2024-05-08 15:43:55,198:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:55,198:INFO:Checking exceptions
2024-05-08 15:43:55,198:INFO:Importing libraries
2024-05-08 15:43:55,198:INFO:Copying training dataset
2024-05-08 15:43:55,201:INFO:Defining folds
2024-05-08 15:43:55,201:INFO:Declaring metric variables
2024-05-08 15:43:55,204:INFO:Importing untrained model
2024-05-08 15:43:55,207:INFO:Lasso Least Angle Regression Imported successfully
2024-05-08 15:43:55,212:INFO:Starting cross validation
2024-05-08 15:43:55,213:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:55,230:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,236:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,237:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,244:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,245:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,249:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,249:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,256:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,338:INFO:Calculating mean and std
2024-05-08 15:43:55,339:INFO:Creating metrics dataframe
2024-05-08 15:43:55,341:INFO:Uploading results into container
2024-05-08 15:43:55,342:INFO:Uploading model into container now
2024-05-08 15:43:55,342:INFO:_master_model_container: 6
2024-05-08 15:43:55,342:INFO:_display_container: 2
2024-05-08 15:43:55,342:INFO:LassoLars(random_state=123)
2024-05-08 15:43:55,342:INFO:create_model() successfully completed......................................
2024-05-08 15:43:55,442:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:55,442:INFO:Creating metrics dataframe
2024-05-08 15:43:55,447:INFO:Initializing Orthogonal Matching Pursuit
2024-05-08 15:43:55,447:INFO:Total runtime is 0.20412920713424682 minutes
2024-05-08 15:43:55,449:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:55,449:INFO:Initializing create_model()
2024-05-08 15:43:55,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:55,449:INFO:Checking exceptions
2024-05-08 15:43:55,449:INFO:Importing libraries
2024-05-08 15:43:55,450:INFO:Copying training dataset
2024-05-08 15:43:55,452:INFO:Defining folds
2024-05-08 15:43:55,452:INFO:Declaring metric variables
2024-05-08 15:43:55,455:INFO:Importing untrained model
2024-05-08 15:43:55,458:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-08 15:43:55,463:INFO:Starting cross validation
2024-05-08 15:43:55,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:55,478:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,483:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,485:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,487:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,490:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,492:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,494:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,498:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,504:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,592:INFO:Calculating mean and std
2024-05-08 15:43:55,593:INFO:Creating metrics dataframe
2024-05-08 15:43:55,596:INFO:Uploading results into container
2024-05-08 15:43:55,596:INFO:Uploading model into container now
2024-05-08 15:43:55,596:INFO:_master_model_container: 7
2024-05-08 15:43:55,596:INFO:_display_container: 2
2024-05-08 15:43:55,596:INFO:OrthogonalMatchingPursuit()
2024-05-08 15:43:55,596:INFO:create_model() successfully completed......................................
2024-05-08 15:43:55,713:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:55,713:INFO:Creating metrics dataframe
2024-05-08 15:43:55,724:INFO:Initializing Bayesian Ridge
2024-05-08 15:43:55,724:INFO:Total runtime is 0.20874767303466796 minutes
2024-05-08 15:43:55,729:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:55,729:INFO:Initializing create_model()
2024-05-08 15:43:55,729:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:55,729:INFO:Checking exceptions
2024-05-08 15:43:55,729:INFO:Importing libraries
2024-05-08 15:43:55,729:INFO:Copying training dataset
2024-05-08 15:43:55,734:INFO:Defining folds
2024-05-08 15:43:55,734:INFO:Declaring metric variables
2024-05-08 15:43:55,738:INFO:Importing untrained model
2024-05-08 15:43:55,743:INFO:Bayesian Ridge Imported successfully
2024-05-08 15:43:55,750:INFO:Starting cross validation
2024-05-08 15:43:55,752:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:55,771:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,773:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,778:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,780:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,786:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,791:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,795:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,799:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,806:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:55,900:INFO:Calculating mean and std
2024-05-08 15:43:55,901:INFO:Creating metrics dataframe
2024-05-08 15:43:55,904:INFO:Uploading results into container
2024-05-08 15:43:55,904:INFO:Uploading model into container now
2024-05-08 15:43:55,905:INFO:_master_model_container: 8
2024-05-08 15:43:55,905:INFO:_display_container: 2
2024-05-08 15:43:55,905:INFO:BayesianRidge()
2024-05-08 15:43:55,905:INFO:create_model() successfully completed......................................
2024-05-08 15:43:55,999:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:55,999:INFO:Creating metrics dataframe
2024-05-08 15:43:56,006:INFO:Initializing Passive Aggressive Regressor
2024-05-08 15:43:56,006:INFO:Total runtime is 0.21343697309494017 minutes
2024-05-08 15:43:56,008:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:56,008:INFO:Initializing create_model()
2024-05-08 15:43:56,008:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:56,008:INFO:Checking exceptions
2024-05-08 15:43:56,008:INFO:Importing libraries
2024-05-08 15:43:56,008:INFO:Copying training dataset
2024-05-08 15:43:56,011:INFO:Defining folds
2024-05-08 15:43:56,011:INFO:Declaring metric variables
2024-05-08 15:43:56,014:INFO:Importing untrained model
2024-05-08 15:43:56,016:INFO:Passive Aggressive Regressor Imported successfully
2024-05-08 15:43:56,021:INFO:Starting cross validation
2024-05-08 15:43:56,022:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:56,041:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,043:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,046:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,048:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,049:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,054:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,057:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,059:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,064:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,128:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:56,128:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:56,129:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:56,129:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:56,129:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:56,129:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 15:43:56,150:INFO:Calculating mean and std
2024-05-08 15:43:56,151:INFO:Creating metrics dataframe
2024-05-08 15:43:56,154:INFO:Uploading results into container
2024-05-08 15:43:56,155:INFO:Uploading model into container now
2024-05-08 15:43:56,155:INFO:_master_model_container: 9
2024-05-08 15:43:56,155:INFO:_display_container: 2
2024-05-08 15:43:56,155:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-08 15:43:56,155:INFO:create_model() successfully completed......................................
2024-05-08 15:43:56,268:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:56,268:INFO:Creating metrics dataframe
2024-05-08 15:43:56,281:INFO:Initializing Huber Regressor
2024-05-08 15:43:56,281:INFO:Total runtime is 0.21802769104639688 minutes
2024-05-08 15:43:56,286:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:56,287:INFO:Initializing create_model()
2024-05-08 15:43:56,287:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:56,287:INFO:Checking exceptions
2024-05-08 15:43:56,287:INFO:Importing libraries
2024-05-08 15:43:56,287:INFO:Copying training dataset
2024-05-08 15:43:56,291:INFO:Defining folds
2024-05-08 15:43:56,291:INFO:Declaring metric variables
2024-05-08 15:43:56,295:INFO:Importing untrained model
2024-05-08 15:43:56,298:INFO:Huber Regressor Imported successfully
2024-05-08 15:43:56,306:INFO:Starting cross validation
2024-05-08 15:43:56,307:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:56,327:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,328:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,333:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,335:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,336:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,341:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,343:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,346:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,353:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,390:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,405:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,408:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,415:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,437:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,439:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,444:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,448:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,452:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,453:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 15:43:56,489:INFO:Calculating mean and std
2024-05-08 15:43:56,490:INFO:Creating metrics dataframe
2024-05-08 15:43:56,493:INFO:Uploading results into container
2024-05-08 15:43:56,493:INFO:Uploading model into container now
2024-05-08 15:43:56,494:INFO:_master_model_container: 10
2024-05-08 15:43:56,494:INFO:_display_container: 2
2024-05-08 15:43:56,494:INFO:HuberRegressor()
2024-05-08 15:43:56,495:INFO:create_model() successfully completed......................................
2024-05-08 15:43:56,593:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:56,593:INFO:Creating metrics dataframe
2024-05-08 15:43:56,598:INFO:Initializing K Neighbors Regressor
2024-05-08 15:43:56,598:INFO:Total runtime is 0.22331550121307372 minutes
2024-05-08 15:43:56,600:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:56,600:INFO:Initializing create_model()
2024-05-08 15:43:56,600:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:56,600:INFO:Checking exceptions
2024-05-08 15:43:56,600:INFO:Importing libraries
2024-05-08 15:43:56,601:INFO:Copying training dataset
2024-05-08 15:43:56,603:INFO:Defining folds
2024-05-08 15:43:56,603:INFO:Declaring metric variables
2024-05-08 15:43:56,606:INFO:Importing untrained model
2024-05-08 15:43:56,610:INFO:K Neighbors Regressor Imported successfully
2024-05-08 15:43:56,617:INFO:Starting cross validation
2024-05-08 15:43:56,618:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:56,636:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,639:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,642:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,642:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,649:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,654:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,655:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,663:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,793:INFO:Calculating mean and std
2024-05-08 15:43:56,794:INFO:Creating metrics dataframe
2024-05-08 15:43:56,798:INFO:Uploading results into container
2024-05-08 15:43:56,798:INFO:Uploading model into container now
2024-05-08 15:43:56,799:INFO:_master_model_container: 11
2024-05-08 15:43:56,799:INFO:_display_container: 2
2024-05-08 15:43:56,799:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-08 15:43:56,799:INFO:create_model() successfully completed......................................
2024-05-08 15:43:56,896:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:56,897:INFO:Creating metrics dataframe
2024-05-08 15:43:56,905:INFO:Initializing Decision Tree Regressor
2024-05-08 15:43:56,905:INFO:Total runtime is 0.22842600742975872 minutes
2024-05-08 15:43:56,907:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:56,908:INFO:Initializing create_model()
2024-05-08 15:43:56,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:56,908:INFO:Checking exceptions
2024-05-08 15:43:56,908:INFO:Importing libraries
2024-05-08 15:43:56,908:INFO:Copying training dataset
2024-05-08 15:43:56,910:INFO:Defining folds
2024-05-08 15:43:56,910:INFO:Declaring metric variables
2024-05-08 15:43:56,913:INFO:Importing untrained model
2024-05-08 15:43:56,917:INFO:Decision Tree Regressor Imported successfully
2024-05-08 15:43:56,924:INFO:Starting cross validation
2024-05-08 15:43:56,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:56,948:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,954:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,959:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,963:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,964:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,966:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:56,973:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,076:INFO:Calculating mean and std
2024-05-08 15:43:57,077:INFO:Creating metrics dataframe
2024-05-08 15:43:57,079:INFO:Uploading results into container
2024-05-08 15:43:57,079:INFO:Uploading model into container now
2024-05-08 15:43:57,080:INFO:_master_model_container: 12
2024-05-08 15:43:57,080:INFO:_display_container: 2
2024-05-08 15:43:57,081:INFO:DecisionTreeRegressor(random_state=123)
2024-05-08 15:43:57,081:INFO:create_model() successfully completed......................................
2024-05-08 15:43:57,202:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:57,203:INFO:Creating metrics dataframe
2024-05-08 15:43:57,212:INFO:Initializing Random Forest Regressor
2024-05-08 15:43:57,212:INFO:Total runtime is 0.23354771137237548 minutes
2024-05-08 15:43:57,216:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:57,216:INFO:Initializing create_model()
2024-05-08 15:43:57,216:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:57,216:INFO:Checking exceptions
2024-05-08 15:43:57,216:INFO:Importing libraries
2024-05-08 15:43:57,216:INFO:Copying training dataset
2024-05-08 15:43:57,220:INFO:Defining folds
2024-05-08 15:43:57,220:INFO:Declaring metric variables
2024-05-08 15:43:57,224:INFO:Importing untrained model
2024-05-08 15:43:57,227:INFO:Random Forest Regressor Imported successfully
2024-05-08 15:43:57,233:INFO:Starting cross validation
2024-05-08 15:43:57,234:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:57,256:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,259:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,262:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,263:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,268:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,268:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,270:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,274:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:57,280:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,600:INFO:Calculating mean and std
2024-05-08 15:43:58,601:INFO:Creating metrics dataframe
2024-05-08 15:43:58,603:INFO:Uploading results into container
2024-05-08 15:43:58,603:INFO:Uploading model into container now
2024-05-08 15:43:58,604:INFO:_master_model_container: 13
2024-05-08 15:43:58,604:INFO:_display_container: 2
2024-05-08 15:43:58,604:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 15:43:58,604:INFO:create_model() successfully completed......................................
2024-05-08 15:43:58,682:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:58,682:INFO:Creating metrics dataframe
2024-05-08 15:43:58,689:INFO:Initializing Extra Trees Regressor
2024-05-08 15:43:58,689:INFO:Total runtime is 0.258159331480662 minutes
2024-05-08 15:43:58,691:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:58,691:INFO:Initializing create_model()
2024-05-08 15:43:58,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:58,691:INFO:Checking exceptions
2024-05-08 15:43:58,691:INFO:Importing libraries
2024-05-08 15:43:58,691:INFO:Copying training dataset
2024-05-08 15:43:58,694:INFO:Defining folds
2024-05-08 15:43:58,694:INFO:Declaring metric variables
2024-05-08 15:43:58,698:INFO:Importing untrained model
2024-05-08 15:43:58,704:INFO:Extra Trees Regressor Imported successfully
2024-05-08 15:43:58,713:INFO:Starting cross validation
2024-05-08 15:43:58,715:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:58,734:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,736:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,737:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,741:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,744:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,747:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,750:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,750:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:58,757:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,365:INFO:Calculating mean and std
2024-05-08 15:43:59,366:INFO:Creating metrics dataframe
2024-05-08 15:43:59,368:INFO:Uploading results into container
2024-05-08 15:43:59,369:INFO:Uploading model into container now
2024-05-08 15:43:59,369:INFO:_master_model_container: 14
2024-05-08 15:43:59,369:INFO:_display_container: 2
2024-05-08 15:43:59,369:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 15:43:59,369:INFO:create_model() successfully completed......................................
2024-05-08 15:43:59,448:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:59,448:INFO:Creating metrics dataframe
2024-05-08 15:43:59,455:INFO:Initializing AdaBoost Regressor
2024-05-08 15:43:59,455:INFO:Total runtime is 0.270926026503245 minutes
2024-05-08 15:43:59,457:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:59,457:INFO:Initializing create_model()
2024-05-08 15:43:59,457:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:59,457:INFO:Checking exceptions
2024-05-08 15:43:59,457:INFO:Importing libraries
2024-05-08 15:43:59,457:INFO:Copying training dataset
2024-05-08 15:43:59,459:INFO:Defining folds
2024-05-08 15:43:59,459:INFO:Declaring metric variables
2024-05-08 15:43:59,461:INFO:Importing untrained model
2024-05-08 15:43:59,463:INFO:AdaBoost Regressor Imported successfully
2024-05-08 15:43:59,468:INFO:Starting cross validation
2024-05-08 15:43:59,469:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:43:59,487:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,488:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,491:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,496:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,500:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,502:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,505:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,513:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,522:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:43:59,895:INFO:Calculating mean and std
2024-05-08 15:43:59,896:INFO:Creating metrics dataframe
2024-05-08 15:43:59,898:INFO:Uploading results into container
2024-05-08 15:43:59,898:INFO:Uploading model into container now
2024-05-08 15:43:59,898:INFO:_master_model_container: 15
2024-05-08 15:43:59,898:INFO:_display_container: 2
2024-05-08 15:43:59,898:INFO:AdaBoostRegressor(random_state=123)
2024-05-08 15:43:59,898:INFO:create_model() successfully completed......................................
2024-05-08 15:43:59,977:INFO:SubProcess create_model() end ==================================
2024-05-08 15:43:59,977:INFO:Creating metrics dataframe
2024-05-08 15:43:59,985:INFO:Initializing Gradient Boosting Regressor
2024-05-08 15:43:59,985:INFO:Total runtime is 0.2797548135121663 minutes
2024-05-08 15:43:59,986:INFO:SubProcess create_model() called ==================================
2024-05-08 15:43:59,986:INFO:Initializing create_model()
2024-05-08 15:43:59,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:43:59,987:INFO:Checking exceptions
2024-05-08 15:43:59,987:INFO:Importing libraries
2024-05-08 15:43:59,987:INFO:Copying training dataset
2024-05-08 15:43:59,988:INFO:Defining folds
2024-05-08 15:43:59,989:INFO:Declaring metric variables
2024-05-08 15:43:59,991:INFO:Importing untrained model
2024-05-08 15:43:59,994:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 15:44:00,001:INFO:Starting cross validation
2024-05-08 15:44:00,003:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:44:00,020:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:00,024:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:00,026:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:00,028:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:00,031:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:00,034:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:00,038:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:00,040:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:00,049:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,020:INFO:Calculating mean and std
2024-05-08 15:44:01,020:INFO:Creating metrics dataframe
2024-05-08 15:44:01,022:INFO:Uploading results into container
2024-05-08 15:44:01,022:INFO:Uploading model into container now
2024-05-08 15:44:01,022:INFO:_master_model_container: 16
2024-05-08 15:44:01,023:INFO:_display_container: 2
2024-05-08 15:44:01,023:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 15:44:01,023:INFO:create_model() successfully completed......................................
2024-05-08 15:44:01,100:INFO:SubProcess create_model() end ==================================
2024-05-08 15:44:01,100:INFO:Creating metrics dataframe
2024-05-08 15:44:01,107:INFO:Initializing Light Gradient Boosting Machine
2024-05-08 15:44:01,107:INFO:Total runtime is 0.2984615604082743 minutes
2024-05-08 15:44:01,109:INFO:SubProcess create_model() called ==================================
2024-05-08 15:44:01,109:INFO:Initializing create_model()
2024-05-08 15:44:01,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:44:01,109:INFO:Checking exceptions
2024-05-08 15:44:01,109:INFO:Importing libraries
2024-05-08 15:44:01,110:INFO:Copying training dataset
2024-05-08 15:44:01,112:INFO:Defining folds
2024-05-08 15:44:01,112:INFO:Declaring metric variables
2024-05-08 15:44:01,114:INFO:Importing untrained model
2024-05-08 15:44:01,117:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-08 15:44:01,122:INFO:Starting cross validation
2024-05-08 15:44:01,123:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:44:01,143:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,145:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,148:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,154:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,162:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,167:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,171:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:01,181:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,059:INFO:Calculating mean and std
2024-05-08 15:44:02,060:INFO:Creating metrics dataframe
2024-05-08 15:44:02,062:INFO:Uploading results into container
2024-05-08 15:44:02,063:INFO:Uploading model into container now
2024-05-08 15:44:02,063:INFO:_master_model_container: 17
2024-05-08 15:44:02,063:INFO:_display_container: 2
2024-05-08 15:44:02,064:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-08 15:44:02,064:INFO:create_model() successfully completed......................................
2024-05-08 15:44:02,141:INFO:SubProcess create_model() end ==================================
2024-05-08 15:44:02,142:INFO:Creating metrics dataframe
2024-05-08 15:44:02,148:INFO:Initializing Dummy Regressor
2024-05-08 15:44:02,149:INFO:Total runtime is 0.3158196449279785 minutes
2024-05-08 15:44:02,151:INFO:SubProcess create_model() called ==================================
2024-05-08 15:44:02,152:INFO:Initializing create_model()
2024-05-08 15:44:02,152:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bc0467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:44:02,152:INFO:Checking exceptions
2024-05-08 15:44:02,152:INFO:Importing libraries
2024-05-08 15:44:02,152:INFO:Copying training dataset
2024-05-08 15:44:02,154:INFO:Defining folds
2024-05-08 15:44:02,154:INFO:Declaring metric variables
2024-05-08 15:44:02,157:INFO:Importing untrained model
2024-05-08 15:44:02,160:INFO:Dummy Regressor Imported successfully
2024-05-08 15:44:02,169:INFO:Starting cross validation
2024-05-08 15:44:02,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:44:02,190:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,191:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,194:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,194:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,197:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,202:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,204:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,205:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,210:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,281:INFO:Calculating mean and std
2024-05-08 15:44:02,281:INFO:Creating metrics dataframe
2024-05-08 15:44:02,283:INFO:Uploading results into container
2024-05-08 15:44:02,283:INFO:Uploading model into container now
2024-05-08 15:44:02,284:INFO:_master_model_container: 18
2024-05-08 15:44:02,284:INFO:_display_container: 2
2024-05-08 15:44:02,284:INFO:DummyRegressor()
2024-05-08 15:44:02,284:INFO:create_model() successfully completed......................................
2024-05-08 15:44:02,369:INFO:SubProcess create_model() end ==================================
2024-05-08 15:44:02,369:INFO:Creating metrics dataframe
2024-05-08 15:44:02,380:INFO:Initializing create_model()
2024-05-08 15:44:02,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:44:02,381:INFO:Checking exceptions
2024-05-08 15:44:02,382:INFO:Importing libraries
2024-05-08 15:44:02,382:INFO:Copying training dataset
2024-05-08 15:44:02,384:INFO:Defining folds
2024-05-08 15:44:02,384:INFO:Declaring metric variables
2024-05-08 15:44:02,384:INFO:Importing untrained model
2024-05-08 15:44:02,384:INFO:Declaring custom model
2024-05-08 15:44:02,385:INFO:Extra Trees Regressor Imported successfully
2024-05-08 15:44:02,386:INFO:Cross validation set to False
2024-05-08 15:44:02,386:INFO:Fitting Model
2024-05-08 15:44:02,389:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,506:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 15:44:02,506:INFO:create_model() successfully completed......................................
2024-05-08 15:44:02,626:INFO:_master_model_container: 18
2024-05-08 15:44:02,626:INFO:_display_container: 2
2024-05-08 15:44:02,627:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 15:44:02,627:INFO:compare_models() successfully completed......................................
2024-05-08 15:44:02,627:INFO:Initializing tune_model()
2024-05-08 15:44:02,627:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>)
2024-05-08 15:44:02,627:INFO:Checking exceptions
2024-05-08 15:44:02,646:INFO:Copying training dataset
2024-05-08 15:44:02,650:INFO:Checking base model
2024-05-08 15:44:02,650:INFO:Base model : Extra Trees Regressor
2024-05-08 15:44:02,653:INFO:Declaring metric variables
2024-05-08 15:44:02,655:INFO:Defining Hyperparameters
2024-05-08 15:44:02,764:INFO:Tuning with n_jobs=-1
2024-05-08 15:44:02,765:INFO:Initializing RandomizedSearchCV
2024-05-08 15:44:02,802:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,805:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,805:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,808:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,810:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,812:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,815:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,817:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,821:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,826:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,827:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,829:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,858:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,873:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:02,874:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,127:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,173:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,224:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,230:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,235:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,245:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,247:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,257:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,264:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,279:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,290:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,566:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,634:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,647:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,659:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,725:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,738:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,952:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,975:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,985:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:03,986:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,012:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,020:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,029:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,034:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,036:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,047:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,067:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,068:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,074:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,076:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,233:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,363:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,436:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,442:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,454:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,465:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,467:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,491:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,538:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,544:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,545:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,554:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,601:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,771:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,773:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,816:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,824:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,882:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,891:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,891:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,898:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,901:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,904:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,908:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,910:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,914:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:04,928:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,001:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,200:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,238:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,292:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,305:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,310:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,317:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,320:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,329:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,331:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,374:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,385:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,630:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-08 15:44:05,630:INFO:Hyperparameter search completed
2024-05-08 15:44:05,631:INFO:SubProcess create_model() called ==================================
2024-05-08 15:44:05,631:INFO:Initializing create_model()
2024-05-08 15:44:05,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bee90550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-08 15:44:05,631:INFO:Checking exceptions
2024-05-08 15:44:05,631:INFO:Importing libraries
2024-05-08 15:44:05,631:INFO:Copying training dataset
2024-05-08 15:44:05,634:INFO:Defining folds
2024-05-08 15:44:05,634:INFO:Declaring metric variables
2024-05-08 15:44:05,636:INFO:Importing untrained model
2024-05-08 15:44:05,636:INFO:Declaring custom model
2024-05-08 15:44:05,638:INFO:Extra Trees Regressor Imported successfully
2024-05-08 15:44:05,642:INFO:Starting cross validation
2024-05-08 15:44:05,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:44:05,656:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,657:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,658:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,662:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,664:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,666:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,668:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,668:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:05,676:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,038:INFO:Calculating mean and std
2024-05-08 15:44:06,039:INFO:Creating metrics dataframe
2024-05-08 15:44:06,043:INFO:Finalizing model
2024-05-08 15:44:06,046:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,211:INFO:Uploading results into container
2024-05-08 15:44:06,213:INFO:Uploading model into container now
2024-05-08 15:44:06,213:INFO:_master_model_container: 19
2024-05-08 15:44:06,213:INFO:_display_container: 3
2024-05-08 15:44:06,214:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-08 15:44:06,214:INFO:create_model() successfully completed......................................
2024-05-08 15:44:06,308:INFO:SubProcess create_model() end ==================================
2024-05-08 15:44:06,308:INFO:choose_better activated
2024-05-08 15:44:06,310:INFO:SubProcess create_model() called ==================================
2024-05-08 15:44:06,310:INFO:Initializing create_model()
2024-05-08 15:44:06,310:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:44:06,310:INFO:Checking exceptions
2024-05-08 15:44:06,312:INFO:Importing libraries
2024-05-08 15:44:06,312:INFO:Copying training dataset
2024-05-08 15:44:06,313:INFO:Defining folds
2024-05-08 15:44:06,314:INFO:Declaring metric variables
2024-05-08 15:44:06,314:INFO:Importing untrained model
2024-05-08 15:44:06,314:INFO:Declaring custom model
2024-05-08 15:44:06,314:INFO:Extra Trees Regressor Imported successfully
2024-05-08 15:44:06,314:INFO:Starting cross validation
2024-05-08 15:44:06,315:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 15:44:06,329:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,329:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,331:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,334:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,335:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,337:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,341:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,345:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,356:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:06,948:INFO:Calculating mean and std
2024-05-08 15:44:06,948:INFO:Creating metrics dataframe
2024-05-08 15:44:06,950:INFO:Finalizing model
2024-05-08 15:44:06,953:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:07,044:INFO:Uploading results into container
2024-05-08 15:44:07,045:INFO:Uploading model into container now
2024-05-08 15:44:07,045:INFO:_master_model_container: 20
2024-05-08 15:44:07,045:INFO:_display_container: 4
2024-05-08 15:44:07,046:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 15:44:07,046:INFO:create_model() successfully completed......................................
2024-05-08 15:44:07,126:INFO:SubProcess create_model() end ==================================
2024-05-08 15:44:07,126:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7669
2024-05-08 15:44:07,127:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.7032
2024-05-08 15:44:07,127:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-08 15:44:07,127:INFO:choose_better completed
2024-05-08 15:44:07,127:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-08 15:44:07,133:INFO:_master_model_container: 20
2024-05-08 15:44:07,133:INFO:_display_container: 3
2024-05-08 15:44:07,134:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 15:44:07,134:INFO:tune_model() successfully completed......................................
2024-05-08 15:44:07,257:INFO:Initializing finalize_model()
2024-05-08 15:44:07,257:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-08 15:44:07,258:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 15:44:07,260:INFO:Initializing create_model()
2024-05-08 15:44:07,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 15:44:07,260:INFO:Checking exceptions
2024-05-08 15:44:07,262:INFO:Importing libraries
2024-05-08 15:44:07,262:INFO:Copying training dataset
2024-05-08 15:44:07,262:INFO:Defining folds
2024-05-08 15:44:07,262:INFO:Declaring metric variables
2024-05-08 15:44:07,262:INFO:Importing untrained model
2024-05-08 15:44:07,262:INFO:Declaring custom model
2024-05-08 15:44:07,263:INFO:Extra Trees Regressor Imported successfully
2024-05-08 15:44:07,264:INFO:Cross validation set to False
2024-05-08 15:44:07,264:INFO:Fitting Model
2024-05-08 15:44:07,267:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 15:44:07,392:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['cumulative',
                                             'averag...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2024-05-08 15:44:07,392:INFO:create_model() successfully completed......................................
2024-05-08 15:44:07,473:INFO:_master_model_container: 20
2024-05-08 15:44:07,473:INFO:_display_container: 3
2024-05-08 15:44:07,479:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['cumulative',
                                             'averag...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2024-05-08 15:44:07,479:INFO:finalize_model() successfully completed......................................
2024-05-08 15:44:07,567:INFO:Initializing predict_model()
2024-05-08 15:44:07,567:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc2c8250>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['cumulative',
                                             'averag...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x74c8bc336f70>)
2024-05-08 15:44:07,567:INFO:Checking exceptions
2024-05-08 15:44:07,567:INFO:Preloading libraries
2024-05-08 15:44:07,569:INFO:Set up data.
2024-05-08 15:44:07,572:INFO:Set up index.
2024-05-08 15:44:07,610:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-08 16:02:57,514:WARNING:/tmp/ipykernel_19548/49387130.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-08 16:04:05,658:WARNING:/tmp/ipykernel_19548/1315434538.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-08 16:04:23,801:INFO:PyCaret RegressionExperiment
2024-05-08 16:04:23,801:INFO:Logging name: reg-default-name
2024-05-08 16:04:23,801:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-08 16:04:23,801:INFO:version 3.3.2
2024-05-08 16:04:23,801:INFO:Initializing setup()
2024-05-08 16:04:23,801:INFO:self.USI: eb09
2024-05-08 16:04:23,801:INFO:self._variable_keys: {'y_train', 'X_test', 'seed', 'exp_name_log', 'X', 'y_test', '_ml_usecase', 'log_plots_param', 'idx', '_available_plots', 'html_param', 'exp_id', 'pipeline', 'n_jobs_param', 'data', 'fold_generator', 'transform_target_param', 'X_train', 'fold_groups_param', 'logging_param', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'fold_shuffle_param', 'target_param', 'memory', 'y'}
2024-05-08 16:04:23,801:INFO:Checking environment
2024-05-08 16:04:23,801:INFO:python_version: 3.9.18
2024-05-08 16:04:23,801:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-08 16:04:23,801:INFO:machine: x86_64
2024-05-08 16:04:23,802:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:04:23,802:INFO:Memory: svmem(total=16429801472, available=6569549824, percent=60.0, used=8496783360, free=2855079936, active=6787817472, inactive=5503410176, buffers=125853696, cached=4952084480, shared=878469120, slab=659935232)
2024-05-08 16:04:23,802:INFO:Physical Core: 12
2024-05-08 16:04:23,803:INFO:Logical Core: 16
2024-05-08 16:04:23,803:INFO:Checking libraries
2024-05-08 16:04:23,803:INFO:System:
2024-05-08 16:04:23,803:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-08 16:04:23,803:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-08 16:04:23,803:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:04:23,803:INFO:PyCaret required dependencies:
2024-05-08 16:04:23,803:INFO:                 pip: 23.2.1
2024-05-08 16:04:23,803:INFO:          setuptools: 68.0.0
2024-05-08 16:04:23,803:INFO:             pycaret: 3.3.2
2024-05-08 16:04:23,803:INFO:             IPython: 8.15.0
2024-05-08 16:04:23,803:INFO:          ipywidgets: 8.0.4
2024-05-08 16:04:23,803:INFO:                tqdm: 4.65.0
2024-05-08 16:04:23,803:INFO:               numpy: 1.24.3
2024-05-08 16:04:23,803:INFO:              pandas: 1.4.2
2024-05-08 16:04:23,803:INFO:              jinja2: 3.1.4
2024-05-08 16:04:23,803:INFO:               scipy: 1.11.3
2024-05-08 16:04:23,803:INFO:              joblib: 1.2.0
2024-05-08 16:04:23,803:INFO:             sklearn: 1.4.2
2024-05-08 16:04:23,803:INFO:                pyod: 1.1.3
2024-05-08 16:04:23,803:INFO:            imblearn: 0.12.2
2024-05-08 16:04:23,803:INFO:   category_encoders: 2.6.3
2024-05-08 16:04:23,803:INFO:            lightgbm: 4.3.0
2024-05-08 16:04:23,803:INFO:               numba: 0.58.0
2024-05-08 16:04:23,803:INFO:            requests: 2.31.0
2024-05-08 16:04:23,803:INFO:          matplotlib: 3.7.2
2024-05-08 16:04:23,803:INFO:          scikitplot: 0.3.7
2024-05-08 16:04:23,803:INFO:         yellowbrick: 1.5
2024-05-08 16:04:23,803:INFO:              plotly: 5.22.0
2024-05-08 16:04:23,803:INFO:    plotly-resampler: Not installed
2024-05-08 16:04:23,804:INFO:             kaleido: 0.2.1
2024-05-08 16:04:23,804:INFO:           schemdraw: 0.15
2024-05-08 16:04:23,804:INFO:         statsmodels: 0.14.0
2024-05-08 16:04:23,804:INFO:              sktime: 0.26.0
2024-05-08 16:04:23,804:INFO:               tbats: 1.1.3
2024-05-08 16:04:23,804:INFO:            pmdarima: 2.0.4
2024-05-08 16:04:23,804:INFO:              psutil: 5.9.0
2024-05-08 16:04:23,804:INFO:          markupsafe: 2.0.1
2024-05-08 16:04:23,804:INFO:             pickle5: Not installed
2024-05-08 16:04:23,804:INFO:         cloudpickle: 2.2.1
2024-05-08 16:04:23,804:INFO:         deprecation: 2.1.0
2024-05-08 16:04:23,804:INFO:              xxhash: 2.0.2
2024-05-08 16:04:23,804:INFO:           wurlitzer: 3.0.2
2024-05-08 16:04:23,804:INFO:PyCaret optional dependencies:
2024-05-08 16:04:23,804:INFO:                shap: Not installed
2024-05-08 16:04:23,804:INFO:           interpret: Not installed
2024-05-08 16:04:23,804:INFO:                umap: Not installed
2024-05-08 16:04:23,804:INFO:     ydata_profiling: Not installed
2024-05-08 16:04:23,804:INFO:  explainerdashboard: Not installed
2024-05-08 16:04:23,804:INFO:             autoviz: Not installed
2024-05-08 16:04:23,804:INFO:           fairlearn: Not installed
2024-05-08 16:04:23,804:INFO:          deepchecks: Not installed
2024-05-08 16:04:23,804:INFO:             xgboost: Not installed
2024-05-08 16:04:23,804:INFO:            catboost: Not installed
2024-05-08 16:04:23,804:INFO:              kmodes: Not installed
2024-05-08 16:04:23,804:INFO:             mlxtend: Not installed
2024-05-08 16:04:23,804:INFO:       statsforecast: Not installed
2024-05-08 16:04:23,804:INFO:        tune_sklearn: Not installed
2024-05-08 16:04:23,804:INFO:                 ray: Not installed
2024-05-08 16:04:23,804:INFO:            hyperopt: Not installed
2024-05-08 16:04:23,804:INFO:              optuna: Not installed
2024-05-08 16:04:23,804:INFO:               skopt: Not installed
2024-05-08 16:04:23,804:INFO:              mlflow: Not installed
2024-05-08 16:04:23,805:INFO:              gradio: Not installed
2024-05-08 16:04:23,805:INFO:             fastapi: Not installed
2024-05-08 16:04:23,805:INFO:             uvicorn: Not installed
2024-05-08 16:04:23,805:INFO:              m2cgen: Not installed
2024-05-08 16:04:23,805:INFO:           evidently: Not installed
2024-05-08 16:04:23,805:INFO:               fugue: Not installed
2024-05-08 16:04:23,805:INFO:           streamlit: Not installed
2024-05-08 16:04:23,805:INFO:             prophet: Not installed
2024-05-08 16:04:23,805:INFO:None
2024-05-08 16:04:23,805:INFO:Set up data.
2024-05-08 16:04:23,811:INFO:Set up folding strategy.
2024-05-08 16:04:23,811:INFO:Set up train/test split.
2024-05-08 16:04:23,815:INFO:Set up index.
2024-05-08 16:04:23,815:INFO:Assigning column types.
2024-05-08 16:04:23,818:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-08 16:04:23,818:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:04:23,824:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:04:23,831:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:04:23,925:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:23,963:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:04:23,963:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:23,963:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:23,963:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:04:23,966:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:04:23,968:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:04:23,994:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,015:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,015:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-08 16:04:24,018:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,020:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,047:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,069:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,069:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,069:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,072:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,074:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,103:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,125:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,125:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,125:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,125:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-08 16:04:24,130:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,159:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,181:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,181:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,186:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,212:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,233:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,234:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-08 16:04:24,265:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,287:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,318:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,339:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,339:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-08 16:04:24,370:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,391:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:04:24,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,444:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-08 16:04:24,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,550:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,550:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,551:INFO:Preparing preprocessing pipeline...
2024-05-08 16:04:24,551:INFO:Set up target transformation.
2024-05-08 16:04:24,551:INFO:Set up date feature engineering.
2024-05-08 16:04:24,551:INFO:Set up simple imputation.
2024-05-08 16:04:24,551:INFO:Set up polynomial features.
2024-05-08 16:04:24,551:INFO:Set up feature normalization.
2024-05-08 16:04:24,551:INFO:Set up column name cleaning.
2024-05-08 16:04:24,555:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:24,580:INFO:Finished creating preprocessing pipeline.
2024-05-08 16:04:24,585:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['cumulati...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-08 16:04:24,585:INFO:Creating final display dataframe.
2024-05-08 16:04:24,668:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape         (552, 10)
4        Transformed data shape         (552, 78)
5   Transformed train set shape         (386, 78)
6    Transformed test set shape         (166, 78)
7              Numeric features                 8
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13          Polynomial features              True
14            Polynomial degree                 2
15                    Normalize              True
16             Normalize method            zscore
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              eb09
2024-05-08 16:04:24,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,728:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,781:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,781:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:04:24,781:INFO:setup() successfully completed in 0.98s...............
2024-05-08 16:04:24,782:INFO:Initializing compare_models()
2024-05-08 16:04:24,782:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-08 16:04:24,782:INFO:Checking exceptions
2024-05-08 16:04:24,783:INFO:Preparing display monitor
2024-05-08 16:04:24,796:INFO:Initializing Linear Regression
2024-05-08 16:04:24,796:INFO:Total runtime is 4.327297210693359e-06 minutes
2024-05-08 16:04:24,799:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:24,799:INFO:Initializing create_model()
2024-05-08 16:04:24,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:24,799:INFO:Checking exceptions
2024-05-08 16:04:24,799:INFO:Importing libraries
2024-05-08 16:04:24,799:INFO:Copying training dataset
2024-05-08 16:04:24,801:INFO:Defining folds
2024-05-08 16:04:24,801:INFO:Declaring metric variables
2024-05-08 16:04:24,803:INFO:Importing untrained model
2024-05-08 16:04:24,805:INFO:Linear Regression Imported successfully
2024-05-08 16:04:24,809:INFO:Starting cross validation
2024-05-08 16:04:24,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:26,774:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:26,779:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:26,805:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:26,805:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:26,843:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:27,125:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:27,125:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:27,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:27,161:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:27,237:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:27,330:INFO:Calculating mean and std
2024-05-08 16:04:27,331:INFO:Creating metrics dataframe
2024-05-08 16:04:27,334:INFO:Uploading results into container
2024-05-08 16:04:27,335:INFO:Uploading model into container now
2024-05-08 16:04:27,335:INFO:_master_model_container: 1
2024-05-08 16:04:27,335:INFO:_display_container: 2
2024-05-08 16:04:27,336:INFO:LinearRegression(n_jobs=-1)
2024-05-08 16:04:27,336:INFO:create_model() successfully completed......................................
2024-05-08 16:04:27,431:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:27,432:INFO:Creating metrics dataframe
2024-05-08 16:04:27,436:INFO:Initializing Lasso Regression
2024-05-08 16:04:27,436:INFO:Total runtime is 0.04400798479715983 minutes
2024-05-08 16:04:27,438:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:27,439:INFO:Initializing create_model()
2024-05-08 16:04:27,439:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:27,439:INFO:Checking exceptions
2024-05-08 16:04:27,439:INFO:Importing libraries
2024-05-08 16:04:27,439:INFO:Copying training dataset
2024-05-08 16:04:27,442:INFO:Defining folds
2024-05-08 16:04:27,442:INFO:Declaring metric variables
2024-05-08 16:04:27,444:INFO:Importing untrained model
2024-05-08 16:04:27,447:INFO:Lasso Regression Imported successfully
2024-05-08 16:04:27,452:INFO:Starting cross validation
2024-05-08 16:04:27,453:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:27,488:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:27,492:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:27,497:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:28,639:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:28,639:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:28,641:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:28,669:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:28,968:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:28,982:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,022:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,085:INFO:Calculating mean and std
2024-05-08 16:04:29,085:INFO:Creating metrics dataframe
2024-05-08 16:04:29,088:INFO:Uploading results into container
2024-05-08 16:04:29,088:INFO:Uploading model into container now
2024-05-08 16:04:29,088:INFO:_master_model_container: 2
2024-05-08 16:04:29,089:INFO:_display_container: 2
2024-05-08 16:04:29,089:INFO:Lasso(random_state=123)
2024-05-08 16:04:29,089:INFO:create_model() successfully completed......................................
2024-05-08 16:04:29,172:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:29,172:INFO:Creating metrics dataframe
2024-05-08 16:04:29,177:INFO:Initializing Ridge Regression
2024-05-08 16:04:29,177:INFO:Total runtime is 0.07302053769429524 minutes
2024-05-08 16:04:29,179:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:29,180:INFO:Initializing create_model()
2024-05-08 16:04:29,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:29,180:INFO:Checking exceptions
2024-05-08 16:04:29,180:INFO:Importing libraries
2024-05-08 16:04:29,180:INFO:Copying training dataset
2024-05-08 16:04:29,182:INFO:Defining folds
2024-05-08 16:04:29,182:INFO:Declaring metric variables
2024-05-08 16:04:29,184:INFO:Importing untrained model
2024-05-08 16:04:29,186:INFO:Ridge Regression Imported successfully
2024-05-08 16:04:29,190:INFO:Starting cross validation
2024-05-08 16:04:29,191:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:29,205:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,205:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,212:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,214:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,214:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:29,217:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,221:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,227:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,231:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,280:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,280:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,280:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,280:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,281:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,281:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,286:INFO:Calculating mean and std
2024-05-08 16:04:29,286:INFO:Creating metrics dataframe
2024-05-08 16:04:29,289:INFO:Uploading results into container
2024-05-08 16:04:29,289:INFO:Uploading model into container now
2024-05-08 16:04:29,289:INFO:_master_model_container: 3
2024-05-08 16:04:29,289:INFO:_display_container: 2
2024-05-08 16:04:29,289:INFO:Ridge(random_state=123)
2024-05-08 16:04:29,289:INFO:create_model() successfully completed......................................
2024-05-08 16:04:29,370:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:29,370:INFO:Creating metrics dataframe
2024-05-08 16:04:29,375:INFO:Initializing Elastic Net
2024-05-08 16:04:29,375:INFO:Total runtime is 0.07632471323013305 minutes
2024-05-08 16:04:29,377:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:29,377:INFO:Initializing create_model()
2024-05-08 16:04:29,378:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:29,378:INFO:Checking exceptions
2024-05-08 16:04:29,378:INFO:Importing libraries
2024-05-08 16:04:29,378:INFO:Copying training dataset
2024-05-08 16:04:29,380:INFO:Defining folds
2024-05-08 16:04:29,380:INFO:Declaring metric variables
2024-05-08 16:04:29,382:INFO:Importing untrained model
2024-05-08 16:04:29,384:INFO:Elastic Net Imported successfully
2024-05-08 16:04:29,388:INFO:Starting cross validation
2024-05-08 16:04:29,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:29,402:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,404:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,405:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,408:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,410:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,410:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:29,413:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,419:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,422:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,426:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,495:INFO:Calculating mean and std
2024-05-08 16:04:29,496:INFO:Creating metrics dataframe
2024-05-08 16:04:29,498:INFO:Uploading results into container
2024-05-08 16:04:29,498:INFO:Uploading model into container now
2024-05-08 16:04:29,498:INFO:_master_model_container: 4
2024-05-08 16:04:29,498:INFO:_display_container: 2
2024-05-08 16:04:29,499:INFO:ElasticNet(random_state=123)
2024-05-08 16:04:29,499:INFO:create_model() successfully completed......................................
2024-05-08 16:04:29,589:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:29,589:INFO:Creating metrics dataframe
2024-05-08 16:04:29,594:INFO:Initializing Least Angle Regression
2024-05-08 16:04:29,594:INFO:Total runtime is 0.07996939023335775 minutes
2024-05-08 16:04:29,596:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:29,596:INFO:Initializing create_model()
2024-05-08 16:04:29,596:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:29,596:INFO:Checking exceptions
2024-05-08 16:04:29,596:INFO:Importing libraries
2024-05-08 16:04:29,596:INFO:Copying training dataset
2024-05-08 16:04:29,598:INFO:Defining folds
2024-05-08 16:04:29,598:INFO:Declaring metric variables
2024-05-08 16:04:29,600:INFO:Importing untrained model
2024-05-08 16:04:29,602:INFO:Least Angle Regression Imported successfully
2024-05-08 16:04:29,605:INFO:Starting cross validation
2024-05-08 16:04:29,606:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:29,619:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,621:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,621:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,622:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,625:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,626:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:29,626:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,635:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,638:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,642:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,648:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.308e+00, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,648:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 78 iterations, i.e. alpha=1.213e+00, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,649:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=7.865e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,649:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=7.221e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,649:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.880e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,650:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 98 iterations, i.e. alpha=6.660e-01, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,650:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=6.087e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,650:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=4.852e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,650:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 102 iterations, i.e. alpha=2.277e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=8.328e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 86 iterations, i.e. alpha=8.176e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,653:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=4.203e-01, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,656:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=1.883e-01, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,669:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.010e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,669:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.696e-04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,669:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.442e-04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,669:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 63 iterations, i.e. alpha=6.414e-04, with an active set of 45 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,670:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 72 iterations, i.e. alpha=6.242e-04, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,671:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=6.071e-04, with an active set of 51 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,671:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 79 iterations, i.e. alpha=4.441e-04, with an active set of 55 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,671:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 80 iterations, i.e. alpha=3.948e-04, with an active set of 56 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,674:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=4.488e-03, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,674:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=7.454e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,675:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 110 iterations, i.e. alpha=3.365e-03, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,675:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=2.562e-03, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,675:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=2.309e-01, with an active set of 68 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,676:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 117 iterations, i.e. alpha=1.739e+00, with an active set of 74 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,677:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=8.092e-02, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,677:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=4.382e-02, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,678:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 75 iterations, i.e. alpha=3.987e-01, with an active set of 58 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,679:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 81 iterations, i.e. alpha=3.425e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,680:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.741e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,681:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.681e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,681:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 89 iterations, i.e. alpha=2.368e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,681:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=7.878e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,681:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=5.106e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,682:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=2.880e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,682:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 100 iterations, i.e. alpha=1.468e-01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,683:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=6.743e-02, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,683:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 103 iterations, i.e. alpha=4.981e-02, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,684:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=3.980e+00, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,685:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=3.230e+00, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,685:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=6.353e+03, with an active set of 61 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,685:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=2.242e+00, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,685:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 97 iterations, i.e. alpha=1.899e+00, with an active set of 64 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=3.412e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=3.125e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 111 iterations, i.e. alpha=6.144e+03, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 113 iterations, i.e. alpha=2.921e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 114 iterations, i.e. alpha=6.373e+03, with an active set of 67 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=5.294e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.528e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=5.386e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,689:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=3.367e+03, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,689:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 122 iterations, i.e. alpha=3.258e+03, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,689:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=1.324e+03, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,689:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 123 iterations, i.e. alpha=6.619e+02, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,690:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 68 iterations, i.e. alpha=4.090e-01, with an active set of 47 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,691:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 71 iterations, i.e. alpha=3.813e-01, with an active set of 50 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=3.538e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 76 iterations, i.e. alpha=3.348e-01, with an active set of 54 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.356e+00, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,693:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=3.103e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,694:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=2.031e-01, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,695:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 90 iterations, i.e. alpha=1.694e-01, with an active set of 65 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,695:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 91 iterations, i.e. alpha=1.459e-01, with an active set of 66 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:29,697:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.155e-01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,697:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 94 iterations, i.e. alpha=1.069e-01, with an active set of 69 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,697:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=6.045e-02, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,697:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=5.533e-02, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,698:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 95 iterations, i.e. alpha=4.185e-02, with an active set of 70 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,698:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 73 iterations, i.e. alpha=1.774e+00, with an active set of 53 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,699:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=1.353e-02, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,699:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 99 iterations, i.e. alpha=2.435e-03, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,700:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 83 iterations, i.e. alpha=1.499e+00, with an active set of 60 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,701:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 85 iterations, i.e. alpha=1.030e+00, with an active set of 62 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,704:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=9.953e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,705:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 105 iterations, i.e. alpha=7.540e+01, with an active set of 72 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,705:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.064e+01, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,705:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 106 iterations, i.e. alpha=1.329e+00, with an active set of 73 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:04:29,724:INFO:Calculating mean and std
2024-05-08 16:04:29,725:INFO:Creating metrics dataframe
2024-05-08 16:04:29,728:INFO:Uploading results into container
2024-05-08 16:04:29,728:INFO:Uploading model into container now
2024-05-08 16:04:29,728:INFO:_master_model_container: 5
2024-05-08 16:04:29,729:INFO:_display_container: 2
2024-05-08 16:04:29,729:INFO:Lars(random_state=123)
2024-05-08 16:04:29,729:INFO:create_model() successfully completed......................................
2024-05-08 16:04:29,811:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:29,811:INFO:Creating metrics dataframe
2024-05-08 16:04:29,817:INFO:Initializing Lasso Least Angle Regression
2024-05-08 16:04:29,817:INFO:Total runtime is 0.08368415037790934 minutes
2024-05-08 16:04:29,819:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:29,819:INFO:Initializing create_model()
2024-05-08 16:04:29,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:29,819:INFO:Checking exceptions
2024-05-08 16:04:29,819:INFO:Importing libraries
2024-05-08 16:04:29,819:INFO:Copying training dataset
2024-05-08 16:04:29,821:INFO:Defining folds
2024-05-08 16:04:29,821:INFO:Declaring metric variables
2024-05-08 16:04:29,823:INFO:Importing untrained model
2024-05-08 16:04:29,825:INFO:Lasso Least Angle Regression Imported successfully
2024-05-08 16:04:29,830:INFO:Starting cross validation
2024-05-08 16:04:29,831:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:29,844:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,847:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,848:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,852:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,853:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,853:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:29,856:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,860:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,861:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,867:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:29,929:INFO:Calculating mean and std
2024-05-08 16:04:29,930:INFO:Creating metrics dataframe
2024-05-08 16:04:29,932:INFO:Uploading results into container
2024-05-08 16:04:29,932:INFO:Uploading model into container now
2024-05-08 16:04:29,932:INFO:_master_model_container: 6
2024-05-08 16:04:29,932:INFO:_display_container: 2
2024-05-08 16:04:29,932:INFO:LassoLars(random_state=123)
2024-05-08 16:04:29,932:INFO:create_model() successfully completed......................................
2024-05-08 16:04:30,023:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:30,023:INFO:Creating metrics dataframe
2024-05-08 16:04:30,028:INFO:Initializing Orthogonal Matching Pursuit
2024-05-08 16:04:30,028:INFO:Total runtime is 0.08720777034759522 minutes
2024-05-08 16:04:30,030:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:30,030:INFO:Initializing create_model()
2024-05-08 16:04:30,030:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:30,030:INFO:Checking exceptions
2024-05-08 16:04:30,030:INFO:Importing libraries
2024-05-08 16:04:30,031:INFO:Copying training dataset
2024-05-08 16:04:30,033:INFO:Defining folds
2024-05-08 16:04:30,033:INFO:Declaring metric variables
2024-05-08 16:04:30,035:INFO:Importing untrained model
2024-05-08 16:04:30,037:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-08 16:04:30,043:INFO:Starting cross validation
2024-05-08 16:04:30,043:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:30,058:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,060:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,063:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,065:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,065:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,066:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:30,070:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,078:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,082:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,085:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,152:INFO:Calculating mean and std
2024-05-08 16:04:30,153:INFO:Creating metrics dataframe
2024-05-08 16:04:30,156:INFO:Uploading results into container
2024-05-08 16:04:30,156:INFO:Uploading model into container now
2024-05-08 16:04:30,156:INFO:_master_model_container: 7
2024-05-08 16:04:30,157:INFO:_display_container: 2
2024-05-08 16:04:30,157:INFO:OrthogonalMatchingPursuit()
2024-05-08 16:04:30,157:INFO:create_model() successfully completed......................................
2024-05-08 16:04:30,250:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:30,250:INFO:Creating metrics dataframe
2024-05-08 16:04:30,256:INFO:Initializing Bayesian Ridge
2024-05-08 16:04:30,256:INFO:Total runtime is 0.09099899530410767 minutes
2024-05-08 16:04:30,258:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:30,258:INFO:Initializing create_model()
2024-05-08 16:04:30,258:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:30,258:INFO:Checking exceptions
2024-05-08 16:04:30,258:INFO:Importing libraries
2024-05-08 16:04:30,258:INFO:Copying training dataset
2024-05-08 16:04:30,261:INFO:Defining folds
2024-05-08 16:04:30,261:INFO:Declaring metric variables
2024-05-08 16:04:30,263:INFO:Importing untrained model
2024-05-08 16:04:30,267:INFO:Bayesian Ridge Imported successfully
2024-05-08 16:04:30,271:INFO:Starting cross validation
2024-05-08 16:04:30,272:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:30,286:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,287:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,290:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,292:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,297:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,297:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:30,299:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,302:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,306:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,307:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,360:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,360:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,360:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,361:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,361:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,361:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,378:INFO:Calculating mean and std
2024-05-08 16:04:30,378:INFO:Creating metrics dataframe
2024-05-08 16:04:30,381:INFO:Uploading results into container
2024-05-08 16:04:30,381:INFO:Uploading model into container now
2024-05-08 16:04:30,382:INFO:_master_model_container: 8
2024-05-08 16:04:30,382:INFO:_display_container: 2
2024-05-08 16:04:30,382:INFO:BayesianRidge()
2024-05-08 16:04:30,382:INFO:create_model() successfully completed......................................
2024-05-08 16:04:30,473:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:30,473:INFO:Creating metrics dataframe
2024-05-08 16:04:30,479:INFO:Initializing Passive Aggressive Regressor
2024-05-08 16:04:30,479:INFO:Total runtime is 0.09472110271453858 minutes
2024-05-08 16:04:30,481:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:30,481:INFO:Initializing create_model()
2024-05-08 16:04:30,481:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:30,481:INFO:Checking exceptions
2024-05-08 16:04:30,481:INFO:Importing libraries
2024-05-08 16:04:30,481:INFO:Copying training dataset
2024-05-08 16:04:30,483:INFO:Defining folds
2024-05-08 16:04:30,484:INFO:Declaring metric variables
2024-05-08 16:04:30,486:INFO:Importing untrained model
2024-05-08 16:04:30,487:INFO:Passive Aggressive Regressor Imported successfully
2024-05-08 16:04:30,491:INFO:Starting cross validation
2024-05-08 16:04:30,492:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:30,505:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,507:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,509:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,511:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,513:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,513:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:30,515:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,521:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,526:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,532:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,569:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,569:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,570:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,570:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,570:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,570:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,593:INFO:Calculating mean and std
2024-05-08 16:04:30,594:INFO:Creating metrics dataframe
2024-05-08 16:04:30,597:INFO:Uploading results into container
2024-05-08 16:04:30,597:INFO:Uploading model into container now
2024-05-08 16:04:30,598:INFO:_master_model_container: 9
2024-05-08 16:04:30,598:INFO:_display_container: 2
2024-05-08 16:04:30,598:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-08 16:04:30,598:INFO:create_model() successfully completed......................................
2024-05-08 16:04:30,694:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:30,694:INFO:Creating metrics dataframe
2024-05-08 16:04:30,699:INFO:Initializing Huber Regressor
2024-05-08 16:04:30,699:INFO:Total runtime is 0.09838913679122925 minutes
2024-05-08 16:04:30,701:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:30,701:INFO:Initializing create_model()
2024-05-08 16:04:30,701:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:30,701:INFO:Checking exceptions
2024-05-08 16:04:30,701:INFO:Importing libraries
2024-05-08 16:04:30,701:INFO:Copying training dataset
2024-05-08 16:04:30,704:INFO:Defining folds
2024-05-08 16:04:30,704:INFO:Declaring metric variables
2024-05-08 16:04:30,706:INFO:Importing untrained model
2024-05-08 16:04:30,708:INFO:Huber Regressor Imported successfully
2024-05-08 16:04:30,712:INFO:Starting cross validation
2024-05-08 16:04:30,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:30,727:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,730:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,734:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,735:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,735:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,735:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:30,739:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,741:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,744:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,744:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,769:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,785:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,785:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,789:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,804:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,812:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,816:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,816:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,822:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,828:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:04:30,852:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,853:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,853:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,853:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,853:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,853:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:04:30,854:INFO:Calculating mean and std
2024-05-08 16:04:30,855:INFO:Creating metrics dataframe
2024-05-08 16:04:30,857:INFO:Uploading results into container
2024-05-08 16:04:30,858:INFO:Uploading model into container now
2024-05-08 16:04:30,858:INFO:_master_model_container: 10
2024-05-08 16:04:30,858:INFO:_display_container: 2
2024-05-08 16:04:30,858:INFO:HuberRegressor()
2024-05-08 16:04:30,858:INFO:create_model() successfully completed......................................
2024-05-08 16:04:30,942:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:30,942:INFO:Creating metrics dataframe
2024-05-08 16:04:30,948:INFO:Initializing K Neighbors Regressor
2024-05-08 16:04:30,948:INFO:Total runtime is 0.10252922773361206 minutes
2024-05-08 16:04:30,949:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:30,950:INFO:Initializing create_model()
2024-05-08 16:04:30,950:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:30,950:INFO:Checking exceptions
2024-05-08 16:04:30,950:INFO:Importing libraries
2024-05-08 16:04:30,950:INFO:Copying training dataset
2024-05-08 16:04:30,951:INFO:Defining folds
2024-05-08 16:04:30,952:INFO:Declaring metric variables
2024-05-08 16:04:30,954:INFO:Importing untrained model
2024-05-08 16:04:30,956:INFO:K Neighbors Regressor Imported successfully
2024-05-08 16:04:30,960:INFO:Starting cross validation
2024-05-08 16:04:30,961:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:30,973:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,975:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,978:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:30,985:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,987:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,989:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:30,993:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,098:INFO:Calculating mean and std
2024-05-08 16:04:31,099:INFO:Creating metrics dataframe
2024-05-08 16:04:31,101:INFO:Uploading results into container
2024-05-08 16:04:31,101:INFO:Uploading model into container now
2024-05-08 16:04:31,102:INFO:_master_model_container: 11
2024-05-08 16:04:31,102:INFO:_display_container: 2
2024-05-08 16:04:31,102:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-08 16:04:31,102:INFO:create_model() successfully completed......................................
2024-05-08 16:04:31,191:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:31,191:INFO:Creating metrics dataframe
2024-05-08 16:04:31,198:INFO:Initializing Decision Tree Regressor
2024-05-08 16:04:31,198:INFO:Total runtime is 0.1066994309425354 minutes
2024-05-08 16:04:31,200:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:31,200:INFO:Initializing create_model()
2024-05-08 16:04:31,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:31,200:INFO:Checking exceptions
2024-05-08 16:04:31,200:INFO:Importing libraries
2024-05-08 16:04:31,200:INFO:Copying training dataset
2024-05-08 16:04:31,203:INFO:Defining folds
2024-05-08 16:04:31,203:INFO:Declaring metric variables
2024-05-08 16:04:31,205:INFO:Importing untrained model
2024-05-08 16:04:31,207:INFO:Decision Tree Regressor Imported successfully
2024-05-08 16:04:31,211:INFO:Starting cross validation
2024-05-08 16:04:31,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:31,226:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,228:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,230:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,231:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:31,237:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,241:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,243:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,245:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,336:INFO:Calculating mean and std
2024-05-08 16:04:31,337:INFO:Creating metrics dataframe
2024-05-08 16:04:31,339:INFO:Uploading results into container
2024-05-08 16:04:31,339:INFO:Uploading model into container now
2024-05-08 16:04:31,340:INFO:_master_model_container: 12
2024-05-08 16:04:31,340:INFO:_display_container: 2
2024-05-08 16:04:31,340:INFO:DecisionTreeRegressor(random_state=123)
2024-05-08 16:04:31,340:INFO:create_model() successfully completed......................................
2024-05-08 16:04:31,421:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:31,421:INFO:Creating metrics dataframe
2024-05-08 16:04:31,427:INFO:Initializing Random Forest Regressor
2024-05-08 16:04:31,427:INFO:Total runtime is 0.11052454312642415 minutes
2024-05-08 16:04:31,429:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:31,429:INFO:Initializing create_model()
2024-05-08 16:04:31,429:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:31,429:INFO:Checking exceptions
2024-05-08 16:04:31,429:INFO:Importing libraries
2024-05-08 16:04:31,429:INFO:Copying training dataset
2024-05-08 16:04:31,431:INFO:Defining folds
2024-05-08 16:04:31,431:INFO:Declaring metric variables
2024-05-08 16:04:31,433:INFO:Importing untrained model
2024-05-08 16:04:31,435:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:04:31,438:INFO:Starting cross validation
2024-05-08 16:04:31,439:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:31,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,454:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,454:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,457:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,459:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,459:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:31,461:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,463:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,466:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:31,469:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,583:INFO:Calculating mean and std
2024-05-08 16:04:32,583:INFO:Creating metrics dataframe
2024-05-08 16:04:32,585:INFO:Uploading results into container
2024-05-08 16:04:32,586:INFO:Uploading model into container now
2024-05-08 16:04:32,586:INFO:_master_model_container: 13
2024-05-08 16:04:32,586:INFO:_display_container: 2
2024-05-08 16:04:32,586:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:04:32,586:INFO:create_model() successfully completed......................................
2024-05-08 16:04:32,666:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:32,666:INFO:Creating metrics dataframe
2024-05-08 16:04:32,672:INFO:Initializing Extra Trees Regressor
2024-05-08 16:04:32,672:INFO:Total runtime is 0.1312712868054708 minutes
2024-05-08 16:04:32,674:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:32,674:INFO:Initializing create_model()
2024-05-08 16:04:32,674:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:32,674:INFO:Checking exceptions
2024-05-08 16:04:32,674:INFO:Importing libraries
2024-05-08 16:04:32,675:INFO:Copying training dataset
2024-05-08 16:04:32,676:INFO:Defining folds
2024-05-08 16:04:32,676:INFO:Declaring metric variables
2024-05-08 16:04:32,678:INFO:Importing untrained model
2024-05-08 16:04:32,680:INFO:Extra Trees Regressor Imported successfully
2024-05-08 16:04:32,684:INFO:Starting cross validation
2024-05-08 16:04:32,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:32,697:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,698:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,701:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,701:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,704:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,704:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:32,707:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,714:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,716:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:32,717:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,205:INFO:Calculating mean and std
2024-05-08 16:04:33,205:INFO:Creating metrics dataframe
2024-05-08 16:04:33,207:INFO:Uploading results into container
2024-05-08 16:04:33,208:INFO:Uploading model into container now
2024-05-08 16:04:33,208:INFO:_master_model_container: 14
2024-05-08 16:04:33,208:INFO:_display_container: 2
2024-05-08 16:04:33,208:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:04:33,208:INFO:create_model() successfully completed......................................
2024-05-08 16:04:33,287:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:33,287:INFO:Creating metrics dataframe
2024-05-08 16:04:33,293:INFO:Initializing AdaBoost Regressor
2024-05-08 16:04:33,293:INFO:Total runtime is 0.141625714302063 minutes
2024-05-08 16:04:33,295:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:33,295:INFO:Initializing create_model()
2024-05-08 16:04:33,295:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:33,295:INFO:Checking exceptions
2024-05-08 16:04:33,295:INFO:Importing libraries
2024-05-08 16:04:33,295:INFO:Copying training dataset
2024-05-08 16:04:33,297:INFO:Defining folds
2024-05-08 16:04:33,297:INFO:Declaring metric variables
2024-05-08 16:04:33,299:INFO:Importing untrained model
2024-05-08 16:04:33,302:INFO:AdaBoost Regressor Imported successfully
2024-05-08 16:04:33,307:INFO:Starting cross validation
2024-05-08 16:04:33,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:33,323:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,325:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,326:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,330:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,333:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,333:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:33,335:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,341:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,346:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,349:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,665:INFO:Calculating mean and std
2024-05-08 16:04:33,666:INFO:Creating metrics dataframe
2024-05-08 16:04:33,670:INFO:Uploading results into container
2024-05-08 16:04:33,670:INFO:Uploading model into container now
2024-05-08 16:04:33,671:INFO:_master_model_container: 15
2024-05-08 16:04:33,671:INFO:_display_container: 2
2024-05-08 16:04:33,671:INFO:AdaBoostRegressor(random_state=123)
2024-05-08 16:04:33,671:INFO:create_model() successfully completed......................................
2024-05-08 16:04:33,752:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:33,752:INFO:Creating metrics dataframe
2024-05-08 16:04:33,758:INFO:Initializing Gradient Boosting Regressor
2024-05-08 16:04:33,758:INFO:Total runtime is 0.14937369823455812 minutes
2024-05-08 16:04:33,760:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:33,760:INFO:Initializing create_model()
2024-05-08 16:04:33,760:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:33,760:INFO:Checking exceptions
2024-05-08 16:04:33,760:INFO:Importing libraries
2024-05-08 16:04:33,760:INFO:Copying training dataset
2024-05-08 16:04:33,762:INFO:Defining folds
2024-05-08 16:04:33,762:INFO:Declaring metric variables
2024-05-08 16:04:33,764:INFO:Importing untrained model
2024-05-08 16:04:33,766:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:04:33,771:INFO:Starting cross validation
2024-05-08 16:04:33,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:33,787:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,789:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,790:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,794:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,794:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,794:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:33,798:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,804:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,808:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:33,811:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,584:INFO:Calculating mean and std
2024-05-08 16:04:34,585:INFO:Creating metrics dataframe
2024-05-08 16:04:34,587:INFO:Uploading results into container
2024-05-08 16:04:34,587:INFO:Uploading model into container now
2024-05-08 16:04:34,587:INFO:_master_model_container: 16
2024-05-08 16:04:34,587:INFO:_display_container: 2
2024-05-08 16:04:34,588:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:04:34,588:INFO:create_model() successfully completed......................................
2024-05-08 16:04:34,662:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:34,662:INFO:Creating metrics dataframe
2024-05-08 16:04:34,668:INFO:Initializing Light Gradient Boosting Machine
2024-05-08 16:04:34,669:INFO:Total runtime is 0.1645427743593852 minutes
2024-05-08 16:04:34,670:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:34,670:INFO:Initializing create_model()
2024-05-08 16:04:34,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:34,671:INFO:Checking exceptions
2024-05-08 16:04:34,671:INFO:Importing libraries
2024-05-08 16:04:34,671:INFO:Copying training dataset
2024-05-08 16:04:34,672:INFO:Defining folds
2024-05-08 16:04:34,672:INFO:Declaring metric variables
2024-05-08 16:04:34,674:INFO:Importing untrained model
2024-05-08 16:04:34,676:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-08 16:04:34,680:INFO:Starting cross validation
2024-05-08 16:04:34,681:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:34,695:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,697:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,699:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,702:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,707:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,707:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:34,709:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,714:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,717:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:34,719:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,408:INFO:Calculating mean and std
2024-05-08 16:04:35,409:INFO:Creating metrics dataframe
2024-05-08 16:04:35,412:INFO:Uploading results into container
2024-05-08 16:04:35,412:INFO:Uploading model into container now
2024-05-08 16:04:35,412:INFO:_master_model_container: 17
2024-05-08 16:04:35,412:INFO:_display_container: 2
2024-05-08 16:04:35,413:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:04:35,413:INFO:create_model() successfully completed......................................
2024-05-08 16:04:35,489:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:35,489:INFO:Creating metrics dataframe
2024-05-08 16:04:35,495:INFO:Initializing Dummy Regressor
2024-05-08 16:04:35,495:INFO:Total runtime is 0.17832502126693728 minutes
2024-05-08 16:04:35,497:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:35,498:INFO:Initializing create_model()
2024-05-08 16:04:35,498:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bec56280>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:35,498:INFO:Checking exceptions
2024-05-08 16:04:35,498:INFO:Importing libraries
2024-05-08 16:04:35,498:INFO:Copying training dataset
2024-05-08 16:04:35,499:INFO:Defining folds
2024-05-08 16:04:35,499:INFO:Declaring metric variables
2024-05-08 16:04:35,501:INFO:Importing untrained model
2024-05-08 16:04:35,503:INFO:Dummy Regressor Imported successfully
2024-05-08 16:04:35,506:INFO:Starting cross validation
2024-05-08 16:04:35,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:35,520:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,523:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,524:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,528:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,530:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,530:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:35,533:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,540:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,543:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,549:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:35,606:INFO:Calculating mean and std
2024-05-08 16:04:35,607:INFO:Creating metrics dataframe
2024-05-08 16:04:35,609:INFO:Uploading results into container
2024-05-08 16:04:35,610:INFO:Uploading model into container now
2024-05-08 16:04:35,610:INFO:_master_model_container: 18
2024-05-08 16:04:35,610:INFO:_display_container: 2
2024-05-08 16:04:35,610:INFO:DummyRegressor()
2024-05-08 16:04:35,610:INFO:create_model() successfully completed......................................
2024-05-08 16:04:35,695:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:35,695:INFO:Creating metrics dataframe
2024-05-08 16:04:35,706:INFO:Initializing create_model()
2024-05-08 16:04:35,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:35,706:INFO:Checking exceptions
2024-05-08 16:04:35,707:INFO:Importing libraries
2024-05-08 16:04:35,707:INFO:Copying training dataset
2024-05-08 16:04:35,709:INFO:Defining folds
2024-05-08 16:04:35,709:INFO:Declaring metric variables
2024-05-08 16:04:35,710:INFO:Importing untrained model
2024-05-08 16:04:35,710:INFO:Declaring custom model
2024-05-08 16:04:35,710:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:04:35,711:INFO:Cross validation set to False
2024-05-08 16:04:35,711:INFO:Fitting Model
2024-05-08 16:04:35,712:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,276:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:04:36,276:INFO:create_model() successfully completed......................................
2024-05-08 16:04:36,370:INFO:_master_model_container: 18
2024-05-08 16:04:36,370:INFO:_display_container: 2
2024-05-08 16:04:36,370:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:04:36,370:INFO:compare_models() successfully completed......................................
2024-05-08 16:04:36,371:INFO:Initializing tune_model()
2024-05-08 16:04:36,371:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>)
2024-05-08 16:04:36,371:INFO:Checking exceptions
2024-05-08 16:04:36,380:INFO:Copying training dataset
2024-05-08 16:04:36,382:INFO:Checking base model
2024-05-08 16:04:36,382:INFO:Base model : Gradient Boosting Regressor
2024-05-08 16:04:36,384:INFO:Declaring metric variables
2024-05-08 16:04:36,388:INFO:Defining Hyperparameters
2024-05-08 16:04:36,489:INFO:Tuning with n_jobs=-1
2024-05-08 16:04:36,489:INFO:Initializing RandomizedSearchCV
2024-05-08 16:04:36,514:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:36,519:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,519:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,519:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,522:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,524:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,527:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,529:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,530:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,531:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,533:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,533:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:36,540:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,560:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,834:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,848:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,850:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,876:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,877:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,885:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,946:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:36,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:36,966:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,027:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,036:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,049:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,089:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,098:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,130:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,133:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,142:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,142:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:37,163:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,530:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,738:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,744:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,752:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,758:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,780:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,786:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,797:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,797:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:37,829:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,855:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,868:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,883:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,902:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,922:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,940:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,952:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:37,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:38,038:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,039:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,063:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,067:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,072:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,074:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,101:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,173:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,173:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:38,175:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,184:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,192:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,207:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,214:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,271:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,391:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,483:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,492:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,492:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:38,503:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,552:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,608:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,621:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,634:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,643:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,675:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,810:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,811:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:38,849:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,895:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,896:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:38,923:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,036:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,053:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,097:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,119:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,146:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,146:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:39,160:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,482:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,492:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:39,512:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,506:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2024-05-08 16:04:41,507:INFO:Hyperparameter search completed
2024-05-08 16:04:41,507:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:41,507:INFO:Initializing create_model()
2024-05-08 16:04:41,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bece5430>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2024-05-08 16:04:41,508:INFO:Checking exceptions
2024-05-08 16:04:41,508:INFO:Importing libraries
2024-05-08 16:04:41,508:INFO:Copying training dataset
2024-05-08 16:04:41,511:INFO:Defining folds
2024-05-08 16:04:41,511:INFO:Declaring metric variables
2024-05-08 16:04:41,513:INFO:Importing untrained model
2024-05-08 16:04:41,513:INFO:Declaring custom model
2024-05-08 16:04:41,516:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:04:41,520:INFO:Starting cross validation
2024-05-08 16:04:41,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:41,539:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,542:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,544:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,548:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,551:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,551:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:41,554:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,562:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,565:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:41,567:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:44,394:INFO:Calculating mean and std
2024-05-08 16:04:44,395:INFO:Creating metrics dataframe
2024-05-08 16:04:44,398:INFO:Finalizing model
2024-05-08 16:04:44,400:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,613:INFO:Uploading results into container
2024-05-08 16:04:46,613:INFO:Uploading model into container now
2024-05-08 16:04:46,613:INFO:_master_model_container: 19
2024-05-08 16:04:46,613:INFO:_display_container: 3
2024-05-08 16:04:46,614:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85)
2024-05-08 16:04:46,614:INFO:create_model() successfully completed......................................
2024-05-08 16:04:46,703:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:46,703:INFO:choose_better activated
2024-05-08 16:04:46,706:INFO:SubProcess create_model() called ==================================
2024-05-08 16:04:46,706:INFO:Initializing create_model()
2024-05-08 16:04:46,706:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:46,706:INFO:Checking exceptions
2024-05-08 16:04:46,707:INFO:Importing libraries
2024-05-08 16:04:46,707:INFO:Copying training dataset
2024-05-08 16:04:46,709:INFO:Defining folds
2024-05-08 16:04:46,709:INFO:Declaring metric variables
2024-05-08 16:04:46,709:INFO:Importing untrained model
2024-05-08 16:04:46,709:INFO:Declaring custom model
2024-05-08 16:04:46,709:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:04:46,710:INFO:Starting cross validation
2024-05-08 16:04:46,710:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:04:46,723:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,726:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,728:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,731:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,733:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,733:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:04:46,737:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,744:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,748:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:46,753:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:47,597:INFO:Calculating mean and std
2024-05-08 16:04:47,598:INFO:Creating metrics dataframe
2024-05-08 16:04:47,600:INFO:Finalizing model
2024-05-08 16:04:47,603:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:48,181:INFO:Uploading results into container
2024-05-08 16:04:48,181:INFO:Uploading model into container now
2024-05-08 16:04:48,181:INFO:_master_model_container: 20
2024-05-08 16:04:48,181:INFO:_display_container: 4
2024-05-08 16:04:48,182:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:04:48,182:INFO:create_model() successfully completed......................................
2024-05-08 16:04:48,257:INFO:SubProcess create_model() end ==================================
2024-05-08 16:04:48,258:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.7858
2024-05-08 16:04:48,258:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85) result for R2 is 0.6861
2024-05-08 16:04:48,258:INFO:GradientBoostingRegressor(random_state=123) is best model
2024-05-08 16:04:48,258:INFO:choose_better completed
2024-05-08 16:04:48,258:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-08 16:04:48,263:INFO:_master_model_container: 20
2024-05-08 16:04:48,263:INFO:_display_container: 3
2024-05-08 16:04:48,264:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:04:48,264:INFO:tune_model() successfully completed......................................
2024-05-08 16:04:48,370:INFO:Initializing finalize_model()
2024-05-08 16:04:48,370:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=GradientBoostingRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-08 16:04:48,370:INFO:Finalizing GradientBoostingRegressor(random_state=123)
2024-05-08 16:04:48,372:INFO:Initializing create_model()
2024-05-08 16:04:48,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:04:48,372:INFO:Checking exceptions
2024-05-08 16:04:48,373:INFO:Importing libraries
2024-05-08 16:04:48,373:INFO:Copying training dataset
2024-05-08 16:04:48,373:INFO:Defining folds
2024-05-08 16:04:48,373:INFO:Declaring metric variables
2024-05-08 16:04:48,373:INFO:Importing untrained model
2024-05-08 16:04:48,373:INFO:Declaring custom model
2024-05-08 16:04:48,373:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:04:48,374:INFO:Cross validation set to False
2024-05-08 16:04:48,374:INFO:Fitting Model
2024-05-08 16:04:48,376:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:04:49,190:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['cumulative',
                                             'averag...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2024-05-08 16:04:49,190:INFO:create_model() successfully completed......................................
2024-05-08 16:04:49,265:INFO:_master_model_container: 20
2024-05-08 16:04:49,265:INFO:_display_container: 3
2024-05-08 16:04:49,271:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['cumulative',
                                             'averag...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2024-05-08 16:04:49,271:INFO:finalize_model() successfully completed......................................
2024-05-08 16:04:49,351:INFO:Initializing predict_model()
2024-05-08 16:04:49,351:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8bc6d8070>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['cumulative',
                                             'averag...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x74c8bc045af0>)
2024-05-08 16:04:49,351:INFO:Checking exceptions
2024-05-08 16:04:49,351:INFO:Preloading libraries
2024-05-08 16:04:49,352:INFO:Set up data.
2024-05-08 16:04:49,355:INFO:Set up index.
2024-05-08 16:04:49,369:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-08 16:24:17,520:WARNING:/tmp/ipykernel_19548/2317310308.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-08 16:24:22,456:INFO:PyCaret RegressionExperiment
2024-05-08 16:24:22,457:INFO:Logging name: reg-default-name
2024-05-08 16:24:22,457:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-08 16:24:22,457:INFO:version 3.3.2
2024-05-08 16:24:22,457:INFO:Initializing setup()
2024-05-08 16:24:22,457:INFO:self.USI: ba81
2024-05-08 16:24:22,457:INFO:self._variable_keys: {'y_train', 'X_test', 'seed', 'exp_name_log', 'X', 'y_test', '_ml_usecase', 'log_plots_param', 'idx', '_available_plots', 'html_param', 'exp_id', 'pipeline', 'n_jobs_param', 'data', 'fold_generator', 'transform_target_param', 'X_train', 'fold_groups_param', 'logging_param', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'fold_shuffle_param', 'target_param', 'memory', 'y'}
2024-05-08 16:24:22,457:INFO:Checking environment
2024-05-08 16:24:22,457:INFO:python_version: 3.9.18
2024-05-08 16:24:22,457:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-08 16:24:22,457:INFO:machine: x86_64
2024-05-08 16:24:22,457:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:24:22,457:INFO:Memory: svmem(total=16429801472, available=6761185280, percent=58.8, used=8477622272, free=2983391232, active=7060701184, inactive=5134036992, buffers=134672384, cached=4834115584, shared=844435456, slab=656531456)
2024-05-08 16:24:22,458:INFO:Physical Core: 12
2024-05-08 16:24:22,458:INFO:Logical Core: 16
2024-05-08 16:24:22,458:INFO:Checking libraries
2024-05-08 16:24:22,458:INFO:System:
2024-05-08 16:24:22,458:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-08 16:24:22,458:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-08 16:24:22,458:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:24:22,458:INFO:PyCaret required dependencies:
2024-05-08 16:24:22,458:INFO:                 pip: 23.2.1
2024-05-08 16:24:22,458:INFO:          setuptools: 68.0.0
2024-05-08 16:24:22,458:INFO:             pycaret: 3.3.2
2024-05-08 16:24:22,458:INFO:             IPython: 8.15.0
2024-05-08 16:24:22,458:INFO:          ipywidgets: 8.0.4
2024-05-08 16:24:22,458:INFO:                tqdm: 4.65.0
2024-05-08 16:24:22,458:INFO:               numpy: 1.24.3
2024-05-08 16:24:22,459:INFO:              pandas: 1.4.2
2024-05-08 16:24:22,459:INFO:              jinja2: 3.1.4
2024-05-08 16:24:22,459:INFO:               scipy: 1.11.3
2024-05-08 16:24:22,459:INFO:              joblib: 1.2.0
2024-05-08 16:24:22,459:INFO:             sklearn: 1.4.2
2024-05-08 16:24:22,459:INFO:                pyod: 1.1.3
2024-05-08 16:24:22,459:INFO:            imblearn: 0.12.2
2024-05-08 16:24:22,459:INFO:   category_encoders: 2.6.3
2024-05-08 16:24:22,459:INFO:            lightgbm: 4.3.0
2024-05-08 16:24:22,459:INFO:               numba: 0.58.0
2024-05-08 16:24:22,459:INFO:            requests: 2.31.0
2024-05-08 16:24:22,459:INFO:          matplotlib: 3.7.2
2024-05-08 16:24:22,459:INFO:          scikitplot: 0.3.7
2024-05-08 16:24:22,459:INFO:         yellowbrick: 1.5
2024-05-08 16:24:22,459:INFO:              plotly: 5.22.0
2024-05-08 16:24:22,459:INFO:    plotly-resampler: Not installed
2024-05-08 16:24:22,459:INFO:             kaleido: 0.2.1
2024-05-08 16:24:22,459:INFO:           schemdraw: 0.15
2024-05-08 16:24:22,459:INFO:         statsmodels: 0.14.0
2024-05-08 16:24:22,459:INFO:              sktime: 0.26.0
2024-05-08 16:24:22,459:INFO:               tbats: 1.1.3
2024-05-08 16:24:22,459:INFO:            pmdarima: 2.0.4
2024-05-08 16:24:22,459:INFO:              psutil: 5.9.0
2024-05-08 16:24:22,459:INFO:          markupsafe: 2.0.1
2024-05-08 16:24:22,459:INFO:             pickle5: Not installed
2024-05-08 16:24:22,459:INFO:         cloudpickle: 2.2.1
2024-05-08 16:24:22,459:INFO:         deprecation: 2.1.0
2024-05-08 16:24:22,459:INFO:              xxhash: 2.0.2
2024-05-08 16:24:22,459:INFO:           wurlitzer: 3.0.2
2024-05-08 16:24:22,459:INFO:PyCaret optional dependencies:
2024-05-08 16:24:22,459:INFO:                shap: Not installed
2024-05-08 16:24:22,460:INFO:           interpret: Not installed
2024-05-08 16:24:22,460:INFO:                umap: Not installed
2024-05-08 16:24:22,460:INFO:     ydata_profiling: Not installed
2024-05-08 16:24:22,460:INFO:  explainerdashboard: Not installed
2024-05-08 16:24:22,460:INFO:             autoviz: Not installed
2024-05-08 16:24:22,460:INFO:           fairlearn: Not installed
2024-05-08 16:24:22,460:INFO:          deepchecks: Not installed
2024-05-08 16:24:22,460:INFO:             xgboost: Not installed
2024-05-08 16:24:22,460:INFO:            catboost: Not installed
2024-05-08 16:24:22,460:INFO:              kmodes: Not installed
2024-05-08 16:24:22,460:INFO:             mlxtend: Not installed
2024-05-08 16:24:22,460:INFO:       statsforecast: Not installed
2024-05-08 16:24:22,460:INFO:        tune_sklearn: Not installed
2024-05-08 16:24:22,460:INFO:                 ray: Not installed
2024-05-08 16:24:22,460:INFO:            hyperopt: Not installed
2024-05-08 16:24:22,460:INFO:              optuna: Not installed
2024-05-08 16:24:22,460:INFO:               skopt: Not installed
2024-05-08 16:24:22,460:INFO:              mlflow: Not installed
2024-05-08 16:24:22,460:INFO:              gradio: Not installed
2024-05-08 16:24:22,460:INFO:             fastapi: Not installed
2024-05-08 16:24:22,460:INFO:             uvicorn: Not installed
2024-05-08 16:24:22,460:INFO:              m2cgen: Not installed
2024-05-08 16:24:22,460:INFO:           evidently: Not installed
2024-05-08 16:24:22,460:INFO:               fugue: Not installed
2024-05-08 16:24:22,460:INFO:           streamlit: Not installed
2024-05-08 16:24:22,460:INFO:             prophet: Not installed
2024-05-08 16:24:22,460:INFO:None
2024-05-08 16:24:22,460:INFO:Set up data.
2024-05-08 16:24:22,467:INFO:Set up folding strategy.
2024-05-08 16:24:22,467:INFO:Set up train/test split.
2024-05-08 16:24:22,471:INFO:Set up index.
2024-05-08 16:24:22,471:INFO:Assigning column types.
2024-05-08 16:24:22,474:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-08 16:24:22,475:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,482:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,490:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,536:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,563:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,563:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,565:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,568:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,623:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,624:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,624:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,624:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-08 16:24:22,626:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,629:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,656:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,677:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,678:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,678:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,680:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,682:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,710:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,731:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,732:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,732:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-08 16:24:22,736:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,766:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,787:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,787:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,788:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,792:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,817:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,838:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,838:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,838:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,838:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-08 16:24:22,868:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,889:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,889:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,889:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,920:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,940:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,941:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,941:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-08 16:24:22,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:22,992:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:22,992:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,022:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:24:23,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,043:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-08 16:24:23,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,147:INFO:Preparing preprocessing pipeline...
2024-05-08 16:24:23,147:INFO:Set up target transformation.
2024-05-08 16:24:23,147:INFO:Set up date feature engineering.
2024-05-08 16:24:23,147:INFO:Set up simple imputation.
2024-05-08 16:24:23,147:INFO:Set up polynomial features.
2024-05-08 16:24:23,147:INFO:Set up feature normalization.
2024-05-08 16:24:23,148:INFO:Set up column name cleaning.
2024-05-08 16:24:23,151:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:23,175:INFO:Finished creating preprocessing pipeline.
2024-05-08 16:24:23,180:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-08 16:24:23,180:INFO:Creating final display dataframe.
2024-05-08 16:24:23,258:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (552, 7)
4        Transformed data shape         (552, 45)
5   Transformed train set shape         (386, 45)
6    Transformed test set shape         (166, 45)
7              Numeric features                 5
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13          Polynomial features              True
14            Polynomial degree                 2
15                    Normalize              True
16             Normalize method            zscore
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              ba81
2024-05-08 16:24:23,320:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,320:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,378:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,378:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:24:23,378:INFO:setup() successfully completed in 0.92s...............
2024-05-08 16:24:23,379:INFO:Initializing compare_models()
2024-05-08 16:24:23,379:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-08 16:24:23,379:INFO:Checking exceptions
2024-05-08 16:24:23,381:INFO:Preparing display monitor
2024-05-08 16:24:23,396:INFO:Initializing Linear Regression
2024-05-08 16:24:23,396:INFO:Total runtime is 2.408027648925781e-06 minutes
2024-05-08 16:24:23,399:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:23,399:INFO:Initializing create_model()
2024-05-08 16:24:23,399:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:23,399:INFO:Checking exceptions
2024-05-08 16:24:23,399:INFO:Importing libraries
2024-05-08 16:24:23,399:INFO:Copying training dataset
2024-05-08 16:24:23,402:INFO:Defining folds
2024-05-08 16:24:23,402:INFO:Declaring metric variables
2024-05-08 16:24:23,404:INFO:Importing untrained model
2024-05-08 16:24:23,406:INFO:Linear Regression Imported successfully
2024-05-08 16:24:23,410:INFO:Starting cross validation
2024-05-08 16:24:23,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:25,533:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:25,540:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:25,591:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:25,727:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:25,824:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:25,862:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:25,869:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:25,870:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:25,870:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:25,912:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:26,065:INFO:Calculating mean and std
2024-05-08 16:24:26,067:INFO:Creating metrics dataframe
2024-05-08 16:24:26,071:INFO:Uploading results into container
2024-05-08 16:24:26,072:INFO:Uploading model into container now
2024-05-08 16:24:26,072:INFO:_master_model_container: 1
2024-05-08 16:24:26,072:INFO:_display_container: 2
2024-05-08 16:24:26,073:INFO:LinearRegression(n_jobs=-1)
2024-05-08 16:24:26,073:INFO:create_model() successfully completed......................................
2024-05-08 16:24:26,202:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:26,203:INFO:Creating metrics dataframe
2024-05-08 16:24:26,207:INFO:Initializing Lasso Regression
2024-05-08 16:24:26,208:INFO:Total runtime is 0.046862661838531494 minutes
2024-05-08 16:24:26,209:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:26,210:INFO:Initializing create_model()
2024-05-08 16:24:26,210:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:26,210:INFO:Checking exceptions
2024-05-08 16:24:26,210:INFO:Importing libraries
2024-05-08 16:24:26,210:INFO:Copying training dataset
2024-05-08 16:24:26,212:INFO:Defining folds
2024-05-08 16:24:26,212:INFO:Declaring metric variables
2024-05-08 16:24:26,215:INFO:Importing untrained model
2024-05-08 16:24:26,217:INFO:Lasso Regression Imported successfully
2024-05-08 16:24:26,221:INFO:Starting cross validation
2024-05-08 16:24:26,222:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:26,259:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:26,263:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:26,267:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:27,414:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:27,415:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:27,426:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:27,437:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:27,786:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:27,797:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:27,797:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:27,877:INFO:Calculating mean and std
2024-05-08 16:24:27,877:INFO:Creating metrics dataframe
2024-05-08 16:24:27,880:INFO:Uploading results into container
2024-05-08 16:24:27,880:INFO:Uploading model into container now
2024-05-08 16:24:27,881:INFO:_master_model_container: 2
2024-05-08 16:24:27,881:INFO:_display_container: 2
2024-05-08 16:24:27,881:INFO:Lasso(random_state=123)
2024-05-08 16:24:27,881:INFO:create_model() successfully completed......................................
2024-05-08 16:24:27,991:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:27,991:INFO:Creating metrics dataframe
2024-05-08 16:24:27,997:INFO:Initializing Ridge Regression
2024-05-08 16:24:27,997:INFO:Total runtime is 0.0766824722290039 minutes
2024-05-08 16:24:27,998:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:27,999:INFO:Initializing create_model()
2024-05-08 16:24:27,999:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:27,999:INFO:Checking exceptions
2024-05-08 16:24:27,999:INFO:Importing libraries
2024-05-08 16:24:27,999:INFO:Copying training dataset
2024-05-08 16:24:28,001:INFO:Defining folds
2024-05-08 16:24:28,001:INFO:Declaring metric variables
2024-05-08 16:24:28,003:INFO:Importing untrained model
2024-05-08 16:24:28,005:INFO:Ridge Regression Imported successfully
2024-05-08 16:24:28,008:INFO:Starting cross validation
2024-05-08 16:24:28,009:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:28,021:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,024:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,025:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,026:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,030:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,030:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:28,031:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,034:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,039:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,043:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,104:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,106:INFO:Calculating mean and std
2024-05-08 16:24:28,107:INFO:Creating metrics dataframe
2024-05-08 16:24:28,109:INFO:Uploading results into container
2024-05-08 16:24:28,109:INFO:Uploading model into container now
2024-05-08 16:24:28,110:INFO:_master_model_container: 3
2024-05-08 16:24:28,110:INFO:_display_container: 2
2024-05-08 16:24:28,110:INFO:Ridge(random_state=123)
2024-05-08 16:24:28,110:INFO:create_model() successfully completed......................................
2024-05-08 16:24:28,219:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:28,219:INFO:Creating metrics dataframe
2024-05-08 16:24:28,225:INFO:Initializing Elastic Net
2024-05-08 16:24:28,225:INFO:Total runtime is 0.0804845372835795 minutes
2024-05-08 16:24:28,227:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:28,228:INFO:Initializing create_model()
2024-05-08 16:24:28,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:28,228:INFO:Checking exceptions
2024-05-08 16:24:28,228:INFO:Importing libraries
2024-05-08 16:24:28,228:INFO:Copying training dataset
2024-05-08 16:24:28,230:INFO:Defining folds
2024-05-08 16:24:28,230:INFO:Declaring metric variables
2024-05-08 16:24:28,232:INFO:Importing untrained model
2024-05-08 16:24:28,234:INFO:Elastic Net Imported successfully
2024-05-08 16:24:28,238:INFO:Starting cross validation
2024-05-08 16:24:28,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:28,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,254:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,256:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,256:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,258:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,258:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:28,262:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,265:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,266:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,271:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,334:INFO:Calculating mean and std
2024-05-08 16:24:28,335:INFO:Creating metrics dataframe
2024-05-08 16:24:28,337:INFO:Uploading results into container
2024-05-08 16:24:28,337:INFO:Uploading model into container now
2024-05-08 16:24:28,338:INFO:_master_model_container: 4
2024-05-08 16:24:28,338:INFO:_display_container: 2
2024-05-08 16:24:28,338:INFO:ElasticNet(random_state=123)
2024-05-08 16:24:28,338:INFO:create_model() successfully completed......................................
2024-05-08 16:24:28,449:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:28,449:INFO:Creating metrics dataframe
2024-05-08 16:24:28,454:INFO:Initializing Least Angle Regression
2024-05-08 16:24:28,454:INFO:Total runtime is 0.08431015412012735 minutes
2024-05-08 16:24:28,456:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:28,456:INFO:Initializing create_model()
2024-05-08 16:24:28,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:28,457:INFO:Checking exceptions
2024-05-08 16:24:28,457:INFO:Importing libraries
2024-05-08 16:24:28,457:INFO:Copying training dataset
2024-05-08 16:24:28,458:INFO:Defining folds
2024-05-08 16:24:28,459:INFO:Declaring metric variables
2024-05-08 16:24:28,461:INFO:Importing untrained model
2024-05-08 16:24:28,463:INFO:Least Angle Regression Imported successfully
2024-05-08 16:24:28,466:INFO:Starting cross validation
2024-05-08 16:24:28,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:28,478:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,481:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,482:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,484:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,486:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,487:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:28,488:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,492:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,494:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,494:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,514:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=1.245e+00, with an active set of 30 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,515:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=6.964e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,516:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.277e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,515:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 43 iterations, i.e. alpha=9.385e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,516:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.026e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,516:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 54 iterations, i.e. alpha=5.560e-02, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=1.011e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,519:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.921e+01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,519:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=6.192e+00, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,519:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.512e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,519:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=3.045e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,520:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=1.142e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,520:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=1.169e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,520:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.393e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,520:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 62 iterations, i.e. alpha=9.744e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,522:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.116e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,522:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 47 iterations, i.e. alpha=4.885e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,522:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.407e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,523:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.113e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,523:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=2.849e-02, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,523:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=4.703e-03, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,538:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.820e-04, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,539:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=6.930e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,540:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 56 iterations, i.e. alpha=3.522e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,541:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=9.316e-04, with an active set of 32 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,542:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.097e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,542:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=3.670e-01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,543:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=4.296e-01, with an active set of 26 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,543:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 59 iterations, i.e. alpha=8.509e-05, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,543:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.733e-05, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,544:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=2.501e-06, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,545:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=4.248e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,545:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=3.808e+00, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,545:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.175e-01, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=2.170e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=1.142e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=3.378e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 65 iterations, i.e. alpha=1.930e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=2.372e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.514e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:24:28,572:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,572:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,572:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,572:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,572:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,572:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:28,573:INFO:Calculating mean and std
2024-05-08 16:24:28,574:INFO:Creating metrics dataframe
2024-05-08 16:24:28,577:INFO:Uploading results into container
2024-05-08 16:24:28,577:INFO:Uploading model into container now
2024-05-08 16:24:28,577:INFO:_master_model_container: 5
2024-05-08 16:24:28,578:INFO:_display_container: 2
2024-05-08 16:24:28,578:INFO:Lars(random_state=123)
2024-05-08 16:24:28,578:INFO:create_model() successfully completed......................................
2024-05-08 16:24:28,684:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:28,684:INFO:Creating metrics dataframe
2024-05-08 16:24:28,689:INFO:Initializing Lasso Least Angle Regression
2024-05-08 16:24:28,689:INFO:Total runtime is 0.08822493155797322 minutes
2024-05-08 16:24:28,691:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:28,691:INFO:Initializing create_model()
2024-05-08 16:24:28,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:28,691:INFO:Checking exceptions
2024-05-08 16:24:28,691:INFO:Importing libraries
2024-05-08 16:24:28,691:INFO:Copying training dataset
2024-05-08 16:24:28,693:INFO:Defining folds
2024-05-08 16:24:28,694:INFO:Declaring metric variables
2024-05-08 16:24:28,695:INFO:Importing untrained model
2024-05-08 16:24:28,697:INFO:Lasso Least Angle Regression Imported successfully
2024-05-08 16:24:28,702:INFO:Starting cross validation
2024-05-08 16:24:28,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:28,715:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,715:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,718:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,720:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,722:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,722:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:28,726:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,731:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,732:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,735:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,802:INFO:Calculating mean and std
2024-05-08 16:24:28,802:INFO:Creating metrics dataframe
2024-05-08 16:24:28,804:INFO:Uploading results into container
2024-05-08 16:24:28,805:INFO:Uploading model into container now
2024-05-08 16:24:28,805:INFO:_master_model_container: 6
2024-05-08 16:24:28,805:INFO:_display_container: 2
2024-05-08 16:24:28,805:INFO:LassoLars(random_state=123)
2024-05-08 16:24:28,806:INFO:create_model() successfully completed......................................
2024-05-08 16:24:28,911:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:28,911:INFO:Creating metrics dataframe
2024-05-08 16:24:28,916:INFO:Initializing Orthogonal Matching Pursuit
2024-05-08 16:24:28,917:INFO:Total runtime is 0.09201307694117228 minutes
2024-05-08 16:24:28,918:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:28,918:INFO:Initializing create_model()
2024-05-08 16:24:28,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:28,918:INFO:Checking exceptions
2024-05-08 16:24:28,918:INFO:Importing libraries
2024-05-08 16:24:28,919:INFO:Copying training dataset
2024-05-08 16:24:28,921:INFO:Defining folds
2024-05-08 16:24:28,921:INFO:Declaring metric variables
2024-05-08 16:24:28,923:INFO:Importing untrained model
2024-05-08 16:24:28,926:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-08 16:24:28,930:INFO:Starting cross validation
2024-05-08 16:24:28,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:28,943:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,946:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,947:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,952:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,952:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:28,953:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,958:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,960:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:28,962:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,031:INFO:Calculating mean and std
2024-05-08 16:24:29,032:INFO:Creating metrics dataframe
2024-05-08 16:24:29,034:INFO:Uploading results into container
2024-05-08 16:24:29,034:INFO:Uploading model into container now
2024-05-08 16:24:29,034:INFO:_master_model_container: 7
2024-05-08 16:24:29,034:INFO:_display_container: 2
2024-05-08 16:24:29,034:INFO:OrthogonalMatchingPursuit()
2024-05-08 16:24:29,035:INFO:create_model() successfully completed......................................
2024-05-08 16:24:29,149:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:29,150:INFO:Creating metrics dataframe
2024-05-08 16:24:29,155:INFO:Initializing Bayesian Ridge
2024-05-08 16:24:29,155:INFO:Total runtime is 0.09598764578501383 minutes
2024-05-08 16:24:29,157:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:29,157:INFO:Initializing create_model()
2024-05-08 16:24:29,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:29,157:INFO:Checking exceptions
2024-05-08 16:24:29,157:INFO:Importing libraries
2024-05-08 16:24:29,157:INFO:Copying training dataset
2024-05-08 16:24:29,159:INFO:Defining folds
2024-05-08 16:24:29,159:INFO:Declaring metric variables
2024-05-08 16:24:29,161:INFO:Importing untrained model
2024-05-08 16:24:29,163:INFO:Bayesian Ridge Imported successfully
2024-05-08 16:24:29,167:INFO:Starting cross validation
2024-05-08 16:24:29,167:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:29,180:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,182:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,184:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,186:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,186:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,186:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:29,190:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,194:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,197:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,200:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,238:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,238:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,238:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,268:INFO:Calculating mean and std
2024-05-08 16:24:29,269:INFO:Creating metrics dataframe
2024-05-08 16:24:29,271:INFO:Uploading results into container
2024-05-08 16:24:29,272:INFO:Uploading model into container now
2024-05-08 16:24:29,272:INFO:_master_model_container: 8
2024-05-08 16:24:29,272:INFO:_display_container: 2
2024-05-08 16:24:29,273:INFO:BayesianRidge()
2024-05-08 16:24:29,273:INFO:create_model() successfully completed......................................
2024-05-08 16:24:29,388:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:29,388:INFO:Creating metrics dataframe
2024-05-08 16:24:29,393:INFO:Initializing Passive Aggressive Regressor
2024-05-08 16:24:29,393:INFO:Total runtime is 0.09995652834574381 minutes
2024-05-08 16:24:29,395:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:29,395:INFO:Initializing create_model()
2024-05-08 16:24:29,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:29,395:INFO:Checking exceptions
2024-05-08 16:24:29,395:INFO:Importing libraries
2024-05-08 16:24:29,395:INFO:Copying training dataset
2024-05-08 16:24:29,397:INFO:Defining folds
2024-05-08 16:24:29,398:INFO:Declaring metric variables
2024-05-08 16:24:29,400:INFO:Importing untrained model
2024-05-08 16:24:29,402:INFO:Passive Aggressive Regressor Imported successfully
2024-05-08 16:24:29,405:INFO:Starting cross validation
2024-05-08 16:24:29,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:29,418:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,419:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,422:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,424:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,427:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,427:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:29,429:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,431:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,436:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,438:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,484:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,484:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,485:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,485:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,485:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,485:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,505:INFO:Calculating mean and std
2024-05-08 16:24:29,506:INFO:Creating metrics dataframe
2024-05-08 16:24:29,508:INFO:Uploading results into container
2024-05-08 16:24:29,508:INFO:Uploading model into container now
2024-05-08 16:24:29,509:INFO:_master_model_container: 9
2024-05-08 16:24:29,509:INFO:_display_container: 2
2024-05-08 16:24:29,509:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-08 16:24:29,509:INFO:create_model() successfully completed......................................
2024-05-08 16:24:29,621:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:29,621:INFO:Creating metrics dataframe
2024-05-08 16:24:29,626:INFO:Initializing Huber Regressor
2024-05-08 16:24:29,626:INFO:Total runtime is 0.10384395122528076 minutes
2024-05-08 16:24:29,628:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:29,628:INFO:Initializing create_model()
2024-05-08 16:24:29,628:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:29,628:INFO:Checking exceptions
2024-05-08 16:24:29,628:INFO:Importing libraries
2024-05-08 16:24:29,629:INFO:Copying training dataset
2024-05-08 16:24:29,631:INFO:Defining folds
2024-05-08 16:24:29,631:INFO:Declaring metric variables
2024-05-08 16:24:29,633:INFO:Importing untrained model
2024-05-08 16:24:29,636:INFO:Huber Regressor Imported successfully
2024-05-08 16:24:29,639:INFO:Starting cross validation
2024-05-08 16:24:29,640:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:29,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,655:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,657:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,660:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,665:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,665:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:29,668:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,674:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,679:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,682:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,697:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,712:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,721:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,733:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,734:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,741:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,748:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,752:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,757:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:24:29,771:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:24:29,775:INFO:Calculating mean and std
2024-05-08 16:24:29,775:INFO:Creating metrics dataframe
2024-05-08 16:24:29,777:INFO:Uploading results into container
2024-05-08 16:24:29,778:INFO:Uploading model into container now
2024-05-08 16:24:29,778:INFO:_master_model_container: 10
2024-05-08 16:24:29,778:INFO:_display_container: 2
2024-05-08 16:24:29,779:INFO:HuberRegressor()
2024-05-08 16:24:29,779:INFO:create_model() successfully completed......................................
2024-05-08 16:24:29,884:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:29,884:INFO:Creating metrics dataframe
2024-05-08 16:24:29,890:INFO:Initializing K Neighbors Regressor
2024-05-08 16:24:29,890:INFO:Total runtime is 0.10823042392730713 minutes
2024-05-08 16:24:29,891:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:29,891:INFO:Initializing create_model()
2024-05-08 16:24:29,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:29,891:INFO:Checking exceptions
2024-05-08 16:24:29,892:INFO:Importing libraries
2024-05-08 16:24:29,892:INFO:Copying training dataset
2024-05-08 16:24:29,894:INFO:Defining folds
2024-05-08 16:24:29,894:INFO:Declaring metric variables
2024-05-08 16:24:29,896:INFO:Importing untrained model
2024-05-08 16:24:29,897:INFO:K Neighbors Regressor Imported successfully
2024-05-08 16:24:29,901:INFO:Starting cross validation
2024-05-08 16:24:29,901:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:29,914:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,917:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,917:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,919:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,920:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,920:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:29,924:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,928:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,933:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:29,935:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,042:INFO:Calculating mean and std
2024-05-08 16:24:30,043:INFO:Creating metrics dataframe
2024-05-08 16:24:30,045:INFO:Uploading results into container
2024-05-08 16:24:30,046:INFO:Uploading model into container now
2024-05-08 16:24:30,046:INFO:_master_model_container: 11
2024-05-08 16:24:30,046:INFO:_display_container: 2
2024-05-08 16:24:30,046:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-08 16:24:30,046:INFO:create_model() successfully completed......................................
2024-05-08 16:24:30,151:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:30,152:INFO:Creating metrics dataframe
2024-05-08 16:24:30,157:INFO:Initializing Decision Tree Regressor
2024-05-08 16:24:30,157:INFO:Total runtime is 0.11269206206003825 minutes
2024-05-08 16:24:30,159:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:30,159:INFO:Initializing create_model()
2024-05-08 16:24:30,159:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:30,159:INFO:Checking exceptions
2024-05-08 16:24:30,159:INFO:Importing libraries
2024-05-08 16:24:30,159:INFO:Copying training dataset
2024-05-08 16:24:30,162:INFO:Defining folds
2024-05-08 16:24:30,162:INFO:Declaring metric variables
2024-05-08 16:24:30,163:INFO:Importing untrained model
2024-05-08 16:24:30,166:INFO:Decision Tree Regressor Imported successfully
2024-05-08 16:24:30,169:INFO:Starting cross validation
2024-05-08 16:24:30,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:30,184:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,185:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,185:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,188:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,189:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,189:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:30,192:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,198:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,202:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,205:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,277:INFO:Calculating mean and std
2024-05-08 16:24:30,278:INFO:Creating metrics dataframe
2024-05-08 16:24:30,280:INFO:Uploading results into container
2024-05-08 16:24:30,280:INFO:Uploading model into container now
2024-05-08 16:24:30,281:INFO:_master_model_container: 12
2024-05-08 16:24:30,281:INFO:_display_container: 2
2024-05-08 16:24:30,281:INFO:DecisionTreeRegressor(random_state=123)
2024-05-08 16:24:30,281:INFO:create_model() successfully completed......................................
2024-05-08 16:24:30,387:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:30,387:INFO:Creating metrics dataframe
2024-05-08 16:24:30,393:INFO:Initializing Random Forest Regressor
2024-05-08 16:24:30,393:INFO:Total runtime is 0.11661802530288697 minutes
2024-05-08 16:24:30,394:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:30,395:INFO:Initializing create_model()
2024-05-08 16:24:30,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:30,395:INFO:Checking exceptions
2024-05-08 16:24:30,395:INFO:Importing libraries
2024-05-08 16:24:30,395:INFO:Copying training dataset
2024-05-08 16:24:30,397:INFO:Defining folds
2024-05-08 16:24:30,397:INFO:Declaring metric variables
2024-05-08 16:24:30,399:INFO:Importing untrained model
2024-05-08 16:24:30,401:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:24:30,405:INFO:Starting cross validation
2024-05-08 16:24:30,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:30,421:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,423:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,425:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,429:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,429:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,430:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:30,434:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,438:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,444:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:30,448:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,121:INFO:Calculating mean and std
2024-05-08 16:24:31,123:INFO:Creating metrics dataframe
2024-05-08 16:24:31,125:INFO:Uploading results into container
2024-05-08 16:24:31,125:INFO:Uploading model into container now
2024-05-08 16:24:31,125:INFO:_master_model_container: 13
2024-05-08 16:24:31,125:INFO:_display_container: 2
2024-05-08 16:24:31,125:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:24:31,125:INFO:create_model() successfully completed......................................
2024-05-08 16:24:31,226:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:31,226:INFO:Creating metrics dataframe
2024-05-08 16:24:31,232:INFO:Initializing Extra Trees Regressor
2024-05-08 16:24:31,232:INFO:Total runtime is 0.13060166835784912 minutes
2024-05-08 16:24:31,234:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:31,234:INFO:Initializing create_model()
2024-05-08 16:24:31,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:31,234:INFO:Checking exceptions
2024-05-08 16:24:31,234:INFO:Importing libraries
2024-05-08 16:24:31,234:INFO:Copying training dataset
2024-05-08 16:24:31,236:INFO:Defining folds
2024-05-08 16:24:31,236:INFO:Declaring metric variables
2024-05-08 16:24:31,238:INFO:Importing untrained model
2024-05-08 16:24:31,240:INFO:Extra Trees Regressor Imported successfully
2024-05-08 16:24:31,244:INFO:Starting cross validation
2024-05-08 16:24:31,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:31,259:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,262:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,264:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,267:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,269:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,269:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:31,273:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,277:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,280:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,281:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,616:INFO:Calculating mean and std
2024-05-08 16:24:31,616:INFO:Creating metrics dataframe
2024-05-08 16:24:31,618:INFO:Uploading results into container
2024-05-08 16:24:31,619:INFO:Uploading model into container now
2024-05-08 16:24:31,619:INFO:_master_model_container: 14
2024-05-08 16:24:31,619:INFO:_display_container: 2
2024-05-08 16:24:31,619:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:24:31,619:INFO:create_model() successfully completed......................................
2024-05-08 16:24:31,719:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:31,719:INFO:Creating metrics dataframe
2024-05-08 16:24:31,725:INFO:Initializing AdaBoost Regressor
2024-05-08 16:24:31,725:INFO:Total runtime is 0.13882914781570435 minutes
2024-05-08 16:24:31,727:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:31,727:INFO:Initializing create_model()
2024-05-08 16:24:31,727:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:31,727:INFO:Checking exceptions
2024-05-08 16:24:31,727:INFO:Importing libraries
2024-05-08 16:24:31,727:INFO:Copying training dataset
2024-05-08 16:24:31,729:INFO:Defining folds
2024-05-08 16:24:31,730:INFO:Declaring metric variables
2024-05-08 16:24:31,732:INFO:Importing untrained model
2024-05-08 16:24:31,734:INFO:AdaBoost Regressor Imported successfully
2024-05-08 16:24:31,737:INFO:Starting cross validation
2024-05-08 16:24:31,738:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:31,751:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,753:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,755:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,756:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,757:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,757:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:31,760:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,763:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,765:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,767:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:31,989:INFO:Calculating mean and std
2024-05-08 16:24:31,990:INFO:Creating metrics dataframe
2024-05-08 16:24:31,992:INFO:Uploading results into container
2024-05-08 16:24:31,992:INFO:Uploading model into container now
2024-05-08 16:24:31,993:INFO:_master_model_container: 15
2024-05-08 16:24:31,993:INFO:_display_container: 2
2024-05-08 16:24:31,993:INFO:AdaBoostRegressor(random_state=123)
2024-05-08 16:24:31,993:INFO:create_model() successfully completed......................................
2024-05-08 16:24:32,096:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:32,096:INFO:Creating metrics dataframe
2024-05-08 16:24:32,102:INFO:Initializing Gradient Boosting Regressor
2024-05-08 16:24:32,102:INFO:Total runtime is 0.14510362148284914 minutes
2024-05-08 16:24:32,104:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:32,104:INFO:Initializing create_model()
2024-05-08 16:24:32,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:32,104:INFO:Checking exceptions
2024-05-08 16:24:32,104:INFO:Importing libraries
2024-05-08 16:24:32,104:INFO:Copying training dataset
2024-05-08 16:24:32,106:INFO:Defining folds
2024-05-08 16:24:32,106:INFO:Declaring metric variables
2024-05-08 16:24:32,108:INFO:Importing untrained model
2024-05-08 16:24:32,110:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:24:32,114:INFO:Starting cross validation
2024-05-08 16:24:32,115:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:32,130:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,133:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,136:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,140:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,140:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:32,144:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,150:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,154:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,157:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,623:INFO:Calculating mean and std
2024-05-08 16:24:32,624:INFO:Creating metrics dataframe
2024-05-08 16:24:32,626:INFO:Uploading results into container
2024-05-08 16:24:32,626:INFO:Uploading model into container now
2024-05-08 16:24:32,627:INFO:_master_model_container: 16
2024-05-08 16:24:32,627:INFO:_display_container: 2
2024-05-08 16:24:32,627:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:24:32,627:INFO:create_model() successfully completed......................................
2024-05-08 16:24:32,727:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:32,727:INFO:Creating metrics dataframe
2024-05-08 16:24:32,733:INFO:Initializing Light Gradient Boosting Machine
2024-05-08 16:24:32,733:INFO:Total runtime is 0.1556246598561605 minutes
2024-05-08 16:24:32,735:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:32,735:INFO:Initializing create_model()
2024-05-08 16:24:32,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:32,735:INFO:Checking exceptions
2024-05-08 16:24:32,735:INFO:Importing libraries
2024-05-08 16:24:32,736:INFO:Copying training dataset
2024-05-08 16:24:32,738:INFO:Defining folds
2024-05-08 16:24:32,738:INFO:Declaring metric variables
2024-05-08 16:24:32,740:INFO:Importing untrained model
2024-05-08 16:24:32,742:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-08 16:24:32,745:INFO:Starting cross validation
2024-05-08 16:24:32,746:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:32,760:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,762:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,762:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,765:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,766:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,766:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:32,770:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,773:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,773:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:32,778:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,400:INFO:Calculating mean and std
2024-05-08 16:24:33,401:INFO:Creating metrics dataframe
2024-05-08 16:24:33,403:INFO:Uploading results into container
2024-05-08 16:24:33,403:INFO:Uploading model into container now
2024-05-08 16:24:33,404:INFO:_master_model_container: 17
2024-05-08 16:24:33,404:INFO:_display_container: 2
2024-05-08 16:24:33,404:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:24:33,404:INFO:create_model() successfully completed......................................
2024-05-08 16:24:33,506:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:33,506:INFO:Creating metrics dataframe
2024-05-08 16:24:33,512:INFO:Initializing Dummy Regressor
2024-05-08 16:24:33,512:INFO:Total runtime is 0.16861056486765547 minutes
2024-05-08 16:24:33,514:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:33,514:INFO:Initializing create_model()
2024-05-08 16:24:33,514:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8bebcfc70>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:33,514:INFO:Checking exceptions
2024-05-08 16:24:33,514:INFO:Importing libraries
2024-05-08 16:24:33,514:INFO:Copying training dataset
2024-05-08 16:24:33,516:INFO:Defining folds
2024-05-08 16:24:33,516:INFO:Declaring metric variables
2024-05-08 16:24:33,518:INFO:Importing untrained model
2024-05-08 16:24:33,522:INFO:Dummy Regressor Imported successfully
2024-05-08 16:24:33,527:INFO:Starting cross validation
2024-05-08 16:24:33,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:33,541:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,542:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,543:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:33,547:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,550:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,554:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,556:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,557:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:33,619:INFO:Calculating mean and std
2024-05-08 16:24:33,620:INFO:Creating metrics dataframe
2024-05-08 16:24:33,623:INFO:Uploading results into container
2024-05-08 16:24:33,624:INFO:Uploading model into container now
2024-05-08 16:24:33,624:INFO:_master_model_container: 18
2024-05-08 16:24:33,624:INFO:_display_container: 2
2024-05-08 16:24:33,625:INFO:DummyRegressor()
2024-05-08 16:24:33,625:INFO:create_model() successfully completed......................................
2024-05-08 16:24:33,738:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:33,738:INFO:Creating metrics dataframe
2024-05-08 16:24:33,750:INFO:Initializing create_model()
2024-05-08 16:24:33,750:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:33,750:INFO:Checking exceptions
2024-05-08 16:24:33,752:INFO:Importing libraries
2024-05-08 16:24:33,752:INFO:Copying training dataset
2024-05-08 16:24:33,753:INFO:Defining folds
2024-05-08 16:24:33,754:INFO:Declaring metric variables
2024-05-08 16:24:33,754:INFO:Importing untrained model
2024-05-08 16:24:33,754:INFO:Declaring custom model
2024-05-08 16:24:33,754:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:24:33,755:INFO:Cross validation set to False
2024-05-08 16:24:33,755:INFO:Fitting Model
2024-05-08 16:24:33,757:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,083:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:24:34,083:INFO:create_model() successfully completed......................................
2024-05-08 16:24:34,200:INFO:_master_model_container: 18
2024-05-08 16:24:34,200:INFO:_display_container: 2
2024-05-08 16:24:34,200:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:24:34,200:INFO:compare_models() successfully completed......................................
2024-05-08 16:24:34,201:INFO:Initializing tune_model()
2024-05-08 16:24:34,201:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>)
2024-05-08 16:24:34,201:INFO:Checking exceptions
2024-05-08 16:24:34,209:INFO:Copying training dataset
2024-05-08 16:24:34,211:INFO:Checking base model
2024-05-08 16:24:34,211:INFO:Base model : Gradient Boosting Regressor
2024-05-08 16:24:34,213:INFO:Declaring metric variables
2024-05-08 16:24:34,214:INFO:Defining Hyperparameters
2024-05-08 16:24:34,331:INFO:Tuning with n_jobs=-1
2024-05-08 16:24:34,332:INFO:Initializing RandomizedSearchCV
2024-05-08 16:24:34,357:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,358:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,358:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,359:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,360:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,360:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:34,363:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,365:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,367:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,368:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,370:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,371:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,386:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,386:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,389:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,389:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:34,390:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,632:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,643:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,646:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,657:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,667:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,737:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,745:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,815:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,816:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:34,823:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,889:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,897:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,901:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,904:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,908:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,960:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:34,960:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:34,978:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,093:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,108:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,114:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,120:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,122:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,142:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,165:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,165:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:35,212:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,222:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,245:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,262:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,311:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,322:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,326:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,326:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,327:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:35,330:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,390:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,433:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,434:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,454:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,455:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,523:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,523:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:35,531:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,539:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,546:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,560:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,616:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,655:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,702:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,754:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:35,811:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,836:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,873:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,904:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,915:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,916:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,920:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,923:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,927:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:35,927:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:35,929:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,138:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,142:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,145:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,146:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,152:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,262:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,350:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,351:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:36,355:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,360:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,533:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:36,614:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,695:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2024-05-08 16:24:37,695:INFO:Hyperparameter search completed
2024-05-08 16:24:37,695:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:37,696:INFO:Initializing create_model()
2024-05-08 16:24:37,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8c4541f10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2024-05-08 16:24:37,696:INFO:Checking exceptions
2024-05-08 16:24:37,696:INFO:Importing libraries
2024-05-08 16:24:37,696:INFO:Copying training dataset
2024-05-08 16:24:37,698:INFO:Defining folds
2024-05-08 16:24:37,698:INFO:Declaring metric variables
2024-05-08 16:24:37,700:INFO:Importing untrained model
2024-05-08 16:24:37,700:INFO:Declaring custom model
2024-05-08 16:24:37,702:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:24:37,706:INFO:Starting cross validation
2024-05-08 16:24:37,706:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:37,718:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,720:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,722:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,724:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,727:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,727:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:37,728:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,732:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,733:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:37,733:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:39,436:INFO:Calculating mean and std
2024-05-08 16:24:39,436:INFO:Creating metrics dataframe
2024-05-08 16:24:39,439:INFO:Finalizing model
2024-05-08 16:24:39,442:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,567:INFO:Uploading results into container
2024-05-08 16:24:40,567:INFO:Uploading model into container now
2024-05-08 16:24:40,567:INFO:_master_model_container: 19
2024-05-08 16:24:40,567:INFO:_display_container: 3
2024-05-08 16:24:40,568:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85)
2024-05-08 16:24:40,568:INFO:create_model() successfully completed......................................
2024-05-08 16:24:40,673:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:40,674:INFO:choose_better activated
2024-05-08 16:24:40,676:INFO:SubProcess create_model() called ==================================
2024-05-08 16:24:40,676:INFO:Initializing create_model()
2024-05-08 16:24:40,676:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:40,676:INFO:Checking exceptions
2024-05-08 16:24:40,677:INFO:Importing libraries
2024-05-08 16:24:40,677:INFO:Copying training dataset
2024-05-08 16:24:40,679:INFO:Defining folds
2024-05-08 16:24:40,679:INFO:Declaring metric variables
2024-05-08 16:24:40,679:INFO:Importing untrained model
2024-05-08 16:24:40,679:INFO:Declaring custom model
2024-05-08 16:24:40,680:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:24:40,680:INFO:Starting cross validation
2024-05-08 16:24:40,680:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:24:40,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,693:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,700:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,700:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:24:40,701:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,705:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,707:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:40,709:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:41,203:INFO:Calculating mean and std
2024-05-08 16:24:41,203:INFO:Creating metrics dataframe
2024-05-08 16:24:41,205:INFO:Finalizing model
2024-05-08 16:24:41,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:41,507:INFO:Uploading results into container
2024-05-08 16:24:41,507:INFO:Uploading model into container now
2024-05-08 16:24:41,507:INFO:_master_model_container: 20
2024-05-08 16:24:41,507:INFO:_display_container: 4
2024-05-08 16:24:41,507:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:24:41,507:INFO:create_model() successfully completed......................................
2024-05-08 16:24:41,606:INFO:SubProcess create_model() end ==================================
2024-05-08 16:24:41,607:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.7785
2024-05-08 16:24:41,607:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85) result for R2 is 0.6652
2024-05-08 16:24:41,607:INFO:GradientBoostingRegressor(random_state=123) is best model
2024-05-08 16:24:41,608:INFO:choose_better completed
2024-05-08 16:24:41,608:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-08 16:24:41,613:INFO:_master_model_container: 20
2024-05-08 16:24:41,613:INFO:_display_container: 3
2024-05-08 16:24:41,613:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:24:41,613:INFO:tune_model() successfully completed......................................
2024-05-08 16:24:41,720:INFO:Initializing finalize_model()
2024-05-08 16:24:41,720:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=GradientBoostingRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-08 16:24:41,720:INFO:Finalizing GradientBoostingRegressor(random_state=123)
2024-05-08 16:24:41,722:INFO:Initializing create_model()
2024-05-08 16:24:41,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:24:41,722:INFO:Checking exceptions
2024-05-08 16:24:41,723:INFO:Importing libraries
2024-05-08 16:24:41,723:INFO:Copying training dataset
2024-05-08 16:24:41,724:INFO:Defining folds
2024-05-08 16:24:41,724:INFO:Declaring metric variables
2024-05-08 16:24:41,724:INFO:Importing untrained model
2024-05-08 16:24:41,724:INFO:Declaring custom model
2024-05-08 16:24:41,724:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:24:41,725:INFO:Cross validation set to False
2024-05-08 16:24:41,725:INFO:Fitting Model
2024-05-08 16:24:41,727:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:24:42,160:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2024-05-08 16:24:42,160:INFO:create_model() successfully completed......................................
2024-05-08 16:24:42,257:INFO:_master_model_container: 20
2024-05-08 16:24:42,257:INFO:_display_container: 3
2024-05-08 16:24:42,262:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2024-05-08 16:24:42,262:INFO:finalize_model() successfully completed......................................
2024-05-08 16:24:42,367:INFO:Initializing predict_model()
2024-05-08 16:24:42,367:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b4f3d700>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x74c8b62145e0>)
2024-05-08 16:24:42,367:INFO:Checking exceptions
2024-05-08 16:24:42,367:INFO:Preloading libraries
2024-05-08 16:24:42,368:INFO:Set up data.
2024-05-08 16:24:42,370:INFO:Set up index.
2024-05-08 16:24:42,384:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-08 16:29:06,019:WARNING:/tmp/ipykernel_19548/2317310308.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-08 16:29:19,423:WARNING:/tmp/ipykernel_19548/3367873080.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-08 16:29:49,957:WARNING:/tmp/ipykernel_19548/881686184.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-08 16:29:56,215:INFO:PyCaret RegressionExperiment
2024-05-08 16:29:56,215:INFO:Logging name: reg-default-name
2024-05-08 16:29:56,216:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-08 16:29:56,216:INFO:version 3.3.2
2024-05-08 16:29:56,216:INFO:Initializing setup()
2024-05-08 16:29:56,217:INFO:self.USI: 29b8
2024-05-08 16:29:56,217:INFO:self._variable_keys: {'y_train', 'X_test', 'seed', 'exp_name_log', 'X', 'y_test', '_ml_usecase', 'log_plots_param', 'idx', '_available_plots', 'html_param', 'exp_id', 'pipeline', 'n_jobs_param', 'data', 'fold_generator', 'transform_target_param', 'X_train', 'fold_groups_param', 'logging_param', 'gpu_param', 'USI', 'gpu_n_jobs_param', 'fold_shuffle_param', 'target_param', 'memory', 'y'}
2024-05-08 16:29:56,217:INFO:Checking environment
2024-05-08 16:29:56,217:INFO:python_version: 3.9.18
2024-05-08 16:29:56,217:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-08 16:29:56,217:INFO:machine: x86_64
2024-05-08 16:29:56,217:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:29:56,217:INFO:Memory: svmem(total=16429801472, available=6713872384, percent=59.1, used=8551346176, free=2973241344, active=7179411456, inactive=4949176320, buffers=137342976, cached=4767870976, shared=817975296, slab=659910656)
2024-05-08 16:29:56,219:INFO:Physical Core: 12
2024-05-08 16:29:56,219:INFO:Logical Core: 16
2024-05-08 16:29:56,219:INFO:Checking libraries
2024-05-08 16:29:56,219:INFO:System:
2024-05-08 16:29:56,219:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-08 16:29:56,219:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-08 16:29:56,219:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:29:56,219:INFO:PyCaret required dependencies:
2024-05-08 16:29:56,219:INFO:                 pip: 23.2.1
2024-05-08 16:29:56,219:INFO:          setuptools: 68.0.0
2024-05-08 16:29:56,219:INFO:             pycaret: 3.3.2
2024-05-08 16:29:56,219:INFO:             IPython: 8.15.0
2024-05-08 16:29:56,219:INFO:          ipywidgets: 8.0.4
2024-05-08 16:29:56,219:INFO:                tqdm: 4.65.0
2024-05-08 16:29:56,219:INFO:               numpy: 1.24.3
2024-05-08 16:29:56,219:INFO:              pandas: 1.4.2
2024-05-08 16:29:56,219:INFO:              jinja2: 3.1.4
2024-05-08 16:29:56,219:INFO:               scipy: 1.11.3
2024-05-08 16:29:56,219:INFO:              joblib: 1.2.0
2024-05-08 16:29:56,219:INFO:             sklearn: 1.4.2
2024-05-08 16:29:56,219:INFO:                pyod: 1.1.3
2024-05-08 16:29:56,219:INFO:            imblearn: 0.12.2
2024-05-08 16:29:56,219:INFO:   category_encoders: 2.6.3
2024-05-08 16:29:56,219:INFO:            lightgbm: 4.3.0
2024-05-08 16:29:56,219:INFO:               numba: 0.58.0
2024-05-08 16:29:56,219:INFO:            requests: 2.31.0
2024-05-08 16:29:56,219:INFO:          matplotlib: 3.7.2
2024-05-08 16:29:56,219:INFO:          scikitplot: 0.3.7
2024-05-08 16:29:56,220:INFO:         yellowbrick: 1.5
2024-05-08 16:29:56,220:INFO:              plotly: 5.22.0
2024-05-08 16:29:56,220:INFO:    plotly-resampler: Not installed
2024-05-08 16:29:56,220:INFO:             kaleido: 0.2.1
2024-05-08 16:29:56,220:INFO:           schemdraw: 0.15
2024-05-08 16:29:56,220:INFO:         statsmodels: 0.14.0
2024-05-08 16:29:56,220:INFO:              sktime: 0.26.0
2024-05-08 16:29:56,220:INFO:               tbats: 1.1.3
2024-05-08 16:29:56,221:INFO:            pmdarima: 2.0.4
2024-05-08 16:29:56,222:INFO:              psutil: 5.9.0
2024-05-08 16:29:56,222:INFO:          markupsafe: 2.0.1
2024-05-08 16:29:56,222:INFO:             pickle5: Not installed
2024-05-08 16:29:56,222:INFO:         cloudpickle: 2.2.1
2024-05-08 16:29:56,222:INFO:         deprecation: 2.1.0
2024-05-08 16:29:56,222:INFO:              xxhash: 2.0.2
2024-05-08 16:29:56,222:INFO:           wurlitzer: 3.0.2
2024-05-08 16:29:56,222:INFO:PyCaret optional dependencies:
2024-05-08 16:29:56,222:INFO:                shap: Not installed
2024-05-08 16:29:56,222:INFO:           interpret: Not installed
2024-05-08 16:29:56,222:INFO:                umap: Not installed
2024-05-08 16:29:56,222:INFO:     ydata_profiling: Not installed
2024-05-08 16:29:56,222:INFO:  explainerdashboard: Not installed
2024-05-08 16:29:56,222:INFO:             autoviz: Not installed
2024-05-08 16:29:56,222:INFO:           fairlearn: Not installed
2024-05-08 16:29:56,222:INFO:          deepchecks: Not installed
2024-05-08 16:29:56,222:INFO:             xgboost: Not installed
2024-05-08 16:29:56,222:INFO:            catboost: Not installed
2024-05-08 16:29:56,222:INFO:              kmodes: Not installed
2024-05-08 16:29:56,222:INFO:             mlxtend: Not installed
2024-05-08 16:29:56,222:INFO:       statsforecast: Not installed
2024-05-08 16:29:56,222:INFO:        tune_sklearn: Not installed
2024-05-08 16:29:56,222:INFO:                 ray: Not installed
2024-05-08 16:29:56,222:INFO:            hyperopt: Not installed
2024-05-08 16:29:56,222:INFO:              optuna: Not installed
2024-05-08 16:29:56,222:INFO:               skopt: Not installed
2024-05-08 16:29:56,222:INFO:              mlflow: Not installed
2024-05-08 16:29:56,222:INFO:              gradio: Not installed
2024-05-08 16:29:56,222:INFO:             fastapi: Not installed
2024-05-08 16:29:56,222:INFO:             uvicorn: Not installed
2024-05-08 16:29:56,222:INFO:              m2cgen: Not installed
2024-05-08 16:29:56,222:INFO:           evidently: Not installed
2024-05-08 16:29:56,222:INFO:               fugue: Not installed
2024-05-08 16:29:56,222:INFO:           streamlit: Not installed
2024-05-08 16:29:56,223:INFO:             prophet: Not installed
2024-05-08 16:29:56,223:INFO:None
2024-05-08 16:29:56,223:INFO:Set up data.
2024-05-08 16:29:56,232:INFO:Set up folding strategy.
2024-05-08 16:29:56,232:INFO:Set up train/test split.
2024-05-08 16:29:56,235:INFO:Set up index.
2024-05-08 16:29:56,235:INFO:Assigning column types.
2024-05-08 16:29:56,237:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-08 16:29:56,238:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,242:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,251:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,333:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,366:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,366:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,366:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,367:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,369:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,371:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,424:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,424:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,424:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-08 16:29:56,428:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,431:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,455:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,475:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,475:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,476:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,478:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,480:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,506:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,526:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,527:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,527:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,527:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-08 16:29:56,532:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,559:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,579:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,579:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,580:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,584:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,610:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,631:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,631:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,631:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,631:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-08 16:29:56,662:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,682:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,682:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,682:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,713:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,733:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,733:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-08 16:29:56,763:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:29:56,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,835:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-08 16:29:56,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,939:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,939:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:56,940:INFO:Preparing preprocessing pipeline...
2024-05-08 16:29:56,940:INFO:Set up target transformation.
2024-05-08 16:29:56,940:INFO:Set up date feature engineering.
2024-05-08 16:29:56,940:INFO:Set up simple imputation.
2024-05-08 16:29:56,940:INFO:Set up polynomial features.
2024-05-08 16:29:56,940:INFO:Set up feature normalization.
2024-05-08 16:29:56,940:INFO:Set up column name cleaning.
2024-05-08 16:29:56,944:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:56,969:INFO:Finished creating preprocessing pipeline.
2024-05-08 16:29:56,974:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-08 16:29:56,974:INFO:Creating final display dataframe.
2024-05-08 16:29:57,061:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (552, 7)
4        Transformed data shape         (552, 45)
5   Transformed train set shape         (386, 45)
6    Transformed test set shape         (166, 45)
7              Numeric features                 5
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13          Polynomial features              True
14            Polynomial degree                 2
15                    Normalize              True
16             Normalize method            zscore
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              29b8
2024-05-08 16:29:57,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:57,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:57,200:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:57,200:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:29:57,200:INFO:setup() successfully completed in 0.99s...............
2024-05-08 16:29:57,201:INFO:Initializing compare_models()
2024-05-08 16:29:57,201:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-08 16:29:57,201:INFO:Checking exceptions
2024-05-08 16:29:57,202:INFO:Preparing display monitor
2024-05-08 16:29:57,220:INFO:Initializing Linear Regression
2024-05-08 16:29:57,220:INFO:Total runtime is 1.9629796346028644e-06 minutes
2024-05-08 16:29:57,223:INFO:SubProcess create_model() called ==================================
2024-05-08 16:29:57,223:INFO:Initializing create_model()
2024-05-08 16:29:57,223:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:29:57,223:INFO:Checking exceptions
2024-05-08 16:29:57,223:INFO:Importing libraries
2024-05-08 16:29:57,223:INFO:Copying training dataset
2024-05-08 16:29:57,226:INFO:Defining folds
2024-05-08 16:29:57,226:INFO:Declaring metric variables
2024-05-08 16:29:57,230:INFO:Importing untrained model
2024-05-08 16:29:57,233:INFO:Linear Regression Imported successfully
2024-05-08 16:29:57,238:INFO:Starting cross validation
2024-05-08 16:29:57,239:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:29:59,007:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,205:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,253:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,255:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,506:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,586:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,589:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,589:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:29:59,605:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,618:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:29:59,816:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:29:59,817:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:29:59,817:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:29:59,817:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:29:59,817:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:29:59,817:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:29:59,820:INFO:Calculating mean and std
2024-05-08 16:29:59,821:INFO:Creating metrics dataframe
2024-05-08 16:29:59,827:INFO:Uploading results into container
2024-05-08 16:29:59,828:INFO:Uploading model into container now
2024-05-08 16:29:59,828:INFO:_master_model_container: 1
2024-05-08 16:29:59,829:INFO:_display_container: 2
2024-05-08 16:29:59,830:INFO:LinearRegression(n_jobs=-1)
2024-05-08 16:29:59,830:INFO:create_model() successfully completed......................................
2024-05-08 16:29:59,971:INFO:SubProcess create_model() end ==================================
2024-05-08 16:29:59,971:INFO:Creating metrics dataframe
2024-05-08 16:29:59,976:INFO:Initializing Lasso Regression
2024-05-08 16:29:59,976:INFO:Total runtime is 0.04593707323074341 minutes
2024-05-08 16:29:59,978:INFO:SubProcess create_model() called ==================================
2024-05-08 16:29:59,978:INFO:Initializing create_model()
2024-05-08 16:29:59,978:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:29:59,978:INFO:Checking exceptions
2024-05-08 16:29:59,978:INFO:Importing libraries
2024-05-08 16:29:59,978:INFO:Copying training dataset
2024-05-08 16:29:59,981:INFO:Defining folds
2024-05-08 16:29:59,981:INFO:Declaring metric variables
2024-05-08 16:29:59,983:INFO:Importing untrained model
2024-05-08 16:29:59,986:INFO:Lasso Regression Imported successfully
2024-05-08 16:29:59,989:INFO:Starting cross validation
2024-05-08 16:29:59,990:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:00,024:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:00,028:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:00,032:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,113:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,163:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,164:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,165:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,501:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,501:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:01,508:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,551:INFO:Calculating mean and std
2024-05-08 16:30:01,552:INFO:Creating metrics dataframe
2024-05-08 16:30:01,555:INFO:Uploading results into container
2024-05-08 16:30:01,555:INFO:Uploading model into container now
2024-05-08 16:30:01,556:INFO:_master_model_container: 2
2024-05-08 16:30:01,556:INFO:_display_container: 2
2024-05-08 16:30:01,556:INFO:Lasso(random_state=123)
2024-05-08 16:30:01,556:INFO:create_model() successfully completed......................................
2024-05-08 16:30:01,670:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:01,670:INFO:Creating metrics dataframe
2024-05-08 16:30:01,677:INFO:Initializing Ridge Regression
2024-05-08 16:30:01,677:INFO:Total runtime is 0.07428868214289347 minutes
2024-05-08 16:30:01,679:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:01,679:INFO:Initializing create_model()
2024-05-08 16:30:01,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:01,679:INFO:Checking exceptions
2024-05-08 16:30:01,679:INFO:Importing libraries
2024-05-08 16:30:01,679:INFO:Copying training dataset
2024-05-08 16:30:01,681:INFO:Defining folds
2024-05-08 16:30:01,681:INFO:Declaring metric variables
2024-05-08 16:30:01,683:INFO:Importing untrained model
2024-05-08 16:30:01,685:INFO:Ridge Regression Imported successfully
2024-05-08 16:30:01,688:INFO:Starting cross validation
2024-05-08 16:30:01,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:01,702:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,704:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,706:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,710:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,712:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,712:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:01,718:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,726:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,729:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,733:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,781:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:01,782:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:01,782:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:01,782:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:01,782:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:01,782:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:01,798:INFO:Calculating mean and std
2024-05-08 16:30:01,798:INFO:Creating metrics dataframe
2024-05-08 16:30:01,800:INFO:Uploading results into container
2024-05-08 16:30:01,801:INFO:Uploading model into container now
2024-05-08 16:30:01,801:INFO:_master_model_container: 3
2024-05-08 16:30:01,801:INFO:_display_container: 2
2024-05-08 16:30:01,801:INFO:Ridge(random_state=123)
2024-05-08 16:30:01,801:INFO:create_model() successfully completed......................................
2024-05-08 16:30:01,912:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:01,912:INFO:Creating metrics dataframe
2024-05-08 16:30:01,917:INFO:Initializing Elastic Net
2024-05-08 16:30:01,917:INFO:Total runtime is 0.07828540007273356 minutes
2024-05-08 16:30:01,918:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:01,919:INFO:Initializing create_model()
2024-05-08 16:30:01,919:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:01,919:INFO:Checking exceptions
2024-05-08 16:30:01,919:INFO:Importing libraries
2024-05-08 16:30:01,919:INFO:Copying training dataset
2024-05-08 16:30:01,921:INFO:Defining folds
2024-05-08 16:30:01,921:INFO:Declaring metric variables
2024-05-08 16:30:01,923:INFO:Importing untrained model
2024-05-08 16:30:01,924:INFO:Elastic Net Imported successfully
2024-05-08 16:30:01,928:INFO:Starting cross validation
2024-05-08 16:30:01,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:01,941:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,945:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,947:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,948:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:01,952:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,955:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,958:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:01,960:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,028:INFO:Calculating mean and std
2024-05-08 16:30:02,029:INFO:Creating metrics dataframe
2024-05-08 16:30:02,031:INFO:Uploading results into container
2024-05-08 16:30:02,031:INFO:Uploading model into container now
2024-05-08 16:30:02,031:INFO:_master_model_container: 4
2024-05-08 16:30:02,031:INFO:_display_container: 2
2024-05-08 16:30:02,032:INFO:ElasticNet(random_state=123)
2024-05-08 16:30:02,032:INFO:create_model() successfully completed......................................
2024-05-08 16:30:02,141:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:02,141:INFO:Creating metrics dataframe
2024-05-08 16:30:02,146:INFO:Initializing Least Angle Regression
2024-05-08 16:30:02,147:INFO:Total runtime is 0.08211397727330526 minutes
2024-05-08 16:30:02,148:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:02,148:INFO:Initializing create_model()
2024-05-08 16:30:02,148:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:02,148:INFO:Checking exceptions
2024-05-08 16:30:02,148:INFO:Importing libraries
2024-05-08 16:30:02,148:INFO:Copying training dataset
2024-05-08 16:30:02,151:INFO:Defining folds
2024-05-08 16:30:02,151:INFO:Declaring metric variables
2024-05-08 16:30:02,153:INFO:Importing untrained model
2024-05-08 16:30:02,156:INFO:Least Angle Regression Imported successfully
2024-05-08 16:30:02,162:INFO:Starting cross validation
2024-05-08 16:30:02,163:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:02,180:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,184:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,186:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,188:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,191:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,191:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:02,196:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,202:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,204:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,205:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=9.831e+00, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 61 iterations, i.e. alpha=8.100e+00, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,229:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=6.863e-06, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,229:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=6.863e-06, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,230:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.449e-06, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,230:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 48 iterations, i.e. alpha=3.414e-06, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.802e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=5.632e-01, with an active set of 31 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,235:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=4.810e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,235:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.891e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,235:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=3.774e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,236:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 52 iterations, i.e. alpha=1.593e+00, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,236:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 55 iterations, i.e. alpha=2.555e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,236:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.778e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,236:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.506e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,237:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 57 iterations, i.e. alpha=1.151e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,238:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 64 iterations, i.e. alpha=3.415e+01, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,238:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.508e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=8.353e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.212e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=5.148e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=4.213e-01, with an active set of 35 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,240:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=5.347e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,240:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 46 iterations, i.e. alpha=4.073e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,240:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.676e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,240:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=2.429e-02, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,240:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 51 iterations, i.e. alpha=4.851e-03, with an active set of 38 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,241:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 53 iterations, i.e. alpha=3.556e-01, with an active set of 39 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,243:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 70 iterations, i.e. alpha=3.120e-03, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,248:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=9.149e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,248:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 58 iterations, i.e. alpha=4.393e-01, with an active set of 40 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,249:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 60 iterations, i.e. alpha=1.537e+00, with an active set of 41 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,250:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 40 iterations, i.e. alpha=3.676e-01, with an active set of 28 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 41 iterations, i.e. alpha=3.351e-01, with an active set of 29 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,252:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 45 iterations, i.e. alpha=1.786e-01, with an active set of 33 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,254:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=1.322e-01, with an active set of 36 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,254:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.282e-01, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,254:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=7.963e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,254:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.997e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,254:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=5.336e-02, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,255:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 50 iterations, i.e. alpha=1.625e-03, with an active set of 37 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:30:02,281:INFO:Calculating mean and std
2024-05-08 16:30:02,282:INFO:Creating metrics dataframe
2024-05-08 16:30:02,284:INFO:Uploading results into container
2024-05-08 16:30:02,285:INFO:Uploading model into container now
2024-05-08 16:30:02,293:INFO:_master_model_container: 5
2024-05-08 16:30:02,293:INFO:_display_container: 2
2024-05-08 16:30:02,294:INFO:Lars(random_state=123)
2024-05-08 16:30:02,294:INFO:create_model() successfully completed......................................
2024-05-08 16:30:02,396:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:02,396:INFO:Creating metrics dataframe
2024-05-08 16:30:02,401:INFO:Initializing Lasso Least Angle Regression
2024-05-08 16:30:02,402:INFO:Total runtime is 0.08636284271876017 minutes
2024-05-08 16:30:02,404:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:02,404:INFO:Initializing create_model()
2024-05-08 16:30:02,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:02,404:INFO:Checking exceptions
2024-05-08 16:30:02,404:INFO:Importing libraries
2024-05-08 16:30:02,404:INFO:Copying training dataset
2024-05-08 16:30:02,406:INFO:Defining folds
2024-05-08 16:30:02,406:INFO:Declaring metric variables
2024-05-08 16:30:02,408:INFO:Importing untrained model
2024-05-08 16:30:02,412:INFO:Lasso Least Angle Regression Imported successfully
2024-05-08 16:30:02,417:INFO:Starting cross validation
2024-05-08 16:30:02,418:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:02,432:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,434:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,438:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,440:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,442:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,442:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:02,444:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,449:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,522:INFO:Calculating mean and std
2024-05-08 16:30:02,522:INFO:Creating metrics dataframe
2024-05-08 16:30:02,525:INFO:Uploading results into container
2024-05-08 16:30:02,525:INFO:Uploading model into container now
2024-05-08 16:30:02,526:INFO:_master_model_container: 6
2024-05-08 16:30:02,526:INFO:_display_container: 2
2024-05-08 16:30:02,526:INFO:LassoLars(random_state=123)
2024-05-08 16:30:02,526:INFO:create_model() successfully completed......................................
2024-05-08 16:30:02,631:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:02,631:INFO:Creating metrics dataframe
2024-05-08 16:30:02,637:INFO:Initializing Orthogonal Matching Pursuit
2024-05-08 16:30:02,637:INFO:Total runtime is 0.09028818209966023 minutes
2024-05-08 16:30:02,639:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:02,639:INFO:Initializing create_model()
2024-05-08 16:30:02,639:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:02,639:INFO:Checking exceptions
2024-05-08 16:30:02,639:INFO:Importing libraries
2024-05-08 16:30:02,639:INFO:Copying training dataset
2024-05-08 16:30:02,641:INFO:Defining folds
2024-05-08 16:30:02,641:INFO:Declaring metric variables
2024-05-08 16:30:02,643:INFO:Importing untrained model
2024-05-08 16:30:02,646:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-08 16:30:02,652:INFO:Starting cross validation
2024-05-08 16:30:02,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:02,668:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,669:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,670:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,671:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,674:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,674:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:02,676:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,680:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,682:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,682:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,749:INFO:Calculating mean and std
2024-05-08 16:30:02,750:INFO:Creating metrics dataframe
2024-05-08 16:30:02,753:INFO:Uploading results into container
2024-05-08 16:30:02,754:INFO:Uploading model into container now
2024-05-08 16:30:02,754:INFO:_master_model_container: 7
2024-05-08 16:30:02,754:INFO:_display_container: 2
2024-05-08 16:30:02,754:INFO:OrthogonalMatchingPursuit()
2024-05-08 16:30:02,754:INFO:create_model() successfully completed......................................
2024-05-08 16:30:02,864:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:02,864:INFO:Creating metrics dataframe
2024-05-08 16:30:02,869:INFO:Initializing Bayesian Ridge
2024-05-08 16:30:02,870:INFO:Total runtime is 0.0941638708114624 minutes
2024-05-08 16:30:02,871:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:02,872:INFO:Initializing create_model()
2024-05-08 16:30:02,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:02,872:INFO:Checking exceptions
2024-05-08 16:30:02,872:INFO:Importing libraries
2024-05-08 16:30:02,872:INFO:Copying training dataset
2024-05-08 16:30:02,875:INFO:Defining folds
2024-05-08 16:30:02,875:INFO:Declaring metric variables
2024-05-08 16:30:02,878:INFO:Importing untrained model
2024-05-08 16:30:02,879:INFO:Bayesian Ridge Imported successfully
2024-05-08 16:30:02,883:INFO:Starting cross validation
2024-05-08 16:30:02,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:02,895:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,898:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,901:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,902:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,904:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,904:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:02,906:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,909:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,914:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,919:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:02,985:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,986:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,986:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,986:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,986:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,986:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:02,991:INFO:Calculating mean and std
2024-05-08 16:30:02,991:INFO:Creating metrics dataframe
2024-05-08 16:30:02,993:INFO:Uploading results into container
2024-05-08 16:30:02,994:INFO:Uploading model into container now
2024-05-08 16:30:02,994:INFO:_master_model_container: 8
2024-05-08 16:30:02,994:INFO:_display_container: 2
2024-05-08 16:30:02,994:INFO:BayesianRidge()
2024-05-08 16:30:02,994:INFO:create_model() successfully completed......................................
2024-05-08 16:30:03,101:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:03,101:INFO:Creating metrics dataframe
2024-05-08 16:30:03,107:INFO:Initializing Passive Aggressive Regressor
2024-05-08 16:30:03,107:INFO:Total runtime is 0.09811544020970661 minutes
2024-05-08 16:30:03,108:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:03,109:INFO:Initializing create_model()
2024-05-08 16:30:03,109:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:03,109:INFO:Checking exceptions
2024-05-08 16:30:03,109:INFO:Importing libraries
2024-05-08 16:30:03,109:INFO:Copying training dataset
2024-05-08 16:30:03,111:INFO:Defining folds
2024-05-08 16:30:03,111:INFO:Declaring metric variables
2024-05-08 16:30:03,113:INFO:Importing untrained model
2024-05-08 16:30:03,114:INFO:Passive Aggressive Regressor Imported successfully
2024-05-08 16:30:03,118:INFO:Starting cross validation
2024-05-08 16:30:03,119:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:03,132:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,135:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,136:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,136:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,136:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:03,139:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,142:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,147:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,149:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,210:INFO:Calculating mean and std
2024-05-08 16:30:03,210:INFO:Creating metrics dataframe
2024-05-08 16:30:03,212:INFO:Uploading results into container
2024-05-08 16:30:03,213:INFO:Uploading model into container now
2024-05-08 16:30:03,213:INFO:_master_model_container: 9
2024-05-08 16:30:03,213:INFO:_display_container: 2
2024-05-08 16:30:03,213:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-08 16:30:03,213:INFO:create_model() successfully completed......................................
2024-05-08 16:30:03,322:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:03,322:INFO:Creating metrics dataframe
2024-05-08 16:30:03,328:INFO:Initializing Huber Regressor
2024-05-08 16:30:03,328:INFO:Total runtime is 0.1017977197964986 minutes
2024-05-08 16:30:03,329:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:03,330:INFO:Initializing create_model()
2024-05-08 16:30:03,330:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:03,330:INFO:Checking exceptions
2024-05-08 16:30:03,330:INFO:Importing libraries
2024-05-08 16:30:03,330:INFO:Copying training dataset
2024-05-08 16:30:03,331:INFO:Defining folds
2024-05-08 16:30:03,332:INFO:Declaring metric variables
2024-05-08 16:30:03,333:INFO:Importing untrained model
2024-05-08 16:30:03,335:INFO:Huber Regressor Imported successfully
2024-05-08 16:30:03,339:INFO:Starting cross validation
2024-05-08 16:30:03,339:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:03,351:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,354:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,357:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,358:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,361:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,361:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:03,363:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,366:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,369:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,375:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,392:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,404:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,413:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,426:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,430:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,434:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,439:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,439:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,440:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,448:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,449:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,449:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,449:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,449:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,449:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:30:03,455:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:30:03,474:INFO:Calculating mean and std
2024-05-08 16:30:03,475:INFO:Creating metrics dataframe
2024-05-08 16:30:03,476:INFO:Uploading results into container
2024-05-08 16:30:03,477:INFO:Uploading model into container now
2024-05-08 16:30:03,477:INFO:_master_model_container: 10
2024-05-08 16:30:03,477:INFO:_display_container: 2
2024-05-08 16:30:03,477:INFO:HuberRegressor()
2024-05-08 16:30:03,477:INFO:create_model() successfully completed......................................
2024-05-08 16:30:03,578:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:03,578:INFO:Creating metrics dataframe
2024-05-08 16:30:03,584:INFO:Initializing K Neighbors Regressor
2024-05-08 16:30:03,584:INFO:Total runtime is 0.1060657501220703 minutes
2024-05-08 16:30:03,585:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:03,585:INFO:Initializing create_model()
2024-05-08 16:30:03,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:03,585:INFO:Checking exceptions
2024-05-08 16:30:03,586:INFO:Importing libraries
2024-05-08 16:30:03,586:INFO:Copying training dataset
2024-05-08 16:30:03,588:INFO:Defining folds
2024-05-08 16:30:03,588:INFO:Declaring metric variables
2024-05-08 16:30:03,589:INFO:Importing untrained model
2024-05-08 16:30:03,591:INFO:K Neighbors Regressor Imported successfully
2024-05-08 16:30:03,595:INFO:Starting cross validation
2024-05-08 16:30:03,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:03,608:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,610:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,613:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,615:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,616:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,616:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:03,619:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,623:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,626:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,627:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,733:INFO:Calculating mean and std
2024-05-08 16:30:03,734:INFO:Creating metrics dataframe
2024-05-08 16:30:03,736:INFO:Uploading results into container
2024-05-08 16:30:03,737:INFO:Uploading model into container now
2024-05-08 16:30:03,737:INFO:_master_model_container: 11
2024-05-08 16:30:03,737:INFO:_display_container: 2
2024-05-08 16:30:03,737:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-08 16:30:03,737:INFO:create_model() successfully completed......................................
2024-05-08 16:30:03,838:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:03,838:INFO:Creating metrics dataframe
2024-05-08 16:30:03,844:INFO:Initializing Decision Tree Regressor
2024-05-08 16:30:03,845:INFO:Total runtime is 0.11041286389032998 minutes
2024-05-08 16:30:03,846:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:03,847:INFO:Initializing create_model()
2024-05-08 16:30:03,847:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:03,847:INFO:Checking exceptions
2024-05-08 16:30:03,847:INFO:Importing libraries
2024-05-08 16:30:03,847:INFO:Copying training dataset
2024-05-08 16:30:03,849:INFO:Defining folds
2024-05-08 16:30:03,849:INFO:Declaring metric variables
2024-05-08 16:30:03,851:INFO:Importing untrained model
2024-05-08 16:30:03,853:INFO:Decision Tree Regressor Imported successfully
2024-05-08 16:30:03,856:INFO:Starting cross validation
2024-05-08 16:30:03,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:03,869:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,872:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,874:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,875:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,878:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,878:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:03,880:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,884:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,885:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,890:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:03,966:INFO:Calculating mean and std
2024-05-08 16:30:03,967:INFO:Creating metrics dataframe
2024-05-08 16:30:03,970:INFO:Uploading results into container
2024-05-08 16:30:03,971:INFO:Uploading model into container now
2024-05-08 16:30:03,971:INFO:_master_model_container: 12
2024-05-08 16:30:03,971:INFO:_display_container: 2
2024-05-08 16:30:03,972:INFO:DecisionTreeRegressor(random_state=123)
2024-05-08 16:30:03,972:INFO:create_model() successfully completed......................................
2024-05-08 16:30:04,072:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:04,072:INFO:Creating metrics dataframe
2024-05-08 16:30:04,078:INFO:Initializing Random Forest Regressor
2024-05-08 16:30:04,078:INFO:Total runtime is 0.11430504719416298 minutes
2024-05-08 16:30:04,080:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:04,080:INFO:Initializing create_model()
2024-05-08 16:30:04,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:04,080:INFO:Checking exceptions
2024-05-08 16:30:04,080:INFO:Importing libraries
2024-05-08 16:30:04,080:INFO:Copying training dataset
2024-05-08 16:30:04,082:INFO:Defining folds
2024-05-08 16:30:04,082:INFO:Declaring metric variables
2024-05-08 16:30:04,084:INFO:Importing untrained model
2024-05-08 16:30:04,086:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:30:04,089:INFO:Starting cross validation
2024-05-08 16:30:04,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:04,104:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,106:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,107:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,112:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,112:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,113:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:04,114:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,121:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,130:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,809:INFO:Calculating mean and std
2024-05-08 16:30:04,809:INFO:Creating metrics dataframe
2024-05-08 16:30:04,812:INFO:Uploading results into container
2024-05-08 16:30:04,813:INFO:Uploading model into container now
2024-05-08 16:30:04,813:INFO:_master_model_container: 13
2024-05-08 16:30:04,813:INFO:_display_container: 2
2024-05-08 16:30:04,813:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:30:04,813:INFO:create_model() successfully completed......................................
2024-05-08 16:30:04,916:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:04,916:INFO:Creating metrics dataframe
2024-05-08 16:30:04,922:INFO:Initializing Extra Trees Regressor
2024-05-08 16:30:04,922:INFO:Total runtime is 0.1283713062604268 minutes
2024-05-08 16:30:04,924:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:04,924:INFO:Initializing create_model()
2024-05-08 16:30:04,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:04,924:INFO:Checking exceptions
2024-05-08 16:30:04,924:INFO:Importing libraries
2024-05-08 16:30:04,924:INFO:Copying training dataset
2024-05-08 16:30:04,926:INFO:Defining folds
2024-05-08 16:30:04,926:INFO:Declaring metric variables
2024-05-08 16:30:04,928:INFO:Importing untrained model
2024-05-08 16:30:04,930:INFO:Extra Trees Regressor Imported successfully
2024-05-08 16:30:04,935:INFO:Starting cross validation
2024-05-08 16:30:04,936:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:04,954:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,959:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,962:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,966:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,966:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:04,970:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,977:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:04,985:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,307:INFO:Calculating mean and std
2024-05-08 16:30:05,308:INFO:Creating metrics dataframe
2024-05-08 16:30:05,309:INFO:Uploading results into container
2024-05-08 16:30:05,310:INFO:Uploading model into container now
2024-05-08 16:30:05,310:INFO:_master_model_container: 14
2024-05-08 16:30:05,310:INFO:_display_container: 2
2024-05-08 16:30:05,310:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:30:05,310:INFO:create_model() successfully completed......................................
2024-05-08 16:30:05,412:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:05,412:INFO:Creating metrics dataframe
2024-05-08 16:30:05,418:INFO:Initializing AdaBoost Regressor
2024-05-08 16:30:05,418:INFO:Total runtime is 0.13664312362670897 minutes
2024-05-08 16:30:05,420:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:05,420:INFO:Initializing create_model()
2024-05-08 16:30:05,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:05,420:INFO:Checking exceptions
2024-05-08 16:30:05,420:INFO:Importing libraries
2024-05-08 16:30:05,420:INFO:Copying training dataset
2024-05-08 16:30:05,422:INFO:Defining folds
2024-05-08 16:30:05,422:INFO:Declaring metric variables
2024-05-08 16:30:05,424:INFO:Importing untrained model
2024-05-08 16:30:05,426:INFO:AdaBoost Regressor Imported successfully
2024-05-08 16:30:05,431:INFO:Starting cross validation
2024-05-08 16:30:05,432:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:05,445:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,446:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,447:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,450:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:05,453:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,457:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,459:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,461:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,667:INFO:Calculating mean and std
2024-05-08 16:30:05,668:INFO:Creating metrics dataframe
2024-05-08 16:30:05,671:INFO:Uploading results into container
2024-05-08 16:30:05,672:INFO:Uploading model into container now
2024-05-08 16:30:05,672:INFO:_master_model_container: 15
2024-05-08 16:30:05,672:INFO:_display_container: 2
2024-05-08 16:30:05,672:INFO:AdaBoostRegressor(random_state=123)
2024-05-08 16:30:05,672:INFO:create_model() successfully completed......................................
2024-05-08 16:30:05,778:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:05,778:INFO:Creating metrics dataframe
2024-05-08 16:30:05,785:INFO:Initializing Gradient Boosting Regressor
2024-05-08 16:30:05,785:INFO:Total runtime is 0.14275550444920856 minutes
2024-05-08 16:30:05,787:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:05,787:INFO:Initializing create_model()
2024-05-08 16:30:05,787:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:05,787:INFO:Checking exceptions
2024-05-08 16:30:05,787:INFO:Importing libraries
2024-05-08 16:30:05,787:INFO:Copying training dataset
2024-05-08 16:30:05,790:INFO:Defining folds
2024-05-08 16:30:05,790:INFO:Declaring metric variables
2024-05-08 16:30:05,792:INFO:Importing untrained model
2024-05-08 16:30:05,794:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:30:05,799:INFO:Starting cross validation
2024-05-08 16:30:05,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:05,813:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,815:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,818:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,818:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,822:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,822:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:05,824:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,827:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,832:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:05,834:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,299:INFO:Calculating mean and std
2024-05-08 16:30:06,300:INFO:Creating metrics dataframe
2024-05-08 16:30:06,302:INFO:Uploading results into container
2024-05-08 16:30:06,302:INFO:Uploading model into container now
2024-05-08 16:30:06,302:INFO:_master_model_container: 16
2024-05-08 16:30:06,303:INFO:_display_container: 2
2024-05-08 16:30:06,303:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:30:06,303:INFO:create_model() successfully completed......................................
2024-05-08 16:30:06,404:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:06,404:INFO:Creating metrics dataframe
2024-05-08 16:30:06,411:INFO:Initializing Light Gradient Boosting Machine
2024-05-08 16:30:06,411:INFO:Total runtime is 0.15318351984024048 minutes
2024-05-08 16:30:06,412:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:06,413:INFO:Initializing create_model()
2024-05-08 16:30:06,413:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:06,413:INFO:Checking exceptions
2024-05-08 16:30:06,413:INFO:Importing libraries
2024-05-08 16:30:06,413:INFO:Copying training dataset
2024-05-08 16:30:06,415:INFO:Defining folds
2024-05-08 16:30:06,415:INFO:Declaring metric variables
2024-05-08 16:30:06,417:INFO:Importing untrained model
2024-05-08 16:30:06,419:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-08 16:30:06,422:INFO:Starting cross validation
2024-05-08 16:30:06,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:06,436:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,438:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,440:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,442:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,444:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,445:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:06,447:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,454:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:06,459:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,077:INFO:Calculating mean and std
2024-05-08 16:30:07,078:INFO:Creating metrics dataframe
2024-05-08 16:30:07,080:INFO:Uploading results into container
2024-05-08 16:30:07,080:INFO:Uploading model into container now
2024-05-08 16:30:07,080:INFO:_master_model_container: 17
2024-05-08 16:30:07,080:INFO:_display_container: 2
2024-05-08 16:30:07,080:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:30:07,080:INFO:create_model() successfully completed......................................
2024-05-08 16:30:07,178:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:07,178:INFO:Creating metrics dataframe
2024-05-08 16:30:07,185:INFO:Initializing Dummy Regressor
2024-05-08 16:30:07,186:INFO:Total runtime is 0.1660972515741984 minutes
2024-05-08 16:30:07,187:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:07,187:INFO:Initializing create_model()
2024-05-08 16:30:07,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b4934850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:07,187:INFO:Checking exceptions
2024-05-08 16:30:07,187:INFO:Importing libraries
2024-05-08 16:30:07,187:INFO:Copying training dataset
2024-05-08 16:30:07,190:INFO:Defining folds
2024-05-08 16:30:07,190:INFO:Declaring metric variables
2024-05-08 16:30:07,192:INFO:Importing untrained model
2024-05-08 16:30:07,193:INFO:Dummy Regressor Imported successfully
2024-05-08 16:30:07,197:INFO:Starting cross validation
2024-05-08 16:30:07,197:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:07,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,211:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,212:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,216:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,218:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,218:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:07,223:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,231:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,291:INFO:Calculating mean and std
2024-05-08 16:30:07,292:INFO:Creating metrics dataframe
2024-05-08 16:30:07,294:INFO:Uploading results into container
2024-05-08 16:30:07,295:INFO:Uploading model into container now
2024-05-08 16:30:07,295:INFO:_master_model_container: 18
2024-05-08 16:30:07,295:INFO:_display_container: 2
2024-05-08 16:30:07,295:INFO:DummyRegressor()
2024-05-08 16:30:07,295:INFO:create_model() successfully completed......................................
2024-05-08 16:30:07,397:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:07,397:INFO:Creating metrics dataframe
2024-05-08 16:30:07,407:INFO:Initializing create_model()
2024-05-08 16:30:07,407:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:07,407:INFO:Checking exceptions
2024-05-08 16:30:07,408:INFO:Importing libraries
2024-05-08 16:30:07,408:INFO:Copying training dataset
2024-05-08 16:30:07,410:INFO:Defining folds
2024-05-08 16:30:07,410:INFO:Declaring metric variables
2024-05-08 16:30:07,410:INFO:Importing untrained model
2024-05-08 16:30:07,410:INFO:Declaring custom model
2024-05-08 16:30:07,411:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:30:07,411:INFO:Cross validation set to False
2024-05-08 16:30:07,411:INFO:Fitting Model
2024-05-08 16:30:07,414:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:07,720:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:30:07,720:INFO:create_model() successfully completed......................................
2024-05-08 16:30:07,835:INFO:_master_model_container: 18
2024-05-08 16:30:07,835:INFO:_display_container: 2
2024-05-08 16:30:07,836:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:30:07,836:INFO:compare_models() successfully completed......................................
2024-05-08 16:30:07,836:INFO:Initializing tune_model()
2024-05-08 16:30:07,836:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>)
2024-05-08 16:30:07,836:INFO:Checking exceptions
2024-05-08 16:30:07,845:INFO:Copying training dataset
2024-05-08 16:30:07,847:INFO:Checking base model
2024-05-08 16:30:07,847:INFO:Base model : Gradient Boosting Regressor
2024-05-08 16:30:07,849:INFO:Declaring metric variables
2024-05-08 16:30:07,851:INFO:Defining Hyperparameters
2024-05-08 16:30:07,977:INFO:Tuning with n_jobs=-1
2024-05-08 16:30:07,977:INFO:Initializing RandomizedSearchCV
2024-05-08 16:30:08,001:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,003:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,004:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,004:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,008:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,008:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:08,009:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,011:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,012:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,013:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,014:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,015:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,016:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,018:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,019:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,019:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:08,021:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,283:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,286:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,286:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,303:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,352:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,384:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,417:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,442:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,442:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:08,462:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,500:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,527:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,533:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,544:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,550:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,585:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,590:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,597:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,597:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:08,604:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,743:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,758:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,771:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,776:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,780:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,781:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,784:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,802:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,802:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:08,860:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,871:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,876:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,891:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,893:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,898:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,940:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,951:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,955:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,955:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:08,968:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:08,984:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,048:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,048:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,066:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,068:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,078:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,092:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,092:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:09,104:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,109:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,161:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,207:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,264:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,273:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,332:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,403:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,431:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,443:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,443:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:09,457:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,495:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,506:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,514:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,515:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,522:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,530:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,561:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,605:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,605:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:09,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,750:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,751:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,758:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,848:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,860:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,958:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,979:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,984:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:09,984:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:09,989:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:10,218:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:10,220:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:10,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,297:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2024-05-08 16:30:11,298:INFO:Hyperparameter search completed
2024-05-08 16:30:11,298:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:11,298:INFO:Initializing create_model()
2024-05-08 16:30:11,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x74c8b6110af0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2024-05-08 16:30:11,298:INFO:Checking exceptions
2024-05-08 16:30:11,298:INFO:Importing libraries
2024-05-08 16:30:11,298:INFO:Copying training dataset
2024-05-08 16:30:11,300:INFO:Defining folds
2024-05-08 16:30:11,300:INFO:Declaring metric variables
2024-05-08 16:30:11,302:INFO:Importing untrained model
2024-05-08 16:30:11,302:INFO:Declaring custom model
2024-05-08 16:30:11,304:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:30:11,308:INFO:Starting cross validation
2024-05-08 16:30:11,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:11,324:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,326:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,328:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,330:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,332:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,332:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,332:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:11,338:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,340:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:11,341:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:13,035:INFO:Calculating mean and std
2024-05-08 16:30:13,035:INFO:Creating metrics dataframe
2024-05-08 16:30:13,039:INFO:Finalizing model
2024-05-08 16:30:13,041:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,274:INFO:Uploading results into container
2024-05-08 16:30:14,274:INFO:Uploading model into container now
2024-05-08 16:30:14,274:INFO:_master_model_container: 19
2024-05-08 16:30:14,274:INFO:_display_container: 3
2024-05-08 16:30:14,275:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85)
2024-05-08 16:30:14,275:INFO:create_model() successfully completed......................................
2024-05-08 16:30:14,379:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:14,379:INFO:choose_better activated
2024-05-08 16:30:14,382:INFO:SubProcess create_model() called ==================================
2024-05-08 16:30:14,382:INFO:Initializing create_model()
2024-05-08 16:30:14,382:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:14,382:INFO:Checking exceptions
2024-05-08 16:30:14,383:INFO:Importing libraries
2024-05-08 16:30:14,383:INFO:Copying training dataset
2024-05-08 16:30:14,385:INFO:Defining folds
2024-05-08 16:30:14,385:INFO:Declaring metric variables
2024-05-08 16:30:14,385:INFO:Importing untrained model
2024-05-08 16:30:14,385:INFO:Declaring custom model
2024-05-08 16:30:14,386:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:30:14,386:INFO:Starting cross validation
2024-05-08 16:30:14,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:30:14,398:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,399:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,401:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,403:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,405:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,405:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:30:14,407:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,410:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,414:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,414:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:14,935:INFO:Calculating mean and std
2024-05-08 16:30:14,936:INFO:Creating metrics dataframe
2024-05-08 16:30:14,938:INFO:Finalizing model
2024-05-08 16:30:14,941:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:15,263:INFO:Uploading results into container
2024-05-08 16:30:15,264:INFO:Uploading model into container now
2024-05-08 16:30:15,264:INFO:_master_model_container: 20
2024-05-08 16:30:15,264:INFO:_display_container: 4
2024-05-08 16:30:15,264:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:30:15,264:INFO:create_model() successfully completed......................................
2024-05-08 16:30:15,365:INFO:SubProcess create_model() end ==================================
2024-05-08 16:30:15,365:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.7464
2024-05-08 16:30:15,366:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85) result for R2 is 0.6418
2024-05-08 16:30:15,366:INFO:GradientBoostingRegressor(random_state=123) is best model
2024-05-08 16:30:15,366:INFO:choose_better completed
2024-05-08 16:30:15,366:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-08 16:30:15,371:INFO:_master_model_container: 20
2024-05-08 16:30:15,371:INFO:_display_container: 3
2024-05-08 16:30:15,372:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:30:15,372:INFO:tune_model() successfully completed......................................
2024-05-08 16:30:15,477:INFO:Initializing finalize_model()
2024-05-08 16:30:15,477:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=GradientBoostingRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-08 16:30:15,477:INFO:Finalizing GradientBoostingRegressor(random_state=123)
2024-05-08 16:30:15,479:INFO:Initializing create_model()
2024-05-08 16:30:15,479:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:30:15,479:INFO:Checking exceptions
2024-05-08 16:30:15,480:INFO:Importing libraries
2024-05-08 16:30:15,480:INFO:Copying training dataset
2024-05-08 16:30:15,480:INFO:Defining folds
2024-05-08 16:30:15,480:INFO:Declaring metric variables
2024-05-08 16:30:15,480:INFO:Importing untrained model
2024-05-08 16:30:15,481:INFO:Declaring custom model
2024-05-08 16:30:15,481:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:30:15,482:INFO:Cross validation set to False
2024-05-08 16:30:15,482:INFO:Fitting Model
2024-05-08 16:30:15,484:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:30:15,922:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2024-05-08 16:30:15,922:INFO:create_model() successfully completed......................................
2024-05-08 16:30:16,019:INFO:_master_model_container: 20
2024-05-08 16:30:16,020:INFO:_display_container: 3
2024-05-08 16:30:16,025:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2024-05-08 16:30:16,025:INFO:finalize_model() successfully completed......................................
2024-05-08 16:30:16,125:INFO:Initializing predict_model()
2024-05-08 16:30:16,125:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x74c8b46579a0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x74c8b4e01ca0>)
2024-05-08 16:30:16,125:INFO:Checking exceptions
2024-05-08 16:30:16,125:INFO:Preloading libraries
2024-05-08 16:30:16,126:INFO:Set up data.
2024-05-08 16:30:16,129:INFO:Set up index.
2024-05-08 16:30:16,142:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-08 16:35:10,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-08 16:35:10,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-08 16:35:10,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-08 16:35:10,630:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-08 16:35:53,201:WARNING:/tmp/ipykernel_44586/2262976735.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-08 16:35:57,889:INFO:PyCaret RegressionExperiment
2024-05-08 16:35:57,889:INFO:Logging name: reg-default-name
2024-05-08 16:35:57,889:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-08 16:35:57,889:INFO:version 3.3.2
2024-05-08 16:35:57,889:INFO:Initializing setup()
2024-05-08 16:35:57,889:INFO:self.USI: f89e
2024-05-08 16:35:57,889:INFO:self._variable_keys: {'transform_target_param', 'y', 'idx', 'X_train', 'target_param', 'fold_shuffle_param', 'exp_name_log', 'y_test', 'gpu_n_jobs_param', 'USI', 'gpu_param', 'X_test', 'seed', 'pipeline', 'logging_param', 'data', '_ml_usecase', 'fold_groups_param', 'log_plots_param', 'memory', 'exp_id', '_available_plots', 'y_train', 'fold_generator', 'X', 'html_param', 'n_jobs_param'}
2024-05-08 16:35:57,889:INFO:Checking environment
2024-05-08 16:35:57,889:INFO:python_version: 3.9.18
2024-05-08 16:35:57,889:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-08 16:35:57,889:INFO:machine: x86_64
2024-05-08 16:35:57,889:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:35:57,889:INFO:Memory: svmem(total=16429801472, available=6428348416, percent=60.9, used=8843726848, free=2651672576, active=7520399360, inactive=4931383296, buffers=135356416, cached=4799045632, shared=811548672, slab=660746240)
2024-05-08 16:35:57,890:INFO:Physical Core: 12
2024-05-08 16:35:57,890:INFO:Logical Core: 16
2024-05-08 16:35:57,890:INFO:Checking libraries
2024-05-08 16:35:57,890:INFO:System:
2024-05-08 16:35:57,890:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-08 16:35:57,890:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-08 16:35:57,891:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:35:57,891:INFO:PyCaret required dependencies:
2024-05-08 16:35:58,233:INFO:                 pip: 23.2.1
2024-05-08 16:35:58,233:INFO:          setuptools: 68.0.0
2024-05-08 16:35:58,233:INFO:             pycaret: 3.3.2
2024-05-08 16:35:58,233:INFO:             IPython: 8.15.0
2024-05-08 16:35:58,233:INFO:          ipywidgets: 8.0.4
2024-05-08 16:35:58,233:INFO:                tqdm: 4.65.0
2024-05-08 16:35:58,233:INFO:               numpy: 1.24.3
2024-05-08 16:35:58,233:INFO:              pandas: 1.4.2
2024-05-08 16:35:58,233:INFO:              jinja2: 3.1.4
2024-05-08 16:35:58,233:INFO:               scipy: 1.11.3
2024-05-08 16:35:58,233:INFO:              joblib: 1.2.0
2024-05-08 16:35:58,233:INFO:             sklearn: 1.4.2
2024-05-08 16:35:58,233:INFO:                pyod: 1.1.3
2024-05-08 16:35:58,233:INFO:            imblearn: 0.12.2
2024-05-08 16:35:58,233:INFO:   category_encoders: 2.6.3
2024-05-08 16:35:58,233:INFO:            lightgbm: 4.3.0
2024-05-08 16:35:58,233:INFO:               numba: 0.58.0
2024-05-08 16:35:58,233:INFO:            requests: 2.31.0
2024-05-08 16:35:58,233:INFO:          matplotlib: 3.7.2
2024-05-08 16:35:58,233:INFO:          scikitplot: 0.3.7
2024-05-08 16:35:58,233:INFO:         yellowbrick: 1.5
2024-05-08 16:35:58,233:INFO:              plotly: 5.22.0
2024-05-08 16:35:58,233:INFO:    plotly-resampler: Not installed
2024-05-08 16:35:58,233:INFO:             kaleido: 0.2.1
2024-05-08 16:35:58,233:INFO:           schemdraw: 0.15
2024-05-08 16:35:58,233:INFO:         statsmodels: 0.14.0
2024-05-08 16:35:58,233:INFO:              sktime: 0.26.0
2024-05-08 16:35:58,233:INFO:               tbats: 1.1.3
2024-05-08 16:35:58,233:INFO:            pmdarima: 2.0.4
2024-05-08 16:35:58,233:INFO:              psutil: 5.9.0
2024-05-08 16:35:58,233:INFO:          markupsafe: 2.0.1
2024-05-08 16:35:58,233:INFO:             pickle5: Not installed
2024-05-08 16:35:58,233:INFO:         cloudpickle: 2.2.1
2024-05-08 16:35:58,233:INFO:         deprecation: 2.1.0
2024-05-08 16:35:58,233:INFO:              xxhash: 2.0.2
2024-05-08 16:35:58,233:INFO:           wurlitzer: 3.0.2
2024-05-08 16:35:58,233:INFO:PyCaret optional dependencies:
2024-05-08 16:35:58,241:INFO:                shap: Not installed
2024-05-08 16:35:58,241:INFO:           interpret: Not installed
2024-05-08 16:35:58,241:INFO:                umap: Not installed
2024-05-08 16:35:58,241:INFO:     ydata_profiling: Not installed
2024-05-08 16:35:58,241:INFO:  explainerdashboard: Not installed
2024-05-08 16:35:58,241:INFO:             autoviz: Not installed
2024-05-08 16:35:58,241:INFO:           fairlearn: Not installed
2024-05-08 16:35:58,241:INFO:          deepchecks: Not installed
2024-05-08 16:35:58,241:INFO:             xgboost: Not installed
2024-05-08 16:35:58,241:INFO:            catboost: Not installed
2024-05-08 16:35:58,241:INFO:              kmodes: Not installed
2024-05-08 16:35:58,241:INFO:             mlxtend: Not installed
2024-05-08 16:35:58,241:INFO:       statsforecast: Not installed
2024-05-08 16:35:58,241:INFO:        tune_sklearn: Not installed
2024-05-08 16:35:58,241:INFO:                 ray: Not installed
2024-05-08 16:35:58,241:INFO:            hyperopt: Not installed
2024-05-08 16:35:58,241:INFO:              optuna: Not installed
2024-05-08 16:35:58,241:INFO:               skopt: Not installed
2024-05-08 16:35:58,241:INFO:              mlflow: Not installed
2024-05-08 16:35:58,241:INFO:              gradio: Not installed
2024-05-08 16:35:58,241:INFO:             fastapi: Not installed
2024-05-08 16:35:58,241:INFO:             uvicorn: Not installed
2024-05-08 16:35:58,241:INFO:              m2cgen: Not installed
2024-05-08 16:35:58,241:INFO:           evidently: Not installed
2024-05-08 16:35:58,241:INFO:               fugue: Not installed
2024-05-08 16:35:58,241:INFO:           streamlit: Not installed
2024-05-08 16:35:58,241:INFO:             prophet: Not installed
2024-05-08 16:35:58,241:INFO:None
2024-05-08 16:35:58,241:INFO:Set up data.
2024-05-08 16:35:58,244:INFO:Set up folding strategy.
2024-05-08 16:35:58,244:INFO:Set up train/test split.
2024-05-08 16:35:58,245:INFO:Set up index.
2024-05-08 16:35:58,246:INFO:Assigning column types.
2024-05-08 16:35:58,247:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-08 16:35:58,247:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,250:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,252:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,305:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,306:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,308:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,337:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,357:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,358:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-08 16:35:58,360:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,362:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,388:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,412:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,461:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,461:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,461:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,461:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-08 16:35:58,465:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,513:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,518:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,565:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,566:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,566:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,566:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-08 16:35:58,597:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,617:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,618:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,648:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,669:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,669:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,670:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,670:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-08 16:35:58,701:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,755:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:35:58,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,775:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-08 16:35:58,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:58,880:INFO:Preparing preprocessing pipeline...
2024-05-08 16:35:58,880:INFO:Set up target transformation.
2024-05-08 16:35:58,880:INFO:Set up date feature engineering.
2024-05-08 16:35:58,880:INFO:Set up simple imputation.
2024-05-08 16:35:58,880:INFO:Set up polynomial features.
2024-05-08 16:35:58,880:INFO:Set up feature normalization.
2024-05-08 16:35:58,881:INFO:Set up column name cleaning.
2024-05-08 16:35:58,888:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:35:58,922:INFO:Finished creating preprocessing pipeline.
2024-05-08 16:35:58,937:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-08 16:35:58,937:INFO:Creating final display dataframe.
2024-05-08 16:35:59,041:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (552, 5)
4        Transformed data shape         (552, 28)
5   Transformed train set shape         (386, 28)
6    Transformed test set shape         (166, 28)
7              Numeric features                 3
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13          Polynomial features              True
14            Polynomial degree                 2
15                    Normalize              True
16             Normalize method            zscore
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              f89e
2024-05-08 16:35:59,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:59,121:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:59,185:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:59,185:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:35:59,185:INFO:setup() successfully completed in 1.3s...............
2024-05-08 16:35:59,185:INFO:Initializing compare_models()
2024-05-08 16:35:59,185:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-08 16:35:59,186:INFO:Checking exceptions
2024-05-08 16:35:59,187:INFO:Preparing display monitor
2024-05-08 16:35:59,208:INFO:Initializing Linear Regression
2024-05-08 16:35:59,208:INFO:Total runtime is 2.8808911641438803e-06 minutes
2024-05-08 16:35:59,211:INFO:SubProcess create_model() called ==================================
2024-05-08 16:35:59,212:INFO:Initializing create_model()
2024-05-08 16:35:59,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:35:59,212:INFO:Checking exceptions
2024-05-08 16:35:59,212:INFO:Importing libraries
2024-05-08 16:35:59,212:INFO:Copying training dataset
2024-05-08 16:35:59,216:INFO:Defining folds
2024-05-08 16:35:59,216:INFO:Declaring metric variables
2024-05-08 16:35:59,219:INFO:Importing untrained model
2024-05-08 16:35:59,222:INFO:Linear Regression Imported successfully
2024-05-08 16:35:59,230:INFO:Starting cross validation
2024-05-08 16:35:59,243:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:01,214:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,297:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,316:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,316:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:01,533:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,544:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,598:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,611:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,661:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,678:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,735:INFO:Calculating mean and std
2024-05-08 16:36:01,737:INFO:Creating metrics dataframe
2024-05-08 16:36:01,741:INFO:Uploading results into container
2024-05-08 16:36:01,741:INFO:Uploading model into container now
2024-05-08 16:36:01,742:INFO:_master_model_container: 1
2024-05-08 16:36:01,742:INFO:_display_container: 2
2024-05-08 16:36:01,742:INFO:LinearRegression(n_jobs=-1)
2024-05-08 16:36:01,742:INFO:create_model() successfully completed......................................
2024-05-08 16:36:01,861:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:01,861:INFO:Creating metrics dataframe
2024-05-08 16:36:01,867:INFO:Initializing Lasso Regression
2024-05-08 16:36:01,867:INFO:Total runtime is 0.04430915514628093 minutes
2024-05-08 16:36:01,869:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:01,869:INFO:Initializing create_model()
2024-05-08 16:36:01,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:01,869:INFO:Checking exceptions
2024-05-08 16:36:01,870:INFO:Importing libraries
2024-05-08 16:36:01,870:INFO:Copying training dataset
2024-05-08 16:36:01,873:INFO:Defining folds
2024-05-08 16:36:01,873:INFO:Declaring metric variables
2024-05-08 16:36:01,876:INFO:Importing untrained model
2024-05-08 16:36:01,880:INFO:Lasso Regression Imported successfully
2024-05-08 16:36:01,885:INFO:Starting cross validation
2024-05-08 16:36:01,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:01,917:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,918:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:01,924:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,117:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,118:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,119:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,203:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,203:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:03,484:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,485:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,512:INFO:Calculating mean and std
2024-05-08 16:36:03,513:INFO:Creating metrics dataframe
2024-05-08 16:36:03,516:INFO:Uploading results into container
2024-05-08 16:36:03,517:INFO:Uploading model into container now
2024-05-08 16:36:03,517:INFO:_master_model_container: 2
2024-05-08 16:36:03,517:INFO:_display_container: 2
2024-05-08 16:36:03,518:INFO:Lasso(random_state=123)
2024-05-08 16:36:03,518:INFO:create_model() successfully completed......................................
2024-05-08 16:36:03,613:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:03,613:INFO:Creating metrics dataframe
2024-05-08 16:36:03,617:INFO:Initializing Ridge Regression
2024-05-08 16:36:03,618:INFO:Total runtime is 0.0734911561012268 minutes
2024-05-08 16:36:03,619:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:03,619:INFO:Initializing create_model()
2024-05-08 16:36:03,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:03,620:INFO:Checking exceptions
2024-05-08 16:36:03,620:INFO:Importing libraries
2024-05-08 16:36:03,620:INFO:Copying training dataset
2024-05-08 16:36:03,622:INFO:Defining folds
2024-05-08 16:36:03,622:INFO:Declaring metric variables
2024-05-08 16:36:03,624:INFO:Importing untrained model
2024-05-08 16:36:03,626:INFO:Ridge Regression Imported successfully
2024-05-08 16:36:03,630:INFO:Starting cross validation
2024-05-08 16:36:03,631:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:03,645:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,649:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,650:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,653:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,653:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:03,655:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,659:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,661:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,662:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,723:INFO:Calculating mean and std
2024-05-08 16:36:03,724:INFO:Creating metrics dataframe
2024-05-08 16:36:03,726:INFO:Uploading results into container
2024-05-08 16:36:03,726:INFO:Uploading model into container now
2024-05-08 16:36:03,726:INFO:_master_model_container: 3
2024-05-08 16:36:03,726:INFO:_display_container: 2
2024-05-08 16:36:03,726:INFO:Ridge(random_state=123)
2024-05-08 16:36:03,726:INFO:create_model() successfully completed......................................
2024-05-08 16:36:03,827:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:03,827:INFO:Creating metrics dataframe
2024-05-08 16:36:03,832:INFO:Initializing Elastic Net
2024-05-08 16:36:03,832:INFO:Total runtime is 0.07706440687179565 minutes
2024-05-08 16:36:03,834:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:03,834:INFO:Initializing create_model()
2024-05-08 16:36:03,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:03,834:INFO:Checking exceptions
2024-05-08 16:36:03,834:INFO:Importing libraries
2024-05-08 16:36:03,834:INFO:Copying training dataset
2024-05-08 16:36:03,836:INFO:Defining folds
2024-05-08 16:36:03,837:INFO:Declaring metric variables
2024-05-08 16:36:03,839:INFO:Importing untrained model
2024-05-08 16:36:03,842:INFO:Elastic Net Imported successfully
2024-05-08 16:36:03,847:INFO:Starting cross validation
2024-05-08 16:36:03,848:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:03,866:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,868:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,870:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,874:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,878:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,878:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:03,880:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,883:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,885:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,887:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:03,944:INFO:Calculating mean and std
2024-05-08 16:36:03,944:INFO:Creating metrics dataframe
2024-05-08 16:36:03,946:INFO:Uploading results into container
2024-05-08 16:36:03,946:INFO:Uploading model into container now
2024-05-08 16:36:03,946:INFO:_master_model_container: 4
2024-05-08 16:36:03,947:INFO:_display_container: 2
2024-05-08 16:36:03,947:INFO:ElasticNet(random_state=123)
2024-05-08 16:36:03,947:INFO:create_model() successfully completed......................................
2024-05-08 16:36:04,039:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:04,039:INFO:Creating metrics dataframe
2024-05-08 16:36:04,045:INFO:Initializing Least Angle Regression
2024-05-08 16:36:04,045:INFO:Total runtime is 0.08060677051544189 minutes
2024-05-08 16:36:04,046:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:04,046:INFO:Initializing create_model()
2024-05-08 16:36:04,046:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:04,046:INFO:Checking exceptions
2024-05-08 16:36:04,046:INFO:Importing libraries
2024-05-08 16:36:04,046:INFO:Copying training dataset
2024-05-08 16:36:04,048:INFO:Defining folds
2024-05-08 16:36:04,049:INFO:Declaring metric variables
2024-05-08 16:36:04,051:INFO:Importing untrained model
2024-05-08 16:36:04,053:INFO:Least Angle Regression Imported successfully
2024-05-08 16:36:04,057:INFO:Starting cross validation
2024-05-08 16:36:04,059:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:04,072:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,077:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,078:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,081:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,085:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,085:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:04,088:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,096:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,099:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,099:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.758e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,101:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.346e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,104:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.556e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.446e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.948e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,106:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.318e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,106:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.141e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,106:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.700e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,108:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.018e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,108:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.995e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,108:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.584e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,108:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.535e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,108:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.774e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,117:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.214e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,118:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.689e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,120:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.268e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,123:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.093e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,123:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.477e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,123:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.846e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.475e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.238e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.119e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,133:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.552e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.249e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.306e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.134e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.093e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=7.614e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,135:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.998e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,137:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.798e-06, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,137:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.120e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,155:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.773e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,155:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.991e+00, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,157:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.691e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,157:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.791e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.326e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.142e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=8.374e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.609e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.367e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,160:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.625e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,160:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.615e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,161:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.480e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,161:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.921e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,161:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.334e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,162:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.807e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,162:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.138e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,162:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.061e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,162:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.464e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,162:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.899e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,177:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.342e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,177:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.339e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,177:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.835e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,177:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.010e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,178:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.088e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,178:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.933e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,194:INFO:Calculating mean and std
2024-05-08 16:36:04,195:INFO:Creating metrics dataframe
2024-05-08 16:36:04,197:INFO:Uploading results into container
2024-05-08 16:36:04,197:INFO:Uploading model into container now
2024-05-08 16:36:04,197:INFO:_master_model_container: 5
2024-05-08 16:36:04,197:INFO:_display_container: 2
2024-05-08 16:36:04,198:INFO:Lars(random_state=123)
2024-05-08 16:36:04,198:INFO:create_model() successfully completed......................................
2024-05-08 16:36:04,289:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:04,289:INFO:Creating metrics dataframe
2024-05-08 16:36:04,294:INFO:Initializing Lasso Least Angle Regression
2024-05-08 16:36:04,294:INFO:Total runtime is 0.08476065794626872 minutes
2024-05-08 16:36:04,295:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:04,296:INFO:Initializing create_model()
2024-05-08 16:36:04,296:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:04,296:INFO:Checking exceptions
2024-05-08 16:36:04,296:INFO:Importing libraries
2024-05-08 16:36:04,296:INFO:Copying training dataset
2024-05-08 16:36:04,298:INFO:Defining folds
2024-05-08 16:36:04,298:INFO:Declaring metric variables
2024-05-08 16:36:04,300:INFO:Importing untrained model
2024-05-08 16:36:04,302:INFO:Lasso Least Angle Regression Imported successfully
2024-05-08 16:36:04,307:INFO:Starting cross validation
2024-05-08 16:36:04,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:04,323:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,325:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,327:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,331:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,332:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,332:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:04,337:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,344:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,348:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,348:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.214e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,349:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.689e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,353:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,380:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.773e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,380:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.991e+00, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:36:04,420:INFO:Calculating mean and std
2024-05-08 16:36:04,420:INFO:Creating metrics dataframe
2024-05-08 16:36:04,422:INFO:Uploading results into container
2024-05-08 16:36:04,423:INFO:Uploading model into container now
2024-05-08 16:36:04,423:INFO:_master_model_container: 6
2024-05-08 16:36:04,423:INFO:_display_container: 2
2024-05-08 16:36:04,423:INFO:LassoLars(random_state=123)
2024-05-08 16:36:04,423:INFO:create_model() successfully completed......................................
2024-05-08 16:36:04,513:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:04,513:INFO:Creating metrics dataframe
2024-05-08 16:36:04,519:INFO:Initializing Orthogonal Matching Pursuit
2024-05-08 16:36:04,519:INFO:Total runtime is 0.08850917021433513 minutes
2024-05-08 16:36:04,521:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:04,521:INFO:Initializing create_model()
2024-05-08 16:36:04,521:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:04,521:INFO:Checking exceptions
2024-05-08 16:36:04,521:INFO:Importing libraries
2024-05-08 16:36:04,521:INFO:Copying training dataset
2024-05-08 16:36:04,523:INFO:Defining folds
2024-05-08 16:36:04,523:INFO:Declaring metric variables
2024-05-08 16:36:04,526:INFO:Importing untrained model
2024-05-08 16:36:04,528:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-08 16:36:04,532:INFO:Starting cross validation
2024-05-08 16:36:04,533:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:04,545:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,548:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,550:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,552:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,553:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,553:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:04,555:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,560:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,562:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,563:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,632:INFO:Calculating mean and std
2024-05-08 16:36:04,633:INFO:Creating metrics dataframe
2024-05-08 16:36:04,636:INFO:Uploading results into container
2024-05-08 16:36:04,636:INFO:Uploading model into container now
2024-05-08 16:36:04,636:INFO:_master_model_container: 7
2024-05-08 16:36:04,636:INFO:_display_container: 2
2024-05-08 16:36:04,637:INFO:OrthogonalMatchingPursuit()
2024-05-08 16:36:04,637:INFO:create_model() successfully completed......................................
2024-05-08 16:36:04,731:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:04,731:INFO:Creating metrics dataframe
2024-05-08 16:36:04,737:INFO:Initializing Bayesian Ridge
2024-05-08 16:36:04,737:INFO:Total runtime is 0.09213928778966268 minutes
2024-05-08 16:36:04,738:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:04,739:INFO:Initializing create_model()
2024-05-08 16:36:04,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:04,739:INFO:Checking exceptions
2024-05-08 16:36:04,739:INFO:Importing libraries
2024-05-08 16:36:04,739:INFO:Copying training dataset
2024-05-08 16:36:04,741:INFO:Defining folds
2024-05-08 16:36:04,741:INFO:Declaring metric variables
2024-05-08 16:36:04,744:INFO:Importing untrained model
2024-05-08 16:36:04,746:INFO:Bayesian Ridge Imported successfully
2024-05-08 16:36:04,749:INFO:Starting cross validation
2024-05-08 16:36:04,750:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:04,764:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,765:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,768:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,775:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,775:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:04,779:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,785:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,789:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,792:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,859:INFO:Calculating mean and std
2024-05-08 16:36:04,860:INFO:Creating metrics dataframe
2024-05-08 16:36:04,863:INFO:Uploading results into container
2024-05-08 16:36:04,863:INFO:Uploading model into container now
2024-05-08 16:36:04,863:INFO:_master_model_container: 8
2024-05-08 16:36:04,863:INFO:_display_container: 2
2024-05-08 16:36:04,864:INFO:BayesianRidge()
2024-05-08 16:36:04,864:INFO:create_model() successfully completed......................................
2024-05-08 16:36:04,957:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:04,957:INFO:Creating metrics dataframe
2024-05-08 16:36:04,962:INFO:Initializing Passive Aggressive Regressor
2024-05-08 16:36:04,962:INFO:Total runtime is 0.09590299924214682 minutes
2024-05-08 16:36:04,964:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:04,964:INFO:Initializing create_model()
2024-05-08 16:36:04,964:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:04,964:INFO:Checking exceptions
2024-05-08 16:36:04,964:INFO:Importing libraries
2024-05-08 16:36:04,964:INFO:Copying training dataset
2024-05-08 16:36:04,966:INFO:Defining folds
2024-05-08 16:36:04,966:INFO:Declaring metric variables
2024-05-08 16:36:04,969:INFO:Importing untrained model
2024-05-08 16:36:04,971:INFO:Passive Aggressive Regressor Imported successfully
2024-05-08 16:36:04,975:INFO:Starting cross validation
2024-05-08 16:36:04,976:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:04,990:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,992:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:04,994:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,000:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,003:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,003:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:05,006:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,012:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,018:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,021:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,052:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:36:05,052:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:36:05,053:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:36:05,053:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:36:05,053:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:36:05,053:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:36:05,079:INFO:Calculating mean and std
2024-05-08 16:36:05,080:INFO:Creating metrics dataframe
2024-05-08 16:36:05,083:INFO:Uploading results into container
2024-05-08 16:36:05,084:INFO:Uploading model into container now
2024-05-08 16:36:05,084:INFO:_master_model_container: 9
2024-05-08 16:36:05,084:INFO:_display_container: 2
2024-05-08 16:36:05,084:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-08 16:36:05,085:INFO:create_model() successfully completed......................................
2024-05-08 16:36:05,182:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:05,182:INFO:Creating metrics dataframe
2024-05-08 16:36:05,188:INFO:Initializing Huber Regressor
2024-05-08 16:36:05,188:INFO:Total runtime is 0.0996655027071635 minutes
2024-05-08 16:36:05,190:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:05,191:INFO:Initializing create_model()
2024-05-08 16:36:05,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:05,191:INFO:Checking exceptions
2024-05-08 16:36:05,191:INFO:Importing libraries
2024-05-08 16:36:05,191:INFO:Copying training dataset
2024-05-08 16:36:05,193:INFO:Defining folds
2024-05-08 16:36:05,193:INFO:Declaring metric variables
2024-05-08 16:36:05,195:INFO:Importing untrained model
2024-05-08 16:36:05,198:INFO:Huber Regressor Imported successfully
2024-05-08 16:36:05,205:INFO:Starting cross validation
2024-05-08 16:36:05,206:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:05,219:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,221:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,225:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,227:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,227:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,227:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:05,231:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,238:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,242:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,246:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,264:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,265:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,266:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,295:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,296:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,299:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,301:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,305:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,308:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,316:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:36:05,333:INFO:Calculating mean and std
2024-05-08 16:36:05,334:INFO:Creating metrics dataframe
2024-05-08 16:36:05,336:INFO:Uploading results into container
2024-05-08 16:36:05,337:INFO:Uploading model into container now
2024-05-08 16:36:05,337:INFO:_master_model_container: 10
2024-05-08 16:36:05,337:INFO:_display_container: 2
2024-05-08 16:36:05,337:INFO:HuberRegressor()
2024-05-08 16:36:05,337:INFO:create_model() successfully completed......................................
2024-05-08 16:36:05,425:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:05,425:INFO:Creating metrics dataframe
2024-05-08 16:36:05,431:INFO:Initializing K Neighbors Regressor
2024-05-08 16:36:05,431:INFO:Total runtime is 0.10370893081029256 minutes
2024-05-08 16:36:05,432:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:05,433:INFO:Initializing create_model()
2024-05-08 16:36:05,433:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:05,433:INFO:Checking exceptions
2024-05-08 16:36:05,433:INFO:Importing libraries
2024-05-08 16:36:05,433:INFO:Copying training dataset
2024-05-08 16:36:05,435:INFO:Defining folds
2024-05-08 16:36:05,435:INFO:Declaring metric variables
2024-05-08 16:36:05,437:INFO:Importing untrained model
2024-05-08 16:36:05,440:INFO:K Neighbors Regressor Imported successfully
2024-05-08 16:36:05,445:INFO:Starting cross validation
2024-05-08 16:36:05,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:05,461:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,461:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,464:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,466:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,468:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,468:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:05,470:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,473:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,476:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,482:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,587:INFO:Calculating mean and std
2024-05-08 16:36:05,588:INFO:Creating metrics dataframe
2024-05-08 16:36:05,591:INFO:Uploading results into container
2024-05-08 16:36:05,592:INFO:Uploading model into container now
2024-05-08 16:36:05,592:INFO:_master_model_container: 11
2024-05-08 16:36:05,592:INFO:_display_container: 2
2024-05-08 16:36:05,592:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-08 16:36:05,592:INFO:create_model() successfully completed......................................
2024-05-08 16:36:05,687:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:05,687:INFO:Creating metrics dataframe
2024-05-08 16:36:05,694:INFO:Initializing Decision Tree Regressor
2024-05-08 16:36:05,694:INFO:Total runtime is 0.10809765656789144 minutes
2024-05-08 16:36:05,696:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:05,696:INFO:Initializing create_model()
2024-05-08 16:36:05,696:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:05,696:INFO:Checking exceptions
2024-05-08 16:36:05,696:INFO:Importing libraries
2024-05-08 16:36:05,696:INFO:Copying training dataset
2024-05-08 16:36:05,698:INFO:Defining folds
2024-05-08 16:36:05,698:INFO:Declaring metric variables
2024-05-08 16:36:05,700:INFO:Importing untrained model
2024-05-08 16:36:05,703:INFO:Decision Tree Regressor Imported successfully
2024-05-08 16:36:05,708:INFO:Starting cross validation
2024-05-08 16:36:05,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:05,723:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,725:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,729:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,731:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,732:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,732:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:05,735:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,740:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,743:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,747:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,812:INFO:Calculating mean and std
2024-05-08 16:36:05,813:INFO:Creating metrics dataframe
2024-05-08 16:36:05,815:INFO:Uploading results into container
2024-05-08 16:36:05,815:INFO:Uploading model into container now
2024-05-08 16:36:05,816:INFO:_master_model_container: 12
2024-05-08 16:36:05,816:INFO:_display_container: 2
2024-05-08 16:36:05,816:INFO:DecisionTreeRegressor(random_state=123)
2024-05-08 16:36:05,816:INFO:create_model() successfully completed......................................
2024-05-08 16:36:05,912:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:05,912:INFO:Creating metrics dataframe
2024-05-08 16:36:05,921:INFO:Initializing Random Forest Regressor
2024-05-08 16:36:05,921:INFO:Total runtime is 0.111876114209493 minutes
2024-05-08 16:36:05,923:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:05,923:INFO:Initializing create_model()
2024-05-08 16:36:05,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:05,923:INFO:Checking exceptions
2024-05-08 16:36:05,923:INFO:Importing libraries
2024-05-08 16:36:05,923:INFO:Copying training dataset
2024-05-08 16:36:05,925:INFO:Defining folds
2024-05-08 16:36:05,925:INFO:Declaring metric variables
2024-05-08 16:36:05,928:INFO:Importing untrained model
2024-05-08 16:36:05,930:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:36:05,934:INFO:Starting cross validation
2024-05-08 16:36:05,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:05,948:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,951:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,952:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,956:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:05,959:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,962:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,965:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:05,968:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,425:INFO:Calculating mean and std
2024-05-08 16:36:06,426:INFO:Creating metrics dataframe
2024-05-08 16:36:06,429:INFO:Uploading results into container
2024-05-08 16:36:06,429:INFO:Uploading model into container now
2024-05-08 16:36:06,430:INFO:_master_model_container: 13
2024-05-08 16:36:06,430:INFO:_display_container: 2
2024-05-08 16:36:06,430:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:36:06,430:INFO:create_model() successfully completed......................................
2024-05-08 16:36:06,517:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:06,517:INFO:Creating metrics dataframe
2024-05-08 16:36:06,523:INFO:Initializing Extra Trees Regressor
2024-05-08 16:36:06,523:INFO:Total runtime is 0.12190964221954347 minutes
2024-05-08 16:36:06,525:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:06,525:INFO:Initializing create_model()
2024-05-08 16:36:06,525:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:06,525:INFO:Checking exceptions
2024-05-08 16:36:06,525:INFO:Importing libraries
2024-05-08 16:36:06,525:INFO:Copying training dataset
2024-05-08 16:36:06,528:INFO:Defining folds
2024-05-08 16:36:06,528:INFO:Declaring metric variables
2024-05-08 16:36:06,530:INFO:Importing untrained model
2024-05-08 16:36:06,532:INFO:Extra Trees Regressor Imported successfully
2024-05-08 16:36:06,536:INFO:Starting cross validation
2024-05-08 16:36:06,536:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:06,550:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,552:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,553:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,555:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,557:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,558:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:06,558:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,566:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,568:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,574:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,834:INFO:Calculating mean and std
2024-05-08 16:36:06,835:INFO:Creating metrics dataframe
2024-05-08 16:36:06,838:INFO:Uploading results into container
2024-05-08 16:36:06,839:INFO:Uploading model into container now
2024-05-08 16:36:06,839:INFO:_master_model_container: 14
2024-05-08 16:36:06,839:INFO:_display_container: 2
2024-05-08 16:36:06,839:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:36:06,839:INFO:create_model() successfully completed......................................
2024-05-08 16:36:06,924:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:06,924:INFO:Creating metrics dataframe
2024-05-08 16:36:06,930:INFO:Initializing AdaBoost Regressor
2024-05-08 16:36:06,930:INFO:Total runtime is 0.12869986295700075 minutes
2024-05-08 16:36:06,932:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:06,932:INFO:Initializing create_model()
2024-05-08 16:36:06,932:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:06,932:INFO:Checking exceptions
2024-05-08 16:36:06,932:INFO:Importing libraries
2024-05-08 16:36:06,932:INFO:Copying training dataset
2024-05-08 16:36:06,934:INFO:Defining folds
2024-05-08 16:36:06,935:INFO:Declaring metric variables
2024-05-08 16:36:06,938:INFO:Importing untrained model
2024-05-08 16:36:06,940:INFO:AdaBoost Regressor Imported successfully
2024-05-08 16:36:06,946:INFO:Starting cross validation
2024-05-08 16:36:06,947:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:06,960:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,962:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,964:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,964:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,967:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,967:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:06,967:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,975:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,978:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:06,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,098:INFO:Calculating mean and std
2024-05-08 16:36:07,098:INFO:Creating metrics dataframe
2024-05-08 16:36:07,100:INFO:Uploading results into container
2024-05-08 16:36:07,100:INFO:Uploading model into container now
2024-05-08 16:36:07,100:INFO:_master_model_container: 15
2024-05-08 16:36:07,101:INFO:_display_container: 2
2024-05-08 16:36:07,101:INFO:AdaBoostRegressor(random_state=123)
2024-05-08 16:36:07,101:INFO:create_model() successfully completed......................................
2024-05-08 16:36:07,188:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:07,188:INFO:Creating metrics dataframe
2024-05-08 16:36:07,194:INFO:Initializing Gradient Boosting Regressor
2024-05-08 16:36:07,194:INFO:Total runtime is 0.1330994486808777 minutes
2024-05-08 16:36:07,196:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:07,196:INFO:Initializing create_model()
2024-05-08 16:36:07,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:07,196:INFO:Checking exceptions
2024-05-08 16:36:07,196:INFO:Importing libraries
2024-05-08 16:36:07,196:INFO:Copying training dataset
2024-05-08 16:36:07,198:INFO:Defining folds
2024-05-08 16:36:07,198:INFO:Declaring metric variables
2024-05-08 16:36:07,200:INFO:Importing untrained model
2024-05-08 16:36:07,202:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:36:07,207:INFO:Starting cross validation
2024-05-08 16:36:07,208:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:07,222:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,225:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,228:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,229:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,232:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,232:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:07,236:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,243:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,247:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,250:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,553:INFO:Calculating mean and std
2024-05-08 16:36:07,553:INFO:Creating metrics dataframe
2024-05-08 16:36:07,555:INFO:Uploading results into container
2024-05-08 16:36:07,555:INFO:Uploading model into container now
2024-05-08 16:36:07,555:INFO:_master_model_container: 16
2024-05-08 16:36:07,555:INFO:_display_container: 2
2024-05-08 16:36:07,556:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:36:07,556:INFO:create_model() successfully completed......................................
2024-05-08 16:36:07,643:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:07,643:INFO:Creating metrics dataframe
2024-05-08 16:36:07,649:INFO:Initializing Light Gradient Boosting Machine
2024-05-08 16:36:07,649:INFO:Total runtime is 0.14068408409754438 minutes
2024-05-08 16:36:07,651:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:07,651:INFO:Initializing create_model()
2024-05-08 16:36:07,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:07,651:INFO:Checking exceptions
2024-05-08 16:36:07,651:INFO:Importing libraries
2024-05-08 16:36:07,651:INFO:Copying training dataset
2024-05-08 16:36:07,653:INFO:Defining folds
2024-05-08 16:36:07,653:INFO:Declaring metric variables
2024-05-08 16:36:07,655:INFO:Importing untrained model
2024-05-08 16:36:07,657:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-08 16:36:07,662:INFO:Starting cross validation
2024-05-08 16:36:07,663:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:07,677:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,678:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,680:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,682:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,684:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,685:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:07,693:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,694:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:07,700:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,338:INFO:Calculating mean and std
2024-05-08 16:36:08,339:INFO:Creating metrics dataframe
2024-05-08 16:36:08,341:INFO:Uploading results into container
2024-05-08 16:36:08,341:INFO:Uploading model into container now
2024-05-08 16:36:08,342:INFO:_master_model_container: 17
2024-05-08 16:36:08,342:INFO:_display_container: 2
2024-05-08 16:36:08,342:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:36:08,342:INFO:create_model() successfully completed......................................
2024-05-08 16:36:08,427:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:08,427:INFO:Creating metrics dataframe
2024-05-08 16:36:08,434:INFO:Initializing Dummy Regressor
2024-05-08 16:36:08,434:INFO:Total runtime is 0.15375665426254276 minutes
2024-05-08 16:36:08,435:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:08,436:INFO:Initializing create_model()
2024-05-08 16:36:08,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843e59d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:08,436:INFO:Checking exceptions
2024-05-08 16:36:08,436:INFO:Importing libraries
2024-05-08 16:36:08,436:INFO:Copying training dataset
2024-05-08 16:36:08,437:INFO:Defining folds
2024-05-08 16:36:08,437:INFO:Declaring metric variables
2024-05-08 16:36:08,439:INFO:Importing untrained model
2024-05-08 16:36:08,442:INFO:Dummy Regressor Imported successfully
2024-05-08 16:36:08,448:INFO:Starting cross validation
2024-05-08 16:36:08,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:08,463:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,464:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,467:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,469:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,470:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,470:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:08,472:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,478:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,482:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,486:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,545:INFO:Calculating mean and std
2024-05-08 16:36:08,545:INFO:Creating metrics dataframe
2024-05-08 16:36:08,547:INFO:Uploading results into container
2024-05-08 16:36:08,548:INFO:Uploading model into container now
2024-05-08 16:36:08,548:INFO:_master_model_container: 18
2024-05-08 16:36:08,548:INFO:_display_container: 2
2024-05-08 16:36:08,548:INFO:DummyRegressor()
2024-05-08 16:36:08,548:INFO:create_model() successfully completed......................................
2024-05-08 16:36:08,641:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:08,641:INFO:Creating metrics dataframe
2024-05-08 16:36:08,653:INFO:Initializing create_model()
2024-05-08 16:36:08,653:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:08,653:INFO:Checking exceptions
2024-05-08 16:36:08,654:INFO:Importing libraries
2024-05-08 16:36:08,654:INFO:Copying training dataset
2024-05-08 16:36:08,657:INFO:Defining folds
2024-05-08 16:36:08,657:INFO:Declaring metric variables
2024-05-08 16:36:08,657:INFO:Importing untrained model
2024-05-08 16:36:08,657:INFO:Declaring custom model
2024-05-08 16:36:08,658:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:36:08,658:INFO:Cross validation set to False
2024-05-08 16:36:08,658:INFO:Fitting Model
2024-05-08 16:36:08,660:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:08,774:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:36:08,774:INFO:create_model() successfully completed......................................
2024-05-08 16:36:08,879:INFO:_master_model_container: 18
2024-05-08 16:36:08,880:INFO:_display_container: 2
2024-05-08 16:36:08,880:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:36:08,880:INFO:compare_models() successfully completed......................................
2024-05-08 16:36:08,880:INFO:Initializing tune_model()
2024-05-08 16:36:08,880:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>)
2024-05-08 16:36:08,880:INFO:Checking exceptions
2024-05-08 16:36:08,892:INFO:Copying training dataset
2024-05-08 16:36:08,895:INFO:Checking base model
2024-05-08 16:36:08,896:INFO:Base model : Random Forest Regressor
2024-05-08 16:36:08,898:INFO:Declaring metric variables
2024-05-08 16:36:08,900:INFO:Defining Hyperparameters
2024-05-08 16:36:09,009:INFO:Tuning with n_jobs=-1
2024-05-08 16:36:09,010:INFO:Initializing RandomizedSearchCV
2024-05-08 16:36:09,036:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,037:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,037:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,037:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,038:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:09,038:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,038:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,044:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,045:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,047:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,048:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,049:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,052:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,053:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,054:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,054:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:09,056:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,369:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,372:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,374:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,386:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,416:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,416:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,424:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,429:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,429:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:09,432:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,441:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,451:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,452:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,471:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,493:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,685:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,710:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,710:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:09,728:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:09,899:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,018:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,098:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,107:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,108:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,108:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,115:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,119:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,119:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:10,121:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,128:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,132:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,149:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,167:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,173:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,222:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,301:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,382:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,382:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:10,624:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,654:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,665:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,666:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,678:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,678:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,710:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,715:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,719:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,719:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:10,726:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,737:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,781:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,795:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:10,805:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,017:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,042:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,059:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,094:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,094:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:11,104:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,149:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,155:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,156:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,175:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,180:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,181:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,184:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,190:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,190:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:11,202:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,445:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,500:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,521:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,564:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,579:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,590:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,679:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:11,693:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,705:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,710:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,718:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,960:INFO:best_params: {'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': False}
2024-05-08 16:36:11,961:INFO:Hyperparameter search completed
2024-05-08 16:36:11,961:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:11,961:INFO:Initializing create_model()
2024-05-08 16:36:11,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e8e8f8cd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 130, 'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 4, 'criterion': 'absolute_error', 'bootstrap': False})
2024-05-08 16:36:11,961:INFO:Checking exceptions
2024-05-08 16:36:11,961:INFO:Importing libraries
2024-05-08 16:36:11,961:INFO:Copying training dataset
2024-05-08 16:36:11,964:INFO:Defining folds
2024-05-08 16:36:11,964:INFO:Declaring metric variables
2024-05-08 16:36:11,966:INFO:Importing untrained model
2024-05-08 16:36:11,966:INFO:Declaring custom model
2024-05-08 16:36:11,968:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:36:11,972:INFO:Starting cross validation
2024-05-08 16:36:11,972:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:11,985:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,987:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,988:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,991:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,995:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:11,995:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:11,995:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,004:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,007:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,009:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,454:INFO:Calculating mean and std
2024-05-08 16:36:12,455:INFO:Creating metrics dataframe
2024-05-08 16:36:12,460:INFO:Finalizing model
2024-05-08 16:36:12,464:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,582:INFO:Uploading results into container
2024-05-08 16:36:12,582:INFO:Uploading model into container now
2024-05-08 16:36:12,582:INFO:_master_model_container: 19
2024-05-08 16:36:12,582:INFO:_display_container: 3
2024-05-08 16:36:12,583:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=4,
                      max_features='log2', min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=9, n_estimators=130,
                      n_jobs=-1, random_state=123)
2024-05-08 16:36:12,583:INFO:create_model() successfully completed......................................
2024-05-08 16:36:12,681:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:12,681:INFO:choose_better activated
2024-05-08 16:36:12,684:INFO:SubProcess create_model() called ==================================
2024-05-08 16:36:12,684:INFO:Initializing create_model()
2024-05-08 16:36:12,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:12,684:INFO:Checking exceptions
2024-05-08 16:36:12,685:INFO:Importing libraries
2024-05-08 16:36:12,685:INFO:Copying training dataset
2024-05-08 16:36:12,687:INFO:Defining folds
2024-05-08 16:36:12,687:INFO:Declaring metric variables
2024-05-08 16:36:12,687:INFO:Importing untrained model
2024-05-08 16:36:12,687:INFO:Declaring custom model
2024-05-08 16:36:12,687:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:36:12,687:INFO:Starting cross validation
2024-05-08 16:36:12,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:36:12,701:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,703:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,705:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,706:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,708:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,708:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:36:12,709:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,716:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,723:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:12,727:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:13,186:INFO:Calculating mean and std
2024-05-08 16:36:13,186:INFO:Creating metrics dataframe
2024-05-08 16:36:13,188:INFO:Finalizing model
2024-05-08 16:36:13,190:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:13,296:INFO:Uploading results into container
2024-05-08 16:36:13,297:INFO:Uploading model into container now
2024-05-08 16:36:13,297:INFO:_master_model_container: 20
2024-05-08 16:36:13,297:INFO:_display_container: 4
2024-05-08 16:36:13,297:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:36:13,297:INFO:create_model() successfully completed......................................
2024-05-08 16:36:13,412:INFO:SubProcess create_model() end ==================================
2024-05-08 16:36:13,413:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for R2 is 0.6724
2024-05-08 16:36:13,413:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=4,
                      max_features='log2', min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=9, n_estimators=130,
                      n_jobs=-1, random_state=123) result for R2 is 0.6352
2024-05-08 16:36:13,414:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) is best model
2024-05-08 16:36:13,414:INFO:choose_better completed
2024-05-08 16:36:13,414:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-08 16:36:13,423:INFO:_master_model_container: 20
2024-05-08 16:36:13,423:INFO:_display_container: 3
2024-05-08 16:36:13,424:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:36:13,424:INFO:tune_model() successfully completed......................................
2024-05-08 16:36:13,574:INFO:Initializing finalize_model()
2024-05-08 16:36:13,574:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-08 16:36:13,574:INFO:Finalizing RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:36:13,578:INFO:Initializing create_model()
2024-05-08 16:36:13,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:36:13,578:INFO:Checking exceptions
2024-05-08 16:36:13,580:INFO:Importing libraries
2024-05-08 16:36:13,580:INFO:Copying training dataset
2024-05-08 16:36:13,581:INFO:Defining folds
2024-05-08 16:36:13,581:INFO:Declaring metric variables
2024-05-08 16:36:13,581:INFO:Importing untrained model
2024-05-08 16:36:13,581:INFO:Declaring custom model
2024-05-08 16:36:13,582:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:36:13,583:INFO:Cross validation set to False
2024-05-08 16:36:13,583:INFO:Fitting Model
2024-05-08 16:36:13,589:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:36:13,795:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-05-08 16:36:13,795:INFO:create_model() successfully completed......................................
2024-05-08 16:36:13,923:INFO:_master_model_container: 20
2024-05-08 16:36:13,923:INFO:_display_container: 3
2024-05-08 16:36:13,933:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-05-08 16:36:13,933:INFO:finalize_model() successfully completed......................................
2024-05-08 16:36:14,073:INFO:Initializing predict_model()
2024-05-08 16:36:14,073:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e854ffe80>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7b0e85255ca0>)
2024-05-08 16:36:14,074:INFO:Checking exceptions
2024-05-08 16:36:14,074:INFO:Preloading libraries
2024-05-08 16:36:14,075:INFO:Set up data.
2024-05-08 16:36:14,078:INFO:Set up index.
2024-05-08 16:36:14,113:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-08 16:38:10,706:INFO:PyCaret RegressionExperiment
2024-05-08 16:38:10,706:INFO:Logging name: reg-default-name
2024-05-08 16:38:10,706:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-08 16:38:10,706:INFO:version 3.3.2
2024-05-08 16:38:10,706:INFO:Initializing setup()
2024-05-08 16:38:10,706:INFO:self.USI: 92f0
2024-05-08 16:38:10,706:INFO:self._variable_keys: {'transform_target_param', 'y', 'idx', 'X_train', 'target_param', 'fold_shuffle_param', 'exp_name_log', 'y_test', 'gpu_n_jobs_param', 'USI', 'gpu_param', 'X_test', 'seed', 'pipeline', 'logging_param', 'data', '_ml_usecase', 'fold_groups_param', 'log_plots_param', 'memory', 'exp_id', '_available_plots', 'y_train', 'fold_generator', 'X', 'html_param', 'n_jobs_param'}
2024-05-08 16:38:10,706:INFO:Checking environment
2024-05-08 16:38:10,706:INFO:python_version: 3.9.18
2024-05-08 16:38:10,706:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-08 16:38:10,706:INFO:machine: x86_64
2024-05-08 16:38:10,706:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:38:10,707:INFO:Memory: svmem(total=16429801472, available=3479339008, percent=78.8, used=11661033472, free=323158016, active=7110316032, inactive=7604391936, buffers=48996352, cached=4396613632, shared=939065344, slab=608837632)
2024-05-08 16:38:10,707:INFO:Physical Core: 12
2024-05-08 16:38:10,707:INFO:Logical Core: 16
2024-05-08 16:38:10,707:INFO:Checking libraries
2024-05-08 16:38:10,707:INFO:System:
2024-05-08 16:38:10,707:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-08 16:38:10,707:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-08 16:38:10,707:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:38:10,707:INFO:PyCaret required dependencies:
2024-05-08 16:38:10,707:INFO:                 pip: 23.2.1
2024-05-08 16:38:10,707:INFO:          setuptools: 68.0.0
2024-05-08 16:38:10,707:INFO:             pycaret: 3.3.2
2024-05-08 16:38:10,707:INFO:             IPython: 8.15.0
2024-05-08 16:38:10,707:INFO:          ipywidgets: 8.0.4
2024-05-08 16:38:10,707:INFO:                tqdm: 4.65.0
2024-05-08 16:38:10,707:INFO:               numpy: 1.24.3
2024-05-08 16:38:10,707:INFO:              pandas: 1.4.2
2024-05-08 16:38:10,707:INFO:              jinja2: 3.1.4
2024-05-08 16:38:10,707:INFO:               scipy: 1.11.3
2024-05-08 16:38:10,707:INFO:              joblib: 1.2.0
2024-05-08 16:38:10,707:INFO:             sklearn: 1.4.2
2024-05-08 16:38:10,707:INFO:                pyod: 1.1.3
2024-05-08 16:38:10,707:INFO:            imblearn: 0.12.2
2024-05-08 16:38:10,707:INFO:   category_encoders: 2.6.3
2024-05-08 16:38:10,708:INFO:            lightgbm: 4.3.0
2024-05-08 16:38:10,708:INFO:               numba: 0.58.0
2024-05-08 16:38:10,708:INFO:            requests: 2.31.0
2024-05-08 16:38:10,708:INFO:          matplotlib: 3.7.2
2024-05-08 16:38:10,708:INFO:          scikitplot: 0.3.7
2024-05-08 16:38:10,708:INFO:         yellowbrick: 1.5
2024-05-08 16:38:10,708:INFO:              plotly: 5.22.0
2024-05-08 16:38:10,708:INFO:    plotly-resampler: Not installed
2024-05-08 16:38:10,708:INFO:             kaleido: 0.2.1
2024-05-08 16:38:10,708:INFO:           schemdraw: 0.15
2024-05-08 16:38:10,708:INFO:         statsmodels: 0.14.0
2024-05-08 16:38:10,708:INFO:              sktime: 0.26.0
2024-05-08 16:38:10,708:INFO:               tbats: 1.1.3
2024-05-08 16:38:10,708:INFO:            pmdarima: 2.0.4
2024-05-08 16:38:10,708:INFO:              psutil: 5.9.0
2024-05-08 16:38:10,708:INFO:          markupsafe: 2.0.1
2024-05-08 16:38:10,708:INFO:             pickle5: Not installed
2024-05-08 16:38:10,708:INFO:         cloudpickle: 2.2.1
2024-05-08 16:38:10,708:INFO:         deprecation: 2.1.0
2024-05-08 16:38:10,708:INFO:              xxhash: 2.0.2
2024-05-08 16:38:10,708:INFO:           wurlitzer: 3.0.2
2024-05-08 16:38:10,708:INFO:PyCaret optional dependencies:
2024-05-08 16:38:10,708:INFO:                shap: Not installed
2024-05-08 16:38:10,708:INFO:           interpret: Not installed
2024-05-08 16:38:10,708:INFO:                umap: Not installed
2024-05-08 16:38:10,708:INFO:     ydata_profiling: Not installed
2024-05-08 16:38:10,708:INFO:  explainerdashboard: Not installed
2024-05-08 16:38:10,708:INFO:             autoviz: Not installed
2024-05-08 16:38:10,708:INFO:           fairlearn: Not installed
2024-05-08 16:38:10,708:INFO:          deepchecks: Not installed
2024-05-08 16:38:10,708:INFO:             xgboost: Not installed
2024-05-08 16:38:10,708:INFO:            catboost: Not installed
2024-05-08 16:38:10,708:INFO:              kmodes: Not installed
2024-05-08 16:38:10,708:INFO:             mlxtend: Not installed
2024-05-08 16:38:10,708:INFO:       statsforecast: Not installed
2024-05-08 16:38:10,708:INFO:        tune_sklearn: Not installed
2024-05-08 16:38:10,708:INFO:                 ray: Not installed
2024-05-08 16:38:10,708:INFO:            hyperopt: Not installed
2024-05-08 16:38:10,708:INFO:              optuna: Not installed
2024-05-08 16:38:10,708:INFO:               skopt: Not installed
2024-05-08 16:38:10,708:INFO:              mlflow: Not installed
2024-05-08 16:38:10,708:INFO:              gradio: Not installed
2024-05-08 16:38:10,708:INFO:             fastapi: Not installed
2024-05-08 16:38:10,708:INFO:             uvicorn: Not installed
2024-05-08 16:38:10,708:INFO:              m2cgen: Not installed
2024-05-08 16:38:10,708:INFO:           evidently: Not installed
2024-05-08 16:38:10,708:INFO:               fugue: Not installed
2024-05-08 16:38:10,708:INFO:           streamlit: Not installed
2024-05-08 16:38:10,708:INFO:             prophet: Not installed
2024-05-08 16:38:10,708:INFO:None
2024-05-08 16:38:10,708:INFO:Set up data.
2024-05-08 16:38:10,711:INFO:Set up folding strategy.
2024-05-08 16:38:10,711:INFO:Set up train/test split.
2024-05-08 16:38:10,713:INFO:Set up index.
2024-05-08 16:38:10,713:INFO:Assigning column types.
2024-05-08 16:38:10,716:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-08 16:38:10,716:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,719:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,771:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,799:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,800:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:10,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:10,801:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,804:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,808:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,837:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,859:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,860:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:10,860:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:10,860:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-08 16:38:10,862:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,864:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,891:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,912:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:10,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:10,915:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,917:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,945:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,966:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:38:10,967:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:10,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:10,967:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-08 16:38:10,971:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,022:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,023:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,023:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,027:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,056:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,078:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,079:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-08 16:38:11,112:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,133:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,164:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,185:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,186:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,186:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-08 16:38:11,217:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,239:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,239:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,270:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:38:11,290:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,291:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,291:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-08 16:38:11,344:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,344:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,396:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,396:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,396:INFO:Preparing preprocessing pipeline...
2024-05-08 16:38:11,397:INFO:Set up target transformation.
2024-05-08 16:38:11,397:INFO:Set up date feature engineering.
2024-05-08 16:38:11,397:INFO:Set up simple imputation.
2024-05-08 16:38:11,397:INFO:Set up polynomial features.
2024-05-08 16:38:11,397:INFO:Set up feature normalization.
2024-05-08 16:38:11,397:INFO:Set up column name cleaning.
2024-05-08 16:38:11,410:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,437:INFO:Finished creating preprocessing pipeline.
2024-05-08 16:38:11,442:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-08 16:38:11,442:INFO:Creating final display dataframe.
2024-05-08 16:38:11,518:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  ac_out_power(Wh)
2                   Target type        Regression
3           Original data shape          (552, 5)
4        Transformed data shape         (552, 28)
5   Transformed train set shape         (386, 28)
6    Transformed test set shape         (166, 28)
7              Numeric features                 3
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13          Polynomial features              True
14            Polynomial degree                 2
15                    Normalize              True
16             Normalize method            zscore
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              92f0
2024-05-08 16:38:11,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,628:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,628:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:38:11,629:INFO:setup() successfully completed in 0.93s...............
2024-05-08 16:38:11,629:INFO:Initializing compare_models()
2024-05-08 16:38:11,629:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-08 16:38:11,629:INFO:Checking exceptions
2024-05-08 16:38:11,630:INFO:Preparing display monitor
2024-05-08 16:38:11,645:INFO:Initializing Linear Regression
2024-05-08 16:38:11,645:INFO:Total runtime is 2.7378400166829425e-06 minutes
2024-05-08 16:38:11,647:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:11,647:INFO:Initializing create_model()
2024-05-08 16:38:11,647:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:11,647:INFO:Checking exceptions
2024-05-08 16:38:11,647:INFO:Importing libraries
2024-05-08 16:38:11,647:INFO:Copying training dataset
2024-05-08 16:38:11,649:INFO:Defining folds
2024-05-08 16:38:11,650:INFO:Declaring metric variables
2024-05-08 16:38:11,651:INFO:Importing untrained model
2024-05-08 16:38:11,653:INFO:Linear Regression Imported successfully
2024-05-08 16:38:11,659:INFO:Starting cross validation
2024-05-08 16:38:11,660:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:11,676:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,678:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,680:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,681:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,681:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,683:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,690:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,750:INFO:Calculating mean and std
2024-05-08 16:38:11,751:INFO:Creating metrics dataframe
2024-05-08 16:38:11,753:INFO:Uploading results into container
2024-05-08 16:38:11,753:INFO:Uploading model into container now
2024-05-08 16:38:11,753:INFO:_master_model_container: 1
2024-05-08 16:38:11,753:INFO:_display_container: 2
2024-05-08 16:38:11,754:INFO:LinearRegression(n_jobs=-1)
2024-05-08 16:38:11,754:INFO:create_model() successfully completed......................................
2024-05-08 16:38:11,879:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:11,879:INFO:Creating metrics dataframe
2024-05-08 16:38:11,887:INFO:Initializing Lasso Regression
2024-05-08 16:38:11,887:INFO:Total runtime is 0.0040342370669047035 minutes
2024-05-08 16:38:11,891:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:11,891:INFO:Initializing create_model()
2024-05-08 16:38:11,891:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:11,891:INFO:Checking exceptions
2024-05-08 16:38:11,891:INFO:Importing libraries
2024-05-08 16:38:11,891:INFO:Copying training dataset
2024-05-08 16:38:11,895:INFO:Defining folds
2024-05-08 16:38:11,895:INFO:Declaring metric variables
2024-05-08 16:38:11,898:INFO:Importing untrained model
2024-05-08 16:38:11,904:INFO:Lasso Regression Imported successfully
2024-05-08 16:38:11,911:INFO:Starting cross validation
2024-05-08 16:38:11,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:11,932:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,936:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,938:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,949:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,949:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,949:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,953:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,955:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,960:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:11,963:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,008:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 6.722e+03, tolerance: 1.814e+03
  model = cd_fast.enet_coordinate_descent(

2024-05-08 16:38:12,008:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_coordinate_descent.py:678: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 3.582e+03, tolerance: 1.221e+03
  model = cd_fast.enet_coordinate_descent(

2024-05-08 16:38:12,033:INFO:Calculating mean and std
2024-05-08 16:38:12,034:INFO:Creating metrics dataframe
2024-05-08 16:38:12,038:INFO:Uploading results into container
2024-05-08 16:38:12,038:INFO:Uploading model into container now
2024-05-08 16:38:12,039:INFO:_master_model_container: 2
2024-05-08 16:38:12,039:INFO:_display_container: 2
2024-05-08 16:38:12,039:INFO:Lasso(random_state=123)
2024-05-08 16:38:12,039:INFO:create_model() successfully completed......................................
2024-05-08 16:38:12,153:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:12,153:INFO:Creating metrics dataframe
2024-05-08 16:38:12,160:INFO:Initializing Ridge Regression
2024-05-08 16:38:12,160:INFO:Total runtime is 0.008581372102101643 minutes
2024-05-08 16:38:12,162:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:12,162:INFO:Initializing create_model()
2024-05-08 16:38:12,162:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:12,162:INFO:Checking exceptions
2024-05-08 16:38:12,162:INFO:Importing libraries
2024-05-08 16:38:12,162:INFO:Copying training dataset
2024-05-08 16:38:12,164:INFO:Defining folds
2024-05-08 16:38:12,164:INFO:Declaring metric variables
2024-05-08 16:38:12,166:INFO:Importing untrained model
2024-05-08 16:38:12,169:INFO:Ridge Regression Imported successfully
2024-05-08 16:38:12,174:INFO:Starting cross validation
2024-05-08 16:38:12,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:12,190:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,194:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,196:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,200:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,203:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,207:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,210:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,214:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,218:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,222:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,277:INFO:Calculating mean and std
2024-05-08 16:38:12,277:INFO:Creating metrics dataframe
2024-05-08 16:38:12,280:INFO:Uploading results into container
2024-05-08 16:38:12,280:INFO:Uploading model into container now
2024-05-08 16:38:12,281:INFO:_master_model_container: 3
2024-05-08 16:38:12,281:INFO:_display_container: 2
2024-05-08 16:38:12,281:INFO:Ridge(random_state=123)
2024-05-08 16:38:12,281:INFO:create_model() successfully completed......................................
2024-05-08 16:38:12,381:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:12,381:INFO:Creating metrics dataframe
2024-05-08 16:38:12,386:INFO:Initializing Elastic Net
2024-05-08 16:38:12,386:INFO:Total runtime is 0.012354004383087158 minutes
2024-05-08 16:38:12,388:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:12,388:INFO:Initializing create_model()
2024-05-08 16:38:12,388:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:12,388:INFO:Checking exceptions
2024-05-08 16:38:12,388:INFO:Importing libraries
2024-05-08 16:38:12,388:INFO:Copying training dataset
2024-05-08 16:38:12,390:INFO:Defining folds
2024-05-08 16:38:12,390:INFO:Declaring metric variables
2024-05-08 16:38:12,392:INFO:Importing untrained model
2024-05-08 16:38:12,394:INFO:Elastic Net Imported successfully
2024-05-08 16:38:12,398:INFO:Starting cross validation
2024-05-08 16:38:12,399:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:12,413:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,415:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,417:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,422:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,425:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,429:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,431:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,436:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,440:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,444:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,503:INFO:Calculating mean and std
2024-05-08 16:38:12,504:INFO:Creating metrics dataframe
2024-05-08 16:38:12,507:INFO:Uploading results into container
2024-05-08 16:38:12,508:INFO:Uploading model into container now
2024-05-08 16:38:12,508:INFO:_master_model_container: 4
2024-05-08 16:38:12,508:INFO:_display_container: 2
2024-05-08 16:38:12,508:INFO:ElasticNet(random_state=123)
2024-05-08 16:38:12,508:INFO:create_model() successfully completed......................................
2024-05-08 16:38:12,615:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:12,615:INFO:Creating metrics dataframe
2024-05-08 16:38:12,621:INFO:Initializing Least Angle Regression
2024-05-08 16:38:12,621:INFO:Total runtime is 0.016278886795043947 minutes
2024-05-08 16:38:12,624:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:12,624:INFO:Initializing create_model()
2024-05-08 16:38:12,624:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:12,624:INFO:Checking exceptions
2024-05-08 16:38:12,624:INFO:Importing libraries
2024-05-08 16:38:12,624:INFO:Copying training dataset
2024-05-08 16:38:12,626:INFO:Defining folds
2024-05-08 16:38:12,626:INFO:Declaring metric variables
2024-05-08 16:38:12,628:INFO:Importing untrained model
2024-05-08 16:38:12,630:INFO:Least Angle Regression Imported successfully
2024-05-08 16:38:12,636:INFO:Starting cross validation
2024-05-08 16:38:12,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:12,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,656:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,660:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,662:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,665:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,669:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,674:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,676:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,681:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,685:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.013e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,686:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.217e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.011e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.692e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.232e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.278e+00, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,687:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.892e+01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=6.357e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=4.201e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.036e+01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.212e+02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 37 iterations, i.e. alpha=1.574e+02, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,690:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.840e+00, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,691:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=3.430e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,691:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.225e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,691:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.879e+01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,691:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.603e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.884e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=2.251e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,693:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=1.155e+01, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,693:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=1.087e+01, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,694:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.083e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,694:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.077e+01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,695:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.343e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,695:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.263e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=4.001e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=3.739e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,698:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.120e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,698:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.745e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,698:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.707e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,704:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.982e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,704:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.948e+00, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,705:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=5.992e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,705:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.426e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,706:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.016e+00, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,706:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=9.308e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,706:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.805e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,707:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.875e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,707:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=8.349e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,707:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.884e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,718:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.027e+01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,720:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.083e+01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,720:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=8.787e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,720:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=6.717e+00, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,720:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.099e+00, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,721:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=5.289e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,721:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=7.909e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,721:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 49 iterations, i.e. alpha=7.422e-03, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,754:INFO:Calculating mean and std
2024-05-08 16:38:12,755:INFO:Creating metrics dataframe
2024-05-08 16:38:12,757:INFO:Uploading results into container
2024-05-08 16:38:12,757:INFO:Uploading model into container now
2024-05-08 16:38:12,757:INFO:_master_model_container: 5
2024-05-08 16:38:12,758:INFO:_display_container: 2
2024-05-08 16:38:12,758:INFO:Lars(random_state=123)
2024-05-08 16:38:12,758:INFO:create_model() successfully completed......................................
2024-05-08 16:38:12,886:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:12,886:INFO:Creating metrics dataframe
2024-05-08 16:38:12,894:INFO:Initializing Lasso Least Angle Regression
2024-05-08 16:38:12,894:INFO:Total runtime is 0.020817101001739502 minutes
2024-05-08 16:38:12,896:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:12,896:INFO:Initializing create_model()
2024-05-08 16:38:12,897:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:12,897:INFO:Checking exceptions
2024-05-08 16:38:12,897:INFO:Importing libraries
2024-05-08 16:38:12,897:INFO:Copying training dataset
2024-05-08 16:38:12,899:INFO:Defining folds
2024-05-08 16:38:12,899:INFO:Declaring metric variables
2024-05-08 16:38:12,902:INFO:Importing untrained model
2024-05-08 16:38:12,905:INFO:Lasso Least Angle Regression Imported successfully
2024-05-08 16:38:12,910:INFO:Starting cross validation
2024-05-08 16:38:12,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:12,929:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,930:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,934:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,937:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,939:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,944:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,947:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,954:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,957:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=2.879e+01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,958:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:12,958:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=1.132e+01, previous alpha=1.118e+01, with an active set of 8 regressors.
  warnings.warn(

2024-05-08 16:38:12,969:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.618e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,971:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.309e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,971:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.230e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,972:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.137e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,974:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 23 iterations, alpha=1.161e+00, previous alpha=1.068e+00, with an active set of 12 regressors.
  warnings.warn(

2024-05-08 16:38:12,975:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.772e+00, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,977:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.248e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,978:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.402e+00, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,980:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=1.156e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,989:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=1.204e+00, previous alpha=1.020e+00, with an active set of 11 regressors.
  warnings.warn(

2024-05-08 16:38:12,994:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=3.027e+01, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:38:12,995:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.184e+01, previous alpha=1.183e+01, with an active set of 9 regressors.
  warnings.warn(

2024-05-08 16:38:13,021:INFO:Calculating mean and std
2024-05-08 16:38:13,022:INFO:Creating metrics dataframe
2024-05-08 16:38:13,025:INFO:Uploading results into container
2024-05-08 16:38:13,025:INFO:Uploading model into container now
2024-05-08 16:38:13,026:INFO:_master_model_container: 6
2024-05-08 16:38:13,026:INFO:_display_container: 2
2024-05-08 16:38:13,026:INFO:LassoLars(random_state=123)
2024-05-08 16:38:13,026:INFO:create_model() successfully completed......................................
2024-05-08 16:38:13,138:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:13,138:INFO:Creating metrics dataframe
2024-05-08 16:38:13,147:INFO:Initializing Orthogonal Matching Pursuit
2024-05-08 16:38:13,147:INFO:Total runtime is 0.025039827823638915 minutes
2024-05-08 16:38:13,151:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:13,151:INFO:Initializing create_model()
2024-05-08 16:38:13,151:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:13,151:INFO:Checking exceptions
2024-05-08 16:38:13,151:INFO:Importing libraries
2024-05-08 16:38:13,151:INFO:Copying training dataset
2024-05-08 16:38:13,156:INFO:Defining folds
2024-05-08 16:38:13,156:INFO:Declaring metric variables
2024-05-08 16:38:13,160:INFO:Importing untrained model
2024-05-08 16:38:13,163:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-08 16:38:13,167:INFO:Starting cross validation
2024-05-08 16:38:13,169:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:13,192:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,195:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,199:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,202:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,206:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,213:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,217:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,221:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,223:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,295:INFO:Calculating mean and std
2024-05-08 16:38:13,296:INFO:Creating metrics dataframe
2024-05-08 16:38:13,299:INFO:Uploading results into container
2024-05-08 16:38:13,300:INFO:Uploading model into container now
2024-05-08 16:38:13,301:INFO:_master_model_container: 7
2024-05-08 16:38:13,301:INFO:_display_container: 2
2024-05-08 16:38:13,301:INFO:OrthogonalMatchingPursuit()
2024-05-08 16:38:13,301:INFO:create_model() successfully completed......................................
2024-05-08 16:38:13,416:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:13,417:INFO:Creating metrics dataframe
2024-05-08 16:38:13,428:INFO:Initializing Bayesian Ridge
2024-05-08 16:38:13,428:INFO:Total runtime is 0.029724586009979247 minutes
2024-05-08 16:38:13,432:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:13,432:INFO:Initializing create_model()
2024-05-08 16:38:13,432:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:13,432:INFO:Checking exceptions
2024-05-08 16:38:13,432:INFO:Importing libraries
2024-05-08 16:38:13,432:INFO:Copying training dataset
2024-05-08 16:38:13,436:INFO:Defining folds
2024-05-08 16:38:13,436:INFO:Declaring metric variables
2024-05-08 16:38:13,443:INFO:Importing untrained model
2024-05-08 16:38:13,447:INFO:Bayesian Ridge Imported successfully
2024-05-08 16:38:13,454:INFO:Starting cross validation
2024-05-08 16:38:13,455:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:13,476:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,479:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,482:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,485:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,487:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,490:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,494:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,497:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,500:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,504:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,578:INFO:Calculating mean and std
2024-05-08 16:38:13,579:INFO:Creating metrics dataframe
2024-05-08 16:38:13,582:INFO:Uploading results into container
2024-05-08 16:38:13,582:INFO:Uploading model into container now
2024-05-08 16:38:13,582:INFO:_master_model_container: 8
2024-05-08 16:38:13,583:INFO:_display_container: 2
2024-05-08 16:38:13,583:INFO:BayesianRidge()
2024-05-08 16:38:13,583:INFO:create_model() successfully completed......................................
2024-05-08 16:38:13,709:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:13,709:INFO:Creating metrics dataframe
2024-05-08 16:38:13,717:INFO:Initializing Passive Aggressive Regressor
2024-05-08 16:38:13,717:INFO:Total runtime is 0.03453644911448161 minutes
2024-05-08 16:38:13,720:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:13,720:INFO:Initializing create_model()
2024-05-08 16:38:13,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:13,720:INFO:Checking exceptions
2024-05-08 16:38:13,720:INFO:Importing libraries
2024-05-08 16:38:13,721:INFO:Copying training dataset
2024-05-08 16:38:13,724:INFO:Defining folds
2024-05-08 16:38:13,724:INFO:Declaring metric variables
2024-05-08 16:38:13,727:INFO:Importing untrained model
2024-05-08 16:38:13,730:INFO:Passive Aggressive Regressor Imported successfully
2024-05-08 16:38:13,737:INFO:Starting cross validation
2024-05-08 16:38:13,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:13,760:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,763:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,765:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,768:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,778:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,781:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,785:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,790:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,792:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,855:INFO:Calculating mean and std
2024-05-08 16:38:13,856:INFO:Creating metrics dataframe
2024-05-08 16:38:13,858:INFO:Uploading results into container
2024-05-08 16:38:13,858:INFO:Uploading model into container now
2024-05-08 16:38:13,858:INFO:_master_model_container: 9
2024-05-08 16:38:13,858:INFO:_display_container: 2
2024-05-08 16:38:13,859:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-08 16:38:13,859:INFO:create_model() successfully completed......................................
2024-05-08 16:38:13,958:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:13,958:INFO:Creating metrics dataframe
2024-05-08 16:38:13,964:INFO:Initializing Huber Regressor
2024-05-08 16:38:13,964:INFO:Total runtime is 0.038655587037404376 minutes
2024-05-08 16:38:13,966:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:13,966:INFO:Initializing create_model()
2024-05-08 16:38:13,966:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:13,966:INFO:Checking exceptions
2024-05-08 16:38:13,966:INFO:Importing libraries
2024-05-08 16:38:13,966:INFO:Copying training dataset
2024-05-08 16:38:13,968:INFO:Defining folds
2024-05-08 16:38:13,968:INFO:Declaring metric variables
2024-05-08 16:38:13,970:INFO:Importing untrained model
2024-05-08 16:38:13,972:INFO:Huber Regressor Imported successfully
2024-05-08 16:38:13,976:INFO:Starting cross validation
2024-05-08 16:38:13,977:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:13,989:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,993:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,994:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:13,997:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,001:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,003:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,007:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,012:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,014:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,018:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,034:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,037:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,048:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,054:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,058:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,069:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,073:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,076:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,081:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,091:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:38:14,110:INFO:Calculating mean and std
2024-05-08 16:38:14,111:INFO:Creating metrics dataframe
2024-05-08 16:38:14,113:INFO:Uploading results into container
2024-05-08 16:38:14,113:INFO:Uploading model into container now
2024-05-08 16:38:14,113:INFO:_master_model_container: 10
2024-05-08 16:38:14,114:INFO:_display_container: 2
2024-05-08 16:38:14,114:INFO:HuberRegressor()
2024-05-08 16:38:14,114:INFO:create_model() successfully completed......................................
2024-05-08 16:38:14,226:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:14,226:INFO:Creating metrics dataframe
2024-05-08 16:38:14,234:INFO:Initializing K Neighbors Regressor
2024-05-08 16:38:14,234:INFO:Total runtime is 0.04316188097000122 minutes
2024-05-08 16:38:14,238:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:14,238:INFO:Initializing create_model()
2024-05-08 16:38:14,238:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:14,238:INFO:Checking exceptions
2024-05-08 16:38:14,238:INFO:Importing libraries
2024-05-08 16:38:14,239:INFO:Copying training dataset
2024-05-08 16:38:14,243:INFO:Defining folds
2024-05-08 16:38:14,243:INFO:Declaring metric variables
2024-05-08 16:38:14,247:INFO:Importing untrained model
2024-05-08 16:38:14,250:INFO:K Neighbors Regressor Imported successfully
2024-05-08 16:38:14,255:INFO:Starting cross validation
2024-05-08 16:38:14,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:14,274:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,276:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,280:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,281:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,285:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,287:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,288:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,292:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,296:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,300:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,385:INFO:Calculating mean and std
2024-05-08 16:38:14,386:INFO:Creating metrics dataframe
2024-05-08 16:38:14,389:INFO:Uploading results into container
2024-05-08 16:38:14,390:INFO:Uploading model into container now
2024-05-08 16:38:14,390:INFO:_master_model_container: 11
2024-05-08 16:38:14,390:INFO:_display_container: 2
2024-05-08 16:38:14,391:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-08 16:38:14,391:INFO:create_model() successfully completed......................................
2024-05-08 16:38:14,478:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:14,478:INFO:Creating metrics dataframe
2024-05-08 16:38:14,484:INFO:Initializing Decision Tree Regressor
2024-05-08 16:38:14,484:INFO:Total runtime is 0.04732856750488281 minutes
2024-05-08 16:38:14,486:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:14,487:INFO:Initializing create_model()
2024-05-08 16:38:14,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:14,487:INFO:Checking exceptions
2024-05-08 16:38:14,487:INFO:Importing libraries
2024-05-08 16:38:14,487:INFO:Copying training dataset
2024-05-08 16:38:14,489:INFO:Defining folds
2024-05-08 16:38:14,489:INFO:Declaring metric variables
2024-05-08 16:38:14,491:INFO:Importing untrained model
2024-05-08 16:38:14,493:INFO:Decision Tree Regressor Imported successfully
2024-05-08 16:38:14,498:INFO:Starting cross validation
2024-05-08 16:38:14,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:14,512:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,514:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,516:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,520:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,522:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,523:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,527:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,530:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,534:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,600:INFO:Calculating mean and std
2024-05-08 16:38:14,601:INFO:Creating metrics dataframe
2024-05-08 16:38:14,603:INFO:Uploading results into container
2024-05-08 16:38:14,603:INFO:Uploading model into container now
2024-05-08 16:38:14,604:INFO:_master_model_container: 12
2024-05-08 16:38:14,604:INFO:_display_container: 2
2024-05-08 16:38:14,604:INFO:DecisionTreeRegressor(random_state=123)
2024-05-08 16:38:14,604:INFO:create_model() successfully completed......................................
2024-05-08 16:38:14,701:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:14,701:INFO:Creating metrics dataframe
2024-05-08 16:38:14,707:INFO:Initializing Random Forest Regressor
2024-05-08 16:38:14,707:INFO:Total runtime is 0.05103909174601237 minutes
2024-05-08 16:38:14,709:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:14,709:INFO:Initializing create_model()
2024-05-08 16:38:14,709:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:14,709:INFO:Checking exceptions
2024-05-08 16:38:14,709:INFO:Importing libraries
2024-05-08 16:38:14,709:INFO:Copying training dataset
2024-05-08 16:38:14,713:INFO:Defining folds
2024-05-08 16:38:14,713:INFO:Declaring metric variables
2024-05-08 16:38:14,715:INFO:Importing untrained model
2024-05-08 16:38:14,717:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:38:14,722:INFO:Starting cross validation
2024-05-08 16:38:14,723:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:14,736:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,737:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,740:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,743:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,745:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,747:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,748:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,748:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,753:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:14,753:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,234:INFO:Calculating mean and std
2024-05-08 16:38:15,235:INFO:Creating metrics dataframe
2024-05-08 16:38:15,237:INFO:Uploading results into container
2024-05-08 16:38:15,237:INFO:Uploading model into container now
2024-05-08 16:38:15,238:INFO:_master_model_container: 13
2024-05-08 16:38:15,238:INFO:_display_container: 2
2024-05-08 16:38:15,238:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:38:15,238:INFO:create_model() successfully completed......................................
2024-05-08 16:38:15,323:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:15,323:INFO:Creating metrics dataframe
2024-05-08 16:38:15,329:INFO:Initializing Extra Trees Regressor
2024-05-08 16:38:15,329:INFO:Total runtime is 0.061406981945037846 minutes
2024-05-08 16:38:15,331:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:15,331:INFO:Initializing create_model()
2024-05-08 16:38:15,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:15,331:INFO:Checking exceptions
2024-05-08 16:38:15,331:INFO:Importing libraries
2024-05-08 16:38:15,331:INFO:Copying training dataset
2024-05-08 16:38:15,333:INFO:Defining folds
2024-05-08 16:38:15,333:INFO:Declaring metric variables
2024-05-08 16:38:15,335:INFO:Importing untrained model
2024-05-08 16:38:15,336:INFO:Extra Trees Regressor Imported successfully
2024-05-08 16:38:15,340:INFO:Starting cross validation
2024-05-08 16:38:15,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:15,355:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,357:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,358:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,360:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,361:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,362:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,367:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,371:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,374:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,378:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,652:INFO:Calculating mean and std
2024-05-08 16:38:15,652:INFO:Creating metrics dataframe
2024-05-08 16:38:15,654:INFO:Uploading results into container
2024-05-08 16:38:15,655:INFO:Uploading model into container now
2024-05-08 16:38:15,655:INFO:_master_model_container: 14
2024-05-08 16:38:15,655:INFO:_display_container: 2
2024-05-08 16:38:15,656:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:38:15,656:INFO:create_model() successfully completed......................................
2024-05-08 16:38:15,745:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:15,745:INFO:Creating metrics dataframe
2024-05-08 16:38:15,751:INFO:Initializing AdaBoost Regressor
2024-05-08 16:38:15,751:INFO:Total runtime is 0.06843592325846355 minutes
2024-05-08 16:38:15,753:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:15,753:INFO:Initializing create_model()
2024-05-08 16:38:15,753:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:15,753:INFO:Checking exceptions
2024-05-08 16:38:15,753:INFO:Importing libraries
2024-05-08 16:38:15,753:INFO:Copying training dataset
2024-05-08 16:38:15,755:INFO:Defining folds
2024-05-08 16:38:15,755:INFO:Declaring metric variables
2024-05-08 16:38:15,757:INFO:Importing untrained model
2024-05-08 16:38:15,760:INFO:AdaBoost Regressor Imported successfully
2024-05-08 16:38:15,767:INFO:Starting cross validation
2024-05-08 16:38:15,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:15,785:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,787:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,789:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,791:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,795:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,797:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,802:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,806:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,810:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,814:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:15,943:INFO:Calculating mean and std
2024-05-08 16:38:15,943:INFO:Creating metrics dataframe
2024-05-08 16:38:15,946:INFO:Uploading results into container
2024-05-08 16:38:15,947:INFO:Uploading model into container now
2024-05-08 16:38:15,947:INFO:_master_model_container: 15
2024-05-08 16:38:15,947:INFO:_display_container: 2
2024-05-08 16:38:15,948:INFO:AdaBoostRegressor(random_state=123)
2024-05-08 16:38:15,948:INFO:create_model() successfully completed......................................
2024-05-08 16:38:16,033:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:16,033:INFO:Creating metrics dataframe
2024-05-08 16:38:16,039:INFO:Initializing Gradient Boosting Regressor
2024-05-08 16:38:16,039:INFO:Total runtime is 0.07324030001958212 minutes
2024-05-08 16:38:16,041:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:16,041:INFO:Initializing create_model()
2024-05-08 16:38:16,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:16,041:INFO:Checking exceptions
2024-05-08 16:38:16,041:INFO:Importing libraries
2024-05-08 16:38:16,041:INFO:Copying training dataset
2024-05-08 16:38:16,043:INFO:Defining folds
2024-05-08 16:38:16,043:INFO:Declaring metric variables
2024-05-08 16:38:16,045:INFO:Importing untrained model
2024-05-08 16:38:16,048:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:38:16,053:INFO:Starting cross validation
2024-05-08 16:38:16,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:16,066:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,067:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,070:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,072:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,074:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,077:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,078:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,080:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,082:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,085:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,393:INFO:Calculating mean and std
2024-05-08 16:38:16,394:INFO:Creating metrics dataframe
2024-05-08 16:38:16,397:INFO:Uploading results into container
2024-05-08 16:38:16,397:INFO:Uploading model into container now
2024-05-08 16:38:16,398:INFO:_master_model_container: 16
2024-05-08 16:38:16,398:INFO:_display_container: 2
2024-05-08 16:38:16,398:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:38:16,398:INFO:create_model() successfully completed......................................
2024-05-08 16:38:16,499:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:16,499:INFO:Creating metrics dataframe
2024-05-08 16:38:16,506:INFO:Initializing Light Gradient Boosting Machine
2024-05-08 16:38:16,506:INFO:Total runtime is 0.08102796872456869 minutes
2024-05-08 16:38:16,509:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:16,509:INFO:Initializing create_model()
2024-05-08 16:38:16,509:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:16,509:INFO:Checking exceptions
2024-05-08 16:38:16,509:INFO:Importing libraries
2024-05-08 16:38:16,509:INFO:Copying training dataset
2024-05-08 16:38:16,513:INFO:Defining folds
2024-05-08 16:38:16,513:INFO:Declaring metric variables
2024-05-08 16:38:16,515:INFO:Importing untrained model
2024-05-08 16:38:16,518:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-08 16:38:16,523:INFO:Starting cross validation
2024-05-08 16:38:16,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:16,538:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,540:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,541:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,545:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,545:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,548:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,549:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,552:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,554:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:16,555:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,198:INFO:Calculating mean and std
2024-05-08 16:38:17,198:INFO:Creating metrics dataframe
2024-05-08 16:38:17,201:INFO:Uploading results into container
2024-05-08 16:38:17,201:INFO:Uploading model into container now
2024-05-08 16:38:17,201:INFO:_master_model_container: 17
2024-05-08 16:38:17,201:INFO:_display_container: 2
2024-05-08 16:38:17,202:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:38:17,202:INFO:create_model() successfully completed......................................
2024-05-08 16:38:17,291:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:17,291:INFO:Creating metrics dataframe
2024-05-08 16:38:17,298:INFO:Initializing Dummy Regressor
2024-05-08 16:38:17,298:INFO:Total runtime is 0.09421853224436443 minutes
2024-05-08 16:38:17,300:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:17,300:INFO:Initializing create_model()
2024-05-08 16:38:17,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ec1088220>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:17,300:INFO:Checking exceptions
2024-05-08 16:38:17,300:INFO:Importing libraries
2024-05-08 16:38:17,300:INFO:Copying training dataset
2024-05-08 16:38:17,302:INFO:Defining folds
2024-05-08 16:38:17,302:INFO:Declaring metric variables
2024-05-08 16:38:17,304:INFO:Importing untrained model
2024-05-08 16:38:17,305:INFO:Dummy Regressor Imported successfully
2024-05-08 16:38:17,309:INFO:Starting cross validation
2024-05-08 16:38:17,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:17,321:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,323:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,326:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,329:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,332:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,335:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,337:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,343:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,347:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,351:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,401:INFO:Calculating mean and std
2024-05-08 16:38:17,402:INFO:Creating metrics dataframe
2024-05-08 16:38:17,404:INFO:Uploading results into container
2024-05-08 16:38:17,404:INFO:Uploading model into container now
2024-05-08 16:38:17,404:INFO:_master_model_container: 18
2024-05-08 16:38:17,404:INFO:_display_container: 2
2024-05-08 16:38:17,404:INFO:DummyRegressor()
2024-05-08 16:38:17,404:INFO:create_model() successfully completed......................................
2024-05-08 16:38:17,493:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:17,493:INFO:Creating metrics dataframe
2024-05-08 16:38:17,504:INFO:Initializing create_model()
2024-05-08 16:38:17,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:17,505:INFO:Checking exceptions
2024-05-08 16:38:17,506:INFO:Importing libraries
2024-05-08 16:38:17,506:INFO:Copying training dataset
2024-05-08 16:38:17,508:INFO:Defining folds
2024-05-08 16:38:17,508:INFO:Declaring metric variables
2024-05-08 16:38:17,508:INFO:Importing untrained model
2024-05-08 16:38:17,508:INFO:Declaring custom model
2024-05-08 16:38:17,508:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:38:17,509:INFO:Cross validation set to False
2024-05-08 16:38:17,509:INFO:Fitting Model
2024-05-08 16:38:17,511:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,619:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:38:17,620:INFO:create_model() successfully completed......................................
2024-05-08 16:38:17,724:INFO:_master_model_container: 18
2024-05-08 16:38:17,724:INFO:_display_container: 2
2024-05-08 16:38:17,724:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:38:17,724:INFO:compare_models() successfully completed......................................
2024-05-08 16:38:17,725:INFO:Initializing tune_model()
2024-05-08 16:38:17,725:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>)
2024-05-08 16:38:17,725:INFO:Checking exceptions
2024-05-08 16:38:17,732:INFO:Copying training dataset
2024-05-08 16:38:17,734:INFO:Checking base model
2024-05-08 16:38:17,734:INFO:Base model : Random Forest Regressor
2024-05-08 16:38:17,736:INFO:Declaring metric variables
2024-05-08 16:38:17,738:INFO:Defining Hyperparameters
2024-05-08 16:38:17,845:INFO:Tuning with n_jobs=-1
2024-05-08 16:38:17,845:INFO:Initializing RandomizedSearchCV
2024-05-08 16:38:17,871:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,871:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,873:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,874:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,874:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,878:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,880:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,883:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,884:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,886:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,888:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,889:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,917:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,919:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,920:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:17,921:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,221:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,227:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,228:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,235:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,239:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,242:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,252:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,266:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,267:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,269:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,274:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,284:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,300:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,302:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,306:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,368:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,540:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,549:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,601:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,634:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,658:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,754:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,943:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,962:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,969:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,970:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,977:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:18,984:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,029:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,030:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,032:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,047:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,059:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,093:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,105:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,114:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,180:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,454:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,490:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,494:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,530:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,562:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,581:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,581:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,581:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,591:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,612:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,674:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,674:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,679:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,685:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,700:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,739:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:19,847:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,047:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,054:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,074:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,075:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,081:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,109:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,127:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,142:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,143:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,159:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,184:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,203:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,275:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,465:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,533:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,597:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,610:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,628:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,630:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,636:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,641:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,661:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,684:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,731:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,732:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,741:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,970:INFO:best_params: {'actual_estimator__n_estimators': 290, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2024-05-08 16:38:20,971:INFO:Hyperparameter search completed
2024-05-08 16:38:20,971:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:20,971:INFO:Initializing create_model()
2024-05-08 16:38:20,972:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e843841f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 290, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'squared_error', 'bootstrap': True})
2024-05-08 16:38:20,972:INFO:Checking exceptions
2024-05-08 16:38:20,972:INFO:Importing libraries
2024-05-08 16:38:20,972:INFO:Copying training dataset
2024-05-08 16:38:20,974:INFO:Defining folds
2024-05-08 16:38:20,974:INFO:Declaring metric variables
2024-05-08 16:38:20,976:INFO:Importing untrained model
2024-05-08 16:38:20,976:INFO:Declaring custom model
2024-05-08 16:38:20,978:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:38:20,982:INFO:Starting cross validation
2024-05-08 16:38:20,983:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:20,995:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,997:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:20,999:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,001:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,002:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,007:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,010:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,013:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,017:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,020:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,472:INFO:Calculating mean and std
2024-05-08 16:38:21,473:INFO:Creating metrics dataframe
2024-05-08 16:38:21,477:INFO:Finalizing model
2024-05-08 16:38:21,479:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,757:INFO:Uploading results into container
2024-05-08 16:38:21,758:INFO:Uploading model into container now
2024-05-08 16:38:21,759:INFO:_master_model_container: 19
2024-05-08 16:38:21,759:INFO:_display_container: 3
2024-05-08 16:38:21,759:INFO:RandomForestRegressor(max_depth=6, max_features='log2',
                      min_impurity_decrease=0.0002, min_samples_leaf=2,
                      n_estimators=290, n_jobs=-1, random_state=123)
2024-05-08 16:38:21,759:INFO:create_model() successfully completed......................................
2024-05-08 16:38:21,846:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:21,846:INFO:choose_better activated
2024-05-08 16:38:21,848:INFO:SubProcess create_model() called ==================================
2024-05-08 16:38:21,848:INFO:Initializing create_model()
2024-05-08 16:38:21,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:21,849:INFO:Checking exceptions
2024-05-08 16:38:21,849:INFO:Importing libraries
2024-05-08 16:38:21,849:INFO:Copying training dataset
2024-05-08 16:38:21,851:INFO:Defining folds
2024-05-08 16:38:21,851:INFO:Declaring metric variables
2024-05-08 16:38:21,851:INFO:Importing untrained model
2024-05-08 16:38:21,851:INFO:Declaring custom model
2024-05-08 16:38:21,852:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:38:21,852:INFO:Starting cross validation
2024-05-08 16:38:21,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:38:21,865:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,867:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,868:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,869:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,871:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,872:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,875:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,877:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,879:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:21,881:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:22,341:INFO:Calculating mean and std
2024-05-08 16:38:22,341:INFO:Creating metrics dataframe
2024-05-08 16:38:22,342:INFO:Finalizing model
2024-05-08 16:38:22,344:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:22,455:INFO:Uploading results into container
2024-05-08 16:38:22,455:INFO:Uploading model into container now
2024-05-08 16:38:22,455:INFO:_master_model_container: 20
2024-05-08 16:38:22,455:INFO:_display_container: 4
2024-05-08 16:38:22,456:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:38:22,456:INFO:create_model() successfully completed......................................
2024-05-08 16:38:22,542:INFO:SubProcess create_model() end ==================================
2024-05-08 16:38:22,542:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for R2 is 0.4286
2024-05-08 16:38:22,543:INFO:RandomForestRegressor(max_depth=6, max_features='log2',
                      min_impurity_decrease=0.0002, min_samples_leaf=2,
                      n_estimators=290, n_jobs=-1, random_state=123) result for R2 is 0.4228
2024-05-08 16:38:22,543:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) is best model
2024-05-08 16:38:22,543:INFO:choose_better completed
2024-05-08 16:38:22,543:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-08 16:38:22,550:INFO:_master_model_container: 20
2024-05-08 16:38:22,550:INFO:_display_container: 3
2024-05-08 16:38:22,551:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:38:22,551:INFO:tune_model() successfully completed......................................
2024-05-08 16:38:22,660:INFO:Initializing finalize_model()
2024-05-08 16:38:22,660:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-08 16:38:22,660:INFO:Finalizing RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:38:22,662:INFO:Initializing create_model()
2024-05-08 16:38:22,662:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:38:22,662:INFO:Checking exceptions
2024-05-08 16:38:22,663:INFO:Importing libraries
2024-05-08 16:38:22,663:INFO:Copying training dataset
2024-05-08 16:38:22,663:INFO:Defining folds
2024-05-08 16:38:22,663:INFO:Declaring metric variables
2024-05-08 16:38:22,663:INFO:Importing untrained model
2024-05-08 16:38:22,663:INFO:Declaring custom model
2024-05-08 16:38:22,664:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:38:22,664:INFO:Cross validation set to False
2024-05-08 16:38:22,664:INFO:Fitting Model
2024-05-08 16:38:22,666:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:38:22,778:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-05-08 16:38:22,778:INFO:create_model() successfully completed......................................
2024-05-08 16:38:22,863:INFO:_master_model_container: 20
2024-05-08 16:38:22,863:INFO:_display_container: 3
2024-05-08 16:38:22,869:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-05-08 16:38:22,869:INFO:finalize_model() successfully completed......................................
2024-05-08 16:38:22,959:INFO:Initializing predict_model()
2024-05-08 16:38:22,959:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e844bbe80>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7b0e843e30d0>)
2024-05-08 16:38:22,959:INFO:Checking exceptions
2024-05-08 16:38:22,960:INFO:Preloading libraries
2024-05-08 16:38:22,961:INFO:Set up data.
2024-05-08 16:38:22,963:INFO:Set up index.
2024-05-08 16:38:22,987:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-08 16:40:32,440:INFO:PyCaret RegressionExperiment
2024-05-08 16:40:32,440:INFO:Logging name: reg-default-name
2024-05-08 16:40:32,440:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-08 16:40:32,440:INFO:version 3.3.2
2024-05-08 16:40:32,440:INFO:Initializing setup()
2024-05-08 16:40:32,440:INFO:self.USI: 81d2
2024-05-08 16:40:32,440:INFO:self._variable_keys: {'transform_target_param', 'y', 'idx', 'X_train', 'target_param', 'fold_shuffle_param', 'exp_name_log', 'y_test', 'gpu_n_jobs_param', 'USI', 'gpu_param', 'X_test', 'seed', 'pipeline', 'logging_param', 'data', '_ml_usecase', 'fold_groups_param', 'log_plots_param', 'memory', 'exp_id', '_available_plots', 'y_train', 'fold_generator', 'X', 'html_param', 'n_jobs_param'}
2024-05-08 16:40:32,440:INFO:Checking environment
2024-05-08 16:40:32,440:INFO:python_version: 3.9.18
2024-05-08 16:40:32,440:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-08 16:40:32,440:INFO:machine: x86_64
2024-05-08 16:40:32,440:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:40:32,440:INFO:Memory: svmem(total=16429801472, available=3476619264, percent=78.8, used=11746570240, free=315682816, active=7173709824, inactive=7612743680, buffers=49291264, cached=4318257152, shared=860426240, slab=609296384)
2024-05-08 16:40:32,441:INFO:Physical Core: 12
2024-05-08 16:40:32,441:INFO:Logical Core: 16
2024-05-08 16:40:32,441:INFO:Checking libraries
2024-05-08 16:40:32,441:INFO:System:
2024-05-08 16:40:32,441:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-08 16:40:32,441:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-08 16:40:32,441:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-08 16:40:32,441:INFO:PyCaret required dependencies:
2024-05-08 16:40:32,441:INFO:                 pip: 23.2.1
2024-05-08 16:40:32,441:INFO:          setuptools: 68.0.0
2024-05-08 16:40:32,441:INFO:             pycaret: 3.3.2
2024-05-08 16:40:32,441:INFO:             IPython: 8.15.0
2024-05-08 16:40:32,441:INFO:          ipywidgets: 8.0.4
2024-05-08 16:40:32,441:INFO:                tqdm: 4.65.0
2024-05-08 16:40:32,441:INFO:               numpy: 1.24.3
2024-05-08 16:40:32,441:INFO:              pandas: 1.4.2
2024-05-08 16:40:32,441:INFO:              jinja2: 3.1.4
2024-05-08 16:40:32,441:INFO:               scipy: 1.11.3
2024-05-08 16:40:32,441:INFO:              joblib: 1.2.0
2024-05-08 16:40:32,441:INFO:             sklearn: 1.4.2
2024-05-08 16:40:32,441:INFO:                pyod: 1.1.3
2024-05-08 16:40:32,441:INFO:            imblearn: 0.12.2
2024-05-08 16:40:32,441:INFO:   category_encoders: 2.6.3
2024-05-08 16:40:32,441:INFO:            lightgbm: 4.3.0
2024-05-08 16:40:32,441:INFO:               numba: 0.58.0
2024-05-08 16:40:32,441:INFO:            requests: 2.31.0
2024-05-08 16:40:32,441:INFO:          matplotlib: 3.7.2
2024-05-08 16:40:32,441:INFO:          scikitplot: 0.3.7
2024-05-08 16:40:32,441:INFO:         yellowbrick: 1.5
2024-05-08 16:40:32,441:INFO:              plotly: 5.22.0
2024-05-08 16:40:32,441:INFO:    plotly-resampler: Not installed
2024-05-08 16:40:32,441:INFO:             kaleido: 0.2.1
2024-05-08 16:40:32,442:INFO:           schemdraw: 0.15
2024-05-08 16:40:32,442:INFO:         statsmodels: 0.14.0
2024-05-08 16:40:32,442:INFO:              sktime: 0.26.0
2024-05-08 16:40:32,442:INFO:               tbats: 1.1.3
2024-05-08 16:40:32,442:INFO:            pmdarima: 2.0.4
2024-05-08 16:40:32,442:INFO:              psutil: 5.9.0
2024-05-08 16:40:32,442:INFO:          markupsafe: 2.0.1
2024-05-08 16:40:32,442:INFO:             pickle5: Not installed
2024-05-08 16:40:32,442:INFO:         cloudpickle: 2.2.1
2024-05-08 16:40:32,442:INFO:         deprecation: 2.1.0
2024-05-08 16:40:32,442:INFO:              xxhash: 2.0.2
2024-05-08 16:40:32,442:INFO:           wurlitzer: 3.0.2
2024-05-08 16:40:32,442:INFO:PyCaret optional dependencies:
2024-05-08 16:40:32,442:INFO:                shap: Not installed
2024-05-08 16:40:32,442:INFO:           interpret: Not installed
2024-05-08 16:40:32,442:INFO:                umap: Not installed
2024-05-08 16:40:32,442:INFO:     ydata_profiling: Not installed
2024-05-08 16:40:32,442:INFO:  explainerdashboard: Not installed
2024-05-08 16:40:32,442:INFO:             autoviz: Not installed
2024-05-08 16:40:32,442:INFO:           fairlearn: Not installed
2024-05-08 16:40:32,442:INFO:          deepchecks: Not installed
2024-05-08 16:40:32,442:INFO:             xgboost: Not installed
2024-05-08 16:40:32,442:INFO:            catboost: Not installed
2024-05-08 16:40:32,442:INFO:              kmodes: Not installed
2024-05-08 16:40:32,442:INFO:             mlxtend: Not installed
2024-05-08 16:40:32,442:INFO:       statsforecast: Not installed
2024-05-08 16:40:32,442:INFO:        tune_sklearn: Not installed
2024-05-08 16:40:32,442:INFO:                 ray: Not installed
2024-05-08 16:40:32,442:INFO:            hyperopt: Not installed
2024-05-08 16:40:32,442:INFO:              optuna: Not installed
2024-05-08 16:40:32,442:INFO:               skopt: Not installed
2024-05-08 16:40:32,442:INFO:              mlflow: Not installed
2024-05-08 16:40:32,442:INFO:              gradio: Not installed
2024-05-08 16:40:32,442:INFO:             fastapi: Not installed
2024-05-08 16:40:32,442:INFO:             uvicorn: Not installed
2024-05-08 16:40:32,442:INFO:              m2cgen: Not installed
2024-05-08 16:40:32,442:INFO:           evidently: Not installed
2024-05-08 16:40:32,442:INFO:               fugue: Not installed
2024-05-08 16:40:32,442:INFO:           streamlit: Not installed
2024-05-08 16:40:32,442:INFO:             prophet: Not installed
2024-05-08 16:40:32,442:INFO:None
2024-05-08 16:40:32,442:INFO:Set up data.
2024-05-08 16:40:32,447:INFO:Set up folding strategy.
2024-05-08 16:40:32,447:INFO:Set up train/test split.
2024-05-08 16:40:32,453:INFO:Set up index.
2024-05-08 16:40:32,454:INFO:Assigning column types.
2024-05-08 16:40:32,459:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-08 16:40:32,459:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,467:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,476:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,553:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,573:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,574:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,576:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,578:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,602:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,622:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,623:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-08 16:40:32,625:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,628:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,652:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,673:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,675:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,678:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,704:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,725:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-08 16:40:32,729:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,756:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,775:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,775:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,775:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,779:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,805:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,824:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,825:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-08 16:40:32,854:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,902:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,921:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,922:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,922:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,922:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-08 16:40:32,951:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:32,970:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:32,970:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-08 16:40:33,019:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,019:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,019:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-08 16:40:33,068:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,068:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,118:INFO:Preparing preprocessing pipeline...
2024-05-08 16:40:33,118:INFO:Set up target transformation.
2024-05-08 16:40:33,118:INFO:Set up date feature engineering.
2024-05-08 16:40:33,118:INFO:Set up simple imputation.
2024-05-08 16:40:33,118:INFO:Set up polynomial features.
2024-05-08 16:40:33,118:INFO:Set up feature normalization.
2024-05-08 16:40:33,119:INFO:Set up column name cleaning.
2024-05-08 16:40:33,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,167:INFO:Finished creating preprocessing pipeline.
2024-05-08 16:40:33,174:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-08 16:40:33,174:INFO:Creating final display dataframe.
2024-05-08 16:40:33,302:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (552, 5)
4        Transformed data shape         (552, 28)
5   Transformed train set shape         (386, 28)
6    Transformed test set shape         (166, 28)
7              Numeric features                 3
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13          Polynomial features              True
14            Polynomial degree                 2
15                    Normalize              True
16             Normalize method            zscore
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              81d2
2024-05-08 16:40:33,373:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,373:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,428:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-08 16:40:33,429:INFO:setup() successfully completed in 0.99s...............
2024-05-08 16:40:33,429:INFO:Initializing compare_models()
2024-05-08 16:40:33,429:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-08 16:40:33,429:INFO:Checking exceptions
2024-05-08 16:40:33,430:INFO:Preparing display monitor
2024-05-08 16:40:33,448:INFO:Initializing Linear Regression
2024-05-08 16:40:33,448:INFO:Total runtime is 1.9550323486328123e-06 minutes
2024-05-08 16:40:33,451:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:33,451:INFO:Initializing create_model()
2024-05-08 16:40:33,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:33,451:INFO:Checking exceptions
2024-05-08 16:40:33,451:INFO:Importing libraries
2024-05-08 16:40:33,451:INFO:Copying training dataset
2024-05-08 16:40:33,453:INFO:Defining folds
2024-05-08 16:40:33,453:INFO:Declaring metric variables
2024-05-08 16:40:33,455:INFO:Importing untrained model
2024-05-08 16:40:33,459:INFO:Linear Regression Imported successfully
2024-05-08 16:40:33,465:INFO:Starting cross validation
2024-05-08 16:40:33,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:33,481:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,484:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,486:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,488:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,490:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,490:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:33,492:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,496:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,498:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,500:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,571:INFO:Calculating mean and std
2024-05-08 16:40:33,571:INFO:Creating metrics dataframe
2024-05-08 16:40:33,574:INFO:Uploading results into container
2024-05-08 16:40:33,575:INFO:Uploading model into container now
2024-05-08 16:40:33,576:INFO:_master_model_container: 1
2024-05-08 16:40:33,576:INFO:_display_container: 2
2024-05-08 16:40:33,576:INFO:LinearRegression(n_jobs=-1)
2024-05-08 16:40:33,576:INFO:create_model() successfully completed......................................
2024-05-08 16:40:33,710:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:33,710:INFO:Creating metrics dataframe
2024-05-08 16:40:33,717:INFO:Initializing Lasso Regression
2024-05-08 16:40:33,718:INFO:Total runtime is 0.004495286941528321 minutes
2024-05-08 16:40:33,721:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:33,721:INFO:Initializing create_model()
2024-05-08 16:40:33,721:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:33,721:INFO:Checking exceptions
2024-05-08 16:40:33,721:INFO:Importing libraries
2024-05-08 16:40:33,721:INFO:Copying training dataset
2024-05-08 16:40:33,724:INFO:Defining folds
2024-05-08 16:40:33,724:INFO:Declaring metric variables
2024-05-08 16:40:33,728:INFO:Importing untrained model
2024-05-08 16:40:33,731:INFO:Lasso Regression Imported successfully
2024-05-08 16:40:33,738:INFO:Starting cross validation
2024-05-08 16:40:33,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:33,757:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,759:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,762:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,766:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,771:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,771:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:33,773:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,779:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,784:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,787:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:33,848:INFO:Calculating mean and std
2024-05-08 16:40:33,848:INFO:Creating metrics dataframe
2024-05-08 16:40:33,850:INFO:Uploading results into container
2024-05-08 16:40:33,851:INFO:Uploading model into container now
2024-05-08 16:40:33,851:INFO:_master_model_container: 2
2024-05-08 16:40:33,851:INFO:_display_container: 2
2024-05-08 16:40:33,851:INFO:Lasso(random_state=123)
2024-05-08 16:40:33,851:INFO:create_model() successfully completed......................................
2024-05-08 16:40:33,971:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:33,972:INFO:Creating metrics dataframe
2024-05-08 16:40:33,978:INFO:Initializing Ridge Regression
2024-05-08 16:40:33,978:INFO:Total runtime is 0.008824559052785237 minutes
2024-05-08 16:40:33,980:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:33,980:INFO:Initializing create_model()
2024-05-08 16:40:33,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:33,981:INFO:Checking exceptions
2024-05-08 16:40:33,981:INFO:Importing libraries
2024-05-08 16:40:33,981:INFO:Copying training dataset
2024-05-08 16:40:33,983:INFO:Defining folds
2024-05-08 16:40:33,983:INFO:Declaring metric variables
2024-05-08 16:40:33,985:INFO:Importing untrained model
2024-05-08 16:40:33,988:INFO:Ridge Regression Imported successfully
2024-05-08 16:40:33,993:INFO:Starting cross validation
2024-05-08 16:40:33,994:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:34,009:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,013:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,014:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,017:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,019:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,019:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:34,021:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,023:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,027:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,030:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,086:INFO:Calculating mean and std
2024-05-08 16:40:34,086:INFO:Creating metrics dataframe
2024-05-08 16:40:34,088:INFO:Uploading results into container
2024-05-08 16:40:34,088:INFO:Uploading model into container now
2024-05-08 16:40:34,088:INFO:_master_model_container: 3
2024-05-08 16:40:34,088:INFO:_display_container: 2
2024-05-08 16:40:34,089:INFO:Ridge(random_state=123)
2024-05-08 16:40:34,089:INFO:create_model() successfully completed......................................
2024-05-08 16:40:34,182:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:34,182:INFO:Creating metrics dataframe
2024-05-08 16:40:34,187:INFO:Initializing Elastic Net
2024-05-08 16:40:34,188:INFO:Total runtime is 0.012323296070098876 minutes
2024-05-08 16:40:34,190:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:34,190:INFO:Initializing create_model()
2024-05-08 16:40:34,190:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:34,190:INFO:Checking exceptions
2024-05-08 16:40:34,190:INFO:Importing libraries
2024-05-08 16:40:34,190:INFO:Copying training dataset
2024-05-08 16:40:34,192:INFO:Defining folds
2024-05-08 16:40:34,192:INFO:Declaring metric variables
2024-05-08 16:40:34,194:INFO:Importing untrained model
2024-05-08 16:40:34,196:INFO:Elastic Net Imported successfully
2024-05-08 16:40:34,200:INFO:Starting cross validation
2024-05-08 16:40:34,200:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:34,214:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,215:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,216:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,219:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,220:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,221:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:34,222:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,225:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,229:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,231:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,296:INFO:Calculating mean and std
2024-05-08 16:40:34,296:INFO:Creating metrics dataframe
2024-05-08 16:40:34,298:INFO:Uploading results into container
2024-05-08 16:40:34,298:INFO:Uploading model into container now
2024-05-08 16:40:34,299:INFO:_master_model_container: 4
2024-05-08 16:40:34,299:INFO:_display_container: 2
2024-05-08 16:40:34,299:INFO:ElasticNet(random_state=123)
2024-05-08 16:40:34,299:INFO:create_model() successfully completed......................................
2024-05-08 16:40:34,424:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:34,424:INFO:Creating metrics dataframe
2024-05-08 16:40:34,431:INFO:Initializing Least Angle Regression
2024-05-08 16:40:34,431:INFO:Total runtime is 0.01637791395187378 minutes
2024-05-08 16:40:34,433:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:34,434:INFO:Initializing create_model()
2024-05-08 16:40:34,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:34,434:INFO:Checking exceptions
2024-05-08 16:40:34,434:INFO:Importing libraries
2024-05-08 16:40:34,434:INFO:Copying training dataset
2024-05-08 16:40:34,437:INFO:Defining folds
2024-05-08 16:40:34,437:INFO:Declaring metric variables
2024-05-08 16:40:34,440:INFO:Importing untrained model
2024-05-08 16:40:34,443:INFO:Least Angle Regression Imported successfully
2024-05-08 16:40:34,448:INFO:Starting cross validation
2024-05-08 16:40:34,449:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:34,463:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,466:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,468:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,469:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,473:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,473:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:34,474:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,483:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,486:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,489:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,497:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=2.018e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,498:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.995e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,498:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.584e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,498:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=1.535e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,498:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.774e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,500:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.758e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,501:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 35 iterations, i.e. alpha=1.346e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,504:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.306e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,504:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.134e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,504:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.093e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,504:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=7.614e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,507:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=5.798e-06, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,508:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=2.120e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,511:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.214e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,512:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.689e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,514:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=6.268e-01, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,515:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.556e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,515:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=2.446e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,516:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.948e-01, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,516:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.093e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,516:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=3.477e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.318e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=7.846e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=3.342e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=4.475e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.339e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.238e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=9.835e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,517:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.119e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.010e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=3.141e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.088e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=2.933e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.700e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,522:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=6.552e-02, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,524:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=6.249e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,525:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 33 iterations, i.e. alpha=4.998e-04, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,525:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=3.625e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,525:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.615e-01, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,525:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=2.480e-01, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,526:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=1.921e-01, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,526:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=1.334e-01, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,527:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.807e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,527:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 28 iterations, i.e. alpha=1.138e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,528:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.773e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,529:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.991e+00, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,529:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=1.061e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,529:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=1.464e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,529:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 38 iterations, i.e. alpha=3.899e-03, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,531:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=5.691e-01, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,532:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 22 iterations, i.e. alpha=3.791e-01, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,532:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.326e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,532:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=3.142e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,532:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=8.374e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,532:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.609e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,532:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.367e-02, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,552:INFO:Calculating mean and std
2024-05-08 16:40:34,552:INFO:Creating metrics dataframe
2024-05-08 16:40:34,554:INFO:Uploading results into container
2024-05-08 16:40:34,555:INFO:Uploading model into container now
2024-05-08 16:40:34,555:INFO:_master_model_container: 5
2024-05-08 16:40:34,555:INFO:_display_container: 2
2024-05-08 16:40:34,555:INFO:Lars(random_state=123)
2024-05-08 16:40:34,555:INFO:create_model() successfully completed......................................
2024-05-08 16:40:34,652:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:34,652:INFO:Creating metrics dataframe
2024-05-08 16:40:34,658:INFO:Initializing Lasso Least Angle Regression
2024-05-08 16:40:34,658:INFO:Total runtime is 0.02016988197962443 minutes
2024-05-08 16:40:34,660:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:34,661:INFO:Initializing create_model()
2024-05-08 16:40:34,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:34,661:INFO:Checking exceptions
2024-05-08 16:40:34,661:INFO:Importing libraries
2024-05-08 16:40:34,661:INFO:Copying training dataset
2024-05-08 16:40:34,663:INFO:Defining folds
2024-05-08 16:40:34,663:INFO:Declaring metric variables
2024-05-08 16:40:34,666:INFO:Importing untrained model
2024-05-08 16:40:34,668:INFO:Lasso Least Angle Regression Imported successfully
2024-05-08 16:40:34,674:INFO:Starting cross validation
2024-05-08 16:40:34,674:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:34,689:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,693:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,696:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,697:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,702:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,702:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:34,703:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,711:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,716:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,720:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,735:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.214e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,736:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.689e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,756:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.773e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,756:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.991e+00, with an active set of 3 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-08 16:40:34,780:INFO:Calculating mean and std
2024-05-08 16:40:34,781:INFO:Creating metrics dataframe
2024-05-08 16:40:34,783:INFO:Uploading results into container
2024-05-08 16:40:34,783:INFO:Uploading model into container now
2024-05-08 16:40:34,783:INFO:_master_model_container: 6
2024-05-08 16:40:34,783:INFO:_display_container: 2
2024-05-08 16:40:34,784:INFO:LassoLars(random_state=123)
2024-05-08 16:40:34,784:INFO:create_model() successfully completed......................................
2024-05-08 16:40:34,875:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:34,875:INFO:Creating metrics dataframe
2024-05-08 16:40:34,881:INFO:Initializing Orthogonal Matching Pursuit
2024-05-08 16:40:34,881:INFO:Total runtime is 0.02387500206629435 minutes
2024-05-08 16:40:34,882:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:34,883:INFO:Initializing create_model()
2024-05-08 16:40:34,883:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:34,883:INFO:Checking exceptions
2024-05-08 16:40:34,883:INFO:Importing libraries
2024-05-08 16:40:34,883:INFO:Copying training dataset
2024-05-08 16:40:34,885:INFO:Defining folds
2024-05-08 16:40:34,885:INFO:Declaring metric variables
2024-05-08 16:40:34,887:INFO:Importing untrained model
2024-05-08 16:40:34,889:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-08 16:40:34,892:INFO:Starting cross validation
2024-05-08 16:40:34,893:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:34,906:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,908:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,910:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,914:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,917:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,917:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:34,921:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,926:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,931:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,936:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:34,994:INFO:Calculating mean and std
2024-05-08 16:40:34,995:INFO:Creating metrics dataframe
2024-05-08 16:40:34,998:INFO:Uploading results into container
2024-05-08 16:40:34,998:INFO:Uploading model into container now
2024-05-08 16:40:34,998:INFO:_master_model_container: 7
2024-05-08 16:40:34,998:INFO:_display_container: 2
2024-05-08 16:40:34,998:INFO:OrthogonalMatchingPursuit()
2024-05-08 16:40:34,998:INFO:create_model() successfully completed......................................
2024-05-08 16:40:35,089:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:35,089:INFO:Creating metrics dataframe
2024-05-08 16:40:35,094:INFO:Initializing Bayesian Ridge
2024-05-08 16:40:35,094:INFO:Total runtime is 0.02743735710779826 minutes
2024-05-08 16:40:35,096:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:35,096:INFO:Initializing create_model()
2024-05-08 16:40:35,096:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:35,096:INFO:Checking exceptions
2024-05-08 16:40:35,096:INFO:Importing libraries
2024-05-08 16:40:35,096:INFO:Copying training dataset
2024-05-08 16:40:35,098:INFO:Defining folds
2024-05-08 16:40:35,098:INFO:Declaring metric variables
2024-05-08 16:40:35,101:INFO:Importing untrained model
2024-05-08 16:40:35,103:INFO:Bayesian Ridge Imported successfully
2024-05-08 16:40:35,107:INFO:Starting cross validation
2024-05-08 16:40:35,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:35,121:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,127:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,128:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,133:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,133:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:35,134:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,144:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,145:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,151:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,218:INFO:Calculating mean and std
2024-05-08 16:40:35,219:INFO:Creating metrics dataframe
2024-05-08 16:40:35,221:INFO:Uploading results into container
2024-05-08 16:40:35,222:INFO:Uploading model into container now
2024-05-08 16:40:35,222:INFO:_master_model_container: 8
2024-05-08 16:40:35,222:INFO:_display_container: 2
2024-05-08 16:40:35,222:INFO:BayesianRidge()
2024-05-08 16:40:35,222:INFO:create_model() successfully completed......................................
2024-05-08 16:40:35,315:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:35,315:INFO:Creating metrics dataframe
2024-05-08 16:40:35,321:INFO:Initializing Passive Aggressive Regressor
2024-05-08 16:40:35,321:INFO:Total runtime is 0.031220972537994385 minutes
2024-05-08 16:40:35,323:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:35,324:INFO:Initializing create_model()
2024-05-08 16:40:35,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:35,324:INFO:Checking exceptions
2024-05-08 16:40:35,324:INFO:Importing libraries
2024-05-08 16:40:35,324:INFO:Copying training dataset
2024-05-08 16:40:35,326:INFO:Defining folds
2024-05-08 16:40:35,326:INFO:Declaring metric variables
2024-05-08 16:40:35,328:INFO:Importing untrained model
2024-05-08 16:40:35,330:INFO:Passive Aggressive Regressor Imported successfully
2024-05-08 16:40:35,333:INFO:Starting cross validation
2024-05-08 16:40:35,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:35,346:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,349:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,350:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,352:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,354:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,354:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:35,358:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,366:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,371:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,374:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,405:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:40:35,405:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:40:35,406:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:40:35,406:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:40:35,406:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:40:35,406:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-08 16:40:35,429:INFO:Calculating mean and std
2024-05-08 16:40:35,429:INFO:Creating metrics dataframe
2024-05-08 16:40:35,431:INFO:Uploading results into container
2024-05-08 16:40:35,432:INFO:Uploading model into container now
2024-05-08 16:40:35,432:INFO:_master_model_container: 9
2024-05-08 16:40:35,432:INFO:_display_container: 2
2024-05-08 16:40:35,432:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-08 16:40:35,432:INFO:create_model() successfully completed......................................
2024-05-08 16:40:35,542:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:35,542:INFO:Creating metrics dataframe
2024-05-08 16:40:35,548:INFO:Initializing Huber Regressor
2024-05-08 16:40:35,548:INFO:Total runtime is 0.03500230709711711 minutes
2024-05-08 16:40:35,550:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:35,550:INFO:Initializing create_model()
2024-05-08 16:40:35,550:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:35,550:INFO:Checking exceptions
2024-05-08 16:40:35,550:INFO:Importing libraries
2024-05-08 16:40:35,550:INFO:Copying training dataset
2024-05-08 16:40:35,553:INFO:Defining folds
2024-05-08 16:40:35,553:INFO:Declaring metric variables
2024-05-08 16:40:35,555:INFO:Importing untrained model
2024-05-08 16:40:35,557:INFO:Huber Regressor Imported successfully
2024-05-08 16:40:35,561:INFO:Starting cross validation
2024-05-08 16:40:35,561:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:35,575:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,579:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,582:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,585:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,587:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,587:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:35,591:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,597:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,602:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,605:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,623:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,641:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,647:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,649:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,650:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,653:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,654:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,660:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,665:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,672:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-08 16:40:35,706:INFO:Calculating mean and std
2024-05-08 16:40:35,707:INFO:Creating metrics dataframe
2024-05-08 16:40:35,711:INFO:Uploading results into container
2024-05-08 16:40:35,712:INFO:Uploading model into container now
2024-05-08 16:40:35,713:INFO:_master_model_container: 10
2024-05-08 16:40:35,713:INFO:_display_container: 2
2024-05-08 16:40:35,713:INFO:HuberRegressor()
2024-05-08 16:40:35,713:INFO:create_model() successfully completed......................................
2024-05-08 16:40:35,844:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:35,845:INFO:Creating metrics dataframe
2024-05-08 16:40:35,852:INFO:Initializing K Neighbors Regressor
2024-05-08 16:40:35,852:INFO:Total runtime is 0.040068725744883224 minutes
2024-05-08 16:40:35,855:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:35,855:INFO:Initializing create_model()
2024-05-08 16:40:35,855:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:35,855:INFO:Checking exceptions
2024-05-08 16:40:35,855:INFO:Importing libraries
2024-05-08 16:40:35,855:INFO:Copying training dataset
2024-05-08 16:40:35,858:INFO:Defining folds
2024-05-08 16:40:35,858:INFO:Declaring metric variables
2024-05-08 16:40:35,861:INFO:Importing untrained model
2024-05-08 16:40:35,863:INFO:K Neighbors Regressor Imported successfully
2024-05-08 16:40:35,866:INFO:Starting cross validation
2024-05-08 16:40:35,867:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:35,880:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,882:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,884:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,886:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,888:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,888:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:35,889:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,894:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,895:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,899:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:35,981:INFO:Calculating mean and std
2024-05-08 16:40:35,982:INFO:Creating metrics dataframe
2024-05-08 16:40:35,985:INFO:Uploading results into container
2024-05-08 16:40:35,986:INFO:Uploading model into container now
2024-05-08 16:40:35,986:INFO:_master_model_container: 11
2024-05-08 16:40:35,986:INFO:_display_container: 2
2024-05-08 16:40:35,986:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-08 16:40:35,986:INFO:create_model() successfully completed......................................
2024-05-08 16:40:36,078:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:36,078:INFO:Creating metrics dataframe
2024-05-08 16:40:36,084:INFO:Initializing Decision Tree Regressor
2024-05-08 16:40:36,084:INFO:Total runtime is 0.04393166700998943 minutes
2024-05-08 16:40:36,086:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:36,086:INFO:Initializing create_model()
2024-05-08 16:40:36,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:36,086:INFO:Checking exceptions
2024-05-08 16:40:36,086:INFO:Importing libraries
2024-05-08 16:40:36,086:INFO:Copying training dataset
2024-05-08 16:40:36,088:INFO:Defining folds
2024-05-08 16:40:36,088:INFO:Declaring metric variables
2024-05-08 16:40:36,090:INFO:Importing untrained model
2024-05-08 16:40:36,093:INFO:Decision Tree Regressor Imported successfully
2024-05-08 16:40:36,096:INFO:Starting cross validation
2024-05-08 16:40:36,097:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:36,109:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,111:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,113:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,115:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,117:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,117:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:36,119:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,122:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,125:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,126:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,191:INFO:Calculating mean and std
2024-05-08 16:40:36,192:INFO:Creating metrics dataframe
2024-05-08 16:40:36,195:INFO:Uploading results into container
2024-05-08 16:40:36,195:INFO:Uploading model into container now
2024-05-08 16:40:36,195:INFO:_master_model_container: 12
2024-05-08 16:40:36,195:INFO:_display_container: 2
2024-05-08 16:40:36,196:INFO:DecisionTreeRegressor(random_state=123)
2024-05-08 16:40:36,196:INFO:create_model() successfully completed......................................
2024-05-08 16:40:36,291:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:36,291:INFO:Creating metrics dataframe
2024-05-08 16:40:36,296:INFO:Initializing Random Forest Regressor
2024-05-08 16:40:36,296:INFO:Total runtime is 0.04747229417165121 minutes
2024-05-08 16:40:36,298:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:36,298:INFO:Initializing create_model()
2024-05-08 16:40:36,298:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:36,298:INFO:Checking exceptions
2024-05-08 16:40:36,298:INFO:Importing libraries
2024-05-08 16:40:36,298:INFO:Copying training dataset
2024-05-08 16:40:36,300:INFO:Defining folds
2024-05-08 16:40:36,301:INFO:Declaring metric variables
2024-05-08 16:40:36,303:INFO:Importing untrained model
2024-05-08 16:40:36,304:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:40:36,308:INFO:Starting cross validation
2024-05-08 16:40:36,308:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:36,320:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,322:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,325:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,326:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,328:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,328:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:36,330:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,334:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,336:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,339:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,796:INFO:Calculating mean and std
2024-05-08 16:40:36,797:INFO:Creating metrics dataframe
2024-05-08 16:40:36,799:INFO:Uploading results into container
2024-05-08 16:40:36,799:INFO:Uploading model into container now
2024-05-08 16:40:36,800:INFO:_master_model_container: 13
2024-05-08 16:40:36,800:INFO:_display_container: 2
2024-05-08 16:40:36,800:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:40:36,800:INFO:create_model() successfully completed......................................
2024-05-08 16:40:36,884:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:36,884:INFO:Creating metrics dataframe
2024-05-08 16:40:36,891:INFO:Initializing Extra Trees Regressor
2024-05-08 16:40:36,891:INFO:Total runtime is 0.05737815300623576 minutes
2024-05-08 16:40:36,892:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:36,893:INFO:Initializing create_model()
2024-05-08 16:40:36,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:36,893:INFO:Checking exceptions
2024-05-08 16:40:36,893:INFO:Importing libraries
2024-05-08 16:40:36,893:INFO:Copying training dataset
2024-05-08 16:40:36,894:INFO:Defining folds
2024-05-08 16:40:36,894:INFO:Declaring metric variables
2024-05-08 16:40:36,896:INFO:Importing untrained model
2024-05-08 16:40:36,898:INFO:Extra Trees Regressor Imported successfully
2024-05-08 16:40:36,901:INFO:Starting cross validation
2024-05-08 16:40:36,902:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:36,916:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,918:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,919:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,922:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,924:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,924:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:36,924:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,930:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,932:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:36,934:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,179:INFO:Calculating mean and std
2024-05-08 16:40:37,180:INFO:Creating metrics dataframe
2024-05-08 16:40:37,182:INFO:Uploading results into container
2024-05-08 16:40:37,182:INFO:Uploading model into container now
2024-05-08 16:40:37,183:INFO:_master_model_container: 14
2024-05-08 16:40:37,183:INFO:_display_container: 2
2024-05-08 16:40:37,183:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:40:37,183:INFO:create_model() successfully completed......................................
2024-05-08 16:40:37,296:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:37,296:INFO:Creating metrics dataframe
2024-05-08 16:40:37,307:INFO:Initializing AdaBoost Regressor
2024-05-08 16:40:37,307:INFO:Total runtime is 0.06432157754898071 minutes
2024-05-08 16:40:37,310:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:37,311:INFO:Initializing create_model()
2024-05-08 16:40:37,311:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:37,311:INFO:Checking exceptions
2024-05-08 16:40:37,311:INFO:Importing libraries
2024-05-08 16:40:37,311:INFO:Copying training dataset
2024-05-08 16:40:37,314:INFO:Defining folds
2024-05-08 16:40:37,314:INFO:Declaring metric variables
2024-05-08 16:40:37,317:INFO:Importing untrained model
2024-05-08 16:40:37,321:INFO:AdaBoost Regressor Imported successfully
2024-05-08 16:40:37,328:INFO:Starting cross validation
2024-05-08 16:40:37,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:37,345:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,347:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,349:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,350:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,353:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,353:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:37,353:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,360:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,363:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,365:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,514:INFO:Calculating mean and std
2024-05-08 16:40:37,514:INFO:Creating metrics dataframe
2024-05-08 16:40:37,516:INFO:Uploading results into container
2024-05-08 16:40:37,516:INFO:Uploading model into container now
2024-05-08 16:40:37,516:INFO:_master_model_container: 15
2024-05-08 16:40:37,516:INFO:_display_container: 2
2024-05-08 16:40:37,516:INFO:AdaBoostRegressor(random_state=123)
2024-05-08 16:40:37,516:INFO:create_model() successfully completed......................................
2024-05-08 16:40:37,601:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:37,602:INFO:Creating metrics dataframe
2024-05-08 16:40:37,608:INFO:Initializing Gradient Boosting Regressor
2024-05-08 16:40:37,608:INFO:Total runtime is 0.0693302830060323 minutes
2024-05-08 16:40:37,609:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:37,610:INFO:Initializing create_model()
2024-05-08 16:40:37,610:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:37,610:INFO:Checking exceptions
2024-05-08 16:40:37,610:INFO:Importing libraries
2024-05-08 16:40:37,610:INFO:Copying training dataset
2024-05-08 16:40:37,612:INFO:Defining folds
2024-05-08 16:40:37,612:INFO:Declaring metric variables
2024-05-08 16:40:37,613:INFO:Importing untrained model
2024-05-08 16:40:37,615:INFO:Gradient Boosting Regressor Imported successfully
2024-05-08 16:40:37,618:INFO:Starting cross validation
2024-05-08 16:40:37,619:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:37,632:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,635:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,639:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,639:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,641:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,641:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:37,645:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,649:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,652:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:37,944:INFO:Calculating mean and std
2024-05-08 16:40:37,945:INFO:Creating metrics dataframe
2024-05-08 16:40:37,948:INFO:Uploading results into container
2024-05-08 16:40:37,948:INFO:Uploading model into container now
2024-05-08 16:40:37,948:INFO:_master_model_container: 16
2024-05-08 16:40:37,948:INFO:_display_container: 2
2024-05-08 16:40:37,948:INFO:GradientBoostingRegressor(random_state=123)
2024-05-08 16:40:37,948:INFO:create_model() successfully completed......................................
2024-05-08 16:40:38,037:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:38,037:INFO:Creating metrics dataframe
2024-05-08 16:40:38,043:INFO:Initializing Light Gradient Boosting Machine
2024-05-08 16:40:38,043:INFO:Total runtime is 0.07658158540725708 minutes
2024-05-08 16:40:38,045:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:38,045:INFO:Initializing create_model()
2024-05-08 16:40:38,045:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:38,045:INFO:Checking exceptions
2024-05-08 16:40:38,045:INFO:Importing libraries
2024-05-08 16:40:38,045:INFO:Copying training dataset
2024-05-08 16:40:38,047:INFO:Defining folds
2024-05-08 16:40:38,047:INFO:Declaring metric variables
2024-05-08 16:40:38,049:INFO:Importing untrained model
2024-05-08 16:40:38,051:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-08 16:40:38,055:INFO:Starting cross validation
2024-05-08 16:40:38,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:38,072:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,074:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,076:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,078:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,079:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,080:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:38,081:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,083:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,090:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,093:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,713:INFO:Calculating mean and std
2024-05-08 16:40:38,714:INFO:Creating metrics dataframe
2024-05-08 16:40:38,717:INFO:Uploading results into container
2024-05-08 16:40:38,717:INFO:Uploading model into container now
2024-05-08 16:40:38,717:INFO:_master_model_container: 17
2024-05-08 16:40:38,717:INFO:_display_container: 2
2024-05-08 16:40:38,718:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:40:38,718:INFO:create_model() successfully completed......................................
2024-05-08 16:40:38,802:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:38,802:INFO:Creating metrics dataframe
2024-05-08 16:40:38,808:INFO:Initializing Dummy Regressor
2024-05-08 16:40:38,808:INFO:Total runtime is 0.08933290640513103 minutes
2024-05-08 16:40:38,810:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:38,810:INFO:Initializing create_model()
2024-05-08 16:40:38,810:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0ed8098fd0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:38,810:INFO:Checking exceptions
2024-05-08 16:40:38,810:INFO:Importing libraries
2024-05-08 16:40:38,810:INFO:Copying training dataset
2024-05-08 16:40:38,812:INFO:Defining folds
2024-05-08 16:40:38,812:INFO:Declaring metric variables
2024-05-08 16:40:38,814:INFO:Importing untrained model
2024-05-08 16:40:38,815:INFO:Dummy Regressor Imported successfully
2024-05-08 16:40:38,820:INFO:Starting cross validation
2024-05-08 16:40:38,820:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:38,834:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,836:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,838:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,839:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,842:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,842:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:38,844:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,847:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,852:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,856:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:38,911:INFO:Calculating mean and std
2024-05-08 16:40:38,912:INFO:Creating metrics dataframe
2024-05-08 16:40:38,914:INFO:Uploading results into container
2024-05-08 16:40:38,915:INFO:Uploading model into container now
2024-05-08 16:40:38,915:INFO:_master_model_container: 18
2024-05-08 16:40:38,915:INFO:_display_container: 2
2024-05-08 16:40:38,915:INFO:DummyRegressor()
2024-05-08 16:40:38,915:INFO:create_model() successfully completed......................................
2024-05-08 16:40:39,009:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:39,009:INFO:Creating metrics dataframe
2024-05-08 16:40:39,021:INFO:Initializing create_model()
2024-05-08 16:40:39,021:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:39,021:INFO:Checking exceptions
2024-05-08 16:40:39,023:INFO:Importing libraries
2024-05-08 16:40:39,023:INFO:Copying training dataset
2024-05-08 16:40:39,026:INFO:Defining folds
2024-05-08 16:40:39,026:INFO:Declaring metric variables
2024-05-08 16:40:39,026:INFO:Importing untrained model
2024-05-08 16:40:39,026:INFO:Declaring custom model
2024-05-08 16:40:39,027:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:40:39,027:INFO:Cross validation set to False
2024-05-08 16:40:39,027:INFO:Fitting Model
2024-05-08 16:40:39,030:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,141:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:40:39,141:INFO:create_model() successfully completed......................................
2024-05-08 16:40:39,245:INFO:_master_model_container: 18
2024-05-08 16:40:39,245:INFO:_display_container: 2
2024-05-08 16:40:39,246:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:40:39,246:INFO:compare_models() successfully completed......................................
2024-05-08 16:40:39,246:INFO:Initializing tune_model()
2024-05-08 16:40:39,246:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>)
2024-05-08 16:40:39,246:INFO:Checking exceptions
2024-05-08 16:40:39,256:INFO:Copying training dataset
2024-05-08 16:40:39,258:INFO:Checking base model
2024-05-08 16:40:39,259:INFO:Base model : Random Forest Regressor
2024-05-08 16:40:39,262:INFO:Declaring metric variables
2024-05-08 16:40:39,265:INFO:Defining Hyperparameters
2024-05-08 16:40:39,373:INFO:Tuning with n_jobs=-1
2024-05-08 16:40:39,373:INFO:Initializing RandomizedSearchCV
2024-05-08 16:40:39,397:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,399:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,399:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,400:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,403:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,403:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:39,404:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,405:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,407:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,407:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,409:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,410:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,412:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,413:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,433:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,433:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:39,435:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,726:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,734:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,737:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,750:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,755:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,760:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,764:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,767:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,767:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:39,767:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,775:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,788:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,796:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,796:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:39,810:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,028:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,033:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,118:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,118:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:40,125:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,252:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,361:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,426:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,430:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,443:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,454:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,467:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,467:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,468:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:40,506:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,518:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,542:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,542:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,559:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,562:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,627:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,731:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,845:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,845:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:40,884:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,951:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:40,987:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,018:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,049:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,071:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,082:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,091:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,097:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,097:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:41,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,166:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,183:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,230:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,297:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,347:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,349:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,397:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,397:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:41,406:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,443:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,501:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,515:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,547:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,550:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,554:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,582:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,628:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,658:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,689:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,689:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:41,729:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,790:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,791:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,851:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,937:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,951:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,976:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:41,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:42,043:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,135:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,153:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,177:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,355:INFO:best_params: {'actual_estimator__n_estimators': 130, 'actual_estimator__min_samples_split': 9, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 4, 'actual_estimator__criterion': 'absolute_error', 'actual_estimator__bootstrap': False}
2024-05-08 16:40:42,355:INFO:Hyperparameter search completed
2024-05-08 16:40:42,355:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:42,356:INFO:Initializing create_model()
2024-05-08 16:40:42,356:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7b0e8e405a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 130, 'min_samples_split': 9, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 4, 'criterion': 'absolute_error', 'bootstrap': False})
2024-05-08 16:40:42,356:INFO:Checking exceptions
2024-05-08 16:40:42,356:INFO:Importing libraries
2024-05-08 16:40:42,356:INFO:Copying training dataset
2024-05-08 16:40:42,358:INFO:Defining folds
2024-05-08 16:40:42,358:INFO:Declaring metric variables
2024-05-08 16:40:42,360:INFO:Importing untrained model
2024-05-08 16:40:42,360:INFO:Declaring custom model
2024-05-08 16:40:42,362:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:40:42,365:INFO:Starting cross validation
2024-05-08 16:40:42,366:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:42,379:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,381:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,384:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,385:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,387:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,387:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:42,390:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,399:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,403:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,406:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,818:INFO:Calculating mean and std
2024-05-08 16:40:42,819:INFO:Creating metrics dataframe
2024-05-08 16:40:42,823:INFO:Finalizing model
2024-05-08 16:40:42,824:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:42,920:INFO:Uploading results into container
2024-05-08 16:40:42,920:INFO:Uploading model into container now
2024-05-08 16:40:42,921:INFO:_master_model_container: 19
2024-05-08 16:40:42,921:INFO:_display_container: 3
2024-05-08 16:40:42,921:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=4,
                      max_features='log2', min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=9, n_estimators=130,
                      n_jobs=-1, random_state=123)
2024-05-08 16:40:42,921:INFO:create_model() successfully completed......................................
2024-05-08 16:40:43,011:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:43,011:INFO:choose_better activated
2024-05-08 16:40:43,013:INFO:SubProcess create_model() called ==================================
2024-05-08 16:40:43,013:INFO:Initializing create_model()
2024-05-08 16:40:43,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:43,014:INFO:Checking exceptions
2024-05-08 16:40:43,014:INFO:Importing libraries
2024-05-08 16:40:43,014:INFO:Copying training dataset
2024-05-08 16:40:43,016:INFO:Defining folds
2024-05-08 16:40:43,016:INFO:Declaring metric variables
2024-05-08 16:40:43,016:INFO:Importing untrained model
2024-05-08 16:40:43,016:INFO:Declaring custom model
2024-05-08 16:40:43,017:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:40:43,017:INFO:Starting cross validation
2024-05-08 16:40:43,017:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-08 16:40:43,029:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,032:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,034:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,037:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,039:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,039:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:250: RuntimeWarning: overflow encountered in reduce
  ret = umr_sum(x, axis, dtype, out, keepdims=keepdims, where=where)

2024-05-08 16:40:43,040:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,045:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,047:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,047:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,497:INFO:Calculating mean and std
2024-05-08 16:40:43,498:INFO:Creating metrics dataframe
2024-05-08 16:40:43,499:INFO:Finalizing model
2024-05-08 16:40:43,501:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,603:INFO:Uploading results into container
2024-05-08 16:40:43,604:INFO:Uploading model into container now
2024-05-08 16:40:43,604:INFO:_master_model_container: 20
2024-05-08 16:40:43,604:INFO:_display_container: 4
2024-05-08 16:40:43,604:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:40:43,604:INFO:create_model() successfully completed......................................
2024-05-08 16:40:43,687:INFO:SubProcess create_model() end ==================================
2024-05-08 16:40:43,687:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for R2 is 0.6724
2024-05-08 16:40:43,688:INFO:RandomForestRegressor(bootstrap=False, criterion='absolute_error', max_depth=4,
                      max_features='log2', min_impurity_decrease=0.0002,
                      min_samples_leaf=5, min_samples_split=9, n_estimators=130,
                      n_jobs=-1, random_state=123) result for R2 is 0.6352
2024-05-08 16:40:43,688:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) is best model
2024-05-08 16:40:43,688:INFO:choose_better completed
2024-05-08 16:40:43,688:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-08 16:40:43,694:INFO:_master_model_container: 20
2024-05-08 16:40:43,694:INFO:_display_container: 3
2024-05-08 16:40:43,694:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:40:43,694:INFO:tune_model() successfully completed......................................
2024-05-08 16:40:43,805:INFO:Initializing finalize_model()
2024-05-08 16:40:43,805:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-08 16:40:43,805:INFO:Finalizing RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-08 16:40:43,807:INFO:Initializing create_model()
2024-05-08 16:40:43,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-08 16:40:43,807:INFO:Checking exceptions
2024-05-08 16:40:43,808:INFO:Importing libraries
2024-05-08 16:40:43,808:INFO:Copying training dataset
2024-05-08 16:40:43,808:INFO:Defining folds
2024-05-08 16:40:43,808:INFO:Declaring metric variables
2024-05-08 16:40:43,808:INFO:Importing untrained model
2024-05-08 16:40:43,808:INFO:Declaring custom model
2024-05-08 16:40:43,809:INFO:Random Forest Regressor Imported successfully
2024-05-08 16:40:43,809:INFO:Cross validation set to False
2024-05-08 16:40:43,809:INFO:Fitting Model
2024-05-08 16:40:43,811:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-08 16:40:43,929:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-05-08 16:40:43,929:INFO:create_model() successfully completed......................................
2024-05-08 16:40:44,014:INFO:_master_model_container: 20
2024-05-08 16:40:44,014:INFO:_display_container: 3
2024-05-08 16:40:44,020:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))])
2024-05-08 16:40:44,020:INFO:finalize_model() successfully completed......................................
2024-05-08 16:40:44,114:INFO:Initializing predict_model()
2024-05-08 16:40:44,114:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7b0e84705310>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7b0e845ccdc0>)
2024-05-08 16:40:44,114:INFO:Checking exceptions
2024-05-08 16:40:44,114:INFO:Preloading libraries
2024-05-08 16:40:44,115:INFO:Set up data.
2024-05-08 16:40:44,119:INFO:Set up index.
2024-05-08 16:40:44,145:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-09 10:57:43,878:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-09 10:57:43,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-09 10:57:43,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-09 10:57:43,879:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-09 10:57:44,202:WARNING:/tmp/ipykernel_14873/2262976735.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-09 10:57:44,211:INFO:PyCaret RegressionExperiment
2024-05-09 10:57:44,211:INFO:Logging name: reg-default-name
2024-05-09 10:57:44,211:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-09 10:57:44,211:INFO:version 3.3.2
2024-05-09 10:57:44,211:INFO:Initializing setup()
2024-05-09 10:57:44,211:INFO:self.USI: 2674
2024-05-09 10:57:44,211:INFO:self._variable_keys: {'y', '_ml_usecase', 'exp_name_log', 'gpu_n_jobs_param', 'n_jobs_param', 'data', 'log_plots_param', 'seed', 'USI', 'exp_id', 'X', 'target_param', 'y_test', 'gpu_param', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'idx', 'fold_groups_param', 'transform_target_param', 'logging_param', 'memory', 'pipeline', 'fold_generator', 'X_train', 'y_train'}
2024-05-09 10:57:44,211:INFO:Checking environment
2024-05-09 10:57:44,211:INFO:python_version: 3.9.18
2024-05-09 10:57:44,211:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-09 10:57:44,211:INFO:machine: x86_64
2024-05-09 10:57:44,211:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 10:57:44,211:INFO:Memory: svmem(total=16429789184, available=6976266240, percent=57.5, used=8352870400, free=239050752, active=10843521024, inactive=4047245312, buffers=329572352, cached=7508295680, shared=778104832, slab=622940160)
2024-05-09 10:57:44,212:INFO:Physical Core: 12
2024-05-09 10:57:44,212:INFO:Logical Core: 16
2024-05-09 10:57:44,212:INFO:Checking libraries
2024-05-09 10:57:44,212:INFO:System:
2024-05-09 10:57:44,212:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-09 10:57:44,212:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-09 10:57:44,212:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 10:57:44,212:INFO:PyCaret required dependencies:
2024-05-09 10:57:44,476:INFO:                 pip: 23.2.1
2024-05-09 10:57:44,476:INFO:          setuptools: 68.0.0
2024-05-09 10:57:44,476:INFO:             pycaret: 3.3.2
2024-05-09 10:57:44,476:INFO:             IPython: 8.15.0
2024-05-09 10:57:44,476:INFO:          ipywidgets: 8.0.4
2024-05-09 10:57:44,476:INFO:                tqdm: 4.65.0
2024-05-09 10:57:44,476:INFO:               numpy: 1.24.3
2024-05-09 10:57:44,476:INFO:              pandas: 1.4.2
2024-05-09 10:57:44,476:INFO:              jinja2: 3.1.4
2024-05-09 10:57:44,476:INFO:               scipy: 1.11.3
2024-05-09 10:57:44,476:INFO:              joblib: 1.2.0
2024-05-09 10:57:44,476:INFO:             sklearn: 1.4.2
2024-05-09 10:57:44,476:INFO:                pyod: 1.1.3
2024-05-09 10:57:44,476:INFO:            imblearn: 0.12.2
2024-05-09 10:57:44,476:INFO:   category_encoders: 2.6.3
2024-05-09 10:57:44,476:INFO:            lightgbm: 4.3.0
2024-05-09 10:57:44,476:INFO:               numba: 0.58.0
2024-05-09 10:57:44,476:INFO:            requests: 2.31.0
2024-05-09 10:57:44,476:INFO:          matplotlib: 3.7.2
2024-05-09 10:57:44,476:INFO:          scikitplot: 0.3.7
2024-05-09 10:57:44,476:INFO:         yellowbrick: 1.5
2024-05-09 10:57:44,476:INFO:              plotly: 5.22.0
2024-05-09 10:57:44,476:INFO:    plotly-resampler: Not installed
2024-05-09 10:57:44,476:INFO:             kaleido: 0.2.1
2024-05-09 10:57:44,476:INFO:           schemdraw: 0.15
2024-05-09 10:57:44,476:INFO:         statsmodels: 0.14.0
2024-05-09 10:57:44,476:INFO:              sktime: 0.26.0
2024-05-09 10:57:44,476:INFO:               tbats: 1.1.3
2024-05-09 10:57:44,476:INFO:            pmdarima: 2.0.4
2024-05-09 10:57:44,476:INFO:              psutil: 5.9.0
2024-05-09 10:57:44,476:INFO:          markupsafe: 2.0.1
2024-05-09 10:57:44,477:INFO:             pickle5: Not installed
2024-05-09 10:57:44,477:INFO:         cloudpickle: 2.2.1
2024-05-09 10:57:44,477:INFO:         deprecation: 2.1.0
2024-05-09 10:57:44,477:INFO:              xxhash: 2.0.2
2024-05-09 10:57:44,477:INFO:           wurlitzer: 3.0.2
2024-05-09 10:57:44,477:INFO:PyCaret optional dependencies:
2024-05-09 10:57:44,484:INFO:                shap: Not installed
2024-05-09 10:57:44,484:INFO:           interpret: Not installed
2024-05-09 10:57:44,484:INFO:                umap: Not installed
2024-05-09 10:57:44,484:INFO:     ydata_profiling: Not installed
2024-05-09 10:57:44,484:INFO:  explainerdashboard: Not installed
2024-05-09 10:57:44,484:INFO:             autoviz: Not installed
2024-05-09 10:57:44,484:INFO:           fairlearn: Not installed
2024-05-09 10:57:44,484:INFO:          deepchecks: Not installed
2024-05-09 10:57:44,484:INFO:             xgboost: Not installed
2024-05-09 10:57:44,484:INFO:            catboost: Not installed
2024-05-09 10:57:44,484:INFO:              kmodes: Not installed
2024-05-09 10:57:44,484:INFO:             mlxtend: Not installed
2024-05-09 10:57:44,484:INFO:       statsforecast: Not installed
2024-05-09 10:57:44,484:INFO:        tune_sklearn: Not installed
2024-05-09 10:57:44,484:INFO:                 ray: Not installed
2024-05-09 10:57:44,484:INFO:            hyperopt: Not installed
2024-05-09 10:57:44,484:INFO:              optuna: Not installed
2024-05-09 10:57:44,484:INFO:               skopt: Not installed
2024-05-09 10:57:44,484:INFO:              mlflow: Not installed
2024-05-09 10:57:44,484:INFO:              gradio: Not installed
2024-05-09 10:57:44,484:INFO:             fastapi: Not installed
2024-05-09 10:57:44,484:INFO:             uvicorn: Not installed
2024-05-09 10:57:44,485:INFO:              m2cgen: Not installed
2024-05-09 10:57:44,485:INFO:           evidently: Not installed
2024-05-09 10:57:44,485:INFO:               fugue: Not installed
2024-05-09 10:57:44,485:INFO:           streamlit: Not installed
2024-05-09 10:57:44,485:INFO:             prophet: Not installed
2024-05-09 10:57:44,485:INFO:None
2024-05-09 10:57:44,485:INFO:Set up data.
2024-05-09 10:57:44,487:INFO:Set up folding strategy.
2024-05-09 10:57:44,487:INFO:Set up train/test split.
2024-05-09 10:57:44,489:INFO:Set up index.
2024-05-09 10:57:44,489:INFO:Assigning column types.
2024-05-09 10:57:44,490:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-09 10:57:44,491:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,493:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,524:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,544:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,546:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,548:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,595:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,596:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-09 10:57:44,598:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,600:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,647:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,648:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,648:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,650:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,652:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,679:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,700:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-09 10:57:44,705:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,731:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,752:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,757:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,785:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,806:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,806:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,807:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,807:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-09 10:57:44,840:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,866:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,905:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,929:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-09 10:57:44,965:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:44,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:44,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,029:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 10:57:45,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,054:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,054:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-09 10:57:45,114:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,114:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,173:INFO:Preparing preprocessing pipeline...
2024-05-09 10:57:45,173:INFO:Set up target transformation.
2024-05-09 10:57:45,173:INFO:Set up date feature engineering.
2024-05-09 10:57:45,173:INFO:Set up simple imputation.
2024-05-09 10:57:45,173:INFO:Set up polynomial features.
2024-05-09 10:57:45,173:INFO:Set up feature normalization.
2024-05-09 10:57:45,174:INFO:Set up column name cleaning.
2024-05-09 10:57:45,188:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:45,221:INFO:Finished creating preprocessing pipeline.
2024-05-09 10:57:45,228:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_...
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-09 10:57:45,228:INFO:Creating final display dataframe.
2024-05-09 10:57:45,317:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (576, 5)
4        Transformed data shape         (576, 28)
5   Transformed train set shape         (403, 28)
6    Transformed test set shape         (173, 28)
7              Numeric features                 3
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13          Polynomial features              True
14            Polynomial degree                 2
15                    Normalize              True
16             Normalize method            zscore
17             Transform target              True
18      Transform target method       yeo-johnson
19               Fold Generator             KFold
20                  Fold Number                10
21                     CPU Jobs                -1
22                      Use GPU             False
23               Log Experiment             False
24              Experiment Name  reg-default-name
25                          USI              2674
2024-05-09 10:57:45,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,451:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 10:57:45,452:INFO:setup() successfully completed in 1.24s...............
2024-05-09 10:57:45,452:INFO:Initializing compare_models()
2024-05-09 10:57:45,452:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-09 10:57:45,452:INFO:Checking exceptions
2024-05-09 10:57:45,453:INFO:Preparing display monitor
2024-05-09 10:57:45,474:INFO:Initializing Linear Regression
2024-05-09 10:57:45,475:INFO:Total runtime is 2.761681874593099e-06 minutes
2024-05-09 10:57:45,479:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:45,480:INFO:Initializing create_model()
2024-05-09 10:57:45,480:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:45,480:INFO:Checking exceptions
2024-05-09 10:57:45,480:INFO:Importing libraries
2024-05-09 10:57:45,480:INFO:Copying training dataset
2024-05-09 10:57:45,484:INFO:Defining folds
2024-05-09 10:57:45,485:INFO:Declaring metric variables
2024-05-09 10:57:45,487:INFO:Importing untrained model
2024-05-09 10:57:45,491:INFO:Linear Regression Imported successfully
2024-05-09 10:57:45,497:INFO:Starting cross validation
2024-05-09 10:57:45,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:47,386:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,388:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,395:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,446:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,742:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,743:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,752:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,817:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,863:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:47,921:INFO:Calculating mean and std
2024-05-09 10:57:47,922:INFO:Creating metrics dataframe
2024-05-09 10:57:47,926:INFO:Uploading results into container
2024-05-09 10:57:47,927:INFO:Uploading model into container now
2024-05-09 10:57:47,928:INFO:_master_model_container: 1
2024-05-09 10:57:47,928:INFO:_display_container: 2
2024-05-09 10:57:47,928:INFO:LinearRegression(n_jobs=-1)
2024-05-09 10:57:47,928:INFO:create_model() successfully completed......................................
2024-05-09 10:57:48,015:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:48,015:INFO:Creating metrics dataframe
2024-05-09 10:57:48,024:INFO:Initializing Lasso Regression
2024-05-09 10:57:48,024:INFO:Total runtime is 0.04248867829640707 minutes
2024-05-09 10:57:48,026:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:48,026:INFO:Initializing create_model()
2024-05-09 10:57:48,026:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:48,026:INFO:Checking exceptions
2024-05-09 10:57:48,026:INFO:Importing libraries
2024-05-09 10:57:48,026:INFO:Copying training dataset
2024-05-09 10:57:48,029:INFO:Defining folds
2024-05-09 10:57:48,029:INFO:Declaring metric variables
2024-05-09 10:57:48,031:INFO:Importing untrained model
2024-05-09 10:57:48,035:INFO:Lasso Regression Imported successfully
2024-05-09 10:57:48,039:INFO:Starting cross validation
2024-05-09 10:57:48,040:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:48,075:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:48,076:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:48,081:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:48,084:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,296:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,320:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,322:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,575:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,577:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,606:INFO:Calculating mean and std
2024-05-09 10:57:49,607:INFO:Creating metrics dataframe
2024-05-09 10:57:49,610:INFO:Uploading results into container
2024-05-09 10:57:49,610:INFO:Uploading model into container now
2024-05-09 10:57:49,611:INFO:_master_model_container: 2
2024-05-09 10:57:49,611:INFO:_display_container: 2
2024-05-09 10:57:49,611:INFO:Lasso(random_state=123)
2024-05-09 10:57:49,611:INFO:create_model() successfully completed......................................
2024-05-09 10:57:49,684:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:49,684:INFO:Creating metrics dataframe
2024-05-09 10:57:49,689:INFO:Initializing Ridge Regression
2024-05-09 10:57:49,689:INFO:Total runtime is 0.07024359305699666 minutes
2024-05-09 10:57:49,691:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:49,691:INFO:Initializing create_model()
2024-05-09 10:57:49,691:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:49,691:INFO:Checking exceptions
2024-05-09 10:57:49,691:INFO:Importing libraries
2024-05-09 10:57:49,691:INFO:Copying training dataset
2024-05-09 10:57:49,693:INFO:Defining folds
2024-05-09 10:57:49,693:INFO:Declaring metric variables
2024-05-09 10:57:49,694:INFO:Importing untrained model
2024-05-09 10:57:49,696:INFO:Ridge Regression Imported successfully
2024-05-09 10:57:49,700:INFO:Starting cross validation
2024-05-09 10:57:49,701:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:49,717:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,719:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,723:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,725:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,732:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,735:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,739:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,743:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,745:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,802:INFO:Calculating mean and std
2024-05-09 10:57:49,803:INFO:Creating metrics dataframe
2024-05-09 10:57:49,805:INFO:Uploading results into container
2024-05-09 10:57:49,806:INFO:Uploading model into container now
2024-05-09 10:57:49,806:INFO:_master_model_container: 3
2024-05-09 10:57:49,806:INFO:_display_container: 2
2024-05-09 10:57:49,806:INFO:Ridge(random_state=123)
2024-05-09 10:57:49,806:INFO:create_model() successfully completed......................................
2024-05-09 10:57:49,867:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:49,867:INFO:Creating metrics dataframe
2024-05-09 10:57:49,873:INFO:Initializing Elastic Net
2024-05-09 10:57:49,873:INFO:Total runtime is 0.07330582141876221 minutes
2024-05-09 10:57:49,875:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:49,875:INFO:Initializing create_model()
2024-05-09 10:57:49,875:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:49,875:INFO:Checking exceptions
2024-05-09 10:57:49,875:INFO:Importing libraries
2024-05-09 10:57:49,875:INFO:Copying training dataset
2024-05-09 10:57:49,877:INFO:Defining folds
2024-05-09 10:57:49,877:INFO:Declaring metric variables
2024-05-09 10:57:49,879:INFO:Importing untrained model
2024-05-09 10:57:49,881:INFO:Elastic Net Imported successfully
2024-05-09 10:57:49,885:INFO:Starting cross validation
2024-05-09 10:57:49,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:49,903:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,904:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,907:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,910:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,918:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,922:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,926:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,930:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,934:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:49,997:INFO:Calculating mean and std
2024-05-09 10:57:49,998:INFO:Creating metrics dataframe
2024-05-09 10:57:50,001:INFO:Uploading results into container
2024-05-09 10:57:50,001:INFO:Uploading model into container now
2024-05-09 10:57:50,002:INFO:_master_model_container: 4
2024-05-09 10:57:50,002:INFO:_display_container: 2
2024-05-09 10:57:50,002:INFO:ElasticNet(random_state=123)
2024-05-09 10:57:50,002:INFO:create_model() successfully completed......................................
2024-05-09 10:57:50,076:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:50,076:INFO:Creating metrics dataframe
2024-05-09 10:57:50,082:INFO:Initializing Least Angle Regression
2024-05-09 10:57:50,082:INFO:Total runtime is 0.076794171333313 minutes
2024-05-09 10:57:50,084:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:50,085:INFO:Initializing create_model()
2024-05-09 10:57:50,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:50,085:INFO:Checking exceptions
2024-05-09 10:57:50,085:INFO:Importing libraries
2024-05-09 10:57:50,085:INFO:Copying training dataset
2024-05-09 10:57:50,087:INFO:Defining folds
2024-05-09 10:57:50,087:INFO:Declaring metric variables
2024-05-09 10:57:50,090:INFO:Importing untrained model
2024-05-09 10:57:50,092:INFO:Least Angle Regression Imported successfully
2024-05-09 10:57:50,096:INFO:Starting cross validation
2024-05-09 10:57:50,097:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:50,111:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,112:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,114:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,117:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,119:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,123:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,126:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,126:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,132:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,150:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.313e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,150:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 26 iterations, i.e. alpha=2.603e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,151:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.503e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,151:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.173e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,151:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=9.741e-02, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,152:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.937e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,152:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.712e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,153:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=1.497e+00, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,155:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.243e+00, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,155:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.725e-01, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,155:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=8.702e-02, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,157:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.002e+00, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=6.803e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.396e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,160:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 29 iterations, i.e. alpha=1.521e+00, with an active set of 19 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,160:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=7.713e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,161:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=6.151e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,161:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.498e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,161:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 32 iterations, i.e. alpha=5.111e-01, with an active set of 21 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,162:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=2.444e-01, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,162:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.425e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,163:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=3.257e+00, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,164:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.105e+00, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,164:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=3.314e-01, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,164:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=1.490e+00, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,166:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=4.098e-06, with an active set of 24 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,168:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 36 iterations, i.e. alpha=3.913e+00, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,205:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.304e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,206:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=2.830e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,207:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=2.739e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=2.191e+00, with an active set of 14 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,208:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 25 iterations, i.e. alpha=4.793e-02, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=2.936e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 27 iterations, i.e. alpha=1.994e-01, with an active set of 20 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 30 iterations, i.e. alpha=1.646e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=3.635e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 31 iterations, i.e. alpha=1.524e-02, with an active set of 23 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,230:INFO:Calculating mean and std
2024-05-09 10:57:50,231:INFO:Creating metrics dataframe
2024-05-09 10:57:50,233:INFO:Uploading results into container
2024-05-09 10:57:50,233:INFO:Uploading model into container now
2024-05-09 10:57:50,234:INFO:_master_model_container: 5
2024-05-09 10:57:50,234:INFO:_display_container: 2
2024-05-09 10:57:50,234:INFO:Lars(random_state=123)
2024-05-09 10:57:50,234:INFO:create_model() successfully completed......................................
2024-05-09 10:57:50,301:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:50,301:INFO:Creating metrics dataframe
2024-05-09 10:57:50,307:INFO:Initializing Lasso Least Angle Regression
2024-05-09 10:57:50,307:INFO:Total runtime is 0.08053961197535198 minutes
2024-05-09 10:57:50,309:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:50,309:INFO:Initializing create_model()
2024-05-09 10:57:50,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:50,309:INFO:Checking exceptions
2024-05-09 10:57:50,309:INFO:Importing libraries
2024-05-09 10:57:50,309:INFO:Copying training dataset
2024-05-09 10:57:50,311:INFO:Defining folds
2024-05-09 10:57:50,311:INFO:Declaring metric variables
2024-05-09 10:57:50,313:INFO:Importing untrained model
2024-05-09 10:57:50,315:INFO:Lasso Least Angle Regression Imported successfully
2024-05-09 10:57:50,319:INFO:Starting cross validation
2024-05-09 10:57:50,319:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:50,334:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,336:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,338:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,340:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,344:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,346:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,351:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,355:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,359:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,377:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=4.304e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,382:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=5.498e+00, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,382:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=3.425e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,387:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=2.858e+00, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,388:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:688: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.718e+00, with an active set of 6 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.
  warnings.warn(

2024-05-09 10:57:50,388:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=1.667e+00, previous alpha=1.664e+00, with an active set of 5 regressors.
  warnings.warn(

2024-05-09 10:57:50,388:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_least_angle.py:718: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 12 iterations, alpha=2.752e+00, previous alpha=2.631e+00, with an active set of 7 regressors.
  warnings.warn(

2024-05-09 10:57:50,445:INFO:Calculating mean and std
2024-05-09 10:57:50,446:INFO:Creating metrics dataframe
2024-05-09 10:57:50,448:INFO:Uploading results into container
2024-05-09 10:57:50,448:INFO:Uploading model into container now
2024-05-09 10:57:50,448:INFO:_master_model_container: 6
2024-05-09 10:57:50,448:INFO:_display_container: 2
2024-05-09 10:57:50,449:INFO:LassoLars(random_state=123)
2024-05-09 10:57:50,449:INFO:create_model() successfully completed......................................
2024-05-09 10:57:50,520:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:50,520:INFO:Creating metrics dataframe
2024-05-09 10:57:50,526:INFO:Initializing Orthogonal Matching Pursuit
2024-05-09 10:57:50,526:INFO:Total runtime is 0.08419520457585654 minutes
2024-05-09 10:57:50,528:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:50,528:INFO:Initializing create_model()
2024-05-09 10:57:50,528:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:50,528:INFO:Checking exceptions
2024-05-09 10:57:50,528:INFO:Importing libraries
2024-05-09 10:57:50,528:INFO:Copying training dataset
2024-05-09 10:57:50,531:INFO:Defining folds
2024-05-09 10:57:50,531:INFO:Declaring metric variables
2024-05-09 10:57:50,533:INFO:Importing untrained model
2024-05-09 10:57:50,535:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-09 10:57:50,542:INFO:Starting cross validation
2024-05-09 10:57:50,544:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:50,562:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,565:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,567:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,569:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,573:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,575:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,577:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,579:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,584:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,643:INFO:Calculating mean and std
2024-05-09 10:57:50,644:INFO:Creating metrics dataframe
2024-05-09 10:57:50,647:INFO:Uploading results into container
2024-05-09 10:57:50,647:INFO:Uploading model into container now
2024-05-09 10:57:50,647:INFO:_master_model_container: 7
2024-05-09 10:57:50,647:INFO:_display_container: 2
2024-05-09 10:57:50,648:INFO:OrthogonalMatchingPursuit()
2024-05-09 10:57:50,648:INFO:create_model() successfully completed......................................
2024-05-09 10:57:50,714:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:50,714:INFO:Creating metrics dataframe
2024-05-09 10:57:50,720:INFO:Initializing Bayesian Ridge
2024-05-09 10:57:50,720:INFO:Total runtime is 0.0874276121457418 minutes
2024-05-09 10:57:50,722:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:50,722:INFO:Initializing create_model()
2024-05-09 10:57:50,722:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:50,723:INFO:Checking exceptions
2024-05-09 10:57:50,723:INFO:Importing libraries
2024-05-09 10:57:50,723:INFO:Copying training dataset
2024-05-09 10:57:50,726:INFO:Defining folds
2024-05-09 10:57:50,726:INFO:Declaring metric variables
2024-05-09 10:57:50,729:INFO:Importing untrained model
2024-05-09 10:57:50,731:INFO:Bayesian Ridge Imported successfully
2024-05-09 10:57:50,735:INFO:Starting cross validation
2024-05-09 10:57:50,736:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:50,750:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,751:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,754:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,756:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,764:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,768:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,771:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,776:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,779:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,851:INFO:Calculating mean and std
2024-05-09 10:57:50,852:INFO:Creating metrics dataframe
2024-05-09 10:57:50,856:INFO:Uploading results into container
2024-05-09 10:57:50,856:INFO:Uploading model into container now
2024-05-09 10:57:50,856:INFO:_master_model_container: 8
2024-05-09 10:57:50,857:INFO:_display_container: 2
2024-05-09 10:57:50,857:INFO:BayesianRidge()
2024-05-09 10:57:50,857:INFO:create_model() successfully completed......................................
2024-05-09 10:57:50,926:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:50,927:INFO:Creating metrics dataframe
2024-05-09 10:57:50,932:INFO:Initializing Passive Aggressive Regressor
2024-05-09 10:57:50,932:INFO:Total runtime is 0.09096631209055585 minutes
2024-05-09 10:57:50,934:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:50,934:INFO:Initializing create_model()
2024-05-09 10:57:50,935:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:50,935:INFO:Checking exceptions
2024-05-09 10:57:50,935:INFO:Importing libraries
2024-05-09 10:57:50,935:INFO:Copying training dataset
2024-05-09 10:57:50,937:INFO:Defining folds
2024-05-09 10:57:50,937:INFO:Declaring metric variables
2024-05-09 10:57:50,939:INFO:Importing untrained model
2024-05-09 10:57:50,941:INFO:Passive Aggressive Regressor Imported successfully
2024-05-09 10:57:50,945:INFO:Starting cross validation
2024-05-09 10:57:50,946:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:50,962:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,963:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,966:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,969:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,976:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,978:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,979:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,981:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:50,983:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,054:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(root_mean_squared_log_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 209, in root_mean_squared_log_error
    metrics.mean_squared_log_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 680, in mean_squared_log_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-09 10:57:51,054:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py:204: FitFailedWarning: Metric 'make_scorer(mean_absolute_percentage_error, greater_is_better=False, response_method='predict')' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/internal/metrics.py", line 196, in _score
    return super()._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/pycaret/containers/metrics/regression.py", line 233, in mean_absolute_percentage_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-09 10:57:51,055:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 207, in mean_absolute_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-09 10:57:51,055:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-09 10:57:51,055:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 572, in root_mean_squared_error
    mean_squared_error(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 186, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 497, in mean_squared_error
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-09 10:57:51,055:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:1011: UserWarning: Scoring failed. The score on this train-test partition for these parameters will be set to 0.0. Details: 
Traceback (most recent call last):
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 137, in __call__
    score = scorer._score(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 1180, in r2_score
    y_type, y_true, y_pred, multioutput = _check_reg_targets(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py", line 104, in _check_reg_targets
    y_pred = check_array(y_pred, ensure_2d=False, dtype=dtype)
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 1049, in check_array
    _assert_all_finite(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 126, in _assert_all_finite
    _assert_all_finite_element_wise(
  File "/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/utils/validation.py", line 175, in _assert_all_finite_element_wise
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2024-05-09 10:57:51,056:INFO:Calculating mean and std
2024-05-09 10:57:51,057:INFO:Creating metrics dataframe
2024-05-09 10:57:51,059:INFO:Uploading results into container
2024-05-09 10:57:51,059:INFO:Uploading model into container now
2024-05-09 10:57:51,059:INFO:_master_model_container: 9
2024-05-09 10:57:51,059:INFO:_display_container: 2
2024-05-09 10:57:51,059:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-09 10:57:51,060:INFO:create_model() successfully completed......................................
2024-05-09 10:57:51,130:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:51,130:INFO:Creating metrics dataframe
2024-05-09 10:57:51,136:INFO:Initializing Huber Regressor
2024-05-09 10:57:51,136:INFO:Total runtime is 0.09436792929967247 minutes
2024-05-09 10:57:51,138:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:51,138:INFO:Initializing create_model()
2024-05-09 10:57:51,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:51,138:INFO:Checking exceptions
2024-05-09 10:57:51,138:INFO:Importing libraries
2024-05-09 10:57:51,138:INFO:Copying training dataset
2024-05-09 10:57:51,140:INFO:Defining folds
2024-05-09 10:57:51,140:INFO:Declaring metric variables
2024-05-09 10:57:51,142:INFO:Importing untrained model
2024-05-09 10:57:51,144:INFO:Huber Regressor Imported successfully
2024-05-09 10:57:51,149:INFO:Starting cross validation
2024-05-09 10:57:51,150:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:51,164:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,167:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,169:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,173:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,179:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,181:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,187:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,190:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,192:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,209:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,231:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,234:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,243:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,248:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,254:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,257:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-09 10:57:51,282:INFO:Calculating mean and std
2024-05-09 10:57:51,283:INFO:Creating metrics dataframe
2024-05-09 10:57:51,286:INFO:Uploading results into container
2024-05-09 10:57:51,286:INFO:Uploading model into container now
2024-05-09 10:57:51,286:INFO:_master_model_container: 10
2024-05-09 10:57:51,287:INFO:_display_container: 2
2024-05-09 10:57:51,287:INFO:HuberRegressor()
2024-05-09 10:57:51,287:INFO:create_model() successfully completed......................................
2024-05-09 10:57:51,358:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:51,358:INFO:Creating metrics dataframe
2024-05-09 10:57:51,365:INFO:Initializing K Neighbors Regressor
2024-05-09 10:57:51,365:INFO:Total runtime is 0.09817357460657758 minutes
2024-05-09 10:57:51,367:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:51,367:INFO:Initializing create_model()
2024-05-09 10:57:51,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:51,367:INFO:Checking exceptions
2024-05-09 10:57:51,367:INFO:Importing libraries
2024-05-09 10:57:51,367:INFO:Copying training dataset
2024-05-09 10:57:51,369:INFO:Defining folds
2024-05-09 10:57:51,370:INFO:Declaring metric variables
2024-05-09 10:57:51,372:INFO:Importing untrained model
2024-05-09 10:57:51,375:INFO:K Neighbors Regressor Imported successfully
2024-05-09 10:57:51,381:INFO:Starting cross validation
2024-05-09 10:57:51,382:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:51,401:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,403:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,405:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,407:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,409:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,413:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,415:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,417:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,419:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,533:INFO:Calculating mean and std
2024-05-09 10:57:51,534:INFO:Creating metrics dataframe
2024-05-09 10:57:51,537:INFO:Uploading results into container
2024-05-09 10:57:51,537:INFO:Uploading model into container now
2024-05-09 10:57:51,538:INFO:_master_model_container: 11
2024-05-09 10:57:51,538:INFO:_display_container: 2
2024-05-09 10:57:51,538:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-09 10:57:51,538:INFO:create_model() successfully completed......................................
2024-05-09 10:57:51,601:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:51,601:INFO:Creating metrics dataframe
2024-05-09 10:57:51,606:INFO:Initializing Decision Tree Regressor
2024-05-09 10:57:51,606:INFO:Total runtime is 0.10220152139663699 minutes
2024-05-09 10:57:51,608:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:51,609:INFO:Initializing create_model()
2024-05-09 10:57:51,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:51,609:INFO:Checking exceptions
2024-05-09 10:57:51,609:INFO:Importing libraries
2024-05-09 10:57:51,609:INFO:Copying training dataset
2024-05-09 10:57:51,612:INFO:Defining folds
2024-05-09 10:57:51,612:INFO:Declaring metric variables
2024-05-09 10:57:51,614:INFO:Importing untrained model
2024-05-09 10:57:51,616:INFO:Decision Tree Regressor Imported successfully
2024-05-09 10:57:51,620:INFO:Starting cross validation
2024-05-09 10:57:51,621:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:51,633:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,637:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,638:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,642:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,646:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,648:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,650:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,653:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,656:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,730:INFO:Calculating mean and std
2024-05-09 10:57:51,731:INFO:Creating metrics dataframe
2024-05-09 10:57:51,734:INFO:Uploading results into container
2024-05-09 10:57:51,734:INFO:Uploading model into container now
2024-05-09 10:57:51,735:INFO:_master_model_container: 12
2024-05-09 10:57:51,735:INFO:_display_container: 2
2024-05-09 10:57:51,735:INFO:DecisionTreeRegressor(random_state=123)
2024-05-09 10:57:51,735:INFO:create_model() successfully completed......................................
2024-05-09 10:57:51,804:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:51,804:INFO:Creating metrics dataframe
2024-05-09 10:57:51,810:INFO:Initializing Random Forest Regressor
2024-05-09 10:57:51,810:INFO:Total runtime is 0.10560053189595543 minutes
2024-05-09 10:57:51,812:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:51,813:INFO:Initializing create_model()
2024-05-09 10:57:51,813:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:51,813:INFO:Checking exceptions
2024-05-09 10:57:51,813:INFO:Importing libraries
2024-05-09 10:57:51,813:INFO:Copying training dataset
2024-05-09 10:57:51,815:INFO:Defining folds
2024-05-09 10:57:51,815:INFO:Declaring metric variables
2024-05-09 10:57:51,817:INFO:Importing untrained model
2024-05-09 10:57:51,820:INFO:Random Forest Regressor Imported successfully
2024-05-09 10:57:51,827:INFO:Starting cross validation
2024-05-09 10:57:51,828:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:51,845:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,848:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,850:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,853:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,857:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,858:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,859:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,864:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:51,865:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,362:INFO:Calculating mean and std
2024-05-09 10:57:52,362:INFO:Creating metrics dataframe
2024-05-09 10:57:52,364:INFO:Uploading results into container
2024-05-09 10:57:52,365:INFO:Uploading model into container now
2024-05-09 10:57:52,365:INFO:_master_model_container: 13
2024-05-09 10:57:52,365:INFO:_display_container: 2
2024-05-09 10:57:52,365:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-09 10:57:52,365:INFO:create_model() successfully completed......................................
2024-05-09 10:57:52,419:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:52,419:INFO:Creating metrics dataframe
2024-05-09 10:57:52,426:INFO:Initializing Extra Trees Regressor
2024-05-09 10:57:52,426:INFO:Total runtime is 0.11585342486699425 minutes
2024-05-09 10:57:52,428:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:52,428:INFO:Initializing create_model()
2024-05-09 10:57:52,428:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:52,428:INFO:Checking exceptions
2024-05-09 10:57:52,428:INFO:Importing libraries
2024-05-09 10:57:52,428:INFO:Copying training dataset
2024-05-09 10:57:52,430:INFO:Defining folds
2024-05-09 10:57:52,430:INFO:Declaring metric variables
2024-05-09 10:57:52,432:INFO:Importing untrained model
2024-05-09 10:57:52,434:INFO:Extra Trees Regressor Imported successfully
2024-05-09 10:57:52,440:INFO:Starting cross validation
2024-05-09 10:57:52,441:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:52,456:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,460:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,461:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,463:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,466:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,471:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,475:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,477:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,478:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,756:INFO:Calculating mean and std
2024-05-09 10:57:52,757:INFO:Creating metrics dataframe
2024-05-09 10:57:52,759:INFO:Uploading results into container
2024-05-09 10:57:52,759:INFO:Uploading model into container now
2024-05-09 10:57:52,759:INFO:_master_model_container: 14
2024-05-09 10:57:52,759:INFO:_display_container: 2
2024-05-09 10:57:52,760:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-09 10:57:52,760:INFO:create_model() successfully completed......................................
2024-05-09 10:57:52,814:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:52,814:INFO:Creating metrics dataframe
2024-05-09 10:57:52,820:INFO:Initializing AdaBoost Regressor
2024-05-09 10:57:52,820:INFO:Total runtime is 0.12243009408315025 minutes
2024-05-09 10:57:52,822:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:52,822:INFO:Initializing create_model()
2024-05-09 10:57:52,823:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:52,823:INFO:Checking exceptions
2024-05-09 10:57:52,823:INFO:Importing libraries
2024-05-09 10:57:52,823:INFO:Copying training dataset
2024-05-09 10:57:52,826:INFO:Defining folds
2024-05-09 10:57:52,826:INFO:Declaring metric variables
2024-05-09 10:57:52,829:INFO:Importing untrained model
2024-05-09 10:57:52,832:INFO:AdaBoost Regressor Imported successfully
2024-05-09 10:57:52,838:INFO:Starting cross validation
2024-05-09 10:57:52,840:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:52,855:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,855:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,858:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,859:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,866:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,868:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,871:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,874:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:52,875:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,024:INFO:Calculating mean and std
2024-05-09 10:57:53,025:INFO:Creating metrics dataframe
2024-05-09 10:57:53,026:INFO:Uploading results into container
2024-05-09 10:57:53,027:INFO:Uploading model into container now
2024-05-09 10:57:53,027:INFO:_master_model_container: 15
2024-05-09 10:57:53,027:INFO:_display_container: 2
2024-05-09 10:57:53,027:INFO:AdaBoostRegressor(random_state=123)
2024-05-09 10:57:53,027:INFO:create_model() successfully completed......................................
2024-05-09 10:57:53,083:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:53,083:INFO:Creating metrics dataframe
2024-05-09 10:57:53,089:INFO:Initializing Gradient Boosting Regressor
2024-05-09 10:57:53,089:INFO:Total runtime is 0.1269090016682943 minutes
2024-05-09 10:57:53,091:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:53,091:INFO:Initializing create_model()
2024-05-09 10:57:53,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:53,091:INFO:Checking exceptions
2024-05-09 10:57:53,091:INFO:Importing libraries
2024-05-09 10:57:53,091:INFO:Copying training dataset
2024-05-09 10:57:53,094:INFO:Defining folds
2024-05-09 10:57:53,094:INFO:Declaring metric variables
2024-05-09 10:57:53,096:INFO:Importing untrained model
2024-05-09 10:57:53,099:INFO:Gradient Boosting Regressor Imported successfully
2024-05-09 10:57:53,103:INFO:Starting cross validation
2024-05-09 10:57:53,104:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:53,120:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,121:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,124:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,127:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,131:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,142:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,145:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,149:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,151:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,469:INFO:Calculating mean and std
2024-05-09 10:57:53,469:INFO:Creating metrics dataframe
2024-05-09 10:57:53,471:INFO:Uploading results into container
2024-05-09 10:57:53,471:INFO:Uploading model into container now
2024-05-09 10:57:53,471:INFO:_master_model_container: 16
2024-05-09 10:57:53,471:INFO:_display_container: 2
2024-05-09 10:57:53,472:INFO:GradientBoostingRegressor(random_state=123)
2024-05-09 10:57:53,472:INFO:create_model() successfully completed......................................
2024-05-09 10:57:53,525:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:53,525:INFO:Creating metrics dataframe
2024-05-09 10:57:53,531:INFO:Initializing Light Gradient Boosting Machine
2024-05-09 10:57:53,531:INFO:Total runtime is 0.13428498903910321 minutes
2024-05-09 10:57:53,533:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:53,534:INFO:Initializing create_model()
2024-05-09 10:57:53,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:53,534:INFO:Checking exceptions
2024-05-09 10:57:53,534:INFO:Importing libraries
2024-05-09 10:57:53,534:INFO:Copying training dataset
2024-05-09 10:57:53,536:INFO:Defining folds
2024-05-09 10:57:53,536:INFO:Declaring metric variables
2024-05-09 10:57:53,538:INFO:Importing untrained model
2024-05-09 10:57:53,541:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-09 10:57:53,545:INFO:Starting cross validation
2024-05-09 10:57:53,545:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:53,560:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,563:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,565:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,566:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,571:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,574:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,575:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,578:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:53,578:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,231:INFO:Calculating mean and std
2024-05-09 10:57:54,232:INFO:Creating metrics dataframe
2024-05-09 10:57:54,234:INFO:Uploading results into container
2024-05-09 10:57:54,234:INFO:Uploading model into container now
2024-05-09 10:57:54,235:INFO:_master_model_container: 17
2024-05-09 10:57:54,235:INFO:_display_container: 2
2024-05-09 10:57:54,235:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-09 10:57:54,235:INFO:create_model() successfully completed......................................
2024-05-09 10:57:54,289:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:54,289:INFO:Creating metrics dataframe
2024-05-09 10:57:54,295:INFO:Initializing Dummy Regressor
2024-05-09 10:57:54,295:INFO:Total runtime is 0.14701640605926516 minutes
2024-05-09 10:57:54,297:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:54,297:INFO:Initializing create_model()
2024-05-09 10:57:54,306:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0cfb1f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:54,306:INFO:Checking exceptions
2024-05-09 10:57:54,306:INFO:Importing libraries
2024-05-09 10:57:54,306:INFO:Copying training dataset
2024-05-09 10:57:54,308:INFO:Defining folds
2024-05-09 10:57:54,308:INFO:Declaring metric variables
2024-05-09 10:57:54,310:INFO:Importing untrained model
2024-05-09 10:57:54,312:INFO:Dummy Regressor Imported successfully
2024-05-09 10:57:54,317:INFO:Starting cross validation
2024-05-09 10:57:54,318:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:54,338:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,340:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,342:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,343:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,345:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,349:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,351:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,353:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,355:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,414:INFO:Calculating mean and std
2024-05-09 10:57:54,415:INFO:Creating metrics dataframe
2024-05-09 10:57:54,418:INFO:Uploading results into container
2024-05-09 10:57:54,419:INFO:Uploading model into container now
2024-05-09 10:57:54,419:INFO:_master_model_container: 18
2024-05-09 10:57:54,419:INFO:_display_container: 2
2024-05-09 10:57:54,419:INFO:DummyRegressor()
2024-05-09 10:57:54,419:INFO:create_model() successfully completed......................................
2024-05-09 10:57:54,484:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:54,485:INFO:Creating metrics dataframe
2024-05-09 10:57:54,497:INFO:Initializing create_model()
2024-05-09 10:57:54,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:54,497:INFO:Checking exceptions
2024-05-09 10:57:54,499:INFO:Importing libraries
2024-05-09 10:57:54,499:INFO:Copying training dataset
2024-05-09 10:57:54,502:INFO:Defining folds
2024-05-09 10:57:54,503:INFO:Declaring metric variables
2024-05-09 10:57:54,503:INFO:Importing untrained model
2024-05-09 10:57:54,503:INFO:Declaring custom model
2024-05-09 10:57:54,503:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-09 10:57:54,504:INFO:Cross validation set to False
2024-05-09 10:57:54,504:INFO:Fitting Model
2024-05-09 10:57:54,506:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,532:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-09 10:57:54,533:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000586 seconds.
2024-05-09 10:57:54,533:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-09 10:57:54,534:INFO:[LightGBM] [Info] Total Bins 2193
2024-05-09 10:57:54,534:INFO:[LightGBM] [Info] Number of data points in the train set: 403, number of used features: 25
2024-05-09 10:57:54,534:INFO:[LightGBM] [Info] Start training from score 65.229456
2024-05-09 10:57:54,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,563:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,564:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,566:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,567:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,569:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,570:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,572:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,574:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,575:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,577:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,578:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,579:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,581:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,582:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,583:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,585:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,586:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,588:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,589:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,590:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,591:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,592:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,593:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,594:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,595:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,596:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,597:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,598:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,599:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,600:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,601:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,602:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,650:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,671:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,672:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:54,674:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-09 10:57:54,674:INFO:create_model() successfully completed......................................
2024-05-09 10:57:54,748:INFO:_master_model_container: 18
2024-05-09 10:57:54,748:INFO:_display_container: 2
2024-05-09 10:57:54,748:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-09 10:57:54,748:INFO:compare_models() successfully completed......................................
2024-05-09 10:57:54,748:INFO:Initializing tune_model()
2024-05-09 10:57:54,748:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>)
2024-05-09 10:57:54,748:INFO:Checking exceptions
2024-05-09 10:57:54,758:INFO:Copying training dataset
2024-05-09 10:57:54,761:INFO:Checking base model
2024-05-09 10:57:54,761:INFO:Base model : Light Gradient Boosting Machine
2024-05-09 10:57:54,764:INFO:Declaring metric variables
2024-05-09 10:57:54,767:INFO:Defining Hyperparameters
2024-05-09 10:57:54,841:INFO:Tuning with n_jobs=-1
2024-05-09 10:57:54,841:INFO:Initializing RandomizedSearchCV
2024-05-09 10:57:54,870:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,871:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,874:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,875:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,877:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,878:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,880:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,881:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,883:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,884:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,886:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,887:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,889:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:54,892:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,152:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,157:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,168:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,176:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,176:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,182:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,227:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,229:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,244:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,247:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,251:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,259:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,268:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,276:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,355:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,381:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,520:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,524:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,582:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,620:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,876:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,950:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:55,962:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,090:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,095:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,158:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,445:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,562:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,565:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,596:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,596:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,618:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,626:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,640:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,651:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,675:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,692:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,724:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,734:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,751:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,761:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,772:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,776:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,784:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,832:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,843:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,860:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,862:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,903:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,922:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:56,970:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,226:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,248:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,315:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,358:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,400:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,456:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,461:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,479:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,484:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,502:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,505:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,516:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,530:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,594:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,603:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,635:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,665:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,688:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,693:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,709:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,712:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,724:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,733:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:57,755:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,459:INFO:best_params: {'actual_estimator__reg_lambda': 3, 'actual_estimator__reg_alpha': 2, 'actual_estimator__num_leaves': 70, 'actual_estimator__n_estimators': 260, 'actual_estimator__min_split_gain': 0.9, 'actual_estimator__min_child_samples': 41, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.4, 'actual_estimator__bagging_freq': 2, 'actual_estimator__bagging_fraction': 0.6}
2024-05-09 10:57:58,460:INFO:Hyperparameter search completed
2024-05-09 10:57:58,460:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:58,461:INFO:Initializing create_model()
2024-05-09 10:57:58,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d299ef10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 3, 'reg_alpha': 2, 'num_leaves': 70, 'n_estimators': 260, 'min_split_gain': 0.9, 'min_child_samples': 41, 'learning_rate': 0.1, 'feature_fraction': 0.4, 'bagging_freq': 2, 'bagging_fraction': 0.6})
2024-05-09 10:57:58,461:INFO:Checking exceptions
2024-05-09 10:57:58,461:INFO:Importing libraries
2024-05-09 10:57:58,461:INFO:Copying training dataset
2024-05-09 10:57:58,463:INFO:Defining folds
2024-05-09 10:57:58,463:INFO:Declaring metric variables
2024-05-09 10:57:58,465:INFO:Importing untrained model
2024-05-09 10:57:58,465:INFO:Declaring custom model
2024-05-09 10:57:58,467:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-09 10:57:58,472:INFO:Starting cross validation
2024-05-09 10:57:58,473:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:58,486:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,487:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,490:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,492:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,496:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,498:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,502:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,503:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:58,507:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,036:INFO:Calculating mean and std
2024-05-09 10:57:59,037:INFO:Creating metrics dataframe
2024-05-09 10:57:59,040:INFO:Finalizing model
2024-05-09 10:57:59,044:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,063:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-05-09 10:57:59,063:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-05-09 10:57:59,063:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-05-09 10:57:59,064:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-09 10:57:59,064:INFO:[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2
2024-05-09 10:57:59,064:INFO:[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4
2024-05-09 10:57:59,064:INFO:[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6
2024-05-09 10:57:59,066:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000870 seconds.
2024-05-09 10:57:59,066:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-09 10:57:59,066:INFO:[LightGBM] [Info] Total Bins 2193
2024-05-09 10:57:59,066:INFO:[LightGBM] [Info] Number of data points in the train set: 403, number of used features: 25
2024-05-09 10:57:59,067:INFO:[LightGBM] [Info] Start training from score 65.229456
2024-05-09 10:57:59,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,132:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,146:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,150:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,164:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,169:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,170:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,171:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,172:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,173:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,174:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,175:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,176:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,177:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,178:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,179:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,180:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,181:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,182:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,183:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,184:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,185:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,186:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,187:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,188:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,189:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,190:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,191:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,192:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,193:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,195:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:57:59,203:INFO:Uploading results into container
2024-05-09 10:57:59,204:INFO:Uploading model into container now
2024-05-09 10:57:59,204:INFO:_master_model_container: 19
2024-05-09 10:57:59,204:INFO:_display_container: 3
2024-05-09 10:57:59,205:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3)
2024-05-09 10:57:59,206:INFO:create_model() successfully completed......................................
2024-05-09 10:57:59,275:INFO:SubProcess create_model() end ==================================
2024-05-09 10:57:59,276:INFO:choose_better activated
2024-05-09 10:57:59,278:INFO:SubProcess create_model() called ==================================
2024-05-09 10:57:59,279:INFO:Initializing create_model()
2024-05-09 10:57:59,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:57:59,279:INFO:Checking exceptions
2024-05-09 10:57:59,280:INFO:Importing libraries
2024-05-09 10:57:59,280:INFO:Copying training dataset
2024-05-09 10:57:59,281:INFO:Defining folds
2024-05-09 10:57:59,281:INFO:Declaring metric variables
2024-05-09 10:57:59,281:INFO:Importing untrained model
2024-05-09 10:57:59,282:INFO:Declaring custom model
2024-05-09 10:57:59,282:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-09 10:57:59,282:INFO:Starting cross validation
2024-05-09 10:57:59,282:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 10:57:59,295:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,298:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,298:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,300:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,304:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,306:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,309:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,311:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,314:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:57:59,986:INFO:Calculating mean and std
2024-05-09 10:57:59,987:INFO:Creating metrics dataframe
2024-05-09 10:57:59,989:INFO:Finalizing model
2024-05-09 10:57:59,991:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:58:00,007:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-09 10:58:00,008:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000458 seconds.
2024-05-09 10:58:00,008:INFO:You can set `force_row_wise=true` to remove the overhead.
2024-05-09 10:58:00,008:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2024-05-09 10:58:00,008:INFO:[LightGBM] [Info] Total Bins 2193
2024-05-09 10:58:00,008:INFO:[LightGBM] [Info] Number of data points in the train set: 403, number of used features: 25
2024-05-09 10:58:00,009:INFO:[LightGBM] [Info] Start training from score 65.229456
2024-05-09 10:58:00,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,011:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,016:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,017:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,018:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,031:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,032:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,033:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,034:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,046:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,047:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,048:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,049:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,051:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,052:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,053:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,054:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,055:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,057:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,058:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,059:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,060:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,061:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,066:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,083:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,086:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,096:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,099:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,116:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,128:INFO:Uploading results into container
2024-05-09 10:58:00,129:INFO:Uploading model into container now
2024-05-09 10:58:00,129:INFO:_master_model_container: 20
2024-05-09 10:58:00,129:INFO:_display_container: 4
2024-05-09 10:58:00,129:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-09 10:58:00,129:INFO:create_model() successfully completed......................................
2024-05-09 10:58:00,183:INFO:SubProcess create_model() end ==================================
2024-05-09 10:58:00,183:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.6826
2024-05-09 10:58:00,184:INFO:LGBMRegressor(bagging_fraction=0.6, bagging_freq=2, feature_fraction=0.4,
              min_child_samples=41, min_split_gain=0.9, n_estimators=260,
              n_jobs=-1, num_leaves=70, random_state=123, reg_alpha=2,
              reg_lambda=3) result for R2 is 0.6143
2024-05-09 10:58:00,184:INFO:LGBMRegressor(n_jobs=-1, random_state=123) is best model
2024-05-09 10:58:00,184:INFO:choose_better completed
2024-05-09 10:58:00,184:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-09 10:58:00,189:INFO:_master_model_container: 20
2024-05-09 10:58:00,189:INFO:_display_container: 3
2024-05-09 10:58:00,189:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-09 10:58:00,189:INFO:tune_model() successfully completed......................................
2024-05-09 10:58:00,267:INFO:Initializing finalize_model()
2024-05-09 10:58:00,267:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-09 10:58:00,267:INFO:Finalizing LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-09 10:58:00,269:INFO:Initializing create_model()
2024-05-09 10:58:00,269:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 10:58:00,269:INFO:Checking exceptions
2024-05-09 10:58:00,270:INFO:Importing libraries
2024-05-09 10:58:00,270:INFO:Copying training dataset
2024-05-09 10:58:00,270:INFO:Defining folds
2024-05-09 10:58:00,270:INFO:Declaring metric variables
2024-05-09 10:58:00,270:INFO:Importing untrained model
2024-05-09 10:58:00,270:INFO:Declaring custom model
2024-05-09 10:58:00,270:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-09 10:58:00,271:INFO:Cross validation set to False
2024-05-09 10:58:00,271:INFO:Fitting Model
2024-05-09 10:58:00,273:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/numpy/core/_methods.py:239: RuntimeWarning: overflow encountered in multiply
  x = um.multiply(x, x, out=x)

2024-05-09 10:58:00,289:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-09 10:58:00,291:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001195 seconds.
2024-05-09 10:58:00,291:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-09 10:58:00,291:INFO:[LightGBM] [Info] Total Bins 3149
2024-05-09 10:58:00,291:INFO:[LightGBM] [Info] Number of data points in the train set: 576, number of used features: 25
2024-05-09 10:58:00,291:INFO:[LightGBM] [Info] Start training from score 49.613906
2024-05-09 10:58:00,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,298:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,300:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,305:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,314:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,330:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,332:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,347:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,349:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,351:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,354:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,371:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,373:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,375:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,376:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,378:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,381:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-09 10:58:00,458:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-05-09 10:58:00,458:INFO:create_model() successfully completed......................................
2024-05-09 10:58:00,511:INFO:_master_model_container: 20
2024-05-09 10:58:00,511:INFO:_display_container: 3
2024-05-09 10:58:00,517:INFO:Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))])
2024-05-09 10:58:00,517:INFO:finalize_model() successfully completed......................................
2024-05-09 10:58:00,575:INFO:Initializing predict_model()
2024-05-09 10:58:00,575:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d28d7f70>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('target_transformation',
                 TransformerWrapperWithInverse(transformer=TargetTransformer(estimator=PowerTransformer(standardize=False)))),
                ('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             '...
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 LGBMRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7866d0cabaf0>)
2024-05-09 10:58:00,575:INFO:Checking exceptions
2024-05-09 10:58:00,575:INFO:Preloading libraries
2024-05-09 10:58:00,576:INFO:Set up data.
2024-05-09 10:58:00,578:INFO:Set up index.
2024-05-09 10:58:00,592:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-09 13:17:50,908:WARNING:/tmp/ipykernel_14873/2262976735.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-09 13:18:17,315:INFO:PyCaret RegressionExperiment
2024-05-09 13:18:17,315:INFO:Logging name: reg-default-name
2024-05-09 13:18:17,315:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-09 13:18:17,315:INFO:version 3.3.2
2024-05-09 13:18:17,315:INFO:Initializing setup()
2024-05-09 13:18:17,315:INFO:self.USI: 89a1
2024-05-09 13:18:17,315:INFO:self._variable_keys: {'y', '_ml_usecase', 'exp_name_log', 'gpu_n_jobs_param', 'n_jobs_param', 'data', 'log_plots_param', 'seed', 'USI', 'exp_id', 'X', 'target_param', 'y_test', 'gpu_param', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'idx', 'fold_groups_param', 'transform_target_param', 'logging_param', 'memory', 'pipeline', 'fold_generator', 'X_train', 'y_train'}
2024-05-09 13:18:17,315:INFO:Checking environment
2024-05-09 13:18:17,315:INFO:python_version: 3.9.18
2024-05-09 13:18:17,315:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-09 13:18:17,315:INFO:machine: x86_64
2024-05-09 13:18:17,315:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 13:18:17,315:INFO:Memory: svmem(total=16429789184, available=6068072448, percent=63.1, used=9134534656, free=1435758592, active=4991438848, inactive=8656048128, buffers=210751488, cached=5648744448, shared=880594944, slab=609603584)
2024-05-09 13:18:17,316:INFO:Physical Core: 12
2024-05-09 13:18:17,316:INFO:Logical Core: 16
2024-05-09 13:18:17,316:INFO:Checking libraries
2024-05-09 13:18:17,316:INFO:System:
2024-05-09 13:18:17,316:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-09 13:18:17,316:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-09 13:18:17,316:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 13:18:17,316:INFO:PyCaret required dependencies:
2024-05-09 13:18:17,317:INFO:                 pip: 23.2.1
2024-05-09 13:18:17,317:INFO:          setuptools: 68.0.0
2024-05-09 13:18:17,317:INFO:             pycaret: 3.3.2
2024-05-09 13:18:17,317:INFO:             IPython: 8.15.0
2024-05-09 13:18:17,317:INFO:          ipywidgets: 8.0.4
2024-05-09 13:18:17,317:INFO:                tqdm: 4.65.0
2024-05-09 13:18:17,317:INFO:               numpy: 1.24.3
2024-05-09 13:18:17,317:INFO:              pandas: 1.4.2
2024-05-09 13:18:17,317:INFO:              jinja2: 3.1.4
2024-05-09 13:18:17,317:INFO:               scipy: 1.11.3
2024-05-09 13:18:17,317:INFO:              joblib: 1.2.0
2024-05-09 13:18:17,317:INFO:             sklearn: 1.4.2
2024-05-09 13:18:17,317:INFO:                pyod: 1.1.3
2024-05-09 13:18:17,317:INFO:            imblearn: 0.12.2
2024-05-09 13:18:17,317:INFO:   category_encoders: 2.6.3
2024-05-09 13:18:17,317:INFO:            lightgbm: 4.3.0
2024-05-09 13:18:17,317:INFO:               numba: 0.58.0
2024-05-09 13:18:17,317:INFO:            requests: 2.31.0
2024-05-09 13:18:17,317:INFO:          matplotlib: 3.7.2
2024-05-09 13:18:17,317:INFO:          scikitplot: 0.3.7
2024-05-09 13:18:17,317:INFO:         yellowbrick: 1.5
2024-05-09 13:18:17,317:INFO:              plotly: 5.22.0
2024-05-09 13:18:17,317:INFO:    plotly-resampler: Not installed
2024-05-09 13:18:17,317:INFO:             kaleido: 0.2.1
2024-05-09 13:18:17,317:INFO:           schemdraw: 0.15
2024-05-09 13:18:17,317:INFO:         statsmodels: 0.14.0
2024-05-09 13:18:17,317:INFO:              sktime: 0.26.0
2024-05-09 13:18:17,317:INFO:               tbats: 1.1.3
2024-05-09 13:18:17,317:INFO:            pmdarima: 2.0.4
2024-05-09 13:18:17,317:INFO:              psutil: 5.9.0
2024-05-09 13:18:17,317:INFO:          markupsafe: 2.0.1
2024-05-09 13:18:17,318:INFO:             pickle5: Not installed
2024-05-09 13:18:17,318:INFO:         cloudpickle: 2.2.1
2024-05-09 13:18:17,318:INFO:         deprecation: 2.1.0
2024-05-09 13:18:17,318:INFO:              xxhash: 2.0.2
2024-05-09 13:18:17,318:INFO:           wurlitzer: 3.0.2
2024-05-09 13:18:17,318:INFO:PyCaret optional dependencies:
2024-05-09 13:18:17,318:INFO:                shap: Not installed
2024-05-09 13:18:17,318:INFO:           interpret: Not installed
2024-05-09 13:18:17,318:INFO:                umap: Not installed
2024-05-09 13:18:17,318:INFO:     ydata_profiling: Not installed
2024-05-09 13:18:17,318:INFO:  explainerdashboard: Not installed
2024-05-09 13:18:17,318:INFO:             autoviz: Not installed
2024-05-09 13:18:17,318:INFO:           fairlearn: Not installed
2024-05-09 13:18:17,318:INFO:          deepchecks: Not installed
2024-05-09 13:18:17,318:INFO:             xgboost: Not installed
2024-05-09 13:18:17,318:INFO:            catboost: Not installed
2024-05-09 13:18:17,318:INFO:              kmodes: Not installed
2024-05-09 13:18:17,318:INFO:             mlxtend: Not installed
2024-05-09 13:18:17,318:INFO:       statsforecast: Not installed
2024-05-09 13:18:17,318:INFO:        tune_sklearn: Not installed
2024-05-09 13:18:17,318:INFO:                 ray: Not installed
2024-05-09 13:18:17,318:INFO:            hyperopt: Not installed
2024-05-09 13:18:17,318:INFO:              optuna: Not installed
2024-05-09 13:18:17,318:INFO:               skopt: Not installed
2024-05-09 13:18:17,318:INFO:              mlflow: Not installed
2024-05-09 13:18:17,318:INFO:              gradio: Not installed
2024-05-09 13:18:17,318:INFO:             fastapi: Not installed
2024-05-09 13:18:17,318:INFO:             uvicorn: Not installed
2024-05-09 13:18:17,318:INFO:              m2cgen: Not installed
2024-05-09 13:18:17,318:INFO:           evidently: Not installed
2024-05-09 13:18:17,318:INFO:               fugue: Not installed
2024-05-09 13:18:17,318:INFO:           streamlit: Not installed
2024-05-09 13:18:17,319:INFO:             prophet: Not installed
2024-05-09 13:18:17,319:INFO:None
2024-05-09 13:18:17,319:INFO:Set up data.
2024-05-09 13:18:35,208:INFO:PyCaret RegressionExperiment
2024-05-09 13:18:35,208:INFO:Logging name: reg-default-name
2024-05-09 13:18:35,208:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-09 13:18:35,208:INFO:version 3.3.2
2024-05-09 13:18:35,208:INFO:Initializing setup()
2024-05-09 13:18:35,208:INFO:self.USI: b172
2024-05-09 13:18:35,208:INFO:self._variable_keys: {'y', '_ml_usecase', 'exp_name_log', 'gpu_n_jobs_param', 'n_jobs_param', 'data', 'log_plots_param', 'seed', 'USI', 'exp_id', 'X', 'target_param', 'y_test', 'gpu_param', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'idx', 'fold_groups_param', 'transform_target_param', 'logging_param', 'memory', 'pipeline', 'fold_generator', 'X_train', 'y_train'}
2024-05-09 13:18:35,208:INFO:Checking environment
2024-05-09 13:18:35,208:INFO:python_version: 3.9.18
2024-05-09 13:18:35,208:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-09 13:18:35,208:INFO:machine: x86_64
2024-05-09 13:18:35,208:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 13:18:35,208:INFO:Memory: svmem(total=16429789184, available=6068809728, percent=63.1, used=9159327744, free=1436057600, active=5020082176, inactive=8656445440, buffers=210841600, cached=5623562240, shared=855097344, slab=609562624)
2024-05-09 13:18:35,209:INFO:Physical Core: 12
2024-05-09 13:18:35,209:INFO:Logical Core: 16
2024-05-09 13:18:35,209:INFO:Checking libraries
2024-05-09 13:18:35,209:INFO:System:
2024-05-09 13:18:35,209:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-09 13:18:35,209:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-09 13:18:35,209:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 13:18:35,209:INFO:PyCaret required dependencies:
2024-05-09 13:18:35,209:INFO:                 pip: 23.2.1
2024-05-09 13:18:35,209:INFO:          setuptools: 68.0.0
2024-05-09 13:18:35,209:INFO:             pycaret: 3.3.2
2024-05-09 13:18:35,209:INFO:             IPython: 8.15.0
2024-05-09 13:18:35,209:INFO:          ipywidgets: 8.0.4
2024-05-09 13:18:35,209:INFO:                tqdm: 4.65.0
2024-05-09 13:18:35,209:INFO:               numpy: 1.24.3
2024-05-09 13:18:35,209:INFO:              pandas: 1.4.2
2024-05-09 13:18:35,209:INFO:              jinja2: 3.1.4
2024-05-09 13:18:35,209:INFO:               scipy: 1.11.3
2024-05-09 13:18:35,209:INFO:              joblib: 1.2.0
2024-05-09 13:18:35,209:INFO:             sklearn: 1.4.2
2024-05-09 13:18:35,209:INFO:                pyod: 1.1.3
2024-05-09 13:18:35,209:INFO:            imblearn: 0.12.2
2024-05-09 13:18:35,209:INFO:   category_encoders: 2.6.3
2024-05-09 13:18:35,209:INFO:            lightgbm: 4.3.0
2024-05-09 13:18:35,209:INFO:               numba: 0.58.0
2024-05-09 13:18:35,209:INFO:            requests: 2.31.0
2024-05-09 13:18:35,209:INFO:          matplotlib: 3.7.2
2024-05-09 13:18:35,209:INFO:          scikitplot: 0.3.7
2024-05-09 13:18:35,209:INFO:         yellowbrick: 1.5
2024-05-09 13:18:35,209:INFO:              plotly: 5.22.0
2024-05-09 13:18:35,209:INFO:    plotly-resampler: Not installed
2024-05-09 13:18:35,209:INFO:             kaleido: 0.2.1
2024-05-09 13:18:35,209:INFO:           schemdraw: 0.15
2024-05-09 13:18:35,209:INFO:         statsmodels: 0.14.0
2024-05-09 13:18:35,209:INFO:              sktime: 0.26.0
2024-05-09 13:18:35,209:INFO:               tbats: 1.1.3
2024-05-09 13:18:35,209:INFO:            pmdarima: 2.0.4
2024-05-09 13:18:35,209:INFO:              psutil: 5.9.0
2024-05-09 13:18:35,209:INFO:          markupsafe: 2.0.1
2024-05-09 13:18:35,209:INFO:             pickle5: Not installed
2024-05-09 13:18:35,209:INFO:         cloudpickle: 2.2.1
2024-05-09 13:18:35,209:INFO:         deprecation: 2.1.0
2024-05-09 13:18:35,209:INFO:              xxhash: 2.0.2
2024-05-09 13:18:35,209:INFO:           wurlitzer: 3.0.2
2024-05-09 13:18:35,209:INFO:PyCaret optional dependencies:
2024-05-09 13:18:35,209:INFO:                shap: Not installed
2024-05-09 13:18:35,209:INFO:           interpret: Not installed
2024-05-09 13:18:35,209:INFO:                umap: Not installed
2024-05-09 13:18:35,209:INFO:     ydata_profiling: Not installed
2024-05-09 13:18:35,209:INFO:  explainerdashboard: Not installed
2024-05-09 13:18:35,209:INFO:             autoviz: Not installed
2024-05-09 13:18:35,209:INFO:           fairlearn: Not installed
2024-05-09 13:18:35,209:INFO:          deepchecks: Not installed
2024-05-09 13:18:35,209:INFO:             xgboost: Not installed
2024-05-09 13:18:35,209:INFO:            catboost: Not installed
2024-05-09 13:18:35,209:INFO:              kmodes: Not installed
2024-05-09 13:18:35,210:INFO:             mlxtend: Not installed
2024-05-09 13:18:35,210:INFO:       statsforecast: Not installed
2024-05-09 13:18:35,210:INFO:        tune_sklearn: Not installed
2024-05-09 13:18:35,210:INFO:                 ray: Not installed
2024-05-09 13:18:35,210:INFO:            hyperopt: Not installed
2024-05-09 13:18:35,210:INFO:              optuna: Not installed
2024-05-09 13:18:35,210:INFO:               skopt: Not installed
2024-05-09 13:18:35,210:INFO:              mlflow: Not installed
2024-05-09 13:18:35,210:INFO:              gradio: Not installed
2024-05-09 13:18:35,210:INFO:             fastapi: Not installed
2024-05-09 13:18:35,210:INFO:             uvicorn: Not installed
2024-05-09 13:18:35,210:INFO:              m2cgen: Not installed
2024-05-09 13:18:35,210:INFO:           evidently: Not installed
2024-05-09 13:18:35,210:INFO:               fugue: Not installed
2024-05-09 13:18:35,210:INFO:           streamlit: Not installed
2024-05-09 13:18:35,210:INFO:             prophet: Not installed
2024-05-09 13:18:35,210:INFO:None
2024-05-09 13:18:35,210:INFO:Set up data.
2024-05-09 13:18:45,860:INFO:PyCaret RegressionExperiment
2024-05-09 13:18:45,860:INFO:Logging name: reg-default-name
2024-05-09 13:18:45,860:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-09 13:18:45,860:INFO:version 3.3.2
2024-05-09 13:18:45,860:INFO:Initializing setup()
2024-05-09 13:18:45,860:INFO:self.USI: 4019
2024-05-09 13:18:45,860:INFO:self._variable_keys: {'y', '_ml_usecase', 'exp_name_log', 'gpu_n_jobs_param', 'n_jobs_param', 'data', 'log_plots_param', 'seed', 'USI', 'exp_id', 'X', 'target_param', 'y_test', 'gpu_param', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'idx', 'fold_groups_param', 'transform_target_param', 'logging_param', 'memory', 'pipeline', 'fold_generator', 'X_train', 'y_train'}
2024-05-09 13:18:45,861:INFO:Checking environment
2024-05-09 13:18:45,861:INFO:python_version: 3.9.18
2024-05-09 13:18:45,861:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-09 13:18:45,861:INFO:machine: x86_64
2024-05-09 13:18:45,861:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 13:18:45,861:INFO:Memory: svmem(total=16429789184, available=6055645184, percent=63.1, used=9163051008, free=1422721024, active=5022527488, inactive=8656551936, buffers=210915328, cached=5633101824, shared=864530432, slab=609579008)
2024-05-09 13:18:45,861:INFO:Physical Core: 12
2024-05-09 13:18:45,861:INFO:Logical Core: 16
2024-05-09 13:18:45,861:INFO:Checking libraries
2024-05-09 13:18:45,861:INFO:System:
2024-05-09 13:18:45,861:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-09 13:18:45,861:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-09 13:18:45,861:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 13:18:45,861:INFO:PyCaret required dependencies:
2024-05-09 13:18:45,862:INFO:                 pip: 23.2.1
2024-05-09 13:18:45,862:INFO:          setuptools: 68.0.0
2024-05-09 13:18:45,862:INFO:             pycaret: 3.3.2
2024-05-09 13:18:45,862:INFO:             IPython: 8.15.0
2024-05-09 13:18:45,862:INFO:          ipywidgets: 8.0.4
2024-05-09 13:18:45,862:INFO:                tqdm: 4.65.0
2024-05-09 13:18:45,862:INFO:               numpy: 1.24.3
2024-05-09 13:18:45,862:INFO:              pandas: 1.4.2
2024-05-09 13:18:45,862:INFO:              jinja2: 3.1.4
2024-05-09 13:18:45,862:INFO:               scipy: 1.11.3
2024-05-09 13:18:45,862:INFO:              joblib: 1.2.0
2024-05-09 13:18:45,862:INFO:             sklearn: 1.4.2
2024-05-09 13:18:45,862:INFO:                pyod: 1.1.3
2024-05-09 13:18:45,862:INFO:            imblearn: 0.12.2
2024-05-09 13:18:45,862:INFO:   category_encoders: 2.6.3
2024-05-09 13:18:45,862:INFO:            lightgbm: 4.3.0
2024-05-09 13:18:45,862:INFO:               numba: 0.58.0
2024-05-09 13:18:45,862:INFO:            requests: 2.31.0
2024-05-09 13:18:45,862:INFO:          matplotlib: 3.7.2
2024-05-09 13:18:45,862:INFO:          scikitplot: 0.3.7
2024-05-09 13:18:45,862:INFO:         yellowbrick: 1.5
2024-05-09 13:18:45,862:INFO:              plotly: 5.22.0
2024-05-09 13:18:45,862:INFO:    plotly-resampler: Not installed
2024-05-09 13:18:45,862:INFO:             kaleido: 0.2.1
2024-05-09 13:18:45,862:INFO:           schemdraw: 0.15
2024-05-09 13:18:45,862:INFO:         statsmodels: 0.14.0
2024-05-09 13:18:45,862:INFO:              sktime: 0.26.0
2024-05-09 13:18:45,862:INFO:               tbats: 1.1.3
2024-05-09 13:18:45,862:INFO:            pmdarima: 2.0.4
2024-05-09 13:18:45,862:INFO:              psutil: 5.9.0
2024-05-09 13:18:45,862:INFO:          markupsafe: 2.0.1
2024-05-09 13:18:45,862:INFO:             pickle5: Not installed
2024-05-09 13:18:45,862:INFO:         cloudpickle: 2.2.1
2024-05-09 13:18:45,862:INFO:         deprecation: 2.1.0
2024-05-09 13:18:45,862:INFO:              xxhash: 2.0.2
2024-05-09 13:18:45,862:INFO:           wurlitzer: 3.0.2
2024-05-09 13:18:45,862:INFO:PyCaret optional dependencies:
2024-05-09 13:18:45,862:INFO:                shap: Not installed
2024-05-09 13:18:45,862:INFO:           interpret: Not installed
2024-05-09 13:18:45,862:INFO:                umap: Not installed
2024-05-09 13:18:45,862:INFO:     ydata_profiling: Not installed
2024-05-09 13:18:45,862:INFO:  explainerdashboard: Not installed
2024-05-09 13:18:45,862:INFO:             autoviz: Not installed
2024-05-09 13:18:45,862:INFO:           fairlearn: Not installed
2024-05-09 13:18:45,862:INFO:          deepchecks: Not installed
2024-05-09 13:18:45,862:INFO:             xgboost: Not installed
2024-05-09 13:18:45,862:INFO:            catboost: Not installed
2024-05-09 13:18:45,862:INFO:              kmodes: Not installed
2024-05-09 13:18:45,862:INFO:             mlxtend: Not installed
2024-05-09 13:18:45,862:INFO:       statsforecast: Not installed
2024-05-09 13:18:45,862:INFO:        tune_sklearn: Not installed
2024-05-09 13:18:45,862:INFO:                 ray: Not installed
2024-05-09 13:18:45,862:INFO:            hyperopt: Not installed
2024-05-09 13:18:45,862:INFO:              optuna: Not installed
2024-05-09 13:18:45,862:INFO:               skopt: Not installed
2024-05-09 13:18:45,862:INFO:              mlflow: Not installed
2024-05-09 13:18:45,862:INFO:              gradio: Not installed
2024-05-09 13:18:45,862:INFO:             fastapi: Not installed
2024-05-09 13:18:45,862:INFO:             uvicorn: Not installed
2024-05-09 13:18:45,862:INFO:              m2cgen: Not installed
2024-05-09 13:18:45,862:INFO:           evidently: Not installed
2024-05-09 13:18:45,862:INFO:               fugue: Not installed
2024-05-09 13:18:45,862:INFO:           streamlit: Not installed
2024-05-09 13:18:45,862:INFO:             prophet: Not installed
2024-05-09 13:18:45,862:INFO:None
2024-05-09 13:18:45,862:INFO:Set up data.
2024-05-09 13:18:45,864:INFO:Set up folding strategy.
2024-05-09 13:18:45,865:INFO:Set up train/test split.
2024-05-09 13:18:45,866:INFO:Set up index.
2024-05-09 13:18:45,867:INFO:Assigning column types.
2024-05-09 13:18:45,868:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-09 13:18:45,868:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-09 13:18:45,873:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 13:18:45,876:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:18:45,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:45,947:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:18:45,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:45,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:45,949:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-09 13:18:45,952:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 13:18:45,954:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:18:45,980:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,001:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,001:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-09 13:18:46,003:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,005:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,031:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,051:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,051:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,051:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,054:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,056:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,082:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,102:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,103:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,103:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-09 13:18:46,107:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,133:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,153:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,153:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,158:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,184:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,205:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,205:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,206:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-09 13:18:46,235:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,256:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,286:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,306:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,306:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-09 13:18:46,335:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,356:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,356:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,386:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:18:46,407:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,407:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-09 13:18:46,457:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,457:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,508:INFO:Preparing preprocessing pipeline...
2024-05-09 13:18:46,508:INFO:Set up simple imputation.
2024-05-09 13:18:46,508:INFO:Set up feature normalization.
2024-05-09 13:18:46,508:INFO:Set up column name cleaning.
2024-05-09 13:18:46,520:INFO:Finished creating preprocessing pipeline.
2024-05-09 13:18:46,522:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-09 13:18:46,522:INFO:Creating final display dataframe.
2024-05-09 13:18:46,559:INFO:Setup _display_container:                     Description             Value
0                    Session id               777
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (506, 4)
4        Transformed data shape          (506, 4)
5   Transformed train set shape          (354, 4)
6    Transformed test set shape          (152, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            minmax
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              4019
2024-05-09 13:18:46,622:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,622:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,687:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:18:46,687:INFO:setup() successfully completed in 0.83s...............
2024-05-09 13:18:46,688:INFO:Initializing compare_models()
2024-05-09 13:18:46,688:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-09 13:18:46,688:INFO:Checking exceptions
2024-05-09 13:18:46,689:INFO:Preparing display monitor
2024-05-09 13:18:46,710:INFO:Initializing Linear Regression
2024-05-09 13:18:46,710:INFO:Total runtime is 3.4054120381673177e-06 minutes
2024-05-09 13:18:46,713:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:46,713:INFO:Initializing create_model()
2024-05-09 13:18:46,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:46,714:INFO:Checking exceptions
2024-05-09 13:18:46,714:INFO:Importing libraries
2024-05-09 13:18:46,714:INFO:Copying training dataset
2024-05-09 13:18:46,716:INFO:Defining folds
2024-05-09 13:18:46,716:INFO:Declaring metric variables
2024-05-09 13:18:46,719:INFO:Importing untrained model
2024-05-09 13:18:46,722:INFO:Linear Regression Imported successfully
2024-05-09 13:18:46,727:INFO:Starting cross validation
2024-05-09 13:18:46,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:49,214:INFO:Calculating mean and std
2024-05-09 13:18:49,216:INFO:Creating metrics dataframe
2024-05-09 13:18:49,220:INFO:Uploading results into container
2024-05-09 13:18:49,221:INFO:Uploading model into container now
2024-05-09 13:18:49,221:INFO:_master_model_container: 1
2024-05-09 13:18:49,221:INFO:_display_container: 2
2024-05-09 13:18:49,221:INFO:LinearRegression(n_jobs=-1)
2024-05-09 13:18:49,221:INFO:create_model() successfully completed......................................
2024-05-09 13:18:49,316:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:49,317:INFO:Creating metrics dataframe
2024-05-09 13:18:49,321:INFO:Initializing Lasso Regression
2024-05-09 13:18:49,321:INFO:Total runtime is 0.04351894855499267 minutes
2024-05-09 13:18:49,323:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:49,323:INFO:Initializing create_model()
2024-05-09 13:18:49,323:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:49,323:INFO:Checking exceptions
2024-05-09 13:18:49,323:INFO:Importing libraries
2024-05-09 13:18:49,323:INFO:Copying training dataset
2024-05-09 13:18:49,325:INFO:Defining folds
2024-05-09 13:18:49,325:INFO:Declaring metric variables
2024-05-09 13:18:49,327:INFO:Importing untrained model
2024-05-09 13:18:49,329:INFO:Lasso Regression Imported successfully
2024-05-09 13:18:49,333:INFO:Starting cross validation
2024-05-09 13:18:49,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:50,870:INFO:Calculating mean and std
2024-05-09 13:18:50,871:INFO:Creating metrics dataframe
2024-05-09 13:18:50,874:INFO:Uploading results into container
2024-05-09 13:18:50,874:INFO:Uploading model into container now
2024-05-09 13:18:50,875:INFO:_master_model_container: 2
2024-05-09 13:18:50,875:INFO:_display_container: 2
2024-05-09 13:18:50,875:INFO:Lasso(random_state=777)
2024-05-09 13:18:50,875:INFO:create_model() successfully completed......................................
2024-05-09 13:18:50,949:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:50,949:INFO:Creating metrics dataframe
2024-05-09 13:18:50,954:INFO:Initializing Ridge Regression
2024-05-09 13:18:50,954:INFO:Total runtime is 0.07074042558670043 minutes
2024-05-09 13:18:50,956:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:50,956:INFO:Initializing create_model()
2024-05-09 13:18:50,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:50,956:INFO:Checking exceptions
2024-05-09 13:18:50,956:INFO:Importing libraries
2024-05-09 13:18:50,956:INFO:Copying training dataset
2024-05-09 13:18:50,958:INFO:Defining folds
2024-05-09 13:18:50,958:INFO:Declaring metric variables
2024-05-09 13:18:50,960:INFO:Importing untrained model
2024-05-09 13:18:50,962:INFO:Ridge Regression Imported successfully
2024-05-09 13:18:50,966:INFO:Starting cross validation
2024-05-09 13:18:50,967:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:51,011:INFO:Calculating mean and std
2024-05-09 13:18:51,011:INFO:Creating metrics dataframe
2024-05-09 13:18:51,013:INFO:Uploading results into container
2024-05-09 13:18:51,014:INFO:Uploading model into container now
2024-05-09 13:18:51,014:INFO:_master_model_container: 3
2024-05-09 13:18:51,014:INFO:_display_container: 2
2024-05-09 13:18:51,014:INFO:Ridge(random_state=777)
2024-05-09 13:18:51,014:INFO:create_model() successfully completed......................................
2024-05-09 13:18:51,091:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:51,091:INFO:Creating metrics dataframe
2024-05-09 13:18:51,096:INFO:Initializing Elastic Net
2024-05-09 13:18:51,096:INFO:Total runtime is 0.07310768763224283 minutes
2024-05-09 13:18:51,098:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:51,098:INFO:Initializing create_model()
2024-05-09 13:18:51,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:51,098:INFO:Checking exceptions
2024-05-09 13:18:51,098:INFO:Importing libraries
2024-05-09 13:18:51,098:INFO:Copying training dataset
2024-05-09 13:18:51,100:INFO:Defining folds
2024-05-09 13:18:51,100:INFO:Declaring metric variables
2024-05-09 13:18:51,101:INFO:Importing untrained model
2024-05-09 13:18:51,103:INFO:Elastic Net Imported successfully
2024-05-09 13:18:51,107:INFO:Starting cross validation
2024-05-09 13:18:51,108:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:51,164:INFO:Calculating mean and std
2024-05-09 13:18:51,165:INFO:Creating metrics dataframe
2024-05-09 13:18:51,168:INFO:Uploading results into container
2024-05-09 13:18:51,169:INFO:Uploading model into container now
2024-05-09 13:18:51,169:INFO:_master_model_container: 4
2024-05-09 13:18:51,169:INFO:_display_container: 2
2024-05-09 13:18:51,170:INFO:ElasticNet(random_state=777)
2024-05-09 13:18:51,170:INFO:create_model() successfully completed......................................
2024-05-09 13:18:51,263:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:51,264:INFO:Creating metrics dataframe
2024-05-09 13:18:51,270:INFO:Initializing Least Angle Regression
2024-05-09 13:18:51,270:INFO:Total runtime is 0.07600284814834594 minutes
2024-05-09 13:18:51,273:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:51,273:INFO:Initializing create_model()
2024-05-09 13:18:51,273:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:51,273:INFO:Checking exceptions
2024-05-09 13:18:51,273:INFO:Importing libraries
2024-05-09 13:18:51,273:INFO:Copying training dataset
2024-05-09 13:18:51,275:INFO:Defining folds
2024-05-09 13:18:51,275:INFO:Declaring metric variables
2024-05-09 13:18:51,278:INFO:Importing untrained model
2024-05-09 13:18:51,281:INFO:Least Angle Regression Imported successfully
2024-05-09 13:18:51,285:INFO:Starting cross validation
2024-05-09 13:18:51,286:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:51,368:INFO:Calculating mean and std
2024-05-09 13:18:51,368:INFO:Creating metrics dataframe
2024-05-09 13:18:51,370:INFO:Uploading results into container
2024-05-09 13:18:51,370:INFO:Uploading model into container now
2024-05-09 13:18:51,370:INFO:_master_model_container: 5
2024-05-09 13:18:51,370:INFO:_display_container: 2
2024-05-09 13:18:51,371:INFO:Lars(random_state=777)
2024-05-09 13:18:51,371:INFO:create_model() successfully completed......................................
2024-05-09 13:18:51,459:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:51,460:INFO:Creating metrics dataframe
2024-05-09 13:18:51,466:INFO:Initializing Lasso Least Angle Regression
2024-05-09 13:18:51,466:INFO:Total runtime is 0.07926318248112996 minutes
2024-05-09 13:18:51,468:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:51,468:INFO:Initializing create_model()
2024-05-09 13:18:51,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:51,468:INFO:Checking exceptions
2024-05-09 13:18:51,468:INFO:Importing libraries
2024-05-09 13:18:51,468:INFO:Copying training dataset
2024-05-09 13:18:51,471:INFO:Defining folds
2024-05-09 13:18:51,471:INFO:Declaring metric variables
2024-05-09 13:18:51,473:INFO:Importing untrained model
2024-05-09 13:18:51,475:INFO:Lasso Least Angle Regression Imported successfully
2024-05-09 13:18:51,479:INFO:Starting cross validation
2024-05-09 13:18:51,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:51,553:INFO:Calculating mean and std
2024-05-09 13:18:51,554:INFO:Creating metrics dataframe
2024-05-09 13:18:51,557:INFO:Uploading results into container
2024-05-09 13:18:51,557:INFO:Uploading model into container now
2024-05-09 13:18:51,557:INFO:_master_model_container: 6
2024-05-09 13:18:51,557:INFO:_display_container: 2
2024-05-09 13:18:51,557:INFO:LassoLars(random_state=777)
2024-05-09 13:18:51,557:INFO:create_model() successfully completed......................................
2024-05-09 13:18:51,642:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:51,642:INFO:Creating metrics dataframe
2024-05-09 13:18:51,648:INFO:Initializing Orthogonal Matching Pursuit
2024-05-09 13:18:51,648:INFO:Total runtime is 0.08230027755101521 minutes
2024-05-09 13:18:51,650:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:51,650:INFO:Initializing create_model()
2024-05-09 13:18:51,650:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:51,650:INFO:Checking exceptions
2024-05-09 13:18:51,650:INFO:Importing libraries
2024-05-09 13:18:51,650:INFO:Copying training dataset
2024-05-09 13:18:51,652:INFO:Defining folds
2024-05-09 13:18:51,652:INFO:Declaring metric variables
2024-05-09 13:18:51,655:INFO:Importing untrained model
2024-05-09 13:18:51,657:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-09 13:18:51,661:INFO:Starting cross validation
2024-05-09 13:18:51,662:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:51,711:INFO:Calculating mean and std
2024-05-09 13:18:51,711:INFO:Creating metrics dataframe
2024-05-09 13:18:51,713:INFO:Uploading results into container
2024-05-09 13:18:51,713:INFO:Uploading model into container now
2024-05-09 13:18:51,713:INFO:_master_model_container: 7
2024-05-09 13:18:51,713:INFO:_display_container: 2
2024-05-09 13:18:51,714:INFO:OrthogonalMatchingPursuit()
2024-05-09 13:18:51,714:INFO:create_model() successfully completed......................................
2024-05-09 13:18:51,799:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:51,799:INFO:Creating metrics dataframe
2024-05-09 13:18:51,805:INFO:Initializing Bayesian Ridge
2024-05-09 13:18:51,805:INFO:Total runtime is 0.08491700490315754 minutes
2024-05-09 13:18:51,807:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:51,807:INFO:Initializing create_model()
2024-05-09 13:18:51,807:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:51,807:INFO:Checking exceptions
2024-05-09 13:18:51,807:INFO:Importing libraries
2024-05-09 13:18:51,807:INFO:Copying training dataset
2024-05-09 13:18:51,810:INFO:Defining folds
2024-05-09 13:18:51,810:INFO:Declaring metric variables
2024-05-09 13:18:51,812:INFO:Importing untrained model
2024-05-09 13:18:51,814:INFO:Bayesian Ridge Imported successfully
2024-05-09 13:18:51,818:INFO:Starting cross validation
2024-05-09 13:18:51,819:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:51,874:INFO:Calculating mean and std
2024-05-09 13:18:51,875:INFO:Creating metrics dataframe
2024-05-09 13:18:51,877:INFO:Uploading results into container
2024-05-09 13:18:51,878:INFO:Uploading model into container now
2024-05-09 13:18:51,878:INFO:_master_model_container: 8
2024-05-09 13:18:51,878:INFO:_display_container: 2
2024-05-09 13:18:51,878:INFO:BayesianRidge()
2024-05-09 13:18:51,878:INFO:create_model() successfully completed......................................
2024-05-09 13:18:51,963:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:51,963:INFO:Creating metrics dataframe
2024-05-09 13:18:51,969:INFO:Initializing Passive Aggressive Regressor
2024-05-09 13:18:51,969:INFO:Total runtime is 0.08765890598297117 minutes
2024-05-09 13:18:51,971:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:51,971:INFO:Initializing create_model()
2024-05-09 13:18:51,971:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:51,971:INFO:Checking exceptions
2024-05-09 13:18:51,971:INFO:Importing libraries
2024-05-09 13:18:51,971:INFO:Copying training dataset
2024-05-09 13:18:51,974:INFO:Defining folds
2024-05-09 13:18:51,974:INFO:Declaring metric variables
2024-05-09 13:18:51,976:INFO:Importing untrained model
2024-05-09 13:18:51,978:INFO:Passive Aggressive Regressor Imported successfully
2024-05-09 13:18:51,983:INFO:Starting cross validation
2024-05-09 13:18:51,984:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:52,041:INFO:Calculating mean and std
2024-05-09 13:18:52,042:INFO:Creating metrics dataframe
2024-05-09 13:18:52,043:INFO:Uploading results into container
2024-05-09 13:18:52,044:INFO:Uploading model into container now
2024-05-09 13:18:52,044:INFO:_master_model_container: 9
2024-05-09 13:18:52,044:INFO:_display_container: 2
2024-05-09 13:18:52,044:INFO:PassiveAggressiveRegressor(random_state=777)
2024-05-09 13:18:52,044:INFO:create_model() successfully completed......................................
2024-05-09 13:18:52,127:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:52,127:INFO:Creating metrics dataframe
2024-05-09 13:18:52,133:INFO:Initializing Huber Regressor
2024-05-09 13:18:52,133:INFO:Total runtime is 0.09038834174474078 minutes
2024-05-09 13:18:52,135:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:52,135:INFO:Initializing create_model()
2024-05-09 13:18:52,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:52,135:INFO:Checking exceptions
2024-05-09 13:18:52,135:INFO:Importing libraries
2024-05-09 13:18:52,135:INFO:Copying training dataset
2024-05-09 13:18:52,137:INFO:Defining folds
2024-05-09 13:18:52,137:INFO:Declaring metric variables
2024-05-09 13:18:52,139:INFO:Importing untrained model
2024-05-09 13:18:52,141:INFO:Huber Regressor Imported successfully
2024-05-09 13:18:52,145:INFO:Starting cross validation
2024-05-09 13:18:52,146:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:52,200:INFO:Calculating mean and std
2024-05-09 13:18:52,200:INFO:Creating metrics dataframe
2024-05-09 13:18:52,203:INFO:Uploading results into container
2024-05-09 13:18:52,203:INFO:Uploading model into container now
2024-05-09 13:18:52,203:INFO:_master_model_container: 10
2024-05-09 13:18:52,203:INFO:_display_container: 2
2024-05-09 13:18:52,203:INFO:HuberRegressor()
2024-05-09 13:18:52,203:INFO:create_model() successfully completed......................................
2024-05-09 13:18:52,293:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:52,293:INFO:Creating metrics dataframe
2024-05-09 13:18:52,300:INFO:Initializing K Neighbors Regressor
2024-05-09 13:18:52,300:INFO:Total runtime is 0.09316378434499102 minutes
2024-05-09 13:18:52,302:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:52,302:INFO:Initializing create_model()
2024-05-09 13:18:52,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:52,302:INFO:Checking exceptions
2024-05-09 13:18:52,302:INFO:Importing libraries
2024-05-09 13:18:52,302:INFO:Copying training dataset
2024-05-09 13:18:52,305:INFO:Defining folds
2024-05-09 13:18:52,305:INFO:Declaring metric variables
2024-05-09 13:18:52,307:INFO:Importing untrained model
2024-05-09 13:18:52,309:INFO:K Neighbors Regressor Imported successfully
2024-05-09 13:18:52,314:INFO:Starting cross validation
2024-05-09 13:18:52,314:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:52,394:INFO:Calculating mean and std
2024-05-09 13:18:52,395:INFO:Creating metrics dataframe
2024-05-09 13:18:52,398:INFO:Uploading results into container
2024-05-09 13:18:52,398:INFO:Uploading model into container now
2024-05-09 13:18:52,399:INFO:_master_model_container: 11
2024-05-09 13:18:52,399:INFO:_display_container: 2
2024-05-09 13:18:52,399:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-09 13:18:52,399:INFO:create_model() successfully completed......................................
2024-05-09 13:18:52,487:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:52,487:INFO:Creating metrics dataframe
2024-05-09 13:18:52,493:INFO:Initializing Decision Tree Regressor
2024-05-09 13:18:52,493:INFO:Total runtime is 0.09638920227686562 minutes
2024-05-09 13:18:52,495:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:52,495:INFO:Initializing create_model()
2024-05-09 13:18:52,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:52,495:INFO:Checking exceptions
2024-05-09 13:18:52,495:INFO:Importing libraries
2024-05-09 13:18:52,495:INFO:Copying training dataset
2024-05-09 13:18:52,497:INFO:Defining folds
2024-05-09 13:18:52,497:INFO:Declaring metric variables
2024-05-09 13:18:52,499:INFO:Importing untrained model
2024-05-09 13:18:52,501:INFO:Decision Tree Regressor Imported successfully
2024-05-09 13:18:52,505:INFO:Starting cross validation
2024-05-09 13:18:52,506:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:52,557:INFO:Calculating mean and std
2024-05-09 13:18:52,558:INFO:Creating metrics dataframe
2024-05-09 13:18:52,560:INFO:Uploading results into container
2024-05-09 13:18:52,561:INFO:Uploading model into container now
2024-05-09 13:18:52,561:INFO:_master_model_container: 12
2024-05-09 13:18:52,561:INFO:_display_container: 2
2024-05-09 13:18:52,561:INFO:DecisionTreeRegressor(random_state=777)
2024-05-09 13:18:52,561:INFO:create_model() successfully completed......................................
2024-05-09 13:18:52,645:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:52,645:INFO:Creating metrics dataframe
2024-05-09 13:18:52,651:INFO:Initializing Random Forest Regressor
2024-05-09 13:18:52,651:INFO:Total runtime is 0.09902203480402627 minutes
2024-05-09 13:18:52,653:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:52,654:INFO:Initializing create_model()
2024-05-09 13:18:52,654:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:52,654:INFO:Checking exceptions
2024-05-09 13:18:52,654:INFO:Importing libraries
2024-05-09 13:18:52,654:INFO:Copying training dataset
2024-05-09 13:18:52,656:INFO:Defining folds
2024-05-09 13:18:52,656:INFO:Declaring metric variables
2024-05-09 13:18:52,658:INFO:Importing untrained model
2024-05-09 13:18:52,661:INFO:Random Forest Regressor Imported successfully
2024-05-09 13:18:52,664:INFO:Starting cross validation
2024-05-09 13:18:52,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:52,916:INFO:Calculating mean and std
2024-05-09 13:18:52,917:INFO:Creating metrics dataframe
2024-05-09 13:18:52,919:INFO:Uploading results into container
2024-05-09 13:18:52,920:INFO:Uploading model into container now
2024-05-09 13:18:52,920:INFO:_master_model_container: 13
2024-05-09 13:18:52,920:INFO:_display_container: 2
2024-05-09 13:18:52,920:INFO:RandomForestRegressor(n_jobs=-1, random_state=777)
2024-05-09 13:18:52,920:INFO:create_model() successfully completed......................................
2024-05-09 13:18:52,994:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:52,994:INFO:Creating metrics dataframe
2024-05-09 13:18:53,000:INFO:Initializing Extra Trees Regressor
2024-05-09 13:18:53,000:INFO:Total runtime is 0.1048403223355611 minutes
2024-05-09 13:18:53,002:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:53,002:INFO:Initializing create_model()
2024-05-09 13:18:53,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:53,002:INFO:Checking exceptions
2024-05-09 13:18:53,002:INFO:Importing libraries
2024-05-09 13:18:53,002:INFO:Copying training dataset
2024-05-09 13:18:53,004:INFO:Defining folds
2024-05-09 13:18:53,004:INFO:Declaring metric variables
2024-05-09 13:18:53,005:INFO:Importing untrained model
2024-05-09 13:18:53,007:INFO:Extra Trees Regressor Imported successfully
2024-05-09 13:18:53,010:INFO:Starting cross validation
2024-05-09 13:18:53,011:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:53,195:INFO:Calculating mean and std
2024-05-09 13:18:53,196:INFO:Creating metrics dataframe
2024-05-09 13:18:53,199:INFO:Uploading results into container
2024-05-09 13:18:53,199:INFO:Uploading model into container now
2024-05-09 13:18:53,199:INFO:_master_model_container: 14
2024-05-09 13:18:53,200:INFO:_display_container: 2
2024-05-09 13:18:53,200:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=777)
2024-05-09 13:18:53,200:INFO:create_model() successfully completed......................................
2024-05-09 13:18:53,270:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:53,270:INFO:Creating metrics dataframe
2024-05-09 13:18:53,276:INFO:Initializing AdaBoost Regressor
2024-05-09 13:18:53,276:INFO:Total runtime is 0.10943731069564819 minutes
2024-05-09 13:18:53,278:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:53,278:INFO:Initializing create_model()
2024-05-09 13:18:53,278:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:53,278:INFO:Checking exceptions
2024-05-09 13:18:53,278:INFO:Importing libraries
2024-05-09 13:18:53,279:INFO:Copying training dataset
2024-05-09 13:18:53,280:INFO:Defining folds
2024-05-09 13:18:53,280:INFO:Declaring metric variables
2024-05-09 13:18:53,282:INFO:Importing untrained model
2024-05-09 13:18:53,284:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:18:53,289:INFO:Starting cross validation
2024-05-09 13:18:53,290:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:53,421:INFO:Calculating mean and std
2024-05-09 13:18:53,422:INFO:Creating metrics dataframe
2024-05-09 13:18:53,426:INFO:Uploading results into container
2024-05-09 13:18:53,426:INFO:Uploading model into container now
2024-05-09 13:18:53,426:INFO:_master_model_container: 15
2024-05-09 13:18:53,427:INFO:_display_container: 2
2024-05-09 13:18:53,427:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 13:18:53,427:INFO:create_model() successfully completed......................................
2024-05-09 13:18:53,509:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:53,509:INFO:Creating metrics dataframe
2024-05-09 13:18:53,515:INFO:Initializing Gradient Boosting Regressor
2024-05-09 13:18:53,515:INFO:Total runtime is 0.11341699759165445 minutes
2024-05-09 13:18:53,517:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:53,517:INFO:Initializing create_model()
2024-05-09 13:18:53,517:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:53,517:INFO:Checking exceptions
2024-05-09 13:18:53,517:INFO:Importing libraries
2024-05-09 13:18:53,517:INFO:Copying training dataset
2024-05-09 13:18:53,518:INFO:Defining folds
2024-05-09 13:18:53,518:INFO:Declaring metric variables
2024-05-09 13:18:53,520:INFO:Importing untrained model
2024-05-09 13:18:53,522:INFO:Gradient Boosting Regressor Imported successfully
2024-05-09 13:18:53,527:INFO:Starting cross validation
2024-05-09 13:18:53,528:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:53,662:INFO:Calculating mean and std
2024-05-09 13:18:53,663:INFO:Creating metrics dataframe
2024-05-09 13:18:53,665:INFO:Uploading results into container
2024-05-09 13:18:53,666:INFO:Uploading model into container now
2024-05-09 13:18:53,666:INFO:_master_model_container: 16
2024-05-09 13:18:53,666:INFO:_display_container: 2
2024-05-09 13:18:53,666:INFO:GradientBoostingRegressor(random_state=777)
2024-05-09 13:18:53,666:INFO:create_model() successfully completed......................................
2024-05-09 13:18:53,739:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:53,739:INFO:Creating metrics dataframe
2024-05-09 13:18:53,747:INFO:Initializing Light Gradient Boosting Machine
2024-05-09 13:18:53,747:INFO:Total runtime is 0.11728052298227945 minutes
2024-05-09 13:18:53,749:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:53,749:INFO:Initializing create_model()
2024-05-09 13:18:53,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:53,749:INFO:Checking exceptions
2024-05-09 13:18:53,749:INFO:Importing libraries
2024-05-09 13:18:53,749:INFO:Copying training dataset
2024-05-09 13:18:53,751:INFO:Defining folds
2024-05-09 13:18:53,751:INFO:Declaring metric variables
2024-05-09 13:18:53,753:INFO:Importing untrained model
2024-05-09 13:18:53,755:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-09 13:18:53,761:INFO:Starting cross validation
2024-05-09 13:18:53,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:54,313:INFO:Calculating mean and std
2024-05-09 13:18:54,314:INFO:Creating metrics dataframe
2024-05-09 13:18:54,324:INFO:Uploading results into container
2024-05-09 13:18:54,324:INFO:Uploading model into container now
2024-05-09 13:18:54,324:INFO:_master_model_container: 17
2024-05-09 13:18:54,324:INFO:_display_container: 2
2024-05-09 13:18:54,324:INFO:LGBMRegressor(n_jobs=-1, random_state=777)
2024-05-09 13:18:54,324:INFO:create_model() successfully completed......................................
2024-05-09 13:18:54,393:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:54,394:INFO:Creating metrics dataframe
2024-05-09 13:18:54,400:INFO:Initializing Dummy Regressor
2024-05-09 13:18:54,400:INFO:Total runtime is 0.12816884120305377 minutes
2024-05-09 13:18:54,402:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:54,402:INFO:Initializing create_model()
2024-05-09 13:18:54,402:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0efdd60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:54,402:INFO:Checking exceptions
2024-05-09 13:18:54,402:INFO:Importing libraries
2024-05-09 13:18:54,402:INFO:Copying training dataset
2024-05-09 13:18:54,403:INFO:Defining folds
2024-05-09 13:18:54,403:INFO:Declaring metric variables
2024-05-09 13:18:54,405:INFO:Importing untrained model
2024-05-09 13:18:54,407:INFO:Dummy Regressor Imported successfully
2024-05-09 13:18:54,410:INFO:Starting cross validation
2024-05-09 13:18:54,411:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:54,457:INFO:Calculating mean and std
2024-05-09 13:18:54,458:INFO:Creating metrics dataframe
2024-05-09 13:18:54,460:INFO:Uploading results into container
2024-05-09 13:18:54,460:INFO:Uploading model into container now
2024-05-09 13:18:54,461:INFO:_master_model_container: 18
2024-05-09 13:18:54,461:INFO:_display_container: 2
2024-05-09 13:18:54,461:INFO:DummyRegressor()
2024-05-09 13:18:54,461:INFO:create_model() successfully completed......................................
2024-05-09 13:18:54,543:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:54,543:INFO:Creating metrics dataframe
2024-05-09 13:18:54,557:INFO:Initializing create_model()
2024-05-09 13:18:54,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=AdaBoostRegressor(random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:54,557:INFO:Checking exceptions
2024-05-09 13:18:54,559:INFO:Importing libraries
2024-05-09 13:18:54,559:INFO:Copying training dataset
2024-05-09 13:18:54,562:INFO:Defining folds
2024-05-09 13:18:54,562:INFO:Declaring metric variables
2024-05-09 13:18:54,562:INFO:Importing untrained model
2024-05-09 13:18:54,562:INFO:Declaring custom model
2024-05-09 13:18:54,562:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:18:54,563:INFO:Cross validation set to False
2024-05-09 13:18:54,563:INFO:Fitting Model
2024-05-09 13:18:54,612:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 13:18:54,612:INFO:create_model() successfully completed......................................
2024-05-09 13:18:54,705:INFO:_master_model_container: 18
2024-05-09 13:18:54,705:INFO:_display_container: 2
2024-05-09 13:18:54,705:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 13:18:54,705:INFO:compare_models() successfully completed......................................
2024-05-09 13:18:54,705:INFO:Initializing tune_model()
2024-05-09 13:18:54,705:INFO:tune_model(estimator=AdaBoostRegressor(random_state=777), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>)
2024-05-09 13:18:54,705:INFO:Checking exceptions
2024-05-09 13:18:54,713:INFO:Copying training dataset
2024-05-09 13:18:54,714:INFO:Checking base model
2024-05-09 13:18:54,714:INFO:Base model : AdaBoost Regressor
2024-05-09 13:18:54,716:INFO:Declaring metric variables
2024-05-09 13:18:54,718:INFO:Defining Hyperparameters
2024-05-09 13:18:54,813:INFO:Tuning with n_jobs=-1
2024-05-09 13:18:54,813:INFO:Initializing RandomizedSearchCV
2024-05-09 13:18:56,663:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__loss': 'linear', 'actual_estimator__learning_rate': 0.05}
2024-05-09 13:18:56,663:INFO:Hyperparameter search completed
2024-05-09 13:18:56,663:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:56,664:INFO:Initializing create_model()
2024-05-09 13:18:56,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=AdaBoostRegressor(random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d3107370>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'loss': 'linear', 'learning_rate': 0.05})
2024-05-09 13:18:56,664:INFO:Checking exceptions
2024-05-09 13:18:56,664:INFO:Importing libraries
2024-05-09 13:18:56,664:INFO:Copying training dataset
2024-05-09 13:18:56,667:INFO:Defining folds
2024-05-09 13:18:56,667:INFO:Declaring metric variables
2024-05-09 13:18:56,670:INFO:Importing untrained model
2024-05-09 13:18:56,670:INFO:Declaring custom model
2024-05-09 13:18:56,672:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:18:56,678:INFO:Starting cross validation
2024-05-09 13:18:56,679:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:56,902:INFO:Calculating mean and std
2024-05-09 13:18:56,903:INFO:Creating metrics dataframe
2024-05-09 13:18:56,907:INFO:Finalizing model
2024-05-09 13:18:57,008:INFO:Uploading results into container
2024-05-09 13:18:57,009:INFO:Uploading model into container now
2024-05-09 13:18:57,009:INFO:_master_model_container: 19
2024-05-09 13:18:57,009:INFO:_display_container: 3
2024-05-09 13:18:57,009:INFO:AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777)
2024-05-09 13:18:57,009:INFO:create_model() successfully completed......................................
2024-05-09 13:18:57,087:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:57,087:INFO:choose_better activated
2024-05-09 13:18:57,089:INFO:SubProcess create_model() called ==================================
2024-05-09 13:18:57,090:INFO:Initializing create_model()
2024-05-09 13:18:57,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=AdaBoostRegressor(random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:57,090:INFO:Checking exceptions
2024-05-09 13:18:57,091:INFO:Importing libraries
2024-05-09 13:18:57,091:INFO:Copying training dataset
2024-05-09 13:18:57,092:INFO:Defining folds
2024-05-09 13:18:57,093:INFO:Declaring metric variables
2024-05-09 13:18:57,093:INFO:Importing untrained model
2024-05-09 13:18:57,093:INFO:Declaring custom model
2024-05-09 13:18:57,093:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:18:57,093:INFO:Starting cross validation
2024-05-09 13:18:57,094:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:18:57,212:INFO:Calculating mean and std
2024-05-09 13:18:57,212:INFO:Creating metrics dataframe
2024-05-09 13:18:57,214:INFO:Finalizing model
2024-05-09 13:18:57,262:INFO:Uploading results into container
2024-05-09 13:18:57,262:INFO:Uploading model into container now
2024-05-09 13:18:57,262:INFO:_master_model_container: 20
2024-05-09 13:18:57,262:INFO:_display_container: 4
2024-05-09 13:18:57,262:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 13:18:57,262:INFO:create_model() successfully completed......................................
2024-05-09 13:18:57,330:INFO:SubProcess create_model() end ==================================
2024-05-09 13:18:57,330:INFO:AdaBoostRegressor(random_state=777) result for R2 is 0.6348
2024-05-09 13:18:57,331:INFO:AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777) result for R2 is 0.6349
2024-05-09 13:18:57,331:INFO:AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777) is best model
2024-05-09 13:18:57,331:INFO:choose_better completed
2024-05-09 13:18:57,336:INFO:_master_model_container: 20
2024-05-09 13:18:57,336:INFO:_display_container: 3
2024-05-09 13:18:57,336:INFO:AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777)
2024-05-09 13:18:57,336:INFO:tune_model() successfully completed......................................
2024-05-09 13:18:57,429:INFO:Initializing finalize_model()
2024-05-09 13:18:57,429:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-09 13:18:57,429:INFO:Finalizing AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777)
2024-05-09 13:18:57,430:INFO:Initializing create_model()
2024-05-09 13:18:57,431:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:18:57,431:INFO:Checking exceptions
2024-05-09 13:18:57,431:INFO:Importing libraries
2024-05-09 13:18:57,432:INFO:Copying training dataset
2024-05-09 13:18:57,432:INFO:Defining folds
2024-05-09 13:18:57,432:INFO:Declaring metric variables
2024-05-09 13:18:57,432:INFO:Importing untrained model
2024-05-09 13:18:57,432:INFO:Declaring custom model
2024-05-09 13:18:57,432:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:18:57,432:INFO:Cross validation set to False
2024-05-09 13:18:57,432:INFO:Fitting Model
2024-05-09 13:18:57,536:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 AdaBoostRegressor(learning_rate=0.05, n_estimators=100,
                                   random_state=777))])
2024-05-09 13:18:57,537:INFO:create_model() successfully completed......................................
2024-05-09 13:18:57,611:INFO:_master_model_container: 20
2024-05-09 13:18:57,611:INFO:_display_container: 3
2024-05-09 13:18:57,614:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 AdaBoostRegressor(learning_rate=0.05, n_estimators=100,
                                   random_state=777))])
2024-05-09 13:18:57,614:INFO:finalize_model() successfully completed......................................
2024-05-09 13:18:57,683:INFO:Initializing predict_model()
2024-05-09 13:18:57,684:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d2808190>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 AdaBoostRegressor(learning_rate=0.05, n_estimators=100,
                                   random_state=777))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x786699219820>)
2024-05-09 13:18:57,684:INFO:Checking exceptions
2024-05-09 13:18:57,684:INFO:Preloading libraries
2024-05-09 13:18:57,685:INFO:Set up data.
2024-05-09 13:18:57,687:INFO:Set up index.
2024-05-09 13:18:57,698:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-09 13:50:05,525:WARNING:/tmp/ipykernel_14873/2262976735.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-09 13:50:05,536:INFO:PyCaret RegressionExperiment
2024-05-09 13:50:05,536:INFO:Logging name: reg-default-name
2024-05-09 13:50:05,536:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-09 13:50:05,536:INFO:version 3.3.2
2024-05-09 13:50:05,536:INFO:Initializing setup()
2024-05-09 13:50:05,536:INFO:self.USI: 6073
2024-05-09 13:50:05,536:INFO:self._variable_keys: {'y', '_ml_usecase', 'exp_name_log', 'gpu_n_jobs_param', 'n_jobs_param', 'data', 'log_plots_param', 'seed', 'USI', 'exp_id', 'X', 'target_param', 'y_test', 'gpu_param', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'idx', 'fold_groups_param', 'transform_target_param', 'logging_param', 'memory', 'pipeline', 'fold_generator', 'X_train', 'y_train'}
2024-05-09 13:50:05,537:INFO:Checking environment
2024-05-09 13:50:05,537:INFO:python_version: 3.9.18
2024-05-09 13:50:05,537:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-09 13:50:05,537:INFO:machine: x86_64
2024-05-09 13:50:05,537:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 13:50:05,537:INFO:Memory: svmem(total=16429789184, available=5124775936, percent=68.8, used=10060218368, free=1154760704, active=7055200256, inactive=6738386944, buffers=116465664, cached=5098344448, shared=898187264, slab=615112704)
2024-05-09 13:50:05,537:INFO:Physical Core: 12
2024-05-09 13:50:05,537:INFO:Logical Core: 16
2024-05-09 13:50:05,537:INFO:Checking libraries
2024-05-09 13:50:05,537:INFO:System:
2024-05-09 13:50:05,537:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-09 13:50:05,537:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-09 13:50:05,537:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 13:50:05,537:INFO:PyCaret required dependencies:
2024-05-09 13:50:05,537:INFO:                 pip: 23.2.1
2024-05-09 13:50:05,537:INFO:          setuptools: 68.0.0
2024-05-09 13:50:05,538:INFO:             pycaret: 3.3.2
2024-05-09 13:50:05,538:INFO:             IPython: 8.15.0
2024-05-09 13:50:05,538:INFO:          ipywidgets: 8.0.4
2024-05-09 13:50:05,538:INFO:                tqdm: 4.65.0
2024-05-09 13:50:05,538:INFO:               numpy: 1.24.3
2024-05-09 13:50:05,538:INFO:              pandas: 1.4.2
2024-05-09 13:50:05,538:INFO:              jinja2: 3.1.4
2024-05-09 13:50:05,538:INFO:               scipy: 1.11.3
2024-05-09 13:50:05,538:INFO:              joblib: 1.2.0
2024-05-09 13:50:05,538:INFO:             sklearn: 1.4.2
2024-05-09 13:50:05,538:INFO:                pyod: 1.1.3
2024-05-09 13:50:05,538:INFO:            imblearn: 0.12.2
2024-05-09 13:50:05,538:INFO:   category_encoders: 2.6.3
2024-05-09 13:50:05,538:INFO:            lightgbm: 4.3.0
2024-05-09 13:50:05,538:INFO:               numba: 0.58.0
2024-05-09 13:50:05,538:INFO:            requests: 2.31.0
2024-05-09 13:50:05,538:INFO:          matplotlib: 3.7.2
2024-05-09 13:50:05,538:INFO:          scikitplot: 0.3.7
2024-05-09 13:50:05,538:INFO:         yellowbrick: 1.5
2024-05-09 13:50:05,538:INFO:              plotly: 5.22.0
2024-05-09 13:50:05,538:INFO:    plotly-resampler: Not installed
2024-05-09 13:50:05,538:INFO:             kaleido: 0.2.1
2024-05-09 13:50:05,538:INFO:           schemdraw: 0.15
2024-05-09 13:50:05,538:INFO:         statsmodels: 0.14.0
2024-05-09 13:50:05,538:INFO:              sktime: 0.26.0
2024-05-09 13:50:05,538:INFO:               tbats: 1.1.3
2024-05-09 13:50:05,538:INFO:            pmdarima: 2.0.4
2024-05-09 13:50:05,538:INFO:              psutil: 5.9.0
2024-05-09 13:50:05,538:INFO:          markupsafe: 2.0.1
2024-05-09 13:50:05,538:INFO:             pickle5: Not installed
2024-05-09 13:50:05,538:INFO:         cloudpickle: 2.2.1
2024-05-09 13:50:05,538:INFO:         deprecation: 2.1.0
2024-05-09 13:50:05,538:INFO:              xxhash: 2.0.2
2024-05-09 13:50:05,538:INFO:           wurlitzer: 3.0.2
2024-05-09 13:50:05,538:INFO:PyCaret optional dependencies:
2024-05-09 13:50:05,538:INFO:                shap: Not installed
2024-05-09 13:50:05,538:INFO:           interpret: Not installed
2024-05-09 13:50:05,538:INFO:                umap: Not installed
2024-05-09 13:50:05,538:INFO:     ydata_profiling: Not installed
2024-05-09 13:50:05,538:INFO:  explainerdashboard: Not installed
2024-05-09 13:50:05,538:INFO:             autoviz: Not installed
2024-05-09 13:50:05,538:INFO:           fairlearn: Not installed
2024-05-09 13:50:05,538:INFO:          deepchecks: Not installed
2024-05-09 13:50:05,538:INFO:             xgboost: Not installed
2024-05-09 13:50:05,538:INFO:            catboost: Not installed
2024-05-09 13:50:05,538:INFO:              kmodes: Not installed
2024-05-09 13:50:05,538:INFO:             mlxtend: Not installed
2024-05-09 13:50:05,538:INFO:       statsforecast: Not installed
2024-05-09 13:50:05,538:INFO:        tune_sklearn: Not installed
2024-05-09 13:50:05,538:INFO:                 ray: Not installed
2024-05-09 13:50:05,538:INFO:            hyperopt: Not installed
2024-05-09 13:50:05,538:INFO:              optuna: Not installed
2024-05-09 13:50:05,538:INFO:               skopt: Not installed
2024-05-09 13:50:05,538:INFO:              mlflow: Not installed
2024-05-09 13:50:05,538:INFO:              gradio: Not installed
2024-05-09 13:50:05,538:INFO:             fastapi: Not installed
2024-05-09 13:50:05,538:INFO:             uvicorn: Not installed
2024-05-09 13:50:05,538:INFO:              m2cgen: Not installed
2024-05-09 13:50:05,538:INFO:           evidently: Not installed
2024-05-09 13:50:05,538:INFO:               fugue: Not installed
2024-05-09 13:50:05,538:INFO:           streamlit: Not installed
2024-05-09 13:50:05,538:INFO:             prophet: Not installed
2024-05-09 13:50:05,538:INFO:None
2024-05-09 13:50:05,538:INFO:Set up data.
2024-05-09 13:50:05,541:INFO:Set up folding strategy.
2024-05-09 13:50:05,541:INFO:Set up train/test split.
2024-05-09 13:50:05,543:INFO:Set up index.
2024-05-09 13:50:05,543:INFO:Assigning column types.
2024-05-09 13:50:05,545:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-09 13:50:05,545:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,547:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,549:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,602:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,602:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,602:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,603:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,605:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,607:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,635:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,658:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,659:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-09 13:50:05,661:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,663:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,693:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,717:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,720:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,722:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,752:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,776:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,776:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-09 13:50:05,781:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,810:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,834:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,839:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,869:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,893:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,893:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,893:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-09 13:50:05,928:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,950:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:50:05,950:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,950:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:05,985:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:06,007:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 13:50:06,007:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,007:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,007:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-09 13:50:06,039:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:06,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 13:50:06,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,117:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-09 13:50:06,172:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,172:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,227:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,227:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,228:INFO:Preparing preprocessing pipeline...
2024-05-09 13:50:06,228:INFO:Set up simple imputation.
2024-05-09 13:50:06,228:INFO:Set up feature normalization.
2024-05-09 13:50:06,228:INFO:Set up column name cleaning.
2024-05-09 13:50:06,240:INFO:Finished creating preprocessing pipeline.
2024-05-09 13:50:06,242:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-09 13:50:06,243:INFO:Creating final display dataframe.
2024-05-09 13:50:06,280:INFO:Setup _display_container:                     Description             Value
0                    Session id               777
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (506, 4)
4        Transformed data shape          (506, 4)
5   Transformed train set shape          (354, 4)
6    Transformed test set shape          (152, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            minmax
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              6073
2024-05-09 13:50:06,338:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,338:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,393:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 13:50:06,395:INFO:setup() successfully completed in 0.86s...............
2024-05-09 13:50:06,396:INFO:Initializing compare_models()
2024-05-09 13:50:06,396:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-09 13:50:06,396:INFO:Checking exceptions
2024-05-09 13:50:06,397:INFO:Preparing display monitor
2024-05-09 13:50:06,418:INFO:Initializing Linear Regression
2024-05-09 13:50:06,418:INFO:Total runtime is 4.458427429199219e-06 minutes
2024-05-09 13:50:06,420:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:06,421:INFO:Initializing create_model()
2024-05-09 13:50:06,421:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:06,421:INFO:Checking exceptions
2024-05-09 13:50:06,421:INFO:Importing libraries
2024-05-09 13:50:06,421:INFO:Copying training dataset
2024-05-09 13:50:06,423:INFO:Defining folds
2024-05-09 13:50:06,424:INFO:Declaring metric variables
2024-05-09 13:50:06,426:INFO:Importing untrained model
2024-05-09 13:50:06,429:INFO:Linear Regression Imported successfully
2024-05-09 13:50:06,434:INFO:Starting cross validation
2024-05-09 13:50:06,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:08,899:INFO:Calculating mean and std
2024-05-09 13:50:08,901:INFO:Creating metrics dataframe
2024-05-09 13:50:08,905:INFO:Uploading results into container
2024-05-09 13:50:08,906:INFO:Uploading model into container now
2024-05-09 13:50:08,907:INFO:_master_model_container: 1
2024-05-09 13:50:08,907:INFO:_display_container: 2
2024-05-09 13:50:08,908:INFO:LinearRegression(n_jobs=-1)
2024-05-09 13:50:08,908:INFO:create_model() successfully completed......................................
2024-05-09 13:50:08,999:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:08,999:INFO:Creating metrics dataframe
2024-05-09 13:50:09,003:INFO:Initializing Lasso Regression
2024-05-09 13:50:09,003:INFO:Total runtime is 0.04309031168619792 minutes
2024-05-09 13:50:09,005:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:09,005:INFO:Initializing create_model()
2024-05-09 13:50:09,005:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:09,006:INFO:Checking exceptions
2024-05-09 13:50:09,006:INFO:Importing libraries
2024-05-09 13:50:09,006:INFO:Copying training dataset
2024-05-09 13:50:09,009:INFO:Defining folds
2024-05-09 13:50:09,009:INFO:Declaring metric variables
2024-05-09 13:50:09,011:INFO:Importing untrained model
2024-05-09 13:50:09,013:INFO:Lasso Regression Imported successfully
2024-05-09 13:50:09,017:INFO:Starting cross validation
2024-05-09 13:50:09,018:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:11,541:INFO:Calculating mean and std
2024-05-09 13:50:11,541:INFO:Creating metrics dataframe
2024-05-09 13:50:11,543:INFO:Uploading results into container
2024-05-09 13:50:11,544:INFO:Uploading model into container now
2024-05-09 13:50:11,544:INFO:_master_model_container: 2
2024-05-09 13:50:11,544:INFO:_display_container: 2
2024-05-09 13:50:11,544:INFO:Lasso(random_state=777)
2024-05-09 13:50:11,544:INFO:create_model() successfully completed......................................
2024-05-09 13:50:11,619:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:11,619:INFO:Creating metrics dataframe
2024-05-09 13:50:11,624:INFO:Initializing Ridge Regression
2024-05-09 13:50:11,624:INFO:Total runtime is 0.08677318890889485 minutes
2024-05-09 13:50:11,626:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:11,626:INFO:Initializing create_model()
2024-05-09 13:50:11,626:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:11,626:INFO:Checking exceptions
2024-05-09 13:50:11,626:INFO:Importing libraries
2024-05-09 13:50:11,626:INFO:Copying training dataset
2024-05-09 13:50:11,628:INFO:Defining folds
2024-05-09 13:50:11,628:INFO:Declaring metric variables
2024-05-09 13:50:11,631:INFO:Importing untrained model
2024-05-09 13:50:11,633:INFO:Ridge Regression Imported successfully
2024-05-09 13:50:11,636:INFO:Starting cross validation
2024-05-09 13:50:11,637:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:11,681:INFO:Calculating mean and std
2024-05-09 13:50:11,682:INFO:Creating metrics dataframe
2024-05-09 13:50:11,685:INFO:Uploading results into container
2024-05-09 13:50:11,685:INFO:Uploading model into container now
2024-05-09 13:50:11,685:INFO:_master_model_container: 3
2024-05-09 13:50:11,685:INFO:_display_container: 2
2024-05-09 13:50:11,685:INFO:Ridge(random_state=777)
2024-05-09 13:50:11,685:INFO:create_model() successfully completed......................................
2024-05-09 13:50:11,761:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:11,761:INFO:Creating metrics dataframe
2024-05-09 13:50:11,766:INFO:Initializing Elastic Net
2024-05-09 13:50:11,766:INFO:Total runtime is 0.08913460175196329 minutes
2024-05-09 13:50:11,767:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:11,768:INFO:Initializing create_model()
2024-05-09 13:50:11,768:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:11,768:INFO:Checking exceptions
2024-05-09 13:50:11,768:INFO:Importing libraries
2024-05-09 13:50:11,768:INFO:Copying training dataset
2024-05-09 13:50:11,769:INFO:Defining folds
2024-05-09 13:50:11,769:INFO:Declaring metric variables
2024-05-09 13:50:11,771:INFO:Importing untrained model
2024-05-09 13:50:11,773:INFO:Elastic Net Imported successfully
2024-05-09 13:50:11,778:INFO:Starting cross validation
2024-05-09 13:50:11,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:11,823:INFO:Calculating mean and std
2024-05-09 13:50:11,824:INFO:Creating metrics dataframe
2024-05-09 13:50:11,826:INFO:Uploading results into container
2024-05-09 13:50:11,827:INFO:Uploading model into container now
2024-05-09 13:50:11,827:INFO:_master_model_container: 4
2024-05-09 13:50:11,827:INFO:_display_container: 2
2024-05-09 13:50:11,827:INFO:ElasticNet(random_state=777)
2024-05-09 13:50:11,827:INFO:create_model() successfully completed......................................
2024-05-09 13:50:11,914:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:11,914:INFO:Creating metrics dataframe
2024-05-09 13:50:11,920:INFO:Initializing Least Angle Regression
2024-05-09 13:50:11,920:INFO:Total runtime is 0.09170804818471272 minutes
2024-05-09 13:50:11,922:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:11,922:INFO:Initializing create_model()
2024-05-09 13:50:11,923:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:11,923:INFO:Checking exceptions
2024-05-09 13:50:11,923:INFO:Importing libraries
2024-05-09 13:50:11,923:INFO:Copying training dataset
2024-05-09 13:50:11,925:INFO:Defining folds
2024-05-09 13:50:11,925:INFO:Declaring metric variables
2024-05-09 13:50:11,927:INFO:Importing untrained model
2024-05-09 13:50:11,929:INFO:Least Angle Regression Imported successfully
2024-05-09 13:50:11,933:INFO:Starting cross validation
2024-05-09 13:50:11,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:11,994:INFO:Calculating mean and std
2024-05-09 13:50:11,994:INFO:Creating metrics dataframe
2024-05-09 13:50:11,996:INFO:Uploading results into container
2024-05-09 13:50:11,996:INFO:Uploading model into container now
2024-05-09 13:50:11,997:INFO:_master_model_container: 5
2024-05-09 13:50:11,997:INFO:_display_container: 2
2024-05-09 13:50:11,997:INFO:Lars(random_state=777)
2024-05-09 13:50:11,997:INFO:create_model() successfully completed......................................
2024-05-09 13:50:12,082:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:12,082:INFO:Creating metrics dataframe
2024-05-09 13:50:12,088:INFO:Initializing Lasso Least Angle Regression
2024-05-09 13:50:12,088:INFO:Total runtime is 0.0945015788078308 minutes
2024-05-09 13:50:12,090:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:12,090:INFO:Initializing create_model()
2024-05-09 13:50:12,090:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:12,090:INFO:Checking exceptions
2024-05-09 13:50:12,090:INFO:Importing libraries
2024-05-09 13:50:12,090:INFO:Copying training dataset
2024-05-09 13:50:12,092:INFO:Defining folds
2024-05-09 13:50:12,092:INFO:Declaring metric variables
2024-05-09 13:50:12,095:INFO:Importing untrained model
2024-05-09 13:50:12,097:INFO:Lasso Least Angle Regression Imported successfully
2024-05-09 13:50:12,100:INFO:Starting cross validation
2024-05-09 13:50:12,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:12,158:INFO:Calculating mean and std
2024-05-09 13:50:12,159:INFO:Creating metrics dataframe
2024-05-09 13:50:12,161:INFO:Uploading results into container
2024-05-09 13:50:12,162:INFO:Uploading model into container now
2024-05-09 13:50:12,162:INFO:_master_model_container: 6
2024-05-09 13:50:12,162:INFO:_display_container: 2
2024-05-09 13:50:12,162:INFO:LassoLars(random_state=777)
2024-05-09 13:50:12,162:INFO:create_model() successfully completed......................................
2024-05-09 13:50:12,254:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:12,254:INFO:Creating metrics dataframe
2024-05-09 13:50:12,260:INFO:Initializing Orthogonal Matching Pursuit
2024-05-09 13:50:12,260:INFO:Total runtime is 0.09736814498901367 minutes
2024-05-09 13:50:12,262:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:12,263:INFO:Initializing create_model()
2024-05-09 13:50:12,263:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:12,263:INFO:Checking exceptions
2024-05-09 13:50:12,263:INFO:Importing libraries
2024-05-09 13:50:12,263:INFO:Copying training dataset
2024-05-09 13:50:12,265:INFO:Defining folds
2024-05-09 13:50:12,265:INFO:Declaring metric variables
2024-05-09 13:50:12,268:INFO:Importing untrained model
2024-05-09 13:50:12,271:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-09 13:50:12,275:INFO:Starting cross validation
2024-05-09 13:50:12,275:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:12,326:INFO:Calculating mean and std
2024-05-09 13:50:12,326:INFO:Creating metrics dataframe
2024-05-09 13:50:12,328:INFO:Uploading results into container
2024-05-09 13:50:12,328:INFO:Uploading model into container now
2024-05-09 13:50:12,329:INFO:_master_model_container: 7
2024-05-09 13:50:12,329:INFO:_display_container: 2
2024-05-09 13:50:12,329:INFO:OrthogonalMatchingPursuit()
2024-05-09 13:50:12,329:INFO:create_model() successfully completed......................................
2024-05-09 13:50:12,411:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:12,411:INFO:Creating metrics dataframe
2024-05-09 13:50:12,417:INFO:Initializing Bayesian Ridge
2024-05-09 13:50:12,417:INFO:Total runtime is 0.0999952991803487 minutes
2024-05-09 13:50:12,419:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:12,420:INFO:Initializing create_model()
2024-05-09 13:50:12,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:12,420:INFO:Checking exceptions
2024-05-09 13:50:12,420:INFO:Importing libraries
2024-05-09 13:50:12,420:INFO:Copying training dataset
2024-05-09 13:50:12,422:INFO:Defining folds
2024-05-09 13:50:12,422:INFO:Declaring metric variables
2024-05-09 13:50:12,424:INFO:Importing untrained model
2024-05-09 13:50:12,427:INFO:Bayesian Ridge Imported successfully
2024-05-09 13:50:12,432:INFO:Starting cross validation
2024-05-09 13:50:12,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:12,489:INFO:Calculating mean and std
2024-05-09 13:50:12,489:INFO:Creating metrics dataframe
2024-05-09 13:50:12,491:INFO:Uploading results into container
2024-05-09 13:50:12,491:INFO:Uploading model into container now
2024-05-09 13:50:12,491:INFO:_master_model_container: 8
2024-05-09 13:50:12,491:INFO:_display_container: 2
2024-05-09 13:50:12,491:INFO:BayesianRidge()
2024-05-09 13:50:12,491:INFO:create_model() successfully completed......................................
2024-05-09 13:50:12,580:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:12,580:INFO:Creating metrics dataframe
2024-05-09 13:50:12,587:INFO:Initializing Passive Aggressive Regressor
2024-05-09 13:50:12,587:INFO:Total runtime is 0.10281496842702229 minutes
2024-05-09 13:50:12,589:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:12,589:INFO:Initializing create_model()
2024-05-09 13:50:12,589:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:12,589:INFO:Checking exceptions
2024-05-09 13:50:12,589:INFO:Importing libraries
2024-05-09 13:50:12,589:INFO:Copying training dataset
2024-05-09 13:50:12,592:INFO:Defining folds
2024-05-09 13:50:12,592:INFO:Declaring metric variables
2024-05-09 13:50:12,595:INFO:Importing untrained model
2024-05-09 13:50:12,597:INFO:Passive Aggressive Regressor Imported successfully
2024-05-09 13:50:12,603:INFO:Starting cross validation
2024-05-09 13:50:12,604:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:12,658:INFO:Calculating mean and std
2024-05-09 13:50:12,658:INFO:Creating metrics dataframe
2024-05-09 13:50:12,661:INFO:Uploading results into container
2024-05-09 13:50:12,661:INFO:Uploading model into container now
2024-05-09 13:50:12,662:INFO:_master_model_container: 9
2024-05-09 13:50:12,662:INFO:_display_container: 2
2024-05-09 13:50:12,662:INFO:PassiveAggressiveRegressor(random_state=777)
2024-05-09 13:50:12,662:INFO:create_model() successfully completed......................................
2024-05-09 13:50:12,750:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:12,750:INFO:Creating metrics dataframe
2024-05-09 13:50:12,756:INFO:Initializing Huber Regressor
2024-05-09 13:50:12,756:INFO:Total runtime is 0.10563512643178302 minutes
2024-05-09 13:50:12,758:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:12,758:INFO:Initializing create_model()
2024-05-09 13:50:12,758:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:12,758:INFO:Checking exceptions
2024-05-09 13:50:12,758:INFO:Importing libraries
2024-05-09 13:50:12,758:INFO:Copying training dataset
2024-05-09 13:50:12,760:INFO:Defining folds
2024-05-09 13:50:12,760:INFO:Declaring metric variables
2024-05-09 13:50:12,762:INFO:Importing untrained model
2024-05-09 13:50:12,764:INFO:Huber Regressor Imported successfully
2024-05-09 13:50:12,769:INFO:Starting cross validation
2024-05-09 13:50:12,769:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:12,829:INFO:Calculating mean and std
2024-05-09 13:50:12,830:INFO:Creating metrics dataframe
2024-05-09 13:50:12,831:INFO:Uploading results into container
2024-05-09 13:50:12,832:INFO:Uploading model into container now
2024-05-09 13:50:12,832:INFO:_master_model_container: 10
2024-05-09 13:50:12,832:INFO:_display_container: 2
2024-05-09 13:50:12,832:INFO:HuberRegressor()
2024-05-09 13:50:12,832:INFO:create_model() successfully completed......................................
2024-05-09 13:50:12,916:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:12,916:INFO:Creating metrics dataframe
2024-05-09 13:50:12,922:INFO:Initializing K Neighbors Regressor
2024-05-09 13:50:12,922:INFO:Total runtime is 0.10840521256128945 minutes
2024-05-09 13:50:12,924:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:12,924:INFO:Initializing create_model()
2024-05-09 13:50:12,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:12,924:INFO:Checking exceptions
2024-05-09 13:50:12,924:INFO:Importing libraries
2024-05-09 13:50:12,924:INFO:Copying training dataset
2024-05-09 13:50:12,926:INFO:Defining folds
2024-05-09 13:50:12,926:INFO:Declaring metric variables
2024-05-09 13:50:12,929:INFO:Importing untrained model
2024-05-09 13:50:12,931:INFO:K Neighbors Regressor Imported successfully
2024-05-09 13:50:12,935:INFO:Starting cross validation
2024-05-09 13:50:12,935:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:12,999:INFO:Calculating mean and std
2024-05-09 13:50:12,999:INFO:Creating metrics dataframe
2024-05-09 13:50:13,001:INFO:Uploading results into container
2024-05-09 13:50:13,002:INFO:Uploading model into container now
2024-05-09 13:50:13,002:INFO:_master_model_container: 11
2024-05-09 13:50:13,002:INFO:_display_container: 2
2024-05-09 13:50:13,002:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-09 13:50:13,002:INFO:create_model() successfully completed......................................
2024-05-09 13:50:13,086:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:13,087:INFO:Creating metrics dataframe
2024-05-09 13:50:13,093:INFO:Initializing Decision Tree Regressor
2024-05-09 13:50:13,093:INFO:Total runtime is 0.11124802430470782 minutes
2024-05-09 13:50:13,094:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:13,095:INFO:Initializing create_model()
2024-05-09 13:50:13,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:13,095:INFO:Checking exceptions
2024-05-09 13:50:13,095:INFO:Importing libraries
2024-05-09 13:50:13,095:INFO:Copying training dataset
2024-05-09 13:50:13,097:INFO:Defining folds
2024-05-09 13:50:13,097:INFO:Declaring metric variables
2024-05-09 13:50:13,099:INFO:Importing untrained model
2024-05-09 13:50:13,101:INFO:Decision Tree Regressor Imported successfully
2024-05-09 13:50:13,105:INFO:Starting cross validation
2024-05-09 13:50:13,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:13,155:INFO:Calculating mean and std
2024-05-09 13:50:13,156:INFO:Creating metrics dataframe
2024-05-09 13:50:13,158:INFO:Uploading results into container
2024-05-09 13:50:13,158:INFO:Uploading model into container now
2024-05-09 13:50:13,158:INFO:_master_model_container: 12
2024-05-09 13:50:13,158:INFO:_display_container: 2
2024-05-09 13:50:13,159:INFO:DecisionTreeRegressor(random_state=777)
2024-05-09 13:50:13,159:INFO:create_model() successfully completed......................................
2024-05-09 13:50:13,247:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:13,247:INFO:Creating metrics dataframe
2024-05-09 13:50:13,254:INFO:Initializing Random Forest Regressor
2024-05-09 13:50:13,254:INFO:Total runtime is 0.11393253405888873 minutes
2024-05-09 13:50:13,256:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:13,256:INFO:Initializing create_model()
2024-05-09 13:50:13,256:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:13,256:INFO:Checking exceptions
2024-05-09 13:50:13,256:INFO:Importing libraries
2024-05-09 13:50:13,256:INFO:Copying training dataset
2024-05-09 13:50:13,258:INFO:Defining folds
2024-05-09 13:50:13,258:INFO:Declaring metric variables
2024-05-09 13:50:13,260:INFO:Importing untrained model
2024-05-09 13:50:13,262:INFO:Random Forest Regressor Imported successfully
2024-05-09 13:50:13,266:INFO:Starting cross validation
2024-05-09 13:50:13,266:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:13,500:INFO:Calculating mean and std
2024-05-09 13:50:13,501:INFO:Creating metrics dataframe
2024-05-09 13:50:13,505:INFO:Uploading results into container
2024-05-09 13:50:13,505:INFO:Uploading model into container now
2024-05-09 13:50:13,505:INFO:_master_model_container: 13
2024-05-09 13:50:13,505:INFO:_display_container: 2
2024-05-09 13:50:13,506:INFO:RandomForestRegressor(n_jobs=-1, random_state=777)
2024-05-09 13:50:13,506:INFO:create_model() successfully completed......................................
2024-05-09 13:50:13,580:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:13,580:INFO:Creating metrics dataframe
2024-05-09 13:50:13,586:INFO:Initializing Extra Trees Regressor
2024-05-09 13:50:13,586:INFO:Total runtime is 0.1194675286610921 minutes
2024-05-09 13:50:13,587:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:13,588:INFO:Initializing create_model()
2024-05-09 13:50:13,588:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:13,588:INFO:Checking exceptions
2024-05-09 13:50:13,588:INFO:Importing libraries
2024-05-09 13:50:13,588:INFO:Copying training dataset
2024-05-09 13:50:13,589:INFO:Defining folds
2024-05-09 13:50:13,589:INFO:Declaring metric variables
2024-05-09 13:50:13,591:INFO:Importing untrained model
2024-05-09 13:50:13,592:INFO:Extra Trees Regressor Imported successfully
2024-05-09 13:50:13,596:INFO:Starting cross validation
2024-05-09 13:50:13,596:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:13,779:INFO:Calculating mean and std
2024-05-09 13:50:13,780:INFO:Creating metrics dataframe
2024-05-09 13:50:13,782:INFO:Uploading results into container
2024-05-09 13:50:13,783:INFO:Uploading model into container now
2024-05-09 13:50:13,783:INFO:_master_model_container: 14
2024-05-09 13:50:13,783:INFO:_display_container: 2
2024-05-09 13:50:13,783:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=777)
2024-05-09 13:50:13,783:INFO:create_model() successfully completed......................................
2024-05-09 13:50:13,863:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:13,863:INFO:Creating metrics dataframe
2024-05-09 13:50:13,869:INFO:Initializing AdaBoost Regressor
2024-05-09 13:50:13,869:INFO:Total runtime is 0.1241879343986511 minutes
2024-05-09 13:50:13,871:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:13,871:INFO:Initializing create_model()
2024-05-09 13:50:13,871:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:13,871:INFO:Checking exceptions
2024-05-09 13:50:13,871:INFO:Importing libraries
2024-05-09 13:50:13,871:INFO:Copying training dataset
2024-05-09 13:50:13,873:INFO:Defining folds
2024-05-09 13:50:13,873:INFO:Declaring metric variables
2024-05-09 13:50:13,875:INFO:Importing untrained model
2024-05-09 13:50:13,877:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:50:13,881:INFO:Starting cross validation
2024-05-09 13:50:13,881:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:14,004:INFO:Calculating mean and std
2024-05-09 13:50:14,004:INFO:Creating metrics dataframe
2024-05-09 13:50:14,006:INFO:Uploading results into container
2024-05-09 13:50:14,007:INFO:Uploading model into container now
2024-05-09 13:50:14,007:INFO:_master_model_container: 15
2024-05-09 13:50:14,007:INFO:_display_container: 2
2024-05-09 13:50:14,007:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 13:50:14,007:INFO:create_model() successfully completed......................................
2024-05-09 13:50:14,090:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:14,090:INFO:Creating metrics dataframe
2024-05-09 13:50:14,096:INFO:Initializing Gradient Boosting Regressor
2024-05-09 13:50:14,096:INFO:Total runtime is 0.1279706001281738 minutes
2024-05-09 13:50:14,098:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:14,098:INFO:Initializing create_model()
2024-05-09 13:50:14,098:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:14,098:INFO:Checking exceptions
2024-05-09 13:50:14,098:INFO:Importing libraries
2024-05-09 13:50:14,098:INFO:Copying training dataset
2024-05-09 13:50:14,099:INFO:Defining folds
2024-05-09 13:50:14,099:INFO:Declaring metric variables
2024-05-09 13:50:14,101:INFO:Importing untrained model
2024-05-09 13:50:14,104:INFO:Gradient Boosting Regressor Imported successfully
2024-05-09 13:50:14,108:INFO:Starting cross validation
2024-05-09 13:50:14,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:14,246:INFO:Calculating mean and std
2024-05-09 13:50:14,246:INFO:Creating metrics dataframe
2024-05-09 13:50:14,248:INFO:Uploading results into container
2024-05-09 13:50:14,248:INFO:Uploading model into container now
2024-05-09 13:50:14,249:INFO:_master_model_container: 16
2024-05-09 13:50:14,249:INFO:_display_container: 2
2024-05-09 13:50:14,249:INFO:GradientBoostingRegressor(random_state=777)
2024-05-09 13:50:14,249:INFO:create_model() successfully completed......................................
2024-05-09 13:50:14,322:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:14,322:INFO:Creating metrics dataframe
2024-05-09 13:50:14,329:INFO:Initializing Light Gradient Boosting Machine
2024-05-09 13:50:14,329:INFO:Total runtime is 0.13184984922409054 minutes
2024-05-09 13:50:14,331:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:14,331:INFO:Initializing create_model()
2024-05-09 13:50:14,331:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:14,331:INFO:Checking exceptions
2024-05-09 13:50:14,331:INFO:Importing libraries
2024-05-09 13:50:14,331:INFO:Copying training dataset
2024-05-09 13:50:14,333:INFO:Defining folds
2024-05-09 13:50:14,333:INFO:Declaring metric variables
2024-05-09 13:50:14,335:INFO:Importing untrained model
2024-05-09 13:50:14,337:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-09 13:50:14,341:INFO:Starting cross validation
2024-05-09 13:50:14,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:14,835:INFO:Calculating mean and std
2024-05-09 13:50:14,836:INFO:Creating metrics dataframe
2024-05-09 13:50:14,839:INFO:Uploading results into container
2024-05-09 13:50:14,839:INFO:Uploading model into container now
2024-05-09 13:50:14,840:INFO:_master_model_container: 17
2024-05-09 13:50:14,840:INFO:_display_container: 2
2024-05-09 13:50:14,840:INFO:LGBMRegressor(n_jobs=-1, random_state=777)
2024-05-09 13:50:14,840:INFO:create_model() successfully completed......................................
2024-05-09 13:50:14,907:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:14,907:INFO:Creating metrics dataframe
2024-05-09 13:50:14,914:INFO:Initializing Dummy Regressor
2024-05-09 13:50:14,914:INFO:Total runtime is 0.14160076379776 minutes
2024-05-09 13:50:14,916:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:14,916:INFO:Initializing create_model()
2024-05-09 13:50:14,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x78669917cdf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:14,916:INFO:Checking exceptions
2024-05-09 13:50:14,916:INFO:Importing libraries
2024-05-09 13:50:14,916:INFO:Copying training dataset
2024-05-09 13:50:14,917:INFO:Defining folds
2024-05-09 13:50:14,917:INFO:Declaring metric variables
2024-05-09 13:50:14,919:INFO:Importing untrained model
2024-05-09 13:50:14,921:INFO:Dummy Regressor Imported successfully
2024-05-09 13:50:14,924:INFO:Starting cross validation
2024-05-09 13:50:14,925:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:14,974:INFO:Calculating mean and std
2024-05-09 13:50:14,974:INFO:Creating metrics dataframe
2024-05-09 13:50:14,976:INFO:Uploading results into container
2024-05-09 13:50:14,977:INFO:Uploading model into container now
2024-05-09 13:50:14,977:INFO:_master_model_container: 18
2024-05-09 13:50:14,977:INFO:_display_container: 2
2024-05-09 13:50:14,977:INFO:DummyRegressor()
2024-05-09 13:50:14,977:INFO:create_model() successfully completed......................................
2024-05-09 13:50:15,053:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:15,053:INFO:Creating metrics dataframe
2024-05-09 13:50:15,065:INFO:Initializing create_model()
2024-05-09 13:50:15,065:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=AdaBoostRegressor(random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:15,065:INFO:Checking exceptions
2024-05-09 13:50:15,066:INFO:Importing libraries
2024-05-09 13:50:15,066:INFO:Copying training dataset
2024-05-09 13:50:15,068:INFO:Defining folds
2024-05-09 13:50:15,068:INFO:Declaring metric variables
2024-05-09 13:50:15,068:INFO:Importing untrained model
2024-05-09 13:50:15,068:INFO:Declaring custom model
2024-05-09 13:50:15,069:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:50:15,069:INFO:Cross validation set to False
2024-05-09 13:50:15,070:INFO:Fitting Model
2024-05-09 13:50:15,123:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 13:50:15,123:INFO:create_model() successfully completed......................................
2024-05-09 13:50:15,219:INFO:_master_model_container: 18
2024-05-09 13:50:15,219:INFO:_display_container: 2
2024-05-09 13:50:15,219:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 13:50:15,219:INFO:compare_models() successfully completed......................................
2024-05-09 13:50:15,219:INFO:Initializing tune_model()
2024-05-09 13:50:15,219:INFO:tune_model(estimator=AdaBoostRegressor(random_state=777), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>)
2024-05-09 13:50:15,219:INFO:Checking exceptions
2024-05-09 13:50:15,229:INFO:Copying training dataset
2024-05-09 13:50:15,231:INFO:Checking base model
2024-05-09 13:50:15,231:INFO:Base model : AdaBoost Regressor
2024-05-09 13:50:15,234:INFO:Declaring metric variables
2024-05-09 13:50:15,237:INFO:Defining Hyperparameters
2024-05-09 13:50:15,324:INFO:Tuning with n_jobs=-1
2024-05-09 13:50:15,324:INFO:Initializing RandomizedSearchCV
2024-05-09 13:50:17,205:INFO:best_params: {'actual_estimator__n_estimators': 100, 'actual_estimator__loss': 'linear', 'actual_estimator__learning_rate': 0.05}
2024-05-09 13:50:17,205:INFO:Hyperparameter search completed
2024-05-09 13:50:17,206:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:17,206:INFO:Initializing create_model()
2024-05-09 13:50:17,206:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=AdaBoostRegressor(random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x786699bf81c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 100, 'loss': 'linear', 'learning_rate': 0.05})
2024-05-09 13:50:17,206:INFO:Checking exceptions
2024-05-09 13:50:17,206:INFO:Importing libraries
2024-05-09 13:50:17,206:INFO:Copying training dataset
2024-05-09 13:50:17,208:INFO:Defining folds
2024-05-09 13:50:17,208:INFO:Declaring metric variables
2024-05-09 13:50:17,211:INFO:Importing untrained model
2024-05-09 13:50:17,211:INFO:Declaring custom model
2024-05-09 13:50:17,213:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:50:17,219:INFO:Starting cross validation
2024-05-09 13:50:17,220:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:17,443:INFO:Calculating mean and std
2024-05-09 13:50:17,444:INFO:Creating metrics dataframe
2024-05-09 13:50:17,450:INFO:Finalizing model
2024-05-09 13:50:17,549:INFO:Uploading results into container
2024-05-09 13:50:17,550:INFO:Uploading model into container now
2024-05-09 13:50:17,550:INFO:_master_model_container: 19
2024-05-09 13:50:17,550:INFO:_display_container: 3
2024-05-09 13:50:17,551:INFO:AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777)
2024-05-09 13:50:17,551:INFO:create_model() successfully completed......................................
2024-05-09 13:50:17,662:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:17,662:INFO:choose_better activated
2024-05-09 13:50:17,665:INFO:SubProcess create_model() called ==================================
2024-05-09 13:50:17,665:INFO:Initializing create_model()
2024-05-09 13:50:17,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=AdaBoostRegressor(random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:17,665:INFO:Checking exceptions
2024-05-09 13:50:17,666:INFO:Importing libraries
2024-05-09 13:50:17,666:INFO:Copying training dataset
2024-05-09 13:50:17,668:INFO:Defining folds
2024-05-09 13:50:17,668:INFO:Declaring metric variables
2024-05-09 13:50:17,668:INFO:Importing untrained model
2024-05-09 13:50:17,668:INFO:Declaring custom model
2024-05-09 13:50:17,669:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:50:17,669:INFO:Starting cross validation
2024-05-09 13:50:17,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 13:50:17,784:INFO:Calculating mean and std
2024-05-09 13:50:17,784:INFO:Creating metrics dataframe
2024-05-09 13:50:17,786:INFO:Finalizing model
2024-05-09 13:50:17,828:INFO:Uploading results into container
2024-05-09 13:50:17,828:INFO:Uploading model into container now
2024-05-09 13:50:17,828:INFO:_master_model_container: 20
2024-05-09 13:50:17,828:INFO:_display_container: 4
2024-05-09 13:50:17,829:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 13:50:17,829:INFO:create_model() successfully completed......................................
2024-05-09 13:50:17,896:INFO:SubProcess create_model() end ==================================
2024-05-09 13:50:17,897:INFO:AdaBoostRegressor(random_state=777) result for R2 is 0.6348
2024-05-09 13:50:17,897:INFO:AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777) result for R2 is 0.6349
2024-05-09 13:50:17,897:INFO:AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777) is best model
2024-05-09 13:50:17,897:INFO:choose_better completed
2024-05-09 13:50:17,902:INFO:_master_model_container: 20
2024-05-09 13:50:17,902:INFO:_display_container: 3
2024-05-09 13:50:17,902:INFO:AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777)
2024-05-09 13:50:17,902:INFO:tune_model() successfully completed......................................
2024-05-09 13:50:17,997:INFO:Initializing finalize_model()
2024-05-09 13:50:17,997:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-09 13:50:17,997:INFO:Finalizing AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777)
2024-05-09 13:50:17,998:INFO:Initializing create_model()
2024-05-09 13:50:17,998:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=AdaBoostRegressor(learning_rate=0.05, n_estimators=100, random_state=777), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 13:50:17,998:INFO:Checking exceptions
2024-05-09 13:50:17,999:INFO:Importing libraries
2024-05-09 13:50:17,999:INFO:Copying training dataset
2024-05-09 13:50:18,000:INFO:Defining folds
2024-05-09 13:50:18,000:INFO:Declaring metric variables
2024-05-09 13:50:18,000:INFO:Importing untrained model
2024-05-09 13:50:18,000:INFO:Declaring custom model
2024-05-09 13:50:18,000:INFO:AdaBoost Regressor Imported successfully
2024-05-09 13:50:18,000:INFO:Cross validation set to False
2024-05-09 13:50:18,000:INFO:Fitting Model
2024-05-09 13:50:18,096:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 AdaBoostRegressor(learning_rate=0.05, n_estimators=100,
                                   random_state=777))])
2024-05-09 13:50:18,096:INFO:create_model() successfully completed......................................
2024-05-09 13:50:18,185:INFO:_master_model_container: 20
2024-05-09 13:50:18,185:INFO:_display_container: 3
2024-05-09 13:50:18,189:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 AdaBoostRegressor(learning_rate=0.05, n_estimators=100,
                                   random_state=777))])
2024-05-09 13:50:18,189:INFO:finalize_model() successfully completed......................................
2024-05-09 13:50:18,323:INFO:Initializing predict_model()
2024-05-09 13:50:18,323:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0f09dc0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 AdaBoostRegressor(learning_rate=0.05, n_estimators=100,
                                   random_state=777))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7866999f1790>)
2024-05-09 13:50:18,323:INFO:Checking exceptions
2024-05-09 13:50:18,323:INFO:Preloading libraries
2024-05-09 13:50:18,324:INFO:Set up data.
2024-05-09 13:50:18,327:INFO:Set up index.
2024-05-09 13:50:18,343:WARNING:/home/nhnacademy/anaconda3/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-09 14:40:42,098:WARNING:/tmp/ipykernel_14873/2262976735.py:6: FutureWarning: DataFrame.mean and DataFrame.median with numeric_only=None will include datetime64 and datetime64tz columns in a future version.
  merged_data.fillna(merged_data.median(), inplace=True)

2024-05-09 14:40:42,108:INFO:PyCaret RegressionExperiment
2024-05-09 14:40:42,108:INFO:Logging name: reg-default-name
2024-05-09 14:40:42,108:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-09 14:40:42,108:INFO:version 3.3.2
2024-05-09 14:40:42,108:INFO:Initializing setup()
2024-05-09 14:40:42,108:INFO:self.USI: 154b
2024-05-09 14:40:42,108:INFO:self._variable_keys: {'y', '_ml_usecase', 'exp_name_log', 'gpu_n_jobs_param', 'n_jobs_param', 'data', 'log_plots_param', 'seed', 'USI', 'exp_id', 'X', 'target_param', 'y_test', 'gpu_param', '_available_plots', 'html_param', 'X_test', 'fold_shuffle_param', 'idx', 'fold_groups_param', 'transform_target_param', 'logging_param', 'memory', 'pipeline', 'fold_generator', 'X_train', 'y_train'}
2024-05-09 14:40:42,108:INFO:Checking environment
2024-05-09 14:40:42,108:INFO:python_version: 3.9.18
2024-05-09 14:40:42,108:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-09 14:40:42,108:INFO:machine: x86_64
2024-05-09 14:40:42,108:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 14:40:42,108:INFO:Memory: svmem(total=16429789184, available=5815193600, percent=64.6, used=9178066944, free=2246971392, active=7990644736, inactive=4775731200, buffers=95264768, cached=4909486080, shared=1089961984, slab=605499392)
2024-05-09 14:40:42,109:INFO:Physical Core: 12
2024-05-09 14:40:42,109:INFO:Logical Core: 16
2024-05-09 14:40:42,109:INFO:Checking libraries
2024-05-09 14:40:42,109:INFO:System:
2024-05-09 14:40:42,109:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-09 14:40:42,109:INFO:executable: /home/nhnacademy/anaconda3/bin/python
2024-05-09 14:40:42,109:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-09 14:40:42,109:INFO:PyCaret required dependencies:
2024-05-09 14:40:42,109:INFO:                 pip: 23.2.1
2024-05-09 14:40:42,109:INFO:          setuptools: 68.0.0
2024-05-09 14:40:42,109:INFO:             pycaret: 3.3.2
2024-05-09 14:40:42,110:INFO:             IPython: 8.15.0
2024-05-09 14:40:42,110:INFO:          ipywidgets: 8.0.4
2024-05-09 14:40:42,110:INFO:                tqdm: 4.65.0
2024-05-09 14:40:42,110:INFO:               numpy: 1.24.3
2024-05-09 14:40:42,110:INFO:              pandas: 1.4.2
2024-05-09 14:40:42,110:INFO:              jinja2: 3.1.4
2024-05-09 14:40:42,110:INFO:               scipy: 1.11.3
2024-05-09 14:40:42,110:INFO:              joblib: 1.2.0
2024-05-09 14:40:42,110:INFO:             sklearn: 1.4.2
2024-05-09 14:40:42,110:INFO:                pyod: 1.1.3
2024-05-09 14:40:42,110:INFO:            imblearn: 0.12.2
2024-05-09 14:40:42,110:INFO:   category_encoders: 2.6.3
2024-05-09 14:40:42,110:INFO:            lightgbm: 4.3.0
2024-05-09 14:40:42,110:INFO:               numba: 0.58.0
2024-05-09 14:40:42,110:INFO:            requests: 2.31.0
2024-05-09 14:40:42,110:INFO:          matplotlib: 3.7.2
2024-05-09 14:40:42,110:INFO:          scikitplot: 0.3.7
2024-05-09 14:40:42,110:INFO:         yellowbrick: 1.5
2024-05-09 14:40:42,110:INFO:              plotly: 5.22.0
2024-05-09 14:40:42,110:INFO:    plotly-resampler: Not installed
2024-05-09 14:40:42,110:INFO:             kaleido: 0.2.1
2024-05-09 14:40:42,110:INFO:           schemdraw: 0.15
2024-05-09 14:40:42,110:INFO:         statsmodels: 0.14.0
2024-05-09 14:40:42,110:INFO:              sktime: 0.26.0
2024-05-09 14:40:42,110:INFO:               tbats: 1.1.3
2024-05-09 14:40:42,110:INFO:            pmdarima: 2.0.4
2024-05-09 14:40:42,110:INFO:              psutil: 5.9.0
2024-05-09 14:40:42,110:INFO:          markupsafe: 2.0.1
2024-05-09 14:40:42,110:INFO:             pickle5: Not installed
2024-05-09 14:40:42,110:INFO:         cloudpickle: 2.2.1
2024-05-09 14:40:42,110:INFO:         deprecation: 2.1.0
2024-05-09 14:40:42,110:INFO:              xxhash: 2.0.2
2024-05-09 14:40:42,110:INFO:           wurlitzer: 3.0.2
2024-05-09 14:40:42,110:INFO:PyCaret optional dependencies:
2024-05-09 14:40:42,110:INFO:                shap: Not installed
2024-05-09 14:40:42,110:INFO:           interpret: Not installed
2024-05-09 14:40:42,110:INFO:                umap: Not installed
2024-05-09 14:40:42,110:INFO:     ydata_profiling: Not installed
2024-05-09 14:40:42,110:INFO:  explainerdashboard: Not installed
2024-05-09 14:40:42,110:INFO:             autoviz: Not installed
2024-05-09 14:40:42,110:INFO:           fairlearn: Not installed
2024-05-09 14:40:42,110:INFO:          deepchecks: Not installed
2024-05-09 14:40:42,110:INFO:             xgboost: Not installed
2024-05-09 14:40:42,110:INFO:            catboost: Not installed
2024-05-09 14:40:42,111:INFO:              kmodes: Not installed
2024-05-09 14:40:42,111:INFO:             mlxtend: Not installed
2024-05-09 14:40:42,111:INFO:       statsforecast: Not installed
2024-05-09 14:40:42,111:INFO:        tune_sklearn: Not installed
2024-05-09 14:40:42,111:INFO:                 ray: Not installed
2024-05-09 14:40:42,111:INFO:            hyperopt: Not installed
2024-05-09 14:40:42,111:INFO:              optuna: Not installed
2024-05-09 14:40:42,111:INFO:               skopt: Not installed
2024-05-09 14:40:42,111:INFO:              mlflow: Not installed
2024-05-09 14:40:42,111:INFO:              gradio: Not installed
2024-05-09 14:40:42,111:INFO:             fastapi: Not installed
2024-05-09 14:40:42,111:INFO:             uvicorn: Not installed
2024-05-09 14:40:42,111:INFO:              m2cgen: Not installed
2024-05-09 14:40:42,111:INFO:           evidently: Not installed
2024-05-09 14:40:42,111:INFO:               fugue: Not installed
2024-05-09 14:40:42,111:INFO:           streamlit: Not installed
2024-05-09 14:40:42,111:INFO:             prophet: Not installed
2024-05-09 14:40:42,111:INFO:None
2024-05-09 14:40:42,111:INFO:Set up data.
2024-05-09 14:40:42,114:INFO:Set up folding strategy.
2024-05-09 14:40:42,114:INFO:Set up train/test split.
2024-05-09 14:40:42,116:INFO:Set up index.
2024-05-09 14:40:42,116:INFO:Assigning column types.
2024-05-09 14:40:42,118:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-09 14:40:42,118:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,120:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,122:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,149:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,171:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,171:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,171:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,171:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,173:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,175:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,203:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,224:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-09 14:40:42,227:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,229:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,256:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,277:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,280:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,282:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,330:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,331:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-09 14:40:42,335:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,362:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,384:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,389:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,438:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,438:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,438:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,438:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-09 14:40:42,470:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,523:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,545:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-09 14:40:42,576:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,598:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,629:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-09 14:40:42,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,651:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-09 14:40:42,704:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,704:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,757:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,760:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,760:INFO:Preparing preprocessing pipeline...
2024-05-09 14:40:42,760:INFO:Set up date feature engineering.
2024-05-09 14:40:42,760:INFO:Set up simple imputation.
2024-05-09 14:40:42,760:INFO:Set up feature normalization.
2024-05-09 14:40:42,761:INFO:Set up column name cleaning.
2024-05-09 14:40:42,779:INFO:Finished creating preprocessing pipeline.
2024-05-09 14:40:42,782:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-09 14:40:42,782:INFO:Creating final display dataframe.
2024-05-09 14:40:42,841:INFO:Setup _display_container:                     Description             Value
0                    Session id               777
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (576, 5)
4        Transformed data shape          (576, 7)
5   Transformed train set shape          (403, 7)
6    Transformed test set shape          (173, 7)
7              Numeric features                 3
8                 Date features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13                    Normalize              True
14             Normalize method            minmax
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              154b
2024-05-09 14:40:42,899:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,899:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,955:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,956:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-09 14:40:42,956:INFO:setup() successfully completed in 0.85s...............
2024-05-09 14:40:42,957:INFO:Initializing compare_models()
2024-05-09 14:40:42,957:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-09 14:40:42,957:INFO:Checking exceptions
2024-05-09 14:40:42,958:INFO:Preparing display monitor
2024-05-09 14:40:42,974:INFO:Initializing Linear Regression
2024-05-09 14:40:42,974:INFO:Total runtime is 1.8239021301269532e-06 minutes
2024-05-09 14:40:42,977:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:42,977:INFO:Initializing create_model()
2024-05-09 14:40:42,977:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:42,977:INFO:Checking exceptions
2024-05-09 14:40:42,977:INFO:Importing libraries
2024-05-09 14:40:42,977:INFO:Copying training dataset
2024-05-09 14:40:42,980:INFO:Defining folds
2024-05-09 14:40:42,981:INFO:Declaring metric variables
2024-05-09 14:40:42,983:INFO:Importing untrained model
2024-05-09 14:40:42,985:INFO:Linear Regression Imported successfully
2024-05-09 14:40:42,991:INFO:Starting cross validation
2024-05-09 14:40:42,992:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:45,561:INFO:Calculating mean and std
2024-05-09 14:40:45,563:INFO:Creating metrics dataframe
2024-05-09 14:40:45,566:INFO:Uploading results into container
2024-05-09 14:40:45,567:INFO:Uploading model into container now
2024-05-09 14:40:45,567:INFO:_master_model_container: 1
2024-05-09 14:40:45,567:INFO:_display_container: 2
2024-05-09 14:40:45,567:INFO:LinearRegression(n_jobs=-1)
2024-05-09 14:40:45,567:INFO:create_model() successfully completed......................................
2024-05-09 14:40:45,657:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:45,657:INFO:Creating metrics dataframe
2024-05-09 14:40:45,662:INFO:Initializing Lasso Regression
2024-05-09 14:40:45,662:INFO:Total runtime is 0.04480291604995727 minutes
2024-05-09 14:40:45,664:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:45,664:INFO:Initializing create_model()
2024-05-09 14:40:45,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:45,664:INFO:Checking exceptions
2024-05-09 14:40:45,664:INFO:Importing libraries
2024-05-09 14:40:45,664:INFO:Copying training dataset
2024-05-09 14:40:45,667:INFO:Defining folds
2024-05-09 14:40:45,667:INFO:Declaring metric variables
2024-05-09 14:40:45,669:INFO:Importing untrained model
2024-05-09 14:40:45,671:INFO:Lasso Regression Imported successfully
2024-05-09 14:40:45,675:INFO:Starting cross validation
2024-05-09 14:40:45,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:47,460:INFO:Calculating mean and std
2024-05-09 14:40:47,460:INFO:Creating metrics dataframe
2024-05-09 14:40:47,462:INFO:Uploading results into container
2024-05-09 14:40:47,463:INFO:Uploading model into container now
2024-05-09 14:40:47,463:INFO:_master_model_container: 2
2024-05-09 14:40:47,463:INFO:_display_container: 2
2024-05-09 14:40:47,464:INFO:Lasso(random_state=777)
2024-05-09 14:40:47,464:INFO:create_model() successfully completed......................................
2024-05-09 14:40:47,541:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:47,541:INFO:Creating metrics dataframe
2024-05-09 14:40:47,546:INFO:Initializing Ridge Regression
2024-05-09 14:40:47,546:INFO:Total runtime is 0.07620064814885458 minutes
2024-05-09 14:40:47,548:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:47,548:INFO:Initializing create_model()
2024-05-09 14:40:47,548:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:47,548:INFO:Checking exceptions
2024-05-09 14:40:47,548:INFO:Importing libraries
2024-05-09 14:40:47,548:INFO:Copying training dataset
2024-05-09 14:40:47,550:INFO:Defining folds
2024-05-09 14:40:47,550:INFO:Declaring metric variables
2024-05-09 14:40:47,552:INFO:Importing untrained model
2024-05-09 14:40:47,554:INFO:Ridge Regression Imported successfully
2024-05-09 14:40:47,558:INFO:Starting cross validation
2024-05-09 14:40:47,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:47,628:INFO:Calculating mean and std
2024-05-09 14:40:47,629:INFO:Creating metrics dataframe
2024-05-09 14:40:47,631:INFO:Uploading results into container
2024-05-09 14:40:47,631:INFO:Uploading model into container now
2024-05-09 14:40:47,632:INFO:_master_model_container: 3
2024-05-09 14:40:47,632:INFO:_display_container: 2
2024-05-09 14:40:47,632:INFO:Ridge(random_state=777)
2024-05-09 14:40:47,632:INFO:create_model() successfully completed......................................
2024-05-09 14:40:47,709:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:47,709:INFO:Creating metrics dataframe
2024-05-09 14:40:47,714:INFO:Initializing Elastic Net
2024-05-09 14:40:47,714:INFO:Total runtime is 0.079012135664622 minutes
2024-05-09 14:40:47,716:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:47,716:INFO:Initializing create_model()
2024-05-09 14:40:47,716:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:47,717:INFO:Checking exceptions
2024-05-09 14:40:47,717:INFO:Importing libraries
2024-05-09 14:40:47,717:INFO:Copying training dataset
2024-05-09 14:40:47,721:INFO:Defining folds
2024-05-09 14:40:47,721:INFO:Declaring metric variables
2024-05-09 14:40:47,723:INFO:Importing untrained model
2024-05-09 14:40:47,725:INFO:Elastic Net Imported successfully
2024-05-09 14:40:47,728:INFO:Starting cross validation
2024-05-09 14:40:47,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:47,801:INFO:Calculating mean and std
2024-05-09 14:40:47,801:INFO:Creating metrics dataframe
2024-05-09 14:40:47,803:INFO:Uploading results into container
2024-05-09 14:40:47,804:INFO:Uploading model into container now
2024-05-09 14:40:47,804:INFO:_master_model_container: 4
2024-05-09 14:40:47,804:INFO:_display_container: 2
2024-05-09 14:40:47,804:INFO:ElasticNet(random_state=777)
2024-05-09 14:40:47,804:INFO:create_model() successfully completed......................................
2024-05-09 14:40:47,885:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:47,885:INFO:Creating metrics dataframe
2024-05-09 14:40:47,890:INFO:Initializing Least Angle Regression
2024-05-09 14:40:47,890:INFO:Total runtime is 0.081942884127299 minutes
2024-05-09 14:40:47,892:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:47,892:INFO:Initializing create_model()
2024-05-09 14:40:47,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:47,892:INFO:Checking exceptions
2024-05-09 14:40:47,892:INFO:Importing libraries
2024-05-09 14:40:47,892:INFO:Copying training dataset
2024-05-09 14:40:47,894:INFO:Defining folds
2024-05-09 14:40:47,894:INFO:Declaring metric variables
2024-05-09 14:40:47,896:INFO:Importing untrained model
2024-05-09 14:40:47,898:INFO:Least Angle Regression Imported successfully
2024-05-09 14:40:47,901:INFO:Starting cross validation
2024-05-09 14:40:47,901:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:47,985:INFO:Calculating mean and std
2024-05-09 14:40:47,985:INFO:Creating metrics dataframe
2024-05-09 14:40:47,987:INFO:Uploading results into container
2024-05-09 14:40:47,988:INFO:Uploading model into container now
2024-05-09 14:40:47,988:INFO:_master_model_container: 5
2024-05-09 14:40:47,988:INFO:_display_container: 2
2024-05-09 14:40:47,988:INFO:Lars(random_state=777)
2024-05-09 14:40:47,988:INFO:create_model() successfully completed......................................
2024-05-09 14:40:48,069:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:48,069:INFO:Creating metrics dataframe
2024-05-09 14:40:48,075:INFO:Initializing Lasso Least Angle Regression
2024-05-09 14:40:48,078:INFO:Total runtime is 0.08507107098897299 minutes
2024-05-09 14:40:48,080:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:48,080:INFO:Initializing create_model()
2024-05-09 14:40:48,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:48,080:INFO:Checking exceptions
2024-05-09 14:40:48,080:INFO:Importing libraries
2024-05-09 14:40:48,080:INFO:Copying training dataset
2024-05-09 14:40:48,082:INFO:Defining folds
2024-05-09 14:40:48,082:INFO:Declaring metric variables
2024-05-09 14:40:48,084:INFO:Importing untrained model
2024-05-09 14:40:48,085:INFO:Lasso Least Angle Regression Imported successfully
2024-05-09 14:40:48,089:INFO:Starting cross validation
2024-05-09 14:40:48,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:48,184:INFO:Calculating mean and std
2024-05-09 14:40:48,185:INFO:Creating metrics dataframe
2024-05-09 14:40:48,187:INFO:Uploading results into container
2024-05-09 14:40:48,188:INFO:Uploading model into container now
2024-05-09 14:40:48,188:INFO:_master_model_container: 6
2024-05-09 14:40:48,188:INFO:_display_container: 2
2024-05-09 14:40:48,188:INFO:LassoLars(random_state=777)
2024-05-09 14:40:48,188:INFO:create_model() successfully completed......................................
2024-05-09 14:40:48,271:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:48,271:INFO:Creating metrics dataframe
2024-05-09 14:40:48,277:INFO:Initializing Orthogonal Matching Pursuit
2024-05-09 14:40:48,277:INFO:Total runtime is 0.08839210669199626 minutes
2024-05-09 14:40:48,279:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:48,280:INFO:Initializing create_model()
2024-05-09 14:40:48,280:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:48,280:INFO:Checking exceptions
2024-05-09 14:40:48,280:INFO:Importing libraries
2024-05-09 14:40:48,280:INFO:Copying training dataset
2024-05-09 14:40:48,282:INFO:Defining folds
2024-05-09 14:40:48,282:INFO:Declaring metric variables
2024-05-09 14:40:48,285:INFO:Importing untrained model
2024-05-09 14:40:48,288:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-09 14:40:48,294:INFO:Starting cross validation
2024-05-09 14:40:48,294:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:48,379:INFO:Calculating mean and std
2024-05-09 14:40:48,380:INFO:Creating metrics dataframe
2024-05-09 14:40:48,384:INFO:Uploading results into container
2024-05-09 14:40:48,384:INFO:Uploading model into container now
2024-05-09 14:40:48,385:INFO:_master_model_container: 7
2024-05-09 14:40:48,385:INFO:_display_container: 2
2024-05-09 14:40:48,385:INFO:OrthogonalMatchingPursuit()
2024-05-09 14:40:48,385:INFO:create_model() successfully completed......................................
2024-05-09 14:40:48,477:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:48,477:INFO:Creating metrics dataframe
2024-05-09 14:40:48,483:INFO:Initializing Bayesian Ridge
2024-05-09 14:40:48,483:INFO:Total runtime is 0.09182831843694052 minutes
2024-05-09 14:40:48,486:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:48,486:INFO:Initializing create_model()
2024-05-09 14:40:48,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:48,486:INFO:Checking exceptions
2024-05-09 14:40:48,486:INFO:Importing libraries
2024-05-09 14:40:48,486:INFO:Copying training dataset
2024-05-09 14:40:48,489:INFO:Defining folds
2024-05-09 14:40:48,489:INFO:Declaring metric variables
2024-05-09 14:40:48,491:INFO:Importing untrained model
2024-05-09 14:40:48,494:INFO:Bayesian Ridge Imported successfully
2024-05-09 14:40:48,498:INFO:Starting cross validation
2024-05-09 14:40:48,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:48,591:INFO:Calculating mean and std
2024-05-09 14:40:48,592:INFO:Creating metrics dataframe
2024-05-09 14:40:48,595:INFO:Uploading results into container
2024-05-09 14:40:48,595:INFO:Uploading model into container now
2024-05-09 14:40:48,595:INFO:_master_model_container: 8
2024-05-09 14:40:48,595:INFO:_display_container: 2
2024-05-09 14:40:48,596:INFO:BayesianRidge()
2024-05-09 14:40:48,596:INFO:create_model() successfully completed......................................
2024-05-09 14:40:48,683:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:48,684:INFO:Creating metrics dataframe
2024-05-09 14:40:48,690:INFO:Initializing Passive Aggressive Regressor
2024-05-09 14:40:48,690:INFO:Total runtime is 0.095273756980896 minutes
2024-05-09 14:40:48,693:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:48,693:INFO:Initializing create_model()
2024-05-09 14:40:48,693:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:48,693:INFO:Checking exceptions
2024-05-09 14:40:48,693:INFO:Importing libraries
2024-05-09 14:40:48,693:INFO:Copying training dataset
2024-05-09 14:40:48,696:INFO:Defining folds
2024-05-09 14:40:48,696:INFO:Declaring metric variables
2024-05-09 14:40:48,698:INFO:Importing untrained model
2024-05-09 14:40:48,700:INFO:Passive Aggressive Regressor Imported successfully
2024-05-09 14:40:48,706:INFO:Starting cross validation
2024-05-09 14:40:48,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:48,797:INFO:Calculating mean and std
2024-05-09 14:40:48,798:INFO:Creating metrics dataframe
2024-05-09 14:40:48,801:INFO:Uploading results into container
2024-05-09 14:40:48,801:INFO:Uploading model into container now
2024-05-09 14:40:48,802:INFO:_master_model_container: 9
2024-05-09 14:40:48,802:INFO:_display_container: 2
2024-05-09 14:40:48,802:INFO:PassiveAggressiveRegressor(random_state=777)
2024-05-09 14:40:48,802:INFO:create_model() successfully completed......................................
2024-05-09 14:40:48,881:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:48,881:INFO:Creating metrics dataframe
2024-05-09 14:40:48,886:INFO:Initializing Huber Regressor
2024-05-09 14:40:48,886:INFO:Total runtime is 0.09853966633478801 minutes
2024-05-09 14:40:48,888:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:48,888:INFO:Initializing create_model()
2024-05-09 14:40:48,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:48,888:INFO:Checking exceptions
2024-05-09 14:40:48,888:INFO:Importing libraries
2024-05-09 14:40:48,888:INFO:Copying training dataset
2024-05-09 14:40:48,890:INFO:Defining folds
2024-05-09 14:40:48,890:INFO:Declaring metric variables
2024-05-09 14:40:48,892:INFO:Importing untrained model
2024-05-09 14:40:48,895:INFO:Huber Regressor Imported successfully
2024-05-09 14:40:48,898:INFO:Starting cross validation
2024-05-09 14:40:48,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:48,988:INFO:Calculating mean and std
2024-05-09 14:40:48,988:INFO:Creating metrics dataframe
2024-05-09 14:40:48,991:INFO:Uploading results into container
2024-05-09 14:40:48,991:INFO:Uploading model into container now
2024-05-09 14:40:48,991:INFO:_master_model_container: 10
2024-05-09 14:40:48,991:INFO:_display_container: 2
2024-05-09 14:40:48,992:INFO:HuberRegressor()
2024-05-09 14:40:48,992:INFO:create_model() successfully completed......................................
2024-05-09 14:40:49,072:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:49,072:INFO:Creating metrics dataframe
2024-05-09 14:40:49,081:INFO:Initializing K Neighbors Regressor
2024-05-09 14:40:49,082:INFO:Total runtime is 0.10180095036824545 minutes
2024-05-09 14:40:49,085:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:49,085:INFO:Initializing create_model()
2024-05-09 14:40:49,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:49,085:INFO:Checking exceptions
2024-05-09 14:40:49,085:INFO:Importing libraries
2024-05-09 14:40:49,085:INFO:Copying training dataset
2024-05-09 14:40:49,088:INFO:Defining folds
2024-05-09 14:40:49,088:INFO:Declaring metric variables
2024-05-09 14:40:49,090:INFO:Importing untrained model
2024-05-09 14:40:49,093:INFO:K Neighbors Regressor Imported successfully
2024-05-09 14:40:49,097:INFO:Starting cross validation
2024-05-09 14:40:49,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:49,191:INFO:Calculating mean and std
2024-05-09 14:40:49,192:INFO:Creating metrics dataframe
2024-05-09 14:40:49,194:INFO:Uploading results into container
2024-05-09 14:40:49,194:INFO:Uploading model into container now
2024-05-09 14:40:49,194:INFO:_master_model_container: 11
2024-05-09 14:40:49,195:INFO:_display_container: 2
2024-05-09 14:40:49,195:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-09 14:40:49,195:INFO:create_model() successfully completed......................................
2024-05-09 14:40:49,277:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:49,277:INFO:Creating metrics dataframe
2024-05-09 14:40:49,282:INFO:Initializing Decision Tree Regressor
2024-05-09 14:40:49,283:INFO:Total runtime is 0.10514832735061647 minutes
2024-05-09 14:40:49,284:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:49,284:INFO:Initializing create_model()
2024-05-09 14:40:49,284:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:49,284:INFO:Checking exceptions
2024-05-09 14:40:49,284:INFO:Importing libraries
2024-05-09 14:40:49,284:INFO:Copying training dataset
2024-05-09 14:40:49,286:INFO:Defining folds
2024-05-09 14:40:49,286:INFO:Declaring metric variables
2024-05-09 14:40:49,288:INFO:Importing untrained model
2024-05-09 14:40:49,290:INFO:Decision Tree Regressor Imported successfully
2024-05-09 14:40:49,294:INFO:Starting cross validation
2024-05-09 14:40:49,294:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:49,380:INFO:Calculating mean and std
2024-05-09 14:40:49,381:INFO:Creating metrics dataframe
2024-05-09 14:40:49,384:INFO:Uploading results into container
2024-05-09 14:40:49,384:INFO:Uploading model into container now
2024-05-09 14:40:49,385:INFO:_master_model_container: 12
2024-05-09 14:40:49,385:INFO:_display_container: 2
2024-05-09 14:40:49,385:INFO:DecisionTreeRegressor(random_state=777)
2024-05-09 14:40:49,385:INFO:create_model() successfully completed......................................
2024-05-09 14:40:49,467:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:49,467:INFO:Creating metrics dataframe
2024-05-09 14:40:49,473:INFO:Initializing Random Forest Regressor
2024-05-09 14:40:49,473:INFO:Total runtime is 0.1083168109258016 minutes
2024-05-09 14:40:49,474:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:49,475:INFO:Initializing create_model()
2024-05-09 14:40:49,475:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:49,475:INFO:Checking exceptions
2024-05-09 14:40:49,475:INFO:Importing libraries
2024-05-09 14:40:49,475:INFO:Copying training dataset
2024-05-09 14:40:49,477:INFO:Defining folds
2024-05-09 14:40:49,477:INFO:Declaring metric variables
2024-05-09 14:40:49,479:INFO:Importing untrained model
2024-05-09 14:40:49,480:INFO:Random Forest Regressor Imported successfully
2024-05-09 14:40:49,484:INFO:Starting cross validation
2024-05-09 14:40:49,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:49,762:INFO:Calculating mean and std
2024-05-09 14:40:49,763:INFO:Creating metrics dataframe
2024-05-09 14:40:49,766:INFO:Uploading results into container
2024-05-09 14:40:49,766:INFO:Uploading model into container now
2024-05-09 14:40:49,766:INFO:_master_model_container: 13
2024-05-09 14:40:49,766:INFO:_display_container: 2
2024-05-09 14:40:49,767:INFO:RandomForestRegressor(n_jobs=-1, random_state=777)
2024-05-09 14:40:49,767:INFO:create_model() successfully completed......................................
2024-05-09 14:40:49,835:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:49,835:INFO:Creating metrics dataframe
2024-05-09 14:40:49,841:INFO:Initializing Extra Trees Regressor
2024-05-09 14:40:49,841:INFO:Total runtime is 0.1144554098447164 minutes
2024-05-09 14:40:49,843:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:49,843:INFO:Initializing create_model()
2024-05-09 14:40:49,843:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:49,843:INFO:Checking exceptions
2024-05-09 14:40:49,843:INFO:Importing libraries
2024-05-09 14:40:49,843:INFO:Copying training dataset
2024-05-09 14:40:49,846:INFO:Defining folds
2024-05-09 14:40:49,847:INFO:Declaring metric variables
2024-05-09 14:40:49,849:INFO:Importing untrained model
2024-05-09 14:40:49,852:INFO:Extra Trees Regressor Imported successfully
2024-05-09 14:40:49,857:INFO:Starting cross validation
2024-05-09 14:40:49,857:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:50,070:INFO:Calculating mean and std
2024-05-09 14:40:50,070:INFO:Creating metrics dataframe
2024-05-09 14:40:50,072:INFO:Uploading results into container
2024-05-09 14:40:50,073:INFO:Uploading model into container now
2024-05-09 14:40:50,073:INFO:_master_model_container: 14
2024-05-09 14:40:50,073:INFO:_display_container: 2
2024-05-09 14:40:50,073:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=777)
2024-05-09 14:40:50,073:INFO:create_model() successfully completed......................................
2024-05-09 14:40:50,148:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:50,148:INFO:Creating metrics dataframe
2024-05-09 14:40:50,154:INFO:Initializing AdaBoost Regressor
2024-05-09 14:40:50,154:INFO:Total runtime is 0.11968022982279461 minutes
2024-05-09 14:40:50,156:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:50,156:INFO:Initializing create_model()
2024-05-09 14:40:50,156:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:50,156:INFO:Checking exceptions
2024-05-09 14:40:50,156:INFO:Importing libraries
2024-05-09 14:40:50,156:INFO:Copying training dataset
2024-05-09 14:40:50,158:INFO:Defining folds
2024-05-09 14:40:50,159:INFO:Declaring metric variables
2024-05-09 14:40:50,160:INFO:Importing untrained model
2024-05-09 14:40:50,162:INFO:AdaBoost Regressor Imported successfully
2024-05-09 14:40:50,165:INFO:Starting cross validation
2024-05-09 14:40:50,166:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:50,294:INFO:Calculating mean and std
2024-05-09 14:40:50,295:INFO:Creating metrics dataframe
2024-05-09 14:40:50,297:INFO:Uploading results into container
2024-05-09 14:40:50,297:INFO:Uploading model into container now
2024-05-09 14:40:50,298:INFO:_master_model_container: 15
2024-05-09 14:40:50,298:INFO:_display_container: 2
2024-05-09 14:40:50,298:INFO:AdaBoostRegressor(random_state=777)
2024-05-09 14:40:50,298:INFO:create_model() successfully completed......................................
2024-05-09 14:40:50,372:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:50,372:INFO:Creating metrics dataframe
2024-05-09 14:40:50,378:INFO:Initializing Gradient Boosting Regressor
2024-05-09 14:40:50,378:INFO:Total runtime is 0.123403004805247 minutes
2024-05-09 14:40:50,380:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:50,380:INFO:Initializing create_model()
2024-05-09 14:40:50,380:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:50,380:INFO:Checking exceptions
2024-05-09 14:40:50,380:INFO:Importing libraries
2024-05-09 14:40:50,380:INFO:Copying training dataset
2024-05-09 14:40:50,381:INFO:Defining folds
2024-05-09 14:40:50,381:INFO:Declaring metric variables
2024-05-09 14:40:50,383:INFO:Importing untrained model
2024-05-09 14:40:50,385:INFO:Gradient Boosting Regressor Imported successfully
2024-05-09 14:40:50,388:INFO:Starting cross validation
2024-05-09 14:40:50,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:50,559:INFO:Calculating mean and std
2024-05-09 14:40:50,560:INFO:Creating metrics dataframe
2024-05-09 14:40:50,562:INFO:Uploading results into container
2024-05-09 14:40:50,562:INFO:Uploading model into container now
2024-05-09 14:40:50,562:INFO:_master_model_container: 16
2024-05-09 14:40:50,562:INFO:_display_container: 2
2024-05-09 14:40:50,563:INFO:GradientBoostingRegressor(random_state=777)
2024-05-09 14:40:50,563:INFO:create_model() successfully completed......................................
2024-05-09 14:40:50,632:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:50,632:INFO:Creating metrics dataframe
2024-05-09 14:40:50,639:INFO:Initializing Light Gradient Boosting Machine
2024-05-09 14:40:50,639:INFO:Total runtime is 0.12775405645370486 minutes
2024-05-09 14:40:50,641:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:50,641:INFO:Initializing create_model()
2024-05-09 14:40:50,641:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:50,641:INFO:Checking exceptions
2024-05-09 14:40:50,641:INFO:Importing libraries
2024-05-09 14:40:50,641:INFO:Copying training dataset
2024-05-09 14:40:50,643:INFO:Defining folds
2024-05-09 14:40:50,643:INFO:Declaring metric variables
2024-05-09 14:40:50,645:INFO:Importing untrained model
2024-05-09 14:40:50,647:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-09 14:40:50,651:INFO:Starting cross validation
2024-05-09 14:40:50,652:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:51,301:INFO:Calculating mean and std
2024-05-09 14:40:51,302:INFO:Creating metrics dataframe
2024-05-09 14:40:51,304:INFO:Uploading results into container
2024-05-09 14:40:51,304:INFO:Uploading model into container now
2024-05-09 14:40:51,304:INFO:_master_model_container: 17
2024-05-09 14:40:51,304:INFO:_display_container: 2
2024-05-09 14:40:51,305:INFO:LGBMRegressor(n_jobs=-1, random_state=777)
2024-05-09 14:40:51,305:INFO:create_model() successfully completed......................................
2024-05-09 14:40:51,371:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:51,371:INFO:Creating metrics dataframe
2024-05-09 14:40:51,377:INFO:Initializing Dummy Regressor
2024-05-09 14:40:51,377:INFO:Total runtime is 0.14005725781122846 minutes
2024-05-09 14:40:51,379:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:51,379:INFO:Initializing create_model()
2024-05-09 14:40:51,379:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0f13a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:51,379:INFO:Checking exceptions
2024-05-09 14:40:51,379:INFO:Importing libraries
2024-05-09 14:40:51,379:INFO:Copying training dataset
2024-05-09 14:40:51,381:INFO:Defining folds
2024-05-09 14:40:51,381:INFO:Declaring metric variables
2024-05-09 14:40:51,383:INFO:Importing untrained model
2024-05-09 14:40:51,385:INFO:Dummy Regressor Imported successfully
2024-05-09 14:40:51,388:INFO:Starting cross validation
2024-05-09 14:40:51,389:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:51,452:INFO:Calculating mean and std
2024-05-09 14:40:51,453:INFO:Creating metrics dataframe
2024-05-09 14:40:51,456:INFO:Uploading results into container
2024-05-09 14:40:51,457:INFO:Uploading model into container now
2024-05-09 14:40:51,457:INFO:_master_model_container: 18
2024-05-09 14:40:51,457:INFO:_display_container: 2
2024-05-09 14:40:51,458:INFO:DummyRegressor()
2024-05-09 14:40:51,458:INFO:create_model() successfully completed......................................
2024-05-09 14:40:51,532:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:51,532:INFO:Creating metrics dataframe
2024-05-09 14:40:51,544:INFO:Initializing create_model()
2024-05-09 14:40:51,544:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:51,544:INFO:Checking exceptions
2024-05-09 14:40:51,545:INFO:Importing libraries
2024-05-09 14:40:51,545:INFO:Copying training dataset
2024-05-09 14:40:51,547:INFO:Defining folds
2024-05-09 14:40:51,547:INFO:Declaring metric variables
2024-05-09 14:40:51,547:INFO:Importing untrained model
2024-05-09 14:40:51,547:INFO:Declaring custom model
2024-05-09 14:40:51,548:INFO:Random Forest Regressor Imported successfully
2024-05-09 14:40:51,548:INFO:Cross validation set to False
2024-05-09 14:40:51,548:INFO:Fitting Model
2024-05-09 14:40:51,650:INFO:RandomForestRegressor(n_jobs=-1, random_state=777)
2024-05-09 14:40:51,650:INFO:create_model() successfully completed......................................
2024-05-09 14:40:51,742:INFO:_master_model_container: 18
2024-05-09 14:40:51,742:INFO:_display_container: 2
2024-05-09 14:40:51,742:INFO:RandomForestRegressor(n_jobs=-1, random_state=777)
2024-05-09 14:40:51,742:INFO:compare_models() successfully completed......................................
2024-05-09 14:40:51,743:INFO:Initializing tune_model()
2024-05-09 14:40:51,743:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=777), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>)
2024-05-09 14:40:51,743:INFO:Checking exceptions
2024-05-09 14:40:51,752:INFO:Copying training dataset
2024-05-09 14:40:51,755:INFO:Checking base model
2024-05-09 14:40:51,755:INFO:Base model : Random Forest Regressor
2024-05-09 14:40:51,759:INFO:Declaring metric variables
2024-05-09 14:40:51,761:INFO:Defining Hyperparameters
2024-05-09 14:40:51,851:INFO:Tuning with n_jobs=-1
2024-05-09 14:40:51,851:INFO:Initializing RandomizedSearchCV
2024-05-09 14:40:55,573:INFO:best_params: {'actual_estimator__n_estimators': 260, 'actual_estimator__min_samples_split': 10, 'actual_estimator__min_samples_leaf': 6, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 9, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-09 14:40:55,574:INFO:Hyperparameter search completed
2024-05-09 14:40:55,574:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:55,575:INFO:Initializing create_model()
2024-05-09 14:40:55,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x7866d0c18a30>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 260, 'min_samples_split': 10, 'min_samples_leaf': 6, 'min_impurity_decrease': 0.0002, 'max_features': 'sqrt', 'max_depth': 9, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-09 14:40:55,575:INFO:Checking exceptions
2024-05-09 14:40:55,575:INFO:Importing libraries
2024-05-09 14:40:55,575:INFO:Copying training dataset
2024-05-09 14:40:55,578:INFO:Defining folds
2024-05-09 14:40:55,578:INFO:Declaring metric variables
2024-05-09 14:40:55,581:INFO:Importing untrained model
2024-05-09 14:40:55,581:INFO:Declaring custom model
2024-05-09 14:40:55,584:INFO:Random Forest Regressor Imported successfully
2024-05-09 14:40:55,589:INFO:Starting cross validation
2024-05-09 14:40:55,589:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:55,954:INFO:Calculating mean and std
2024-05-09 14:40:55,955:INFO:Creating metrics dataframe
2024-05-09 14:40:55,961:INFO:Finalizing model
2024-05-09 14:40:56,110:INFO:Uploading results into container
2024-05-09 14:40:56,111:INFO:Uploading model into container now
2024-05-09 14:40:56,112:INFO:_master_model_container: 19
2024-05-09 14:40:56,112:INFO:_display_container: 3
2024-05-09 14:40:56,112:INFO:RandomForestRegressor(bootstrap=False, max_depth=9, max_features='sqrt',
                      min_impurity_decrease=0.0002, min_samples_leaf=6,
                      min_samples_split=10, n_estimators=260, n_jobs=-1,
                      random_state=777)
2024-05-09 14:40:56,112:INFO:create_model() successfully completed......................................
2024-05-09 14:40:56,232:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:56,232:INFO:choose_better activated
2024-05-09 14:40:56,235:INFO:SubProcess create_model() called ==================================
2024-05-09 14:40:56,236:INFO:Initializing create_model()
2024-05-09 14:40:56,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=777), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:56,236:INFO:Checking exceptions
2024-05-09 14:40:56,237:INFO:Importing libraries
2024-05-09 14:40:56,238:INFO:Copying training dataset
2024-05-09 14:40:56,239:INFO:Defining folds
2024-05-09 14:40:56,240:INFO:Declaring metric variables
2024-05-09 14:40:56,240:INFO:Importing untrained model
2024-05-09 14:40:56,240:INFO:Declaring custom model
2024-05-09 14:40:56,240:INFO:Random Forest Regressor Imported successfully
2024-05-09 14:40:56,240:INFO:Starting cross validation
2024-05-09 14:40:56,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-09 14:40:56,538:INFO:Calculating mean and std
2024-05-09 14:40:56,538:INFO:Creating metrics dataframe
2024-05-09 14:40:56,540:INFO:Finalizing model
2024-05-09 14:40:56,649:INFO:Uploading results into container
2024-05-09 14:40:56,650:INFO:Uploading model into container now
2024-05-09 14:40:56,650:INFO:_master_model_container: 20
2024-05-09 14:40:56,651:INFO:_display_container: 4
2024-05-09 14:40:56,651:INFO:RandomForestRegressor(n_jobs=-1, random_state=777)
2024-05-09 14:40:56,651:INFO:create_model() successfully completed......................................
2024-05-09 14:40:56,772:INFO:SubProcess create_model() end ==================================
2024-05-09 14:40:56,773:INFO:RandomForestRegressor(n_jobs=-1, random_state=777) result for R2 is 0.6964
2024-05-09 14:40:56,773:INFO:RandomForestRegressor(bootstrap=False, max_depth=9, max_features='sqrt',
                      min_impurity_decrease=0.0002, min_samples_leaf=6,
                      min_samples_split=10, n_estimators=260, n_jobs=-1,
                      random_state=777) result for R2 is 0.684
2024-05-09 14:40:56,773:INFO:RandomForestRegressor(n_jobs=-1, random_state=777) is best model
2024-05-09 14:40:56,773:INFO:choose_better completed
2024-05-09 14:40:56,774:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-09 14:40:56,780:INFO:_master_model_container: 20
2024-05-09 14:40:56,780:INFO:_display_container: 3
2024-05-09 14:40:56,780:INFO:RandomForestRegressor(n_jobs=-1, random_state=777)
2024-05-09 14:40:56,780:INFO:tune_model() successfully completed......................................
2024-05-09 14:40:56,891:INFO:Initializing finalize_model()
2024-05-09 14:40:56,891:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=777), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-09 14:40:56,891:INFO:Finalizing RandomForestRegressor(n_jobs=-1, random_state=777)
2024-05-09 14:40:56,893:INFO:Initializing create_model()
2024-05-09 14:40:56,893:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=RandomForestRegressor(n_jobs=-1, random_state=777), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-09 14:40:56,893:INFO:Checking exceptions
2024-05-09 14:40:56,894:INFO:Importing libraries
2024-05-09 14:40:56,894:INFO:Copying training dataset
2024-05-09 14:40:56,894:INFO:Defining folds
2024-05-09 14:40:56,894:INFO:Declaring metric variables
2024-05-09 14:40:56,895:INFO:Importing untrained model
2024-05-09 14:40:56,895:INFO:Declaring custom model
2024-05-09 14:40:56,895:INFO:Random Forest Regressor Imported successfully
2024-05-09 14:40:56,896:INFO:Cross validation set to False
2024-05-09 14:40:56,896:INFO:Fitting Model
2024-05-09 14:40:57,019:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=777))])
2024-05-09 14:40:57,019:INFO:create_model() successfully completed......................................
2024-05-09 14:40:57,090:INFO:_master_model_container: 20
2024-05-09 14:40:57,090:INFO:_display_container: 3
2024-05-09 14:40:57,093:INFO:Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=777))])
2024-05-09 14:40:57,094:INFO:finalize_model() successfully completed......................................
2024-05-09 14:40:57,167:INFO:Initializing predict_model()
2024-05-09 14:40:57,167:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x7866d0add4c0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('date_feature_extractor',
                 TransformerWrapper(include=['time'],
                                    transformer=ExtractDateTimeFeatures())),
                ('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=MinMaxScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 RandomForestRegressor(n_jobs=-1, random_state=777))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x7866993ee160>)
2024-05-09 14:40:57,167:INFO:Checking exceptions
2024-05-09 14:40:57,167:INFO:Preloading libraries
2024-05-09 14:40:57,169:INFO:Set up data.
2024-05-09 14:40:57,170:INFO:Set up index.
2024-05-10 14:11:23,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 14:11:23,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 14:11:23,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 14:11:23,149:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 14:21:22,929:INFO:PyCaret RegressionExperiment
2024-05-10 14:21:22,929:INFO:Logging name: reg-default-name
2024-05-10 14:21:22,929:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:21:22,929:INFO:version 3.3.2
2024-05-10 14:21:22,929:INFO:Initializing setup()
2024-05-10 14:21:22,929:INFO:self.USI: 5cfe
2024-05-10 14:21:22,929:INFO:self._variable_keys: {'X', 'target_param', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'n_jobs_param', 'USI', 'pipeline', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'data', '_ml_usecase', 'fold_shuffle_param', 'X_test', '_available_plots', 'exp_id', 'logging_param', 'transform_target_param', 'fold_generator', 'memory', 'html_param', 'gpu_param', 'y_test', 'seed', 'y'}
2024-05-10 14:21:22,929:INFO:Checking environment
2024-05-10 14:21:22,929:INFO:python_version: 3.9.18
2024-05-10 14:21:22,929:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:21:22,929:INFO:machine: x86_64
2024-05-10 14:21:22,929:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:21:22,929:INFO:Memory: svmem(total=16429797376, available=8915570688, percent=45.7, used=6394425344, free=612454400, active=7602962432, inactive=6662225920, buffers=357785600, cached=9065132032, shared=797798400, slab=799645696)
2024-05-10 14:21:22,930:INFO:Physical Core: 12
2024-05-10 14:21:22,930:INFO:Logical Core: 16
2024-05-10 14:21:22,930:INFO:Checking libraries
2024-05-10 14:21:22,930:INFO:System:
2024-05-10 14:21:22,930:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:21:22,930:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:21:22,930:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:21:22,930:INFO:PyCaret required dependencies:
2024-05-10 14:21:23,199:INFO:                 pip: 23.3.1
2024-05-10 14:21:23,199:INFO:          setuptools: 68.2.2
2024-05-10 14:21:23,199:INFO:             pycaret: 3.3.2
2024-05-10 14:21:23,199:INFO:             IPython: 8.15.0
2024-05-10 14:21:23,199:INFO:          ipywidgets: 7.6.5
2024-05-10 14:21:23,199:INFO:                tqdm: 4.65.0
2024-05-10 14:21:23,199:INFO:               numpy: 1.26.4
2024-05-10 14:21:23,199:INFO:              pandas: 2.1.4
2024-05-10 14:21:23,199:INFO:              jinja2: 3.1.3
2024-05-10 14:21:23,199:INFO:               scipy: 1.11.4
2024-05-10 14:21:23,199:INFO:              joblib: 1.2.0
2024-05-10 14:21:23,199:INFO:             sklearn: 1.4.2
2024-05-10 14:21:23,199:INFO:                pyod: 1.1.3
2024-05-10 14:21:23,199:INFO:            imblearn: 0.12.2
2024-05-10 14:21:23,199:INFO:   category_encoders: 2.6.3
2024-05-10 14:21:23,199:INFO:            lightgbm: 4.3.0
2024-05-10 14:21:23,199:INFO:               numba: 0.59.1
2024-05-10 14:21:23,199:INFO:            requests: 2.31.0
2024-05-10 14:21:23,199:INFO:          matplotlib: 3.7.5
2024-05-10 14:21:23,199:INFO:          scikitplot: 0.3.7
2024-05-10 14:21:23,199:INFO:         yellowbrick: 1.5
2024-05-10 14:21:23,199:INFO:              plotly: 5.19.0
2024-05-10 14:21:23,199:INFO:    plotly-resampler: Not installed
2024-05-10 14:21:23,199:INFO:             kaleido: 0.2.1
2024-05-10 14:21:23,199:INFO:           schemdraw: 0.15
2024-05-10 14:21:23,199:INFO:         statsmodels: 0.14.0
2024-05-10 14:21:23,199:INFO:              sktime: 0.26.0
2024-05-10 14:21:23,199:INFO:               tbats: 1.1.3
2024-05-10 14:21:23,199:INFO:            pmdarima: 2.0.4
2024-05-10 14:21:23,199:INFO:              psutil: 5.9.0
2024-05-10 14:21:23,199:INFO:          markupsafe: 2.1.3
2024-05-10 14:21:23,199:INFO:             pickle5: Not installed
2024-05-10 14:21:23,199:INFO:         cloudpickle: 2.2.1
2024-05-10 14:21:23,199:INFO:         deprecation: 2.1.0
2024-05-10 14:21:23,199:INFO:              xxhash: 3.4.1
2024-05-10 14:21:23,199:INFO:           wurlitzer: 3.0.2
2024-05-10 14:21:23,199:INFO:PyCaret optional dependencies:
2024-05-10 14:21:23,206:INFO:                shap: Not installed
2024-05-10 14:21:23,206:INFO:           interpret: Not installed
2024-05-10 14:21:23,206:INFO:                umap: Not installed
2024-05-10 14:21:23,206:INFO:     ydata_profiling: Not installed
2024-05-10 14:21:23,206:INFO:  explainerdashboard: Not installed
2024-05-10 14:21:23,206:INFO:             autoviz: Not installed
2024-05-10 14:21:23,206:INFO:           fairlearn: Not installed
2024-05-10 14:21:23,206:INFO:          deepchecks: Not installed
2024-05-10 14:21:23,206:INFO:             xgboost: Not installed
2024-05-10 14:21:23,206:INFO:            catboost: Not installed
2024-05-10 14:21:23,206:INFO:              kmodes: Not installed
2024-05-10 14:21:23,206:INFO:             mlxtend: Not installed
2024-05-10 14:21:23,206:INFO:       statsforecast: Not installed
2024-05-10 14:21:23,206:INFO:        tune_sklearn: Not installed
2024-05-10 14:21:23,206:INFO:                 ray: Not installed
2024-05-10 14:21:23,206:INFO:            hyperopt: Not installed
2024-05-10 14:21:23,206:INFO:              optuna: Not installed
2024-05-10 14:21:23,206:INFO:               skopt: Not installed
2024-05-10 14:21:23,206:INFO:              mlflow: Not installed
2024-05-10 14:21:23,206:INFO:              gradio: Not installed
2024-05-10 14:21:23,206:INFO:             fastapi: Not installed
2024-05-10 14:21:23,206:INFO:             uvicorn: Not installed
2024-05-10 14:21:23,206:INFO:              m2cgen: Not installed
2024-05-10 14:21:23,206:INFO:           evidently: Not installed
2024-05-10 14:21:23,206:INFO:               fugue: Not installed
2024-05-10 14:21:23,206:INFO:           streamlit: 1.32.0
2024-05-10 14:21:23,206:INFO:             prophet: Not installed
2024-05-10 14:21:23,206:INFO:None
2024-05-10 14:21:23,206:INFO:Set up data.
2024-05-10 14:21:23,209:INFO:Set up folding strategy.
2024-05-10 14:21:23,209:INFO:Set up train/test split.
2024-05-10 14:21:23,211:INFO:Set up index.
2024-05-10 14:21:23,211:INFO:Assigning column types.
2024-05-10 14:21:23,213:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:21:23,213:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,215:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,218:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,266:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,268:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,270:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,297:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,319:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:21:23,321:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,323:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,351:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,372:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,372:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,372:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,374:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,377:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,425:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:21:23,429:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,478:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,483:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,532:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,533:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:21:23,565:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,586:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,619:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,640:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,641:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:21:23,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,726:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:21:23,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,748:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:21:23,801:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,801:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,854:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,856:INFO:Preparing preprocessing pipeline...
2024-05-10 14:21:23,856:INFO:Set up simple imputation.
2024-05-10 14:21:23,856:INFO:Set up column transformation.
2024-05-10 14:21:23,857:INFO:Set up column name cleaning.
2024-05-10 14:21:23,881:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:21:23,884:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('transformation',
                 TransformerWrapper(transformer=PowerTransformer(standardize=False))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:21:23,884:INFO:Creating final display dataframe.
2024-05-10 14:21:23,928:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (407, 7)
4        Transformed data shape          (407, 7)
5   Transformed train set shape          (325, 7)
6    Transformed test set shape           (82, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Transformation              True
13        Transformation method       yeo-johnson
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              5cfe
2024-05-10 14:21:23,995:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:23,995:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:24,052:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:24,052:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:21:24,052:INFO:setup() successfully completed in 1.12s...............
2024-05-10 14:21:24,052:INFO:Initializing compare_models()
2024-05-10 14:21:24,052:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:21:24,052:INFO:Checking exceptions
2024-05-10 14:21:24,053:INFO:Preparing display monitor
2024-05-10 14:21:24,066:INFO:Initializing Linear Regression
2024-05-10 14:21:24,066:INFO:Total runtime is 2.0265579223632812e-06 minutes
2024-05-10 14:21:24,068:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:24,068:INFO:Initializing create_model()
2024-05-10 14:21:24,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:24,068:INFO:Checking exceptions
2024-05-10 14:21:24,068:INFO:Importing libraries
2024-05-10 14:21:24,068:INFO:Copying training dataset
2024-05-10 14:21:24,071:INFO:Defining folds
2024-05-10 14:21:24,071:INFO:Declaring metric variables
2024-05-10 14:21:24,074:INFO:Importing untrained model
2024-05-10 14:21:24,076:INFO:Linear Regression Imported successfully
2024-05-10 14:21:24,080:INFO:Starting cross validation
2024-05-10 14:21:24,082:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:26,455:INFO:Calculating mean and std
2024-05-10 14:21:26,458:INFO:Creating metrics dataframe
2024-05-10 14:21:26,461:INFO:Uploading results into container
2024-05-10 14:21:26,461:INFO:Uploading model into container now
2024-05-10 14:21:26,462:INFO:_master_model_container: 1
2024-05-10 14:21:26,462:INFO:_display_container: 2
2024-05-10 14:21:26,463:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:21:26,463:INFO:create_model() successfully completed......................................
2024-05-10 14:21:26,556:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:26,556:INFO:Creating metrics dataframe
2024-05-10 14:21:26,561:INFO:Initializing Lasso Regression
2024-05-10 14:21:26,561:INFO:Total runtime is 0.041586565971374514 minutes
2024-05-10 14:21:26,563:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:26,563:INFO:Initializing create_model()
2024-05-10 14:21:26,563:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:26,563:INFO:Checking exceptions
2024-05-10 14:21:26,563:INFO:Importing libraries
2024-05-10 14:21:26,563:INFO:Copying training dataset
2024-05-10 14:21:26,565:INFO:Defining folds
2024-05-10 14:21:26,566:INFO:Declaring metric variables
2024-05-10 14:21:26,567:INFO:Importing untrained model
2024-05-10 14:21:26,570:INFO:Lasso Regression Imported successfully
2024-05-10 14:21:26,577:INFO:Starting cross validation
2024-05-10 14:21:26,578:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:28,168:INFO:Calculating mean and std
2024-05-10 14:21:28,169:INFO:Creating metrics dataframe
2024-05-10 14:21:28,170:INFO:Uploading results into container
2024-05-10 14:21:28,171:INFO:Uploading model into container now
2024-05-10 14:21:28,171:INFO:_master_model_container: 2
2024-05-10 14:21:28,171:INFO:_display_container: 2
2024-05-10 14:21:28,171:INFO:Lasso(random_state=123)
2024-05-10 14:21:28,172:INFO:create_model() successfully completed......................................
2024-05-10 14:21:28,253:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:28,253:INFO:Creating metrics dataframe
2024-05-10 14:21:28,257:INFO:Initializing Ridge Regression
2024-05-10 14:21:28,257:INFO:Total runtime is 0.06985834042231243 minutes
2024-05-10 14:21:28,260:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:28,260:INFO:Initializing create_model()
2024-05-10 14:21:28,260:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:28,260:INFO:Checking exceptions
2024-05-10 14:21:28,260:INFO:Importing libraries
2024-05-10 14:21:28,260:INFO:Copying training dataset
2024-05-10 14:21:28,262:INFO:Defining folds
2024-05-10 14:21:28,262:INFO:Declaring metric variables
2024-05-10 14:21:28,264:INFO:Importing untrained model
2024-05-10 14:21:28,265:INFO:Ridge Regression Imported successfully
2024-05-10 14:21:28,268:INFO:Starting cross validation
2024-05-10 14:21:28,269:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:28,313:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=6.69705e-12): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,313:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.15667e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,313:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.1966e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,313:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.71182e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,313:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=4.29846e-16): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,313:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.3481e-10): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,314:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.0302e-15): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,321:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.78782e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,331:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.03964e-17): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,333:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=1.90144e-13): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2024-05-10 14:21:28,338:INFO:Calculating mean and std
2024-05-10 14:21:28,339:INFO:Creating metrics dataframe
2024-05-10 14:21:28,341:INFO:Uploading results into container
2024-05-10 14:21:28,341:INFO:Uploading model into container now
2024-05-10 14:21:28,342:INFO:_master_model_container: 3
2024-05-10 14:21:28,342:INFO:_display_container: 2
2024-05-10 14:21:28,343:INFO:Ridge(random_state=123)
2024-05-10 14:21:28,343:INFO:create_model() successfully completed......................................
2024-05-10 14:21:28,410:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:28,410:INFO:Creating metrics dataframe
2024-05-10 14:21:28,414:INFO:Initializing Elastic Net
2024-05-10 14:21:28,414:INFO:Total runtime is 0.07247020800908408 minutes
2024-05-10 14:21:28,416:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:28,416:INFO:Initializing create_model()
2024-05-10 14:21:28,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:28,416:INFO:Checking exceptions
2024-05-10 14:21:28,416:INFO:Importing libraries
2024-05-10 14:21:28,416:INFO:Copying training dataset
2024-05-10 14:21:28,418:INFO:Defining folds
2024-05-10 14:21:28,418:INFO:Declaring metric variables
2024-05-10 14:21:28,420:INFO:Importing untrained model
2024-05-10 14:21:28,421:INFO:Elastic Net Imported successfully
2024-05-10 14:21:28,425:INFO:Starting cross validation
2024-05-10 14:21:28,426:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:28,498:INFO:Calculating mean and std
2024-05-10 14:21:28,499:INFO:Creating metrics dataframe
2024-05-10 14:21:28,500:INFO:Uploading results into container
2024-05-10 14:21:28,501:INFO:Uploading model into container now
2024-05-10 14:21:28,501:INFO:_master_model_container: 4
2024-05-10 14:21:28,501:INFO:_display_container: 2
2024-05-10 14:21:28,501:INFO:ElasticNet(random_state=123)
2024-05-10 14:21:28,501:INFO:create_model() successfully completed......................................
2024-05-10 14:21:28,570:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:28,570:INFO:Creating metrics dataframe
2024-05-10 14:21:28,574:INFO:Initializing Least Angle Regression
2024-05-10 14:21:28,574:INFO:Total runtime is 0.07513932387034099 minutes
2024-05-10 14:21:28,577:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:28,577:INFO:Initializing create_model()
2024-05-10 14:21:28,577:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:28,577:INFO:Checking exceptions
2024-05-10 14:21:28,577:INFO:Importing libraries
2024-05-10 14:21:28,577:INFO:Copying training dataset
2024-05-10 14:21:28,580:INFO:Defining folds
2024-05-10 14:21:28,580:INFO:Declaring metric variables
2024-05-10 14:21:28,581:INFO:Importing untrained model
2024-05-10 14:21:28,583:INFO:Least Angle Regression Imported successfully
2024-05-10 14:21:28,586:INFO:Starting cross validation
2024-05-10 14:21:28,587:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:28,662:INFO:Calculating mean and std
2024-05-10 14:21:28,663:INFO:Creating metrics dataframe
2024-05-10 14:21:28,664:INFO:Uploading results into container
2024-05-10 14:21:28,665:INFO:Uploading model into container now
2024-05-10 14:21:28,665:INFO:_master_model_container: 5
2024-05-10 14:21:28,665:INFO:_display_container: 2
2024-05-10 14:21:28,665:INFO:Lars(random_state=123)
2024-05-10 14:21:28,665:INFO:create_model() successfully completed......................................
2024-05-10 14:21:28,733:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:28,733:INFO:Creating metrics dataframe
2024-05-10 14:21:28,737:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:21:28,737:INFO:Total runtime is 0.0778565009435018 minutes
2024-05-10 14:21:28,739:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:28,740:INFO:Initializing create_model()
2024-05-10 14:21:28,740:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:28,740:INFO:Checking exceptions
2024-05-10 14:21:28,740:INFO:Importing libraries
2024-05-10 14:21:28,740:INFO:Copying training dataset
2024-05-10 14:21:28,742:INFO:Defining folds
2024-05-10 14:21:28,742:INFO:Declaring metric variables
2024-05-10 14:21:28,744:INFO:Importing untrained model
2024-05-10 14:21:28,746:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:21:28,750:INFO:Starting cross validation
2024-05-10 14:21:28,751:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:28,830:INFO:Calculating mean and std
2024-05-10 14:21:28,831:INFO:Creating metrics dataframe
2024-05-10 14:21:28,832:INFO:Uploading results into container
2024-05-10 14:21:28,833:INFO:Uploading model into container now
2024-05-10 14:21:28,833:INFO:_master_model_container: 6
2024-05-10 14:21:28,833:INFO:_display_container: 2
2024-05-10 14:21:28,833:INFO:LassoLars(random_state=123)
2024-05-10 14:21:28,833:INFO:create_model() successfully completed......................................
2024-05-10 14:21:28,901:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:28,901:INFO:Creating metrics dataframe
2024-05-10 14:21:28,906:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:21:28,906:INFO:Total runtime is 0.08066129684448244 minutes
2024-05-10 14:21:28,908:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:28,908:INFO:Initializing create_model()
2024-05-10 14:21:28,908:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:28,908:INFO:Checking exceptions
2024-05-10 14:21:28,908:INFO:Importing libraries
2024-05-10 14:21:28,908:INFO:Copying training dataset
2024-05-10 14:21:28,911:INFO:Defining folds
2024-05-10 14:21:28,911:INFO:Declaring metric variables
2024-05-10 14:21:28,912:INFO:Importing untrained model
2024-05-10 14:21:28,914:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:21:28,918:INFO:Starting cross validation
2024-05-10 14:21:28,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:28,998:INFO:Calculating mean and std
2024-05-10 14:21:28,998:INFO:Creating metrics dataframe
2024-05-10 14:21:29,000:INFO:Uploading results into container
2024-05-10 14:21:29,000:INFO:Uploading model into container now
2024-05-10 14:21:29,000:INFO:_master_model_container: 7
2024-05-10 14:21:29,000:INFO:_display_container: 2
2024-05-10 14:21:29,000:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:21:29,000:INFO:create_model() successfully completed......................................
2024-05-10 14:21:29,069:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:29,069:INFO:Creating metrics dataframe
2024-05-10 14:21:29,074:INFO:Initializing Bayesian Ridge
2024-05-10 14:21:29,074:INFO:Total runtime is 0.08346949418385825 minutes
2024-05-10 14:21:29,076:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:29,076:INFO:Initializing create_model()
2024-05-10 14:21:29,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:29,076:INFO:Checking exceptions
2024-05-10 14:21:29,076:INFO:Importing libraries
2024-05-10 14:21:29,076:INFO:Copying training dataset
2024-05-10 14:21:29,079:INFO:Defining folds
2024-05-10 14:21:29,079:INFO:Declaring metric variables
2024-05-10 14:21:29,080:INFO:Importing untrained model
2024-05-10 14:21:29,082:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:21:29,086:INFO:Starting cross validation
2024-05-10 14:21:29,086:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:29,161:INFO:Calculating mean and std
2024-05-10 14:21:29,162:INFO:Creating metrics dataframe
2024-05-10 14:21:29,164:INFO:Uploading results into container
2024-05-10 14:21:29,164:INFO:Uploading model into container now
2024-05-10 14:21:29,165:INFO:_master_model_container: 8
2024-05-10 14:21:29,165:INFO:_display_container: 2
2024-05-10 14:21:29,165:INFO:BayesianRidge()
2024-05-10 14:21:29,165:INFO:create_model() successfully completed......................................
2024-05-10 14:21:29,232:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:29,232:INFO:Creating metrics dataframe
2024-05-10 14:21:29,237:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:21:29,237:INFO:Total runtime is 0.08618558645248414 minutes
2024-05-10 14:21:29,239:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:29,239:INFO:Initializing create_model()
2024-05-10 14:21:29,239:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:29,239:INFO:Checking exceptions
2024-05-10 14:21:29,239:INFO:Importing libraries
2024-05-10 14:21:29,239:INFO:Copying training dataset
2024-05-10 14:21:29,241:INFO:Defining folds
2024-05-10 14:21:29,241:INFO:Declaring metric variables
2024-05-10 14:21:29,243:INFO:Importing untrained model
2024-05-10 14:21:29,245:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:21:29,248:INFO:Starting cross validation
2024-05-10 14:21:29,249:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:29,318:INFO:Calculating mean and std
2024-05-10 14:21:29,319:INFO:Creating metrics dataframe
2024-05-10 14:21:29,321:INFO:Uploading results into container
2024-05-10 14:21:29,321:INFO:Uploading model into container now
2024-05-10 14:21:29,322:INFO:_master_model_container: 9
2024-05-10 14:21:29,322:INFO:_display_container: 2
2024-05-10 14:21:29,322:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:21:29,322:INFO:create_model() successfully completed......................................
2024-05-10 14:21:29,391:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:29,391:INFO:Creating metrics dataframe
2024-05-10 14:21:29,396:INFO:Initializing Huber Regressor
2024-05-10 14:21:29,396:INFO:Total runtime is 0.08882861534754437 minutes
2024-05-10 14:21:29,397:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:29,398:INFO:Initializing create_model()
2024-05-10 14:21:29,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:29,398:INFO:Checking exceptions
2024-05-10 14:21:29,398:INFO:Importing libraries
2024-05-10 14:21:29,398:INFO:Copying training dataset
2024-05-10 14:21:29,399:INFO:Defining folds
2024-05-10 14:21:29,400:INFO:Declaring metric variables
2024-05-10 14:21:29,401:INFO:Importing untrained model
2024-05-10 14:21:29,404:INFO:Huber Regressor Imported successfully
2024-05-10 14:21:29,407:INFO:Starting cross validation
2024-05-10 14:21:29,408:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:29,485:INFO:Calculating mean and std
2024-05-10 14:21:29,486:INFO:Creating metrics dataframe
2024-05-10 14:21:29,488:INFO:Uploading results into container
2024-05-10 14:21:29,489:INFO:Uploading model into container now
2024-05-10 14:21:29,489:INFO:_master_model_container: 10
2024-05-10 14:21:29,489:INFO:_display_container: 2
2024-05-10 14:21:29,490:INFO:HuberRegressor()
2024-05-10 14:21:29,490:INFO:create_model() successfully completed......................................
2024-05-10 14:21:29,558:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:29,558:INFO:Creating metrics dataframe
2024-05-10 14:21:29,563:INFO:Initializing K Neighbors Regressor
2024-05-10 14:21:29,563:INFO:Total runtime is 0.09162439505259197 minutes
2024-05-10 14:21:29,565:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:29,565:INFO:Initializing create_model()
2024-05-10 14:21:29,566:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:29,566:INFO:Checking exceptions
2024-05-10 14:21:29,566:INFO:Importing libraries
2024-05-10 14:21:29,566:INFO:Copying training dataset
2024-05-10 14:21:29,568:INFO:Defining folds
2024-05-10 14:21:29,568:INFO:Declaring metric variables
2024-05-10 14:21:29,569:INFO:Importing untrained model
2024-05-10 14:21:29,571:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:21:29,575:INFO:Starting cross validation
2024-05-10 14:21:29,576:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:29,657:INFO:Calculating mean and std
2024-05-10 14:21:29,658:INFO:Creating metrics dataframe
2024-05-10 14:21:29,660:INFO:Uploading results into container
2024-05-10 14:21:29,660:INFO:Uploading model into container now
2024-05-10 14:21:29,660:INFO:_master_model_container: 11
2024-05-10 14:21:29,660:INFO:_display_container: 2
2024-05-10 14:21:29,661:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:21:29,661:INFO:create_model() successfully completed......................................
2024-05-10 14:21:29,727:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:29,727:INFO:Creating metrics dataframe
2024-05-10 14:21:29,732:INFO:Initializing Decision Tree Regressor
2024-05-10 14:21:29,732:INFO:Total runtime is 0.09443672498067221 minutes
2024-05-10 14:21:29,734:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:29,734:INFO:Initializing create_model()
2024-05-10 14:21:29,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:29,735:INFO:Checking exceptions
2024-05-10 14:21:29,735:INFO:Importing libraries
2024-05-10 14:21:29,735:INFO:Copying training dataset
2024-05-10 14:21:29,738:INFO:Defining folds
2024-05-10 14:21:29,738:INFO:Declaring metric variables
2024-05-10 14:21:29,741:INFO:Importing untrained model
2024-05-10 14:21:29,743:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:21:29,746:INFO:Starting cross validation
2024-05-10 14:21:29,746:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:29,815:INFO:Calculating mean and std
2024-05-10 14:21:29,816:INFO:Creating metrics dataframe
2024-05-10 14:21:29,817:INFO:Uploading results into container
2024-05-10 14:21:29,817:INFO:Uploading model into container now
2024-05-10 14:21:29,817:INFO:_master_model_container: 12
2024-05-10 14:21:29,818:INFO:_display_container: 2
2024-05-10 14:21:29,818:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:21:29,818:INFO:create_model() successfully completed......................................
2024-05-10 14:21:29,888:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:29,888:INFO:Creating metrics dataframe
2024-05-10 14:21:29,894:INFO:Initializing Random Forest Regressor
2024-05-10 14:21:29,894:INFO:Total runtime is 0.0971272349357605 minutes
2024-05-10 14:21:29,895:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:29,896:INFO:Initializing create_model()
2024-05-10 14:21:29,896:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:29,896:INFO:Checking exceptions
2024-05-10 14:21:29,896:INFO:Importing libraries
2024-05-10 14:21:29,896:INFO:Copying training dataset
2024-05-10 14:21:29,898:INFO:Defining folds
2024-05-10 14:21:29,898:INFO:Declaring metric variables
2024-05-10 14:21:29,899:INFO:Importing untrained model
2024-05-10 14:21:29,901:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:21:29,904:INFO:Starting cross validation
2024-05-10 14:21:29,905:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:30,165:INFO:Calculating mean and std
2024-05-10 14:21:30,165:INFO:Creating metrics dataframe
2024-05-10 14:21:30,167:INFO:Uploading results into container
2024-05-10 14:21:30,167:INFO:Uploading model into container now
2024-05-10 14:21:30,167:INFO:_master_model_container: 13
2024-05-10 14:21:30,168:INFO:_display_container: 2
2024-05-10 14:21:30,168:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:21:30,168:INFO:create_model() successfully completed......................................
2024-05-10 14:21:30,233:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:30,233:INFO:Creating metrics dataframe
2024-05-10 14:21:30,238:INFO:Initializing Extra Trees Regressor
2024-05-10 14:21:30,238:INFO:Total runtime is 0.10286947488784791 minutes
2024-05-10 14:21:30,240:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:30,240:INFO:Initializing create_model()
2024-05-10 14:21:30,240:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:30,240:INFO:Checking exceptions
2024-05-10 14:21:30,240:INFO:Importing libraries
2024-05-10 14:21:30,240:INFO:Copying training dataset
2024-05-10 14:21:30,243:INFO:Defining folds
2024-05-10 14:21:30,243:INFO:Declaring metric variables
2024-05-10 14:21:30,245:INFO:Importing untrained model
2024-05-10 14:21:30,246:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:21:30,250:INFO:Starting cross validation
2024-05-10 14:21:30,250:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:30,437:INFO:Calculating mean and std
2024-05-10 14:21:30,438:INFO:Creating metrics dataframe
2024-05-10 14:21:30,439:INFO:Uploading results into container
2024-05-10 14:21:30,440:INFO:Uploading model into container now
2024-05-10 14:21:30,440:INFO:_master_model_container: 14
2024-05-10 14:21:30,441:INFO:_display_container: 2
2024-05-10 14:21:30,441:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:21:30,441:INFO:create_model() successfully completed......................................
2024-05-10 14:21:30,509:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:30,509:INFO:Creating metrics dataframe
2024-05-10 14:21:30,514:INFO:Initializing AdaBoost Regressor
2024-05-10 14:21:30,514:INFO:Total runtime is 0.10747213363647462 minutes
2024-05-10 14:21:30,516:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:30,516:INFO:Initializing create_model()
2024-05-10 14:21:30,516:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:30,516:INFO:Checking exceptions
2024-05-10 14:21:30,516:INFO:Importing libraries
2024-05-10 14:21:30,516:INFO:Copying training dataset
2024-05-10 14:21:30,518:INFO:Defining folds
2024-05-10 14:21:30,518:INFO:Declaring metric variables
2024-05-10 14:21:30,520:INFO:Importing untrained model
2024-05-10 14:21:30,522:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:21:30,525:INFO:Starting cross validation
2024-05-10 14:21:30,526:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:30,663:INFO:Calculating mean and std
2024-05-10 14:21:30,663:INFO:Creating metrics dataframe
2024-05-10 14:21:30,665:INFO:Uploading results into container
2024-05-10 14:21:30,665:INFO:Uploading model into container now
2024-05-10 14:21:30,665:INFO:_master_model_container: 15
2024-05-10 14:21:30,665:INFO:_display_container: 2
2024-05-10 14:21:30,666:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:21:30,666:INFO:create_model() successfully completed......................................
2024-05-10 14:21:30,731:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:30,731:INFO:Creating metrics dataframe
2024-05-10 14:21:30,736:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:21:30,736:INFO:Total runtime is 0.11116686662038168 minutes
2024-05-10 14:21:30,738:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:30,738:INFO:Initializing create_model()
2024-05-10 14:21:30,739:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:30,739:INFO:Checking exceptions
2024-05-10 14:21:30,739:INFO:Importing libraries
2024-05-10 14:21:30,739:INFO:Copying training dataset
2024-05-10 14:21:30,741:INFO:Defining folds
2024-05-10 14:21:30,741:INFO:Declaring metric variables
2024-05-10 14:21:30,743:INFO:Importing untrained model
2024-05-10 14:21:30,745:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:21:30,748:INFO:Starting cross validation
2024-05-10 14:21:30,749:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:30,915:INFO:Calculating mean and std
2024-05-10 14:21:30,916:INFO:Creating metrics dataframe
2024-05-10 14:21:30,917:INFO:Uploading results into container
2024-05-10 14:21:30,917:INFO:Uploading model into container now
2024-05-10 14:21:30,918:INFO:_master_model_container: 16
2024-05-10 14:21:30,918:INFO:_display_container: 2
2024-05-10 14:21:30,918:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:21:30,918:INFO:create_model() successfully completed......................................
2024-05-10 14:21:30,984:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:30,984:INFO:Creating metrics dataframe
2024-05-10 14:21:30,989:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:21:30,989:INFO:Total runtime is 0.11538500785827638 minutes
2024-05-10 14:21:30,991:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:30,991:INFO:Initializing create_model()
2024-05-10 14:21:30,991:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:30,991:INFO:Checking exceptions
2024-05-10 14:21:30,991:INFO:Importing libraries
2024-05-10 14:21:30,991:INFO:Copying training dataset
2024-05-10 14:21:30,994:INFO:Defining folds
2024-05-10 14:21:30,994:INFO:Declaring metric variables
2024-05-10 14:21:30,995:INFO:Importing untrained model
2024-05-10 14:21:30,997:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:21:31,000:INFO:Starting cross validation
2024-05-10 14:21:31,001:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:31,500:INFO:Calculating mean and std
2024-05-10 14:21:31,500:INFO:Creating metrics dataframe
2024-05-10 14:21:31,502:INFO:Uploading results into container
2024-05-10 14:21:31,502:INFO:Uploading model into container now
2024-05-10 14:21:31,502:INFO:_master_model_container: 17
2024-05-10 14:21:31,502:INFO:_display_container: 2
2024-05-10 14:21:31,503:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:21:31,503:INFO:create_model() successfully completed......................................
2024-05-10 14:21:31,571:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:31,571:INFO:Creating metrics dataframe
2024-05-10 14:21:31,577:INFO:Initializing Dummy Regressor
2024-05-10 14:21:31,577:INFO:Total runtime is 0.12518285115559896 minutes
2024-05-10 14:21:31,579:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:31,579:INFO:Initializing create_model()
2024-05-10 14:21:31,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4c77f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:31,579:INFO:Checking exceptions
2024-05-10 14:21:31,579:INFO:Importing libraries
2024-05-10 14:21:31,579:INFO:Copying training dataset
2024-05-10 14:21:31,581:INFO:Defining folds
2024-05-10 14:21:31,581:INFO:Declaring metric variables
2024-05-10 14:21:31,583:INFO:Importing untrained model
2024-05-10 14:21:31,585:INFO:Dummy Regressor Imported successfully
2024-05-10 14:21:31,589:INFO:Starting cross validation
2024-05-10 14:21:31,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:31,660:INFO:Calculating mean and std
2024-05-10 14:21:31,661:INFO:Creating metrics dataframe
2024-05-10 14:21:31,662:INFO:Uploading results into container
2024-05-10 14:21:31,662:INFO:Uploading model into container now
2024-05-10 14:21:31,662:INFO:_master_model_container: 18
2024-05-10 14:21:31,662:INFO:_display_container: 2
2024-05-10 14:21:31,663:INFO:DummyRegressor()
2024-05-10 14:21:31,663:INFO:create_model() successfully completed......................................
2024-05-10 14:21:31,731:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:31,731:INFO:Creating metrics dataframe
2024-05-10 14:21:31,737:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:21:31,742:INFO:Initializing create_model()
2024-05-10 14:21:31,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:31,742:INFO:Checking exceptions
2024-05-10 14:21:31,743:INFO:Importing libraries
2024-05-10 14:21:31,744:INFO:Copying training dataset
2024-05-10 14:21:31,745:INFO:Defining folds
2024-05-10 14:21:31,746:INFO:Declaring metric variables
2024-05-10 14:21:31,746:INFO:Importing untrained model
2024-05-10 14:21:31,746:INFO:Declaring custom model
2024-05-10 14:21:31,746:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:21:31,746:INFO:Cross validation set to False
2024-05-10 14:21:31,746:INFO:Fitting Model
2024-05-10 14:21:31,811:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:21:31,811:INFO:create_model() successfully completed......................................
2024-05-10 14:21:31,899:INFO:_master_model_container: 18
2024-05-10 14:21:31,899:INFO:_display_container: 2
2024-05-10 14:21:31,899:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:21:31,899:INFO:compare_models() successfully completed......................................
2024-05-10 14:21:31,900:INFO:Initializing tune_model()
2024-05-10 14:21:31,900:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>)
2024-05-10 14:21:31,900:INFO:Checking exceptions
2024-05-10 14:21:31,909:INFO:Copying training dataset
2024-05-10 14:21:31,911:INFO:Checking base model
2024-05-10 14:21:31,911:INFO:Base model : Extra Trees Regressor
2024-05-10 14:21:31,913:INFO:Declaring metric variables
2024-05-10 14:21:31,915:INFO:Defining Hyperparameters
2024-05-10 14:21:31,989:INFO:Tuning with n_jobs=-1
2024-05-10 14:21:31,989:INFO:Initializing RandomizedSearchCV
2024-05-10 14:21:33,928:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:21:33,928:INFO:Hyperparameter search completed
2024-05-10 14:21:33,928:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:33,929:INFO:Initializing create_model()
2024-05-10 14:21:33,929:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc3ba3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:21:33,929:INFO:Checking exceptions
2024-05-10 14:21:33,929:INFO:Importing libraries
2024-05-10 14:21:33,929:INFO:Copying training dataset
2024-05-10 14:21:33,931:INFO:Defining folds
2024-05-10 14:21:33,931:INFO:Declaring metric variables
2024-05-10 14:21:33,933:INFO:Importing untrained model
2024-05-10 14:21:33,933:INFO:Declaring custom model
2024-05-10 14:21:33,936:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:21:33,939:INFO:Starting cross validation
2024-05-10 14:21:33,940:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:34,248:INFO:Calculating mean and std
2024-05-10 14:21:34,248:INFO:Creating metrics dataframe
2024-05-10 14:21:34,252:INFO:Finalizing model
2024-05-10 14:21:34,376:INFO:Uploading results into container
2024-05-10 14:21:34,377:INFO:Uploading model into container now
2024-05-10 14:21:34,377:INFO:_master_model_container: 19
2024-05-10 14:21:34,378:INFO:_display_container: 3
2024-05-10 14:21:34,378:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:21:34,378:INFO:create_model() successfully completed......................................
2024-05-10 14:21:34,445:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:34,445:INFO:choose_better activated
2024-05-10 14:21:34,447:INFO:SubProcess create_model() called ==================================
2024-05-10 14:21:34,447:INFO:Initializing create_model()
2024-05-10 14:21:34,447:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:21:34,447:INFO:Checking exceptions
2024-05-10 14:21:34,448:INFO:Importing libraries
2024-05-10 14:21:34,448:INFO:Copying training dataset
2024-05-10 14:21:34,450:INFO:Defining folds
2024-05-10 14:21:34,450:INFO:Declaring metric variables
2024-05-10 14:21:34,450:INFO:Importing untrained model
2024-05-10 14:21:34,450:INFO:Declaring custom model
2024-05-10 14:21:34,451:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:21:34,451:INFO:Starting cross validation
2024-05-10 14:21:34,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:21:34,638:INFO:Calculating mean and std
2024-05-10 14:21:34,638:INFO:Creating metrics dataframe
2024-05-10 14:21:34,639:INFO:Finalizing model
2024-05-10 14:21:34,704:INFO:Uploading results into container
2024-05-10 14:21:34,705:INFO:Uploading model into container now
2024-05-10 14:21:34,705:INFO:_master_model_container: 20
2024-05-10 14:21:34,705:INFO:_display_container: 4
2024-05-10 14:21:34,705:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:21:34,705:INFO:create_model() successfully completed......................................
2024-05-10 14:21:34,771:INFO:SubProcess create_model() end ==================================
2024-05-10 14:21:34,772:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7222
2024-05-10 14:21:34,772:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6571
2024-05-10 14:21:34,772:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:21:34,772:INFO:choose_better completed
2024-05-10 14:21:34,772:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:21:34,780:INFO:_master_model_container: 20
2024-05-10 14:21:34,780:INFO:_display_container: 3
2024-05-10 14:21:34,780:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:21:34,781:INFO:tune_model() successfully completed......................................
2024-05-10 14:21:34,851:INFO:Initializing evaluate_model()
2024-05-10 14:21:34,851:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:21:34,859:INFO:Initializing plot_model()
2024-05-10 14:21:34,859:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, system=True)
2024-05-10 14:21:34,859:INFO:Checking exceptions
2024-05-10 14:21:34,871:INFO:Preloading libraries
2024-05-10 14:21:34,879:INFO:Copying training dataset
2024-05-10 14:21:34,879:INFO:Plot type: pipeline
2024-05-10 14:21:34,959:INFO:Visual Rendered Successfully
2024-05-10 14:21:35,028:INFO:plot_model() successfully completed......................................
2024-05-10 14:21:48,400:INFO:Initializing plot_model()
2024-05-10 14:21:48,401:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, system=True)
2024-05-10 14:21:48,401:INFO:Checking exceptions
2024-05-10 14:21:48,415:INFO:Preloading libraries
2024-05-10 14:21:48,421:INFO:Copying training dataset
2024-05-10 14:21:48,421:INFO:Plot type: residuals
2024-05-10 14:21:48,486:INFO:Fitting Model
2024-05-10 14:21:48,486:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:21:48,525:INFO:Scoring test/hold-out set
2024-05-10 14:21:48,780:INFO:Visual Rendered Successfully
2024-05-10 14:21:48,853:INFO:plot_model() successfully completed......................................
2024-05-10 14:21:53,276:INFO:Initializing plot_model()
2024-05-10 14:21:53,276:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, system=True)
2024-05-10 14:21:53,276:INFO:Checking exceptions
2024-05-10 14:21:53,288:INFO:Preloading libraries
2024-05-10 14:21:53,293:INFO:Copying training dataset
2024-05-10 14:21:53,293:INFO:Plot type: parameter
2024-05-10 14:21:53,296:INFO:Visual Rendered Successfully
2024-05-10 14:21:53,372:INFO:plot_model() successfully completed......................................
2024-05-10 14:21:54,154:INFO:Initializing plot_model()
2024-05-10 14:21:54,154:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, system=True)
2024-05-10 14:21:54,154:INFO:Checking exceptions
2024-05-10 14:21:54,165:INFO:Preloading libraries
2024-05-10 14:21:54,171:INFO:Copying training dataset
2024-05-10 14:21:54,171:INFO:Plot type: error
2024-05-10 14:21:54,213:INFO:Fitting Model
2024-05-10 14:21:54,213:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:21:54,213:INFO:Scoring test/hold-out set
2024-05-10 14:21:54,337:INFO:Visual Rendered Successfully
2024-05-10 14:21:54,409:INFO:plot_model() successfully completed......................................
2024-05-10 14:21:57,272:INFO:Initializing plot_model()
2024-05-10 14:21:57,272:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbeb84e50>, system=True)
2024-05-10 14:21:57,272:INFO:Checking exceptions
2024-05-10 14:21:57,288:INFO:Preloading libraries
2024-05-10 14:21:57,294:INFO:Copying training dataset
2024-05-10 14:21:57,294:INFO:Plot type: residuals
2024-05-10 14:21:57,345:INFO:Fitting Model
2024-05-10 14:21:57,345:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:21:57,392:INFO:Scoring test/hold-out set
2024-05-10 14:21:57,589:INFO:Visual Rendered Successfully
2024-05-10 14:21:57,656:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:22,282:INFO:PyCaret RegressionExperiment
2024-05-10 14:22:22,282:INFO:Logging name: reg-default-name
2024-05-10 14:22:22,282:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:22:22,282:INFO:version 3.3.2
2024-05-10 14:22:22,282:INFO:Initializing setup()
2024-05-10 14:22:22,282:INFO:self.USI: c204
2024-05-10 14:22:22,282:INFO:self._variable_keys: {'X', 'target_param', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'n_jobs_param', 'USI', 'pipeline', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'data', '_ml_usecase', 'fold_shuffle_param', 'X_test', '_available_plots', 'exp_id', 'logging_param', 'transform_target_param', 'fold_generator', 'memory', 'html_param', 'gpu_param', 'y_test', 'seed', 'y'}
2024-05-10 14:22:22,282:INFO:Checking environment
2024-05-10 14:22:22,282:INFO:python_version: 3.9.18
2024-05-10 14:22:22,282:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:22:22,282:INFO:machine: x86_64
2024-05-10 14:22:22,282:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:22:22,282:INFO:Memory: svmem(total=16429797376, available=6115053568, percent=62.8, used=9116352512, free=241176576, active=9431900160, inactive=5396803584, buffers=272510976, cached=6799757312, shared=862896128, slab=797396992)
2024-05-10 14:22:22,283:INFO:Physical Core: 12
2024-05-10 14:22:22,283:INFO:Logical Core: 16
2024-05-10 14:22:22,283:INFO:Checking libraries
2024-05-10 14:22:22,283:INFO:System:
2024-05-10 14:22:22,283:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:22:22,283:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:22:22,283:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:22:22,283:INFO:PyCaret required dependencies:
2024-05-10 14:22:22,283:INFO:                 pip: 23.3.1
2024-05-10 14:22:22,283:INFO:          setuptools: 68.2.2
2024-05-10 14:22:22,283:INFO:             pycaret: 3.3.2
2024-05-10 14:22:22,283:INFO:             IPython: 8.15.0
2024-05-10 14:22:22,283:INFO:          ipywidgets: 7.6.5
2024-05-10 14:22:22,283:INFO:                tqdm: 4.65.0
2024-05-10 14:22:22,283:INFO:               numpy: 1.26.4
2024-05-10 14:22:22,283:INFO:              pandas: 2.1.4
2024-05-10 14:22:22,283:INFO:              jinja2: 3.1.3
2024-05-10 14:22:22,283:INFO:               scipy: 1.11.4
2024-05-10 14:22:22,283:INFO:              joblib: 1.2.0
2024-05-10 14:22:22,283:INFO:             sklearn: 1.4.2
2024-05-10 14:22:22,283:INFO:                pyod: 1.1.3
2024-05-10 14:22:22,283:INFO:            imblearn: 0.12.2
2024-05-10 14:22:22,283:INFO:   category_encoders: 2.6.3
2024-05-10 14:22:22,283:INFO:            lightgbm: 4.3.0
2024-05-10 14:22:22,283:INFO:               numba: 0.59.1
2024-05-10 14:22:22,283:INFO:            requests: 2.31.0
2024-05-10 14:22:22,283:INFO:          matplotlib: 3.7.5
2024-05-10 14:22:22,283:INFO:          scikitplot: 0.3.7
2024-05-10 14:22:22,283:INFO:         yellowbrick: 1.5
2024-05-10 14:22:22,283:INFO:              plotly: 5.19.0
2024-05-10 14:22:22,283:INFO:    plotly-resampler: Not installed
2024-05-10 14:22:22,283:INFO:             kaleido: 0.2.1
2024-05-10 14:22:22,283:INFO:           schemdraw: 0.15
2024-05-10 14:22:22,283:INFO:         statsmodels: 0.14.0
2024-05-10 14:22:22,283:INFO:              sktime: 0.26.0
2024-05-10 14:22:22,283:INFO:               tbats: 1.1.3
2024-05-10 14:22:22,283:INFO:            pmdarima: 2.0.4
2024-05-10 14:22:22,283:INFO:              psutil: 5.9.0
2024-05-10 14:22:22,283:INFO:          markupsafe: 2.1.3
2024-05-10 14:22:22,283:INFO:             pickle5: Not installed
2024-05-10 14:22:22,283:INFO:         cloudpickle: 2.2.1
2024-05-10 14:22:22,283:INFO:         deprecation: 2.1.0
2024-05-10 14:22:22,283:INFO:              xxhash: 3.4.1
2024-05-10 14:22:22,283:INFO:           wurlitzer: 3.0.2
2024-05-10 14:22:22,283:INFO:PyCaret optional dependencies:
2024-05-10 14:22:22,283:INFO:                shap: Not installed
2024-05-10 14:22:22,283:INFO:           interpret: Not installed
2024-05-10 14:22:22,283:INFO:                umap: Not installed
2024-05-10 14:22:22,283:INFO:     ydata_profiling: Not installed
2024-05-10 14:22:22,283:INFO:  explainerdashboard: Not installed
2024-05-10 14:22:22,283:INFO:             autoviz: Not installed
2024-05-10 14:22:22,283:INFO:           fairlearn: Not installed
2024-05-10 14:22:22,283:INFO:          deepchecks: Not installed
2024-05-10 14:22:22,283:INFO:             xgboost: Not installed
2024-05-10 14:22:22,283:INFO:            catboost: Not installed
2024-05-10 14:22:22,283:INFO:              kmodes: Not installed
2024-05-10 14:22:22,283:INFO:             mlxtend: Not installed
2024-05-10 14:22:22,283:INFO:       statsforecast: Not installed
2024-05-10 14:22:22,283:INFO:        tune_sklearn: Not installed
2024-05-10 14:22:22,283:INFO:                 ray: Not installed
2024-05-10 14:22:22,283:INFO:            hyperopt: Not installed
2024-05-10 14:22:22,283:INFO:              optuna: Not installed
2024-05-10 14:22:22,283:INFO:               skopt: Not installed
2024-05-10 14:22:22,283:INFO:              mlflow: Not installed
2024-05-10 14:22:22,283:INFO:              gradio: Not installed
2024-05-10 14:22:22,284:INFO:             fastapi: Not installed
2024-05-10 14:22:22,284:INFO:             uvicorn: Not installed
2024-05-10 14:22:22,284:INFO:              m2cgen: Not installed
2024-05-10 14:22:22,284:INFO:           evidently: Not installed
2024-05-10 14:22:22,284:INFO:               fugue: Not installed
2024-05-10 14:22:22,284:INFO:           streamlit: 1.32.0
2024-05-10 14:22:22,284:INFO:             prophet: Not installed
2024-05-10 14:22:22,284:INFO:None
2024-05-10 14:22:22,284:INFO:Set up data.
2024-05-10 14:22:22,287:INFO:Set up folding strategy.
2024-05-10 14:22:22,288:INFO:Set up train/test split.
2024-05-10 14:22:22,291:INFO:Set up index.
2024-05-10 14:22:22,291:INFO:Assigning column types.
2024-05-10 14:22:22,293:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:22:22,293:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,295:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,298:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,342:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,343:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,343:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,345:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,347:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,392:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,392:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,392:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,392:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:22:22,394:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,397:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,443:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,446:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,448:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,474:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,495:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,495:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,495:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,496:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:22:22,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,527:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,547:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,551:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,579:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,599:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,600:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,600:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,600:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:22:22,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,651:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,682:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,702:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,702:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,702:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:22:22,732:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,753:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,783:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:22,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,804:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:22:22,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,906:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,906:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:22,907:INFO:Preparing preprocessing pipeline...
2024-05-10 14:22:22,907:INFO:Set up simple imputation.
2024-05-10 14:22:22,908:INFO:Set up column name cleaning.
2024-05-10 14:22:22,917:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:22:22,920:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:22:22,920:INFO:Creating final display dataframe.
2024-05-10 14:22:22,956:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (407, 7)
4        Transformed data shape          (407, 7)
5   Transformed train set shape          (325, 7)
6    Transformed test set shape           (82, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              c204
2024-05-10 14:22:23,012:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:23,012:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:23,063:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:23,064:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:23,064:INFO:setup() successfully completed in 0.78s...............
2024-05-10 14:22:23,064:INFO:Initializing compare_models()
2024-05-10 14:22:23,064:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:22:23,064:INFO:Checking exceptions
2024-05-10 14:22:23,065:INFO:Preparing display monitor
2024-05-10 14:22:23,077:INFO:Initializing Linear Regression
2024-05-10 14:22:23,077:INFO:Total runtime is 2.6186307271321613e-06 minutes
2024-05-10 14:22:23,079:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:23,080:INFO:Initializing create_model()
2024-05-10 14:22:23,080:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:23,080:INFO:Checking exceptions
2024-05-10 14:22:23,080:INFO:Importing libraries
2024-05-10 14:22:23,080:INFO:Copying training dataset
2024-05-10 14:22:23,082:INFO:Defining folds
2024-05-10 14:22:23,082:INFO:Declaring metric variables
2024-05-10 14:22:23,085:INFO:Importing untrained model
2024-05-10 14:22:23,087:INFO:Linear Regression Imported successfully
2024-05-10 14:22:23,090:INFO:Starting cross validation
2024-05-10 14:22:23,090:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:23,150:INFO:Calculating mean and std
2024-05-10 14:22:23,150:INFO:Creating metrics dataframe
2024-05-10 14:22:23,151:INFO:Uploading results into container
2024-05-10 14:22:23,152:INFO:Uploading model into container now
2024-05-10 14:22:23,152:INFO:_master_model_container: 1
2024-05-10 14:22:23,152:INFO:_display_container: 2
2024-05-10 14:22:23,152:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:22:23,152:INFO:create_model() successfully completed......................................
2024-05-10 14:22:23,225:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:23,226:INFO:Creating metrics dataframe
2024-05-10 14:22:23,230:INFO:Initializing Lasso Regression
2024-05-10 14:22:23,230:INFO:Total runtime is 0.002545511722564697 minutes
2024-05-10 14:22:23,232:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:23,232:INFO:Initializing create_model()
2024-05-10 14:22:23,232:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:23,232:INFO:Checking exceptions
2024-05-10 14:22:23,232:INFO:Importing libraries
2024-05-10 14:22:23,232:INFO:Copying training dataset
2024-05-10 14:22:23,234:INFO:Defining folds
2024-05-10 14:22:23,234:INFO:Declaring metric variables
2024-05-10 14:22:23,236:INFO:Importing untrained model
2024-05-10 14:22:23,238:INFO:Lasso Regression Imported successfully
2024-05-10 14:22:23,241:INFO:Starting cross validation
2024-05-10 14:22:23,241:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:23,284:INFO:Calculating mean and std
2024-05-10 14:22:23,284:INFO:Creating metrics dataframe
2024-05-10 14:22:23,285:INFO:Uploading results into container
2024-05-10 14:22:23,285:INFO:Uploading model into container now
2024-05-10 14:22:23,286:INFO:_master_model_container: 2
2024-05-10 14:22:23,286:INFO:_display_container: 2
2024-05-10 14:22:23,286:INFO:Lasso(random_state=123)
2024-05-10 14:22:23,286:INFO:create_model() successfully completed......................................
2024-05-10 14:22:23,355:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:23,355:INFO:Creating metrics dataframe
2024-05-10 14:22:23,360:INFO:Initializing Ridge Regression
2024-05-10 14:22:23,360:INFO:Total runtime is 0.004706223805745442 minutes
2024-05-10 14:22:23,362:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:23,362:INFO:Initializing create_model()
2024-05-10 14:22:23,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:23,362:INFO:Checking exceptions
2024-05-10 14:22:23,362:INFO:Importing libraries
2024-05-10 14:22:23,362:INFO:Copying training dataset
2024-05-10 14:22:23,365:INFO:Defining folds
2024-05-10 14:22:23,365:INFO:Declaring metric variables
2024-05-10 14:22:23,367:INFO:Importing untrained model
2024-05-10 14:22:23,368:INFO:Ridge Regression Imported successfully
2024-05-10 14:22:23,371:INFO:Starting cross validation
2024-05-10 14:22:23,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:23,416:INFO:Calculating mean and std
2024-05-10 14:22:23,416:INFO:Creating metrics dataframe
2024-05-10 14:22:23,417:INFO:Uploading results into container
2024-05-10 14:22:23,417:INFO:Uploading model into container now
2024-05-10 14:22:23,418:INFO:_master_model_container: 3
2024-05-10 14:22:23,418:INFO:_display_container: 2
2024-05-10 14:22:23,418:INFO:Ridge(random_state=123)
2024-05-10 14:22:23,418:INFO:create_model() successfully completed......................................
2024-05-10 14:22:23,487:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:23,487:INFO:Creating metrics dataframe
2024-05-10 14:22:23,491:INFO:Initializing Elastic Net
2024-05-10 14:22:23,491:INFO:Total runtime is 0.006893142064412435 minutes
2024-05-10 14:22:23,493:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:23,493:INFO:Initializing create_model()
2024-05-10 14:22:23,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:23,493:INFO:Checking exceptions
2024-05-10 14:22:23,493:INFO:Importing libraries
2024-05-10 14:22:23,493:INFO:Copying training dataset
2024-05-10 14:22:23,495:INFO:Defining folds
2024-05-10 14:22:23,495:INFO:Declaring metric variables
2024-05-10 14:22:23,497:INFO:Importing untrained model
2024-05-10 14:22:23,499:INFO:Elastic Net Imported successfully
2024-05-10 14:22:23,502:INFO:Starting cross validation
2024-05-10 14:22:23,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:23,546:INFO:Calculating mean and std
2024-05-10 14:22:23,546:INFO:Creating metrics dataframe
2024-05-10 14:22:23,548:INFO:Uploading results into container
2024-05-10 14:22:23,548:INFO:Uploading model into container now
2024-05-10 14:22:23,548:INFO:_master_model_container: 4
2024-05-10 14:22:23,548:INFO:_display_container: 2
2024-05-10 14:22:23,548:INFO:ElasticNet(random_state=123)
2024-05-10 14:22:23,548:INFO:create_model() successfully completed......................................
2024-05-10 14:22:23,619:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:23,619:INFO:Creating metrics dataframe
2024-05-10 14:22:23,623:INFO:Initializing Least Angle Regression
2024-05-10 14:22:23,623:INFO:Total runtime is 0.00909579594930013 minutes
2024-05-10 14:22:23,625:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:23,625:INFO:Initializing create_model()
2024-05-10 14:22:23,625:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:23,625:INFO:Checking exceptions
2024-05-10 14:22:23,625:INFO:Importing libraries
2024-05-10 14:22:23,625:INFO:Copying training dataset
2024-05-10 14:22:23,627:INFO:Defining folds
2024-05-10 14:22:23,627:INFO:Declaring metric variables
2024-05-10 14:22:23,629:INFO:Importing untrained model
2024-05-10 14:22:23,631:INFO:Least Angle Regression Imported successfully
2024-05-10 14:22:23,634:INFO:Starting cross validation
2024-05-10 14:22:23,635:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:23,682:INFO:Calculating mean and std
2024-05-10 14:22:23,683:INFO:Creating metrics dataframe
2024-05-10 14:22:23,684:INFO:Uploading results into container
2024-05-10 14:22:23,684:INFO:Uploading model into container now
2024-05-10 14:22:23,684:INFO:_master_model_container: 5
2024-05-10 14:22:23,684:INFO:_display_container: 2
2024-05-10 14:22:23,684:INFO:Lars(random_state=123)
2024-05-10 14:22:23,685:INFO:create_model() successfully completed......................................
2024-05-10 14:22:23,751:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:23,751:INFO:Creating metrics dataframe
2024-05-10 14:22:23,755:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:22:23,755:INFO:Total runtime is 0.011292298634847004 minutes
2024-05-10 14:22:23,757:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:23,757:INFO:Initializing create_model()
2024-05-10 14:22:23,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:23,757:INFO:Checking exceptions
2024-05-10 14:22:23,757:INFO:Importing libraries
2024-05-10 14:22:23,757:INFO:Copying training dataset
2024-05-10 14:22:23,759:INFO:Defining folds
2024-05-10 14:22:23,759:INFO:Declaring metric variables
2024-05-10 14:22:23,760:INFO:Importing untrained model
2024-05-10 14:22:23,762:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:22:23,766:INFO:Starting cross validation
2024-05-10 14:22:23,767:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:23,810:INFO:Calculating mean and std
2024-05-10 14:22:23,811:INFO:Creating metrics dataframe
2024-05-10 14:22:23,812:INFO:Uploading results into container
2024-05-10 14:22:23,813:INFO:Uploading model into container now
2024-05-10 14:22:23,813:INFO:_master_model_container: 6
2024-05-10 14:22:23,813:INFO:_display_container: 2
2024-05-10 14:22:23,813:INFO:LassoLars(random_state=123)
2024-05-10 14:22:23,813:INFO:create_model() successfully completed......................................
2024-05-10 14:22:23,882:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:23,883:INFO:Creating metrics dataframe
2024-05-10 14:22:23,887:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:22:23,887:INFO:Total runtime is 0.013498604297637938 minutes
2024-05-10 14:22:23,889:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:23,889:INFO:Initializing create_model()
2024-05-10 14:22:23,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:23,889:INFO:Checking exceptions
2024-05-10 14:22:23,889:INFO:Importing libraries
2024-05-10 14:22:23,889:INFO:Copying training dataset
2024-05-10 14:22:23,891:INFO:Defining folds
2024-05-10 14:22:23,892:INFO:Declaring metric variables
2024-05-10 14:22:23,893:INFO:Importing untrained model
2024-05-10 14:22:23,895:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:22:23,900:INFO:Starting cross validation
2024-05-10 14:22:23,900:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:23,942:INFO:Calculating mean and std
2024-05-10 14:22:23,942:INFO:Creating metrics dataframe
2024-05-10 14:22:23,943:INFO:Uploading results into container
2024-05-10 14:22:23,944:INFO:Uploading model into container now
2024-05-10 14:22:23,944:INFO:_master_model_container: 7
2024-05-10 14:22:23,944:INFO:_display_container: 2
2024-05-10 14:22:23,944:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:22:23,944:INFO:create_model() successfully completed......................................
2024-05-10 14:22:24,014:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:24,014:INFO:Creating metrics dataframe
2024-05-10 14:22:24,022:INFO:Initializing Bayesian Ridge
2024-05-10 14:22:24,022:INFO:Total runtime is 0.01574014027913411 minutes
2024-05-10 14:22:24,025:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:24,025:INFO:Initializing create_model()
2024-05-10 14:22:24,025:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:24,025:INFO:Checking exceptions
2024-05-10 14:22:24,025:INFO:Importing libraries
2024-05-10 14:22:24,025:INFO:Copying training dataset
2024-05-10 14:22:24,028:INFO:Defining folds
2024-05-10 14:22:24,028:INFO:Declaring metric variables
2024-05-10 14:22:24,030:INFO:Importing untrained model
2024-05-10 14:22:24,033:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:22:24,036:INFO:Starting cross validation
2024-05-10 14:22:24,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:24,084:INFO:Calculating mean and std
2024-05-10 14:22:24,084:INFO:Creating metrics dataframe
2024-05-10 14:22:24,085:INFO:Uploading results into container
2024-05-10 14:22:24,086:INFO:Uploading model into container now
2024-05-10 14:22:24,086:INFO:_master_model_container: 8
2024-05-10 14:22:24,086:INFO:_display_container: 2
2024-05-10 14:22:24,086:INFO:BayesianRidge()
2024-05-10 14:22:24,086:INFO:create_model() successfully completed......................................
2024-05-10 14:22:24,156:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:24,156:INFO:Creating metrics dataframe
2024-05-10 14:22:24,161:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:22:24,161:INFO:Total runtime is 0.018058319886525467 minutes
2024-05-10 14:22:24,163:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:24,163:INFO:Initializing create_model()
2024-05-10 14:22:24,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:24,163:INFO:Checking exceptions
2024-05-10 14:22:24,163:INFO:Importing libraries
2024-05-10 14:22:24,163:INFO:Copying training dataset
2024-05-10 14:22:24,167:INFO:Defining folds
2024-05-10 14:22:24,167:INFO:Declaring metric variables
2024-05-10 14:22:24,169:INFO:Importing untrained model
2024-05-10 14:22:24,171:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:22:24,175:INFO:Starting cross validation
2024-05-10 14:22:24,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:24,218:INFO:Calculating mean and std
2024-05-10 14:22:24,219:INFO:Creating metrics dataframe
2024-05-10 14:22:24,220:INFO:Uploading results into container
2024-05-10 14:22:24,221:INFO:Uploading model into container now
2024-05-10 14:22:24,221:INFO:_master_model_container: 9
2024-05-10 14:22:24,221:INFO:_display_container: 2
2024-05-10 14:22:24,221:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:22:24,221:INFO:create_model() successfully completed......................................
2024-05-10 14:22:24,292:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:24,292:INFO:Creating metrics dataframe
2024-05-10 14:22:24,297:INFO:Initializing Huber Regressor
2024-05-10 14:22:24,297:INFO:Total runtime is 0.02032836278279622 minutes
2024-05-10 14:22:24,299:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:24,299:INFO:Initializing create_model()
2024-05-10 14:22:24,299:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:24,299:INFO:Checking exceptions
2024-05-10 14:22:24,299:INFO:Importing libraries
2024-05-10 14:22:24,299:INFO:Copying training dataset
2024-05-10 14:22:24,301:INFO:Defining folds
2024-05-10 14:22:24,302:INFO:Declaring metric variables
2024-05-10 14:22:24,303:INFO:Importing untrained model
2024-05-10 14:22:24,306:INFO:Huber Regressor Imported successfully
2024-05-10 14:22:24,310:INFO:Starting cross validation
2024-05-10 14:22:24,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:24,344:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:24,352:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:24,358:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:24,358:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:24,360:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:24,367:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:24,368:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:24,368:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:24,374:INFO:Calculating mean and std
2024-05-10 14:22:24,374:INFO:Creating metrics dataframe
2024-05-10 14:22:24,376:INFO:Uploading results into container
2024-05-10 14:22:24,376:INFO:Uploading model into container now
2024-05-10 14:22:24,377:INFO:_master_model_container: 10
2024-05-10 14:22:24,377:INFO:_display_container: 2
2024-05-10 14:22:24,377:INFO:HuberRegressor()
2024-05-10 14:22:24,377:INFO:create_model() successfully completed......................................
2024-05-10 14:22:24,449:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:24,449:INFO:Creating metrics dataframe
2024-05-10 14:22:24,454:INFO:Initializing K Neighbors Regressor
2024-05-10 14:22:24,454:INFO:Total runtime is 0.022948769728342686 minutes
2024-05-10 14:22:24,456:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:24,456:INFO:Initializing create_model()
2024-05-10 14:22:24,456:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:24,456:INFO:Checking exceptions
2024-05-10 14:22:24,456:INFO:Importing libraries
2024-05-10 14:22:24,456:INFO:Copying training dataset
2024-05-10 14:22:24,458:INFO:Defining folds
2024-05-10 14:22:24,458:INFO:Declaring metric variables
2024-05-10 14:22:24,460:INFO:Importing untrained model
2024-05-10 14:22:24,462:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:22:24,467:INFO:Starting cross validation
2024-05-10 14:22:24,467:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:24,544:INFO:Calculating mean and std
2024-05-10 14:22:24,545:INFO:Creating metrics dataframe
2024-05-10 14:22:24,547:INFO:Uploading results into container
2024-05-10 14:22:24,548:INFO:Uploading model into container now
2024-05-10 14:22:24,549:INFO:_master_model_container: 11
2024-05-10 14:22:24,549:INFO:_display_container: 2
2024-05-10 14:22:24,549:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:22:24,549:INFO:create_model() successfully completed......................................
2024-05-10 14:22:24,623:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:24,623:INFO:Creating metrics dataframe
2024-05-10 14:22:24,628:INFO:Initializing Decision Tree Regressor
2024-05-10 14:22:24,629:INFO:Total runtime is 0.025853387514750158 minutes
2024-05-10 14:22:24,632:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:24,632:INFO:Initializing create_model()
2024-05-10 14:22:24,632:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:24,632:INFO:Checking exceptions
2024-05-10 14:22:24,632:INFO:Importing libraries
2024-05-10 14:22:24,632:INFO:Copying training dataset
2024-05-10 14:22:24,636:INFO:Defining folds
2024-05-10 14:22:24,636:INFO:Declaring metric variables
2024-05-10 14:22:24,638:INFO:Importing untrained model
2024-05-10 14:22:24,641:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:22:24,644:INFO:Starting cross validation
2024-05-10 14:22:24,645:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:24,688:INFO:Calculating mean and std
2024-05-10 14:22:24,688:INFO:Creating metrics dataframe
2024-05-10 14:22:24,690:INFO:Uploading results into container
2024-05-10 14:22:24,690:INFO:Uploading model into container now
2024-05-10 14:22:24,691:INFO:_master_model_container: 12
2024-05-10 14:22:24,691:INFO:_display_container: 2
2024-05-10 14:22:24,691:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:22:24,691:INFO:create_model() successfully completed......................................
2024-05-10 14:22:24,761:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:24,761:INFO:Creating metrics dataframe
2024-05-10 14:22:24,767:INFO:Initializing Random Forest Regressor
2024-05-10 14:22:24,767:INFO:Total runtime is 0.02816013097763061 minutes
2024-05-10 14:22:24,769:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:24,769:INFO:Initializing create_model()
2024-05-10 14:22:24,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:24,769:INFO:Checking exceptions
2024-05-10 14:22:24,769:INFO:Importing libraries
2024-05-10 14:22:24,769:INFO:Copying training dataset
2024-05-10 14:22:24,771:INFO:Defining folds
2024-05-10 14:22:24,771:INFO:Declaring metric variables
2024-05-10 14:22:24,773:INFO:Importing untrained model
2024-05-10 14:22:24,774:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:22:24,777:INFO:Starting cross validation
2024-05-10 14:22:24,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:25,020:INFO:Calculating mean and std
2024-05-10 14:22:25,020:INFO:Creating metrics dataframe
2024-05-10 14:22:25,022:INFO:Uploading results into container
2024-05-10 14:22:25,022:INFO:Uploading model into container now
2024-05-10 14:22:25,022:INFO:_master_model_container: 13
2024-05-10 14:22:25,023:INFO:_display_container: 2
2024-05-10 14:22:25,023:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:25,023:INFO:create_model() successfully completed......................................
2024-05-10 14:22:25,092:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:25,093:INFO:Creating metrics dataframe
2024-05-10 14:22:25,098:INFO:Initializing Extra Trees Regressor
2024-05-10 14:22:25,098:INFO:Total runtime is 0.03367555141448974 minutes
2024-05-10 14:22:25,100:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:25,100:INFO:Initializing create_model()
2024-05-10 14:22:25,100:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:25,100:INFO:Checking exceptions
2024-05-10 14:22:25,100:INFO:Importing libraries
2024-05-10 14:22:25,100:INFO:Copying training dataset
2024-05-10 14:22:25,102:INFO:Defining folds
2024-05-10 14:22:25,102:INFO:Declaring metric variables
2024-05-10 14:22:25,103:INFO:Importing untrained model
2024-05-10 14:22:25,105:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:22:25,109:INFO:Starting cross validation
2024-05-10 14:22:25,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:25,270:INFO:Calculating mean and std
2024-05-10 14:22:25,271:INFO:Creating metrics dataframe
2024-05-10 14:22:25,273:INFO:Uploading results into container
2024-05-10 14:22:25,274:INFO:Uploading model into container now
2024-05-10 14:22:25,274:INFO:_master_model_container: 14
2024-05-10 14:22:25,274:INFO:_display_container: 2
2024-05-10 14:22:25,275:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:25,275:INFO:create_model() successfully completed......................................
2024-05-10 14:22:25,345:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:25,346:INFO:Creating metrics dataframe
2024-05-10 14:22:25,351:INFO:Initializing AdaBoost Regressor
2024-05-10 14:22:25,351:INFO:Total runtime is 0.03790085713068644 minutes
2024-05-10 14:22:25,353:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:25,353:INFO:Initializing create_model()
2024-05-10 14:22:25,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:25,353:INFO:Checking exceptions
2024-05-10 14:22:25,353:INFO:Importing libraries
2024-05-10 14:22:25,353:INFO:Copying training dataset
2024-05-10 14:22:25,356:INFO:Defining folds
2024-05-10 14:22:25,356:INFO:Declaring metric variables
2024-05-10 14:22:25,357:INFO:Importing untrained model
2024-05-10 14:22:25,359:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:22:25,362:INFO:Starting cross validation
2024-05-10 14:22:25,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:25,478:INFO:Calculating mean and std
2024-05-10 14:22:25,479:INFO:Creating metrics dataframe
2024-05-10 14:22:25,480:INFO:Uploading results into container
2024-05-10 14:22:25,480:INFO:Uploading model into container now
2024-05-10 14:22:25,481:INFO:_master_model_container: 15
2024-05-10 14:22:25,481:INFO:_display_container: 2
2024-05-10 14:22:25,481:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:22:25,481:INFO:create_model() successfully completed......................................
2024-05-10 14:22:25,553:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:25,553:INFO:Creating metrics dataframe
2024-05-10 14:22:25,559:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:22:25,559:INFO:Total runtime is 0.041357584794362384 minutes
2024-05-10 14:22:25,561:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:25,561:INFO:Initializing create_model()
2024-05-10 14:22:25,561:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:25,561:INFO:Checking exceptions
2024-05-10 14:22:25,561:INFO:Importing libraries
2024-05-10 14:22:25,561:INFO:Copying training dataset
2024-05-10 14:22:25,564:INFO:Defining folds
2024-05-10 14:22:25,564:INFO:Declaring metric variables
2024-05-10 14:22:25,565:INFO:Importing untrained model
2024-05-10 14:22:25,567:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:22:25,570:INFO:Starting cross validation
2024-05-10 14:22:25,570:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:25,717:INFO:Calculating mean and std
2024-05-10 14:22:25,717:INFO:Creating metrics dataframe
2024-05-10 14:22:25,719:INFO:Uploading results into container
2024-05-10 14:22:25,719:INFO:Uploading model into container now
2024-05-10 14:22:25,719:INFO:_master_model_container: 16
2024-05-10 14:22:25,719:INFO:_display_container: 2
2024-05-10 14:22:25,720:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:22:25,720:INFO:create_model() successfully completed......................................
2024-05-10 14:22:25,791:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:25,791:INFO:Creating metrics dataframe
2024-05-10 14:22:25,797:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:22:25,797:INFO:Total runtime is 0.04532378117243449 minutes
2024-05-10 14:22:25,799:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:25,799:INFO:Initializing create_model()
2024-05-10 14:22:25,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:25,799:INFO:Checking exceptions
2024-05-10 14:22:25,799:INFO:Importing libraries
2024-05-10 14:22:25,799:INFO:Copying training dataset
2024-05-10 14:22:25,801:INFO:Defining folds
2024-05-10 14:22:25,801:INFO:Declaring metric variables
2024-05-10 14:22:25,803:INFO:Importing untrained model
2024-05-10 14:22:25,805:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:22:25,808:INFO:Starting cross validation
2024-05-10 14:22:25,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:26,315:INFO:Calculating mean and std
2024-05-10 14:22:26,316:INFO:Creating metrics dataframe
2024-05-10 14:22:26,317:INFO:Uploading results into container
2024-05-10 14:22:26,318:INFO:Uploading model into container now
2024-05-10 14:22:26,318:INFO:_master_model_container: 17
2024-05-10 14:22:26,318:INFO:_display_container: 2
2024-05-10 14:22:26,318:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:26,318:INFO:create_model() successfully completed......................................
2024-05-10 14:22:26,389:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:26,389:INFO:Creating metrics dataframe
2024-05-10 14:22:26,395:INFO:Initializing Dummy Regressor
2024-05-10 14:22:26,395:INFO:Total runtime is 0.05528984864552816 minutes
2024-05-10 14:22:26,397:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:26,397:INFO:Initializing create_model()
2024-05-10 14:22:26,397:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb321a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:26,397:INFO:Checking exceptions
2024-05-10 14:22:26,397:INFO:Importing libraries
2024-05-10 14:22:26,397:INFO:Copying training dataset
2024-05-10 14:22:26,399:INFO:Defining folds
2024-05-10 14:22:26,399:INFO:Declaring metric variables
2024-05-10 14:22:26,401:INFO:Importing untrained model
2024-05-10 14:22:26,402:INFO:Dummy Regressor Imported successfully
2024-05-10 14:22:26,405:INFO:Starting cross validation
2024-05-10 14:22:26,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:26,450:INFO:Calculating mean and std
2024-05-10 14:22:26,451:INFO:Creating metrics dataframe
2024-05-10 14:22:26,452:INFO:Uploading results into container
2024-05-10 14:22:26,452:INFO:Uploading model into container now
2024-05-10 14:22:26,453:INFO:_master_model_container: 18
2024-05-10 14:22:26,453:INFO:_display_container: 2
2024-05-10 14:22:26,453:INFO:DummyRegressor()
2024-05-10 14:22:26,453:INFO:create_model() successfully completed......................................
2024-05-10 14:22:26,525:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:26,525:INFO:Creating metrics dataframe
2024-05-10 14:22:26,531:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:22:26,535:INFO:Initializing create_model()
2024-05-10 14:22:26,536:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:26,536:INFO:Checking exceptions
2024-05-10 14:22:26,537:INFO:Importing libraries
2024-05-10 14:22:26,537:INFO:Copying training dataset
2024-05-10 14:22:26,538:INFO:Defining folds
2024-05-10 14:22:26,538:INFO:Declaring metric variables
2024-05-10 14:22:26,539:INFO:Importing untrained model
2024-05-10 14:22:26,539:INFO:Declaring custom model
2024-05-10 14:22:26,539:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:22:26,539:INFO:Cross validation set to False
2024-05-10 14:22:26,539:INFO:Fitting Model
2024-05-10 14:22:26,596:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:26,596:INFO:create_model() successfully completed......................................
2024-05-10 14:22:26,695:INFO:_master_model_container: 18
2024-05-10 14:22:26,695:INFO:_display_container: 2
2024-05-10 14:22:26,695:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:26,695:INFO:compare_models() successfully completed......................................
2024-05-10 14:22:26,696:INFO:Initializing tune_model()
2024-05-10 14:22:26,696:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>)
2024-05-10 14:22:26,696:INFO:Checking exceptions
2024-05-10 14:22:26,706:INFO:Copying training dataset
2024-05-10 14:22:26,708:INFO:Checking base model
2024-05-10 14:22:26,708:INFO:Base model : Extra Trees Regressor
2024-05-10 14:22:26,710:INFO:Declaring metric variables
2024-05-10 14:22:26,712:INFO:Defining Hyperparameters
2024-05-10 14:22:26,790:INFO:Tuning with n_jobs=-1
2024-05-10 14:22:26,791:INFO:Initializing RandomizedSearchCV
2024-05-10 14:22:28,539:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:22:28,540:INFO:Hyperparameter search completed
2024-05-10 14:22:28,540:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:28,540:INFO:Initializing create_model()
2024-05-10 14:22:28,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc7c5070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:22:28,540:INFO:Checking exceptions
2024-05-10 14:22:28,540:INFO:Importing libraries
2024-05-10 14:22:28,540:INFO:Copying training dataset
2024-05-10 14:22:28,544:INFO:Defining folds
2024-05-10 14:22:28,544:INFO:Declaring metric variables
2024-05-10 14:22:28,546:INFO:Importing untrained model
2024-05-10 14:22:28,547:INFO:Declaring custom model
2024-05-10 14:22:28,549:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:22:28,552:INFO:Starting cross validation
2024-05-10 14:22:28,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:28,802:INFO:Calculating mean and std
2024-05-10 14:22:28,803:INFO:Creating metrics dataframe
2024-05-10 14:22:28,806:INFO:Finalizing model
2024-05-10 14:22:28,935:INFO:Uploading results into container
2024-05-10 14:22:28,936:INFO:Uploading model into container now
2024-05-10 14:22:28,936:INFO:_master_model_container: 19
2024-05-10 14:22:28,936:INFO:_display_container: 3
2024-05-10 14:22:28,937:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:22:28,937:INFO:create_model() successfully completed......................................
2024-05-10 14:22:29,016:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:29,016:INFO:choose_better activated
2024-05-10 14:22:29,019:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:29,019:INFO:Initializing create_model()
2024-05-10 14:22:29,019:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:29,019:INFO:Checking exceptions
2024-05-10 14:22:29,020:INFO:Importing libraries
2024-05-10 14:22:29,020:INFO:Copying training dataset
2024-05-10 14:22:29,022:INFO:Defining folds
2024-05-10 14:22:29,022:INFO:Declaring metric variables
2024-05-10 14:22:29,022:INFO:Importing untrained model
2024-05-10 14:22:29,022:INFO:Declaring custom model
2024-05-10 14:22:29,022:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:22:29,022:INFO:Starting cross validation
2024-05-10 14:22:29,023:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:29,182:INFO:Calculating mean and std
2024-05-10 14:22:29,183:INFO:Creating metrics dataframe
2024-05-10 14:22:29,184:INFO:Finalizing model
2024-05-10 14:22:29,238:INFO:Uploading results into container
2024-05-10 14:22:29,238:INFO:Uploading model into container now
2024-05-10 14:22:29,239:INFO:_master_model_container: 20
2024-05-10 14:22:29,239:INFO:_display_container: 4
2024-05-10 14:22:29,239:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:29,239:INFO:create_model() successfully completed......................................
2024-05-10 14:22:29,308:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:29,309:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.759
2024-05-10 14:22:29,309:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6881
2024-05-10 14:22:29,309:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:22:29,309:INFO:choose_better completed
2024-05-10 14:22:29,310:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:22:29,317:INFO:_master_model_container: 20
2024-05-10 14:22:29,317:INFO:_display_container: 3
2024-05-10 14:22:29,317:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:29,317:INFO:tune_model() successfully completed......................................
2024-05-10 14:22:29,389:INFO:Initializing evaluate_model()
2024-05-10 14:22:29,389:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:22:29,397:INFO:Initializing plot_model()
2024-05-10 14:22:29,397:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, system=True)
2024-05-10 14:22:29,397:INFO:Checking exceptions
2024-05-10 14:22:29,410:INFO:Preloading libraries
2024-05-10 14:22:29,418:INFO:Copying training dataset
2024-05-10 14:22:29,418:INFO:Plot type: pipeline
2024-05-10 14:22:29,467:INFO:Visual Rendered Successfully
2024-05-10 14:22:29,542:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:33,194:INFO:Initializing plot_model()
2024-05-10 14:22:33,195:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, system=True)
2024-05-10 14:22:33,195:INFO:Checking exceptions
2024-05-10 14:22:33,211:INFO:Preloading libraries
2024-05-10 14:22:33,215:INFO:Copying training dataset
2024-05-10 14:22:33,215:INFO:Plot type: parameter
2024-05-10 14:22:33,218:INFO:Visual Rendered Successfully
2024-05-10 14:22:33,288:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:33,800:INFO:Initializing plot_model()
2024-05-10 14:22:33,801:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbcab6be0>, system=True)
2024-05-10 14:22:33,801:INFO:Checking exceptions
2024-05-10 14:22:33,817:INFO:Preloading libraries
2024-05-10 14:22:33,824:INFO:Copying training dataset
2024-05-10 14:22:33,824:INFO:Plot type: residuals
2024-05-10 14:22:33,870:INFO:Fitting Model
2024-05-10 14:22:33,870:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:22:33,911:INFO:Scoring test/hold-out set
2024-05-10 14:22:34,115:INFO:Visual Rendered Successfully
2024-05-10 14:22:34,188:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:43,097:INFO:PyCaret RegressionExperiment
2024-05-10 14:22:43,097:INFO:Logging name: reg-default-name
2024-05-10 14:22:43,097:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:22:43,097:INFO:version 3.3.2
2024-05-10 14:22:43,097:INFO:Initializing setup()
2024-05-10 14:22:43,097:INFO:self.USI: e20d
2024-05-10 14:22:43,097:INFO:self._variable_keys: {'X', 'target_param', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'n_jobs_param', 'USI', 'pipeline', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'data', '_ml_usecase', 'fold_shuffle_param', 'X_test', '_available_plots', 'exp_id', 'logging_param', 'transform_target_param', 'fold_generator', 'memory', 'html_param', 'gpu_param', 'y_test', 'seed', 'y'}
2024-05-10 14:22:43,097:INFO:Checking environment
2024-05-10 14:22:43,097:INFO:python_version: 3.9.18
2024-05-10 14:22:43,097:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:22:43,097:INFO:machine: x86_64
2024-05-10 14:22:43,098:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:22:43,098:INFO:Memory: svmem(total=16429797376, available=6080655360, percent=63.0, used=9182027776, free=310890496, active=9478729728, inactive=5288767488, buffers=270823424, cached=6666055680, shared=828989440, slab=797376512)
2024-05-10 14:22:43,098:INFO:Physical Core: 12
2024-05-10 14:22:43,099:INFO:Logical Core: 16
2024-05-10 14:22:43,099:INFO:Checking libraries
2024-05-10 14:22:43,099:INFO:System:
2024-05-10 14:22:43,099:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:22:43,099:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:22:43,099:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:22:43,099:INFO:PyCaret required dependencies:
2024-05-10 14:22:43,099:INFO:                 pip: 23.3.1
2024-05-10 14:22:43,099:INFO:          setuptools: 68.2.2
2024-05-10 14:22:43,099:INFO:             pycaret: 3.3.2
2024-05-10 14:22:43,099:INFO:             IPython: 8.15.0
2024-05-10 14:22:43,099:INFO:          ipywidgets: 7.6.5
2024-05-10 14:22:43,099:INFO:                tqdm: 4.65.0
2024-05-10 14:22:43,099:INFO:               numpy: 1.26.4
2024-05-10 14:22:43,099:INFO:              pandas: 2.1.4
2024-05-10 14:22:43,099:INFO:              jinja2: 3.1.3
2024-05-10 14:22:43,099:INFO:               scipy: 1.11.4
2024-05-10 14:22:43,099:INFO:              joblib: 1.2.0
2024-05-10 14:22:43,099:INFO:             sklearn: 1.4.2
2024-05-10 14:22:43,099:INFO:                pyod: 1.1.3
2024-05-10 14:22:43,099:INFO:            imblearn: 0.12.2
2024-05-10 14:22:43,099:INFO:   category_encoders: 2.6.3
2024-05-10 14:22:43,099:INFO:            lightgbm: 4.3.0
2024-05-10 14:22:43,099:INFO:               numba: 0.59.1
2024-05-10 14:22:43,099:INFO:            requests: 2.31.0
2024-05-10 14:22:43,099:INFO:          matplotlib: 3.7.5
2024-05-10 14:22:43,099:INFO:          scikitplot: 0.3.7
2024-05-10 14:22:43,099:INFO:         yellowbrick: 1.5
2024-05-10 14:22:43,099:INFO:              plotly: 5.19.0
2024-05-10 14:22:43,100:INFO:    plotly-resampler: Not installed
2024-05-10 14:22:43,100:INFO:             kaleido: 0.2.1
2024-05-10 14:22:43,100:INFO:           schemdraw: 0.15
2024-05-10 14:22:43,100:INFO:         statsmodels: 0.14.0
2024-05-10 14:22:43,100:INFO:              sktime: 0.26.0
2024-05-10 14:22:43,100:INFO:               tbats: 1.1.3
2024-05-10 14:22:43,100:INFO:            pmdarima: 2.0.4
2024-05-10 14:22:43,100:INFO:              psutil: 5.9.0
2024-05-10 14:22:43,100:INFO:          markupsafe: 2.1.3
2024-05-10 14:22:43,100:INFO:             pickle5: Not installed
2024-05-10 14:22:43,100:INFO:         cloudpickle: 2.2.1
2024-05-10 14:22:43,100:INFO:         deprecation: 2.1.0
2024-05-10 14:22:43,100:INFO:              xxhash: 3.4.1
2024-05-10 14:22:43,100:INFO:           wurlitzer: 3.0.2
2024-05-10 14:22:43,100:INFO:PyCaret optional dependencies:
2024-05-10 14:22:43,100:INFO:                shap: Not installed
2024-05-10 14:22:43,100:INFO:           interpret: Not installed
2024-05-10 14:22:43,100:INFO:                umap: Not installed
2024-05-10 14:22:43,100:INFO:     ydata_profiling: Not installed
2024-05-10 14:22:43,100:INFO:  explainerdashboard: Not installed
2024-05-10 14:22:43,100:INFO:             autoviz: Not installed
2024-05-10 14:22:43,100:INFO:           fairlearn: Not installed
2024-05-10 14:22:43,100:INFO:          deepchecks: Not installed
2024-05-10 14:22:43,100:INFO:             xgboost: Not installed
2024-05-10 14:22:43,100:INFO:            catboost: Not installed
2024-05-10 14:22:43,100:INFO:              kmodes: Not installed
2024-05-10 14:22:43,100:INFO:             mlxtend: Not installed
2024-05-10 14:22:43,100:INFO:       statsforecast: Not installed
2024-05-10 14:22:43,101:INFO:        tune_sklearn: Not installed
2024-05-10 14:22:43,101:INFO:                 ray: Not installed
2024-05-10 14:22:43,101:INFO:            hyperopt: Not installed
2024-05-10 14:22:43,101:INFO:              optuna: Not installed
2024-05-10 14:22:43,101:INFO:               skopt: Not installed
2024-05-10 14:22:43,101:INFO:              mlflow: Not installed
2024-05-10 14:22:43,101:INFO:              gradio: Not installed
2024-05-10 14:22:43,101:INFO:             fastapi: Not installed
2024-05-10 14:22:43,101:INFO:             uvicorn: Not installed
2024-05-10 14:22:43,101:INFO:              m2cgen: Not installed
2024-05-10 14:22:43,101:INFO:           evidently: Not installed
2024-05-10 14:22:43,101:INFO:               fugue: Not installed
2024-05-10 14:22:43,101:INFO:           streamlit: 1.32.0
2024-05-10 14:22:43,101:INFO:             prophet: Not installed
2024-05-10 14:22:43,101:INFO:None
2024-05-10 14:22:43,101:INFO:Set up data.
2024-05-10 14:22:43,106:INFO:Set up folding strategy.
2024-05-10 14:22:43,106:INFO:Set up train/test split.
2024-05-10 14:22:43,108:INFO:Set up index.
2024-05-10 14:22:43,108:INFO:Assigning column types.
2024-05-10 14:22:43,111:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:22:43,111:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,114:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,117:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,143:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,163:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,164:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,166:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,168:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,193:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,215:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:22:43,217:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,219:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,245:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,265:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,266:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,266:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,268:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,270:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,297:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,318:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,318:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,318:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,318:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:22:43,323:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,370:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,371:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,371:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,376:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,404:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,425:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,426:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:22:43,457:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,479:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,479:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,479:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,509:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,528:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,529:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,529:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,529:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:22:43,558:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,578:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,578:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,609:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:22:43,630:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,630:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,630:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:22:43,681:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,681:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,732:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,733:INFO:Preparing preprocessing pipeline...
2024-05-10 14:22:43,733:INFO:Set up simple imputation.
2024-05-10 14:22:43,734:INFO:Set up column name cleaning.
2024-05-10 14:22:43,743:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:22:43,746:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:22:43,746:INFO:Creating final display dataframe.
2024-05-10 14:22:43,779:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (407, 7)
4        Transformed data shape          (407, 7)
5   Transformed train set shape          (244, 7)
6    Transformed test set shape          (163, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              e20d
2024-05-10 14:22:43,837:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,887:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:22:43,888:INFO:setup() successfully completed in 0.79s...............
2024-05-10 14:22:43,888:INFO:Initializing compare_models()
2024-05-10 14:22:43,888:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:22:43,888:INFO:Checking exceptions
2024-05-10 14:22:43,889:INFO:Preparing display monitor
2024-05-10 14:22:43,900:INFO:Initializing Linear Regression
2024-05-10 14:22:43,901:INFO:Total runtime is 2.165635426839193e-06 minutes
2024-05-10 14:22:43,902:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:43,902:INFO:Initializing create_model()
2024-05-10 14:22:43,902:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:43,902:INFO:Checking exceptions
2024-05-10 14:22:43,902:INFO:Importing libraries
2024-05-10 14:22:43,902:INFO:Copying training dataset
2024-05-10 14:22:43,904:INFO:Defining folds
2024-05-10 14:22:43,904:INFO:Declaring metric variables
2024-05-10 14:22:43,906:INFO:Importing untrained model
2024-05-10 14:22:43,908:INFO:Linear Regression Imported successfully
2024-05-10 14:22:43,913:INFO:Starting cross validation
2024-05-10 14:22:43,914:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:43,959:INFO:Calculating mean and std
2024-05-10 14:22:43,960:INFO:Creating metrics dataframe
2024-05-10 14:22:43,961:INFO:Uploading results into container
2024-05-10 14:22:43,962:INFO:Uploading model into container now
2024-05-10 14:22:43,962:INFO:_master_model_container: 1
2024-05-10 14:22:43,962:INFO:_display_container: 2
2024-05-10 14:22:43,963:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:22:43,963:INFO:create_model() successfully completed......................................
2024-05-10 14:22:44,046:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:44,046:INFO:Creating metrics dataframe
2024-05-10 14:22:44,050:INFO:Initializing Lasso Regression
2024-05-10 14:22:44,050:INFO:Total runtime is 0.002492038408915202 minutes
2024-05-10 14:22:44,052:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:44,052:INFO:Initializing create_model()
2024-05-10 14:22:44,052:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:44,052:INFO:Checking exceptions
2024-05-10 14:22:44,052:INFO:Importing libraries
2024-05-10 14:22:44,052:INFO:Copying training dataset
2024-05-10 14:22:44,054:INFO:Defining folds
2024-05-10 14:22:44,054:INFO:Declaring metric variables
2024-05-10 14:22:44,057:INFO:Importing untrained model
2024-05-10 14:22:44,060:INFO:Lasso Regression Imported successfully
2024-05-10 14:22:44,065:INFO:Starting cross validation
2024-05-10 14:22:44,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:44,113:INFO:Calculating mean and std
2024-05-10 14:22:44,114:INFO:Creating metrics dataframe
2024-05-10 14:22:44,116:INFO:Uploading results into container
2024-05-10 14:22:44,116:INFO:Uploading model into container now
2024-05-10 14:22:44,116:INFO:_master_model_container: 2
2024-05-10 14:22:44,116:INFO:_display_container: 2
2024-05-10 14:22:44,117:INFO:Lasso(random_state=123)
2024-05-10 14:22:44,117:INFO:create_model() successfully completed......................................
2024-05-10 14:22:44,189:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:44,189:INFO:Creating metrics dataframe
2024-05-10 14:22:44,194:INFO:Initializing Ridge Regression
2024-05-10 14:22:44,194:INFO:Total runtime is 0.004885991414388021 minutes
2024-05-10 14:22:44,196:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:44,196:INFO:Initializing create_model()
2024-05-10 14:22:44,196:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:44,196:INFO:Checking exceptions
2024-05-10 14:22:44,196:INFO:Importing libraries
2024-05-10 14:22:44,196:INFO:Copying training dataset
2024-05-10 14:22:44,198:INFO:Defining folds
2024-05-10 14:22:44,198:INFO:Declaring metric variables
2024-05-10 14:22:44,200:INFO:Importing untrained model
2024-05-10 14:22:44,201:INFO:Ridge Regression Imported successfully
2024-05-10 14:22:44,204:INFO:Starting cross validation
2024-05-10 14:22:44,204:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:44,241:INFO:Calculating mean and std
2024-05-10 14:22:44,242:INFO:Creating metrics dataframe
2024-05-10 14:22:44,244:INFO:Uploading results into container
2024-05-10 14:22:44,244:INFO:Uploading model into container now
2024-05-10 14:22:44,245:INFO:_master_model_container: 3
2024-05-10 14:22:44,245:INFO:_display_container: 2
2024-05-10 14:22:44,245:INFO:Ridge(random_state=123)
2024-05-10 14:22:44,245:INFO:create_model() successfully completed......................................
2024-05-10 14:22:44,316:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:44,316:INFO:Creating metrics dataframe
2024-05-10 14:22:44,320:INFO:Initializing Elastic Net
2024-05-10 14:22:44,320:INFO:Total runtime is 0.006995741526285808 minutes
2024-05-10 14:22:44,322:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:44,322:INFO:Initializing create_model()
2024-05-10 14:22:44,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:44,322:INFO:Checking exceptions
2024-05-10 14:22:44,322:INFO:Importing libraries
2024-05-10 14:22:44,322:INFO:Copying training dataset
2024-05-10 14:22:44,324:INFO:Defining folds
2024-05-10 14:22:44,324:INFO:Declaring metric variables
2024-05-10 14:22:44,326:INFO:Importing untrained model
2024-05-10 14:22:44,328:INFO:Elastic Net Imported successfully
2024-05-10 14:22:44,331:INFO:Starting cross validation
2024-05-10 14:22:44,332:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:44,372:INFO:Calculating mean and std
2024-05-10 14:22:44,372:INFO:Creating metrics dataframe
2024-05-10 14:22:44,373:INFO:Uploading results into container
2024-05-10 14:22:44,373:INFO:Uploading model into container now
2024-05-10 14:22:44,374:INFO:_master_model_container: 4
2024-05-10 14:22:44,374:INFO:_display_container: 2
2024-05-10 14:22:44,374:INFO:ElasticNet(random_state=123)
2024-05-10 14:22:44,374:INFO:create_model() successfully completed......................................
2024-05-10 14:22:44,446:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:44,446:INFO:Creating metrics dataframe
2024-05-10 14:22:44,450:INFO:Initializing Least Angle Regression
2024-05-10 14:22:44,450:INFO:Total runtime is 0.009161615371704103 minutes
2024-05-10 14:22:44,452:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:44,452:INFO:Initializing create_model()
2024-05-10 14:22:44,452:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:44,452:INFO:Checking exceptions
2024-05-10 14:22:44,452:INFO:Importing libraries
2024-05-10 14:22:44,452:INFO:Copying training dataset
2024-05-10 14:22:44,454:INFO:Defining folds
2024-05-10 14:22:44,454:INFO:Declaring metric variables
2024-05-10 14:22:44,456:INFO:Importing untrained model
2024-05-10 14:22:44,457:INFO:Least Angle Regression Imported successfully
2024-05-10 14:22:44,460:INFO:Starting cross validation
2024-05-10 14:22:44,461:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:44,505:INFO:Calculating mean and std
2024-05-10 14:22:44,505:INFO:Creating metrics dataframe
2024-05-10 14:22:44,506:INFO:Uploading results into container
2024-05-10 14:22:44,507:INFO:Uploading model into container now
2024-05-10 14:22:44,507:INFO:_master_model_container: 5
2024-05-10 14:22:44,507:INFO:_display_container: 2
2024-05-10 14:22:44,507:INFO:Lars(random_state=123)
2024-05-10 14:22:44,507:INFO:create_model() successfully completed......................................
2024-05-10 14:22:44,580:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:44,580:INFO:Creating metrics dataframe
2024-05-10 14:22:44,584:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:22:44,584:INFO:Total runtime is 0.01139341195424398 minutes
2024-05-10 14:22:44,586:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:44,586:INFO:Initializing create_model()
2024-05-10 14:22:44,586:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:44,586:INFO:Checking exceptions
2024-05-10 14:22:44,586:INFO:Importing libraries
2024-05-10 14:22:44,586:INFO:Copying training dataset
2024-05-10 14:22:44,588:INFO:Defining folds
2024-05-10 14:22:44,588:INFO:Declaring metric variables
2024-05-10 14:22:44,589:INFO:Importing untrained model
2024-05-10 14:22:44,591:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:22:44,594:INFO:Starting cross validation
2024-05-10 14:22:44,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:44,637:INFO:Calculating mean and std
2024-05-10 14:22:44,638:INFO:Creating metrics dataframe
2024-05-10 14:22:44,639:INFO:Uploading results into container
2024-05-10 14:22:44,639:INFO:Uploading model into container now
2024-05-10 14:22:44,640:INFO:_master_model_container: 6
2024-05-10 14:22:44,640:INFO:_display_container: 2
2024-05-10 14:22:44,640:INFO:LassoLars(random_state=123)
2024-05-10 14:22:44,640:INFO:create_model() successfully completed......................................
2024-05-10 14:22:44,713:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:44,713:INFO:Creating metrics dataframe
2024-05-10 14:22:44,718:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:22:44,718:INFO:Total runtime is 0.013625971476236981 minutes
2024-05-10 14:22:44,720:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:44,720:INFO:Initializing create_model()
2024-05-10 14:22:44,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:44,720:INFO:Checking exceptions
2024-05-10 14:22:44,720:INFO:Importing libraries
2024-05-10 14:22:44,720:INFO:Copying training dataset
2024-05-10 14:22:44,722:INFO:Defining folds
2024-05-10 14:22:44,722:INFO:Declaring metric variables
2024-05-10 14:22:44,724:INFO:Importing untrained model
2024-05-10 14:22:44,725:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:22:44,729:INFO:Starting cross validation
2024-05-10 14:22:44,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:44,771:INFO:Calculating mean and std
2024-05-10 14:22:44,771:INFO:Creating metrics dataframe
2024-05-10 14:22:44,772:INFO:Uploading results into container
2024-05-10 14:22:44,772:INFO:Uploading model into container now
2024-05-10 14:22:44,772:INFO:_master_model_container: 7
2024-05-10 14:22:44,772:INFO:_display_container: 2
2024-05-10 14:22:44,772:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:22:44,772:INFO:create_model() successfully completed......................................
2024-05-10 14:22:44,843:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:44,843:INFO:Creating metrics dataframe
2024-05-10 14:22:44,848:INFO:Initializing Bayesian Ridge
2024-05-10 14:22:44,848:INFO:Total runtime is 0.015785725911458336 minutes
2024-05-10 14:22:44,849:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:44,849:INFO:Initializing create_model()
2024-05-10 14:22:44,850:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:44,850:INFO:Checking exceptions
2024-05-10 14:22:44,850:INFO:Importing libraries
2024-05-10 14:22:44,850:INFO:Copying training dataset
2024-05-10 14:22:44,852:INFO:Defining folds
2024-05-10 14:22:44,852:INFO:Declaring metric variables
2024-05-10 14:22:44,853:INFO:Importing untrained model
2024-05-10 14:22:44,854:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:22:44,858:INFO:Starting cross validation
2024-05-10 14:22:44,858:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:44,904:INFO:Calculating mean and std
2024-05-10 14:22:44,905:INFO:Creating metrics dataframe
2024-05-10 14:22:44,906:INFO:Uploading results into container
2024-05-10 14:22:44,906:INFO:Uploading model into container now
2024-05-10 14:22:44,907:INFO:_master_model_container: 8
2024-05-10 14:22:44,907:INFO:_display_container: 2
2024-05-10 14:22:44,907:INFO:BayesianRidge()
2024-05-10 14:22:44,907:INFO:create_model() successfully completed......................................
2024-05-10 14:22:44,979:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:44,979:INFO:Creating metrics dataframe
2024-05-10 14:22:44,984:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:22:44,984:INFO:Total runtime is 0.018055542310078943 minutes
2024-05-10 14:22:44,986:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:44,986:INFO:Initializing create_model()
2024-05-10 14:22:44,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:44,986:INFO:Checking exceptions
2024-05-10 14:22:44,986:INFO:Importing libraries
2024-05-10 14:22:44,986:INFO:Copying training dataset
2024-05-10 14:22:44,988:INFO:Defining folds
2024-05-10 14:22:44,988:INFO:Declaring metric variables
2024-05-10 14:22:44,989:INFO:Importing untrained model
2024-05-10 14:22:44,991:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:22:44,994:INFO:Starting cross validation
2024-05-10 14:22:44,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:45,035:INFO:Calculating mean and std
2024-05-10 14:22:45,036:INFO:Creating metrics dataframe
2024-05-10 14:22:45,037:INFO:Uploading results into container
2024-05-10 14:22:45,037:INFO:Uploading model into container now
2024-05-10 14:22:45,038:INFO:_master_model_container: 9
2024-05-10 14:22:45,038:INFO:_display_container: 2
2024-05-10 14:22:45,038:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:22:45,038:INFO:create_model() successfully completed......................................
2024-05-10 14:22:45,109:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:45,109:INFO:Creating metrics dataframe
2024-05-10 14:22:45,114:INFO:Initializing Huber Regressor
2024-05-10 14:22:45,114:INFO:Total runtime is 0.02022898594538371 minutes
2024-05-10 14:22:45,116:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:45,116:INFO:Initializing create_model()
2024-05-10 14:22:45,116:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:45,116:INFO:Checking exceptions
2024-05-10 14:22:45,116:INFO:Importing libraries
2024-05-10 14:22:45,116:INFO:Copying training dataset
2024-05-10 14:22:45,118:INFO:Defining folds
2024-05-10 14:22:45,118:INFO:Declaring metric variables
2024-05-10 14:22:45,119:INFO:Importing untrained model
2024-05-10 14:22:45,121:INFO:Huber Regressor Imported successfully
2024-05-10 14:22:45,124:INFO:Starting cross validation
2024-05-10 14:22:45,124:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:45,166:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:45,167:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:45,174:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:45,174:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:45,184:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:22:45,189:INFO:Calculating mean and std
2024-05-10 14:22:45,190:INFO:Creating metrics dataframe
2024-05-10 14:22:45,191:INFO:Uploading results into container
2024-05-10 14:22:45,192:INFO:Uploading model into container now
2024-05-10 14:22:45,192:INFO:_master_model_container: 10
2024-05-10 14:22:45,192:INFO:_display_container: 2
2024-05-10 14:22:45,192:INFO:HuberRegressor()
2024-05-10 14:22:45,192:INFO:create_model() successfully completed......................................
2024-05-10 14:22:45,264:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:45,264:INFO:Creating metrics dataframe
2024-05-10 14:22:45,269:INFO:Initializing K Neighbors Regressor
2024-05-10 14:22:45,269:INFO:Total runtime is 0.022808734575907392 minutes
2024-05-10 14:22:45,271:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:45,271:INFO:Initializing create_model()
2024-05-10 14:22:45,271:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:45,271:INFO:Checking exceptions
2024-05-10 14:22:45,271:INFO:Importing libraries
2024-05-10 14:22:45,271:INFO:Copying training dataset
2024-05-10 14:22:45,273:INFO:Defining folds
2024-05-10 14:22:45,273:INFO:Declaring metric variables
2024-05-10 14:22:45,275:INFO:Importing untrained model
2024-05-10 14:22:45,277:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:22:45,281:INFO:Starting cross validation
2024-05-10 14:22:45,281:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:45,342:INFO:Calculating mean and std
2024-05-10 14:22:45,343:INFO:Creating metrics dataframe
2024-05-10 14:22:45,345:INFO:Uploading results into container
2024-05-10 14:22:45,345:INFO:Uploading model into container now
2024-05-10 14:22:45,346:INFO:_master_model_container: 11
2024-05-10 14:22:45,346:INFO:_display_container: 2
2024-05-10 14:22:45,346:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:22:45,346:INFO:create_model() successfully completed......................................
2024-05-10 14:22:45,433:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:45,433:INFO:Creating metrics dataframe
2024-05-10 14:22:45,439:INFO:Initializing Decision Tree Regressor
2024-05-10 14:22:45,439:INFO:Total runtime is 0.025636498133341474 minutes
2024-05-10 14:22:45,440:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:45,441:INFO:Initializing create_model()
2024-05-10 14:22:45,441:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:45,441:INFO:Checking exceptions
2024-05-10 14:22:45,441:INFO:Importing libraries
2024-05-10 14:22:45,441:INFO:Copying training dataset
2024-05-10 14:22:45,444:INFO:Defining folds
2024-05-10 14:22:45,444:INFO:Declaring metric variables
2024-05-10 14:22:45,446:INFO:Importing untrained model
2024-05-10 14:22:45,448:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:22:45,452:INFO:Starting cross validation
2024-05-10 14:22:45,452:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:45,507:INFO:Calculating mean and std
2024-05-10 14:22:45,508:INFO:Creating metrics dataframe
2024-05-10 14:22:45,509:INFO:Uploading results into container
2024-05-10 14:22:45,510:INFO:Uploading model into container now
2024-05-10 14:22:45,510:INFO:_master_model_container: 12
2024-05-10 14:22:45,510:INFO:_display_container: 2
2024-05-10 14:22:45,511:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:22:45,511:INFO:create_model() successfully completed......................................
2024-05-10 14:22:45,582:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:45,582:INFO:Creating metrics dataframe
2024-05-10 14:22:45,588:INFO:Initializing Random Forest Regressor
2024-05-10 14:22:45,588:INFO:Total runtime is 0.028121145566304528 minutes
2024-05-10 14:22:45,589:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:45,590:INFO:Initializing create_model()
2024-05-10 14:22:45,590:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:45,590:INFO:Checking exceptions
2024-05-10 14:22:45,590:INFO:Importing libraries
2024-05-10 14:22:45,590:INFO:Copying training dataset
2024-05-10 14:22:45,593:INFO:Defining folds
2024-05-10 14:22:45,593:INFO:Declaring metric variables
2024-05-10 14:22:45,595:INFO:Importing untrained model
2024-05-10 14:22:45,597:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:22:45,601:INFO:Starting cross validation
2024-05-10 14:22:45,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:45,826:INFO:Calculating mean and std
2024-05-10 14:22:45,826:INFO:Creating metrics dataframe
2024-05-10 14:22:45,828:INFO:Uploading results into container
2024-05-10 14:22:45,829:INFO:Uploading model into container now
2024-05-10 14:22:45,829:INFO:_master_model_container: 13
2024-05-10 14:22:45,829:INFO:_display_container: 2
2024-05-10 14:22:45,829:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:45,829:INFO:create_model() successfully completed......................................
2024-05-10 14:22:45,900:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:45,901:INFO:Creating metrics dataframe
2024-05-10 14:22:45,906:INFO:Initializing Extra Trees Regressor
2024-05-10 14:22:45,906:INFO:Total runtime is 0.033426547050476076 minutes
2024-05-10 14:22:45,908:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:45,908:INFO:Initializing create_model()
2024-05-10 14:22:45,909:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:45,909:INFO:Checking exceptions
2024-05-10 14:22:45,909:INFO:Importing libraries
2024-05-10 14:22:45,909:INFO:Copying training dataset
2024-05-10 14:22:45,911:INFO:Defining folds
2024-05-10 14:22:45,911:INFO:Declaring metric variables
2024-05-10 14:22:45,913:INFO:Importing untrained model
2024-05-10 14:22:45,914:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:22:45,917:INFO:Starting cross validation
2024-05-10 14:22:45,918:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:46,076:INFO:Calculating mean and std
2024-05-10 14:22:46,077:INFO:Creating metrics dataframe
2024-05-10 14:22:46,079:INFO:Uploading results into container
2024-05-10 14:22:46,079:INFO:Uploading model into container now
2024-05-10 14:22:46,080:INFO:_master_model_container: 14
2024-05-10 14:22:46,080:INFO:_display_container: 2
2024-05-10 14:22:46,080:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:46,080:INFO:create_model() successfully completed......................................
2024-05-10 14:22:46,153:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:46,153:INFO:Creating metrics dataframe
2024-05-10 14:22:46,159:INFO:Initializing AdaBoost Regressor
2024-05-10 14:22:46,159:INFO:Total runtime is 0.03763737281163534 minutes
2024-05-10 14:22:46,161:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:46,161:INFO:Initializing create_model()
2024-05-10 14:22:46,161:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:46,161:INFO:Checking exceptions
2024-05-10 14:22:46,161:INFO:Importing libraries
2024-05-10 14:22:46,161:INFO:Copying training dataset
2024-05-10 14:22:46,164:INFO:Defining folds
2024-05-10 14:22:46,164:INFO:Declaring metric variables
2024-05-10 14:22:46,165:INFO:Importing untrained model
2024-05-10 14:22:46,167:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:22:46,170:INFO:Starting cross validation
2024-05-10 14:22:46,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:46,285:INFO:Calculating mean and std
2024-05-10 14:22:46,286:INFO:Creating metrics dataframe
2024-05-10 14:22:46,287:INFO:Uploading results into container
2024-05-10 14:22:46,287:INFO:Uploading model into container now
2024-05-10 14:22:46,287:INFO:_master_model_container: 15
2024-05-10 14:22:46,287:INFO:_display_container: 2
2024-05-10 14:22:46,288:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:22:46,288:INFO:create_model() successfully completed......................................
2024-05-10 14:22:46,359:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:46,359:INFO:Creating metrics dataframe
2024-05-10 14:22:46,365:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:22:46,365:INFO:Total runtime is 0.04107416868209839 minutes
2024-05-10 14:22:46,367:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:46,367:INFO:Initializing create_model()
2024-05-10 14:22:46,367:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:46,367:INFO:Checking exceptions
2024-05-10 14:22:46,367:INFO:Importing libraries
2024-05-10 14:22:46,367:INFO:Copying training dataset
2024-05-10 14:22:46,369:INFO:Defining folds
2024-05-10 14:22:46,369:INFO:Declaring metric variables
2024-05-10 14:22:46,371:INFO:Importing untrained model
2024-05-10 14:22:46,372:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:22:46,376:INFO:Starting cross validation
2024-05-10 14:22:46,377:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:46,506:INFO:Calculating mean and std
2024-05-10 14:22:46,507:INFO:Creating metrics dataframe
2024-05-10 14:22:46,509:INFO:Uploading results into container
2024-05-10 14:22:46,509:INFO:Uploading model into container now
2024-05-10 14:22:46,510:INFO:_master_model_container: 16
2024-05-10 14:22:46,510:INFO:_display_container: 2
2024-05-10 14:22:46,510:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:22:46,510:INFO:create_model() successfully completed......................................
2024-05-10 14:22:46,583:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:46,583:INFO:Creating metrics dataframe
2024-05-10 14:22:46,589:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:22:46,589:INFO:Total runtime is 0.0448124368985494 minutes
2024-05-10 14:22:46,592:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:46,592:INFO:Initializing create_model()
2024-05-10 14:22:46,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:46,592:INFO:Checking exceptions
2024-05-10 14:22:46,592:INFO:Importing libraries
2024-05-10 14:22:46,592:INFO:Copying training dataset
2024-05-10 14:22:46,595:INFO:Defining folds
2024-05-10 14:22:46,595:INFO:Declaring metric variables
2024-05-10 14:22:46,596:INFO:Importing untrained model
2024-05-10 14:22:46,598:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:22:46,601:INFO:Starting cross validation
2024-05-10 14:22:46,602:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:46,982:INFO:Calculating mean and std
2024-05-10 14:22:46,982:INFO:Creating metrics dataframe
2024-05-10 14:22:46,984:INFO:Uploading results into container
2024-05-10 14:22:46,984:INFO:Uploading model into container now
2024-05-10 14:22:46,984:INFO:_master_model_container: 17
2024-05-10 14:22:46,984:INFO:_display_container: 2
2024-05-10 14:22:46,985:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:46,985:INFO:create_model() successfully completed......................................
2024-05-10 14:22:47,057:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:47,058:INFO:Creating metrics dataframe
2024-05-10 14:22:47,065:INFO:Initializing Dummy Regressor
2024-05-10 14:22:47,065:INFO:Total runtime is 0.052748680114746094 minutes
2024-05-10 14:22:47,067:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:47,068:INFO:Initializing create_model()
2024-05-10 14:22:47,068:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccac41c40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:47,068:INFO:Checking exceptions
2024-05-10 14:22:47,068:INFO:Importing libraries
2024-05-10 14:22:47,068:INFO:Copying training dataset
2024-05-10 14:22:47,070:INFO:Defining folds
2024-05-10 14:22:47,070:INFO:Declaring metric variables
2024-05-10 14:22:47,072:INFO:Importing untrained model
2024-05-10 14:22:47,074:INFO:Dummy Regressor Imported successfully
2024-05-10 14:22:47,077:INFO:Starting cross validation
2024-05-10 14:22:47,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:47,117:INFO:Calculating mean and std
2024-05-10 14:22:47,118:INFO:Creating metrics dataframe
2024-05-10 14:22:47,119:INFO:Uploading results into container
2024-05-10 14:22:47,120:INFO:Uploading model into container now
2024-05-10 14:22:47,120:INFO:_master_model_container: 18
2024-05-10 14:22:47,120:INFO:_display_container: 2
2024-05-10 14:22:47,120:INFO:DummyRegressor()
2024-05-10 14:22:47,120:INFO:create_model() successfully completed......................................
2024-05-10 14:22:47,191:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:47,191:INFO:Creating metrics dataframe
2024-05-10 14:22:47,198:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:22:47,203:INFO:Initializing create_model()
2024-05-10 14:22:47,203:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:47,203:INFO:Checking exceptions
2024-05-10 14:22:47,204:INFO:Importing libraries
2024-05-10 14:22:47,204:INFO:Copying training dataset
2024-05-10 14:22:47,206:INFO:Defining folds
2024-05-10 14:22:47,206:INFO:Declaring metric variables
2024-05-10 14:22:47,206:INFO:Importing untrained model
2024-05-10 14:22:47,206:INFO:Declaring custom model
2024-05-10 14:22:47,207:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:22:47,207:INFO:Cross validation set to False
2024-05-10 14:22:47,207:INFO:Fitting Model
2024-05-10 14:22:47,258:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:47,258:INFO:create_model() successfully completed......................................
2024-05-10 14:22:47,350:INFO:_master_model_container: 18
2024-05-10 14:22:47,350:INFO:_display_container: 2
2024-05-10 14:22:47,350:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:47,350:INFO:compare_models() successfully completed......................................
2024-05-10 14:22:47,350:INFO:Initializing tune_model()
2024-05-10 14:22:47,350:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>)
2024-05-10 14:22:47,350:INFO:Checking exceptions
2024-05-10 14:22:47,358:INFO:Copying training dataset
2024-05-10 14:22:47,361:INFO:Checking base model
2024-05-10 14:22:47,362:INFO:Base model : Extra Trees Regressor
2024-05-10 14:22:47,366:INFO:Declaring metric variables
2024-05-10 14:22:47,369:INFO:Defining Hyperparameters
2024-05-10 14:22:47,456:INFO:Tuning with n_jobs=-1
2024-05-10 14:22:47,456:INFO:Initializing RandomizedSearchCV
2024-05-10 14:22:49,161:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:22:49,162:INFO:Hyperparameter search completed
2024-05-10 14:22:49,162:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:49,163:INFO:Initializing create_model()
2024-05-10 14:22:49,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc4b3910>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:22:49,163:INFO:Checking exceptions
2024-05-10 14:22:49,163:INFO:Importing libraries
2024-05-10 14:22:49,163:INFO:Copying training dataset
2024-05-10 14:22:49,167:INFO:Defining folds
2024-05-10 14:22:49,167:INFO:Declaring metric variables
2024-05-10 14:22:49,169:INFO:Importing untrained model
2024-05-10 14:22:49,169:INFO:Declaring custom model
2024-05-10 14:22:49,171:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:22:49,174:INFO:Starting cross validation
2024-05-10 14:22:49,175:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:49,420:INFO:Calculating mean and std
2024-05-10 14:22:49,421:INFO:Creating metrics dataframe
2024-05-10 14:22:49,427:INFO:Finalizing model
2024-05-10 14:22:49,540:INFO:Uploading results into container
2024-05-10 14:22:49,541:INFO:Uploading model into container now
2024-05-10 14:22:49,542:INFO:_master_model_container: 19
2024-05-10 14:22:49,542:INFO:_display_container: 3
2024-05-10 14:22:49,543:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:22:49,543:INFO:create_model() successfully completed......................................
2024-05-10 14:22:49,617:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:49,617:INFO:choose_better activated
2024-05-10 14:22:49,620:INFO:SubProcess create_model() called ==================================
2024-05-10 14:22:49,620:INFO:Initializing create_model()
2024-05-10 14:22:49,620:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:22:49,620:INFO:Checking exceptions
2024-05-10 14:22:49,621:INFO:Importing libraries
2024-05-10 14:22:49,621:INFO:Copying training dataset
2024-05-10 14:22:49,623:INFO:Defining folds
2024-05-10 14:22:49,623:INFO:Declaring metric variables
2024-05-10 14:22:49,623:INFO:Importing untrained model
2024-05-10 14:22:49,623:INFO:Declaring custom model
2024-05-10 14:22:49,624:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:22:49,624:INFO:Starting cross validation
2024-05-10 14:22:49,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:22:49,779:INFO:Calculating mean and std
2024-05-10 14:22:49,779:INFO:Creating metrics dataframe
2024-05-10 14:22:49,780:INFO:Finalizing model
2024-05-10 14:22:49,831:INFO:Uploading results into container
2024-05-10 14:22:49,832:INFO:Uploading model into container now
2024-05-10 14:22:49,832:INFO:_master_model_container: 20
2024-05-10 14:22:49,832:INFO:_display_container: 4
2024-05-10 14:22:49,832:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:49,832:INFO:create_model() successfully completed......................................
2024-05-10 14:22:49,902:INFO:SubProcess create_model() end ==================================
2024-05-10 14:22:49,903:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7241
2024-05-10 14:22:49,903:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6753
2024-05-10 14:22:49,904:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:22:49,904:INFO:choose_better completed
2024-05-10 14:22:49,904:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:22:49,909:INFO:_master_model_container: 20
2024-05-10 14:22:49,910:INFO:_display_container: 3
2024-05-10 14:22:49,910:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:22:49,910:INFO:tune_model() successfully completed......................................
2024-05-10 14:22:49,985:INFO:Initializing evaluate_model()
2024-05-10 14:22:49,985:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:22:49,992:INFO:Initializing plot_model()
2024-05-10 14:22:49,993:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, system=True)
2024-05-10 14:22:49,993:INFO:Checking exceptions
2024-05-10 14:22:50,005:INFO:Preloading libraries
2024-05-10 14:22:50,017:INFO:Copying training dataset
2024-05-10 14:22:50,017:INFO:Plot type: pipeline
2024-05-10 14:22:50,073:INFO:Visual Rendered Successfully
2024-05-10 14:22:50,147:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:52,280:INFO:Initializing plot_model()
2024-05-10 14:22:52,280:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, system=True)
2024-05-10 14:22:52,280:INFO:Checking exceptions
2024-05-10 14:22:52,296:INFO:Preloading libraries
2024-05-10 14:22:52,303:INFO:Copying training dataset
2024-05-10 14:22:52,303:INFO:Plot type: residuals
2024-05-10 14:22:52,350:INFO:Fitting Model
2024-05-10 14:22:52,350:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:22:52,389:INFO:Scoring test/hold-out set
2024-05-10 14:22:52,595:INFO:Visual Rendered Successfully
2024-05-10 14:22:52,669:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:56,035:INFO:Initializing plot_model()
2024-05-10 14:22:56,035:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, system=True)
2024-05-10 14:22:56,035:INFO:Checking exceptions
2024-05-10 14:22:56,054:INFO:Preloading libraries
2024-05-10 14:22:56,061:INFO:Copying training dataset
2024-05-10 14:22:56,061:INFO:Plot type: error
2024-05-10 14:22:56,094:INFO:Fitting Model
2024-05-10 14:22:56,094:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:22:56,094:INFO:Scoring test/hold-out set
2024-05-10 14:22:56,219:INFO:Visual Rendered Successfully
2024-05-10 14:22:56,306:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:57,691:INFO:Initializing plot_model()
2024-05-10 14:22:57,691:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, system=True)
2024-05-10 14:22:57,691:INFO:Checking exceptions
2024-05-10 14:22:57,705:INFO:Preloading libraries
2024-05-10 14:22:57,710:INFO:Copying training dataset
2024-05-10 14:22:57,710:INFO:Plot type: residuals
2024-05-10 14:22:57,753:INFO:Fitting Model
2024-05-10 14:22:57,753:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:22:57,794:INFO:Scoring test/hold-out set
2024-05-10 14:22:57,995:INFO:Visual Rendered Successfully
2024-05-10 14:22:58,074:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:58,679:INFO:Initializing plot_model()
2024-05-10 14:22:58,679:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, system=True)
2024-05-10 14:22:58,679:INFO:Checking exceptions
2024-05-10 14:22:58,692:INFO:Preloading libraries
2024-05-10 14:22:58,698:INFO:Copying training dataset
2024-05-10 14:22:58,698:INFO:Plot type: parameter
2024-05-10 14:22:58,700:INFO:Visual Rendered Successfully
2024-05-10 14:22:58,776:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:59,246:INFO:Initializing plot_model()
2024-05-10 14:22:59,247:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, system=True)
2024-05-10 14:22:59,247:INFO:Checking exceptions
2024-05-10 14:22:59,263:INFO:Preloading libraries
2024-05-10 14:22:59,271:INFO:Copying training dataset
2024-05-10 14:22:59,271:INFO:Plot type: residuals
2024-05-10 14:22:59,316:INFO:Fitting Model
2024-05-10 14:22:59,317:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:22:59,356:INFO:Scoring test/hold-out set
2024-05-10 14:22:59,563:INFO:Visual Rendered Successfully
2024-05-10 14:22:59,641:INFO:plot_model() successfully completed......................................
2024-05-10 14:22:59,657:INFO:Initializing plot_model()
2024-05-10 14:22:59,657:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccaef1c10>, system=True)
2024-05-10 14:22:59,657:INFO:Checking exceptions
2024-05-10 14:22:59,668:INFO:Preloading libraries
2024-05-10 14:22:59,675:INFO:Copying training dataset
2024-05-10 14:22:59,675:INFO:Plot type: error
2024-05-10 14:22:59,710:INFO:Fitting Model
2024-05-10 14:22:59,710:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:22:59,710:INFO:Scoring test/hold-out set
2024-05-10 14:22:59,840:INFO:Visual Rendered Successfully
2024-05-10 14:22:59,917:INFO:plot_model() successfully completed......................................
2024-05-10 14:23:46,762:INFO:PyCaret RegressionExperiment
2024-05-10 14:23:46,762:INFO:Logging name: reg-default-name
2024-05-10 14:23:46,763:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:23:46,763:INFO:version 3.3.2
2024-05-10 14:23:46,763:INFO:Initializing setup()
2024-05-10 14:23:46,763:INFO:self.USI: d861
2024-05-10 14:23:46,763:INFO:self._variable_keys: {'X', 'target_param', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'n_jobs_param', 'USI', 'pipeline', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'data', '_ml_usecase', 'fold_shuffle_param', 'X_test', '_available_plots', 'exp_id', 'logging_param', 'transform_target_param', 'fold_generator', 'memory', 'html_param', 'gpu_param', 'y_test', 'seed', 'y'}
2024-05-10 14:23:46,763:INFO:Checking environment
2024-05-10 14:23:46,763:INFO:python_version: 3.9.18
2024-05-10 14:23:46,763:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:23:46,763:INFO:machine: x86_64
2024-05-10 14:23:46,763:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:23:46,763:INFO:Memory: svmem(total=16429797376, available=5972377600, percent=63.6, used=9280573440, free=300556288, active=9602170880, inactive=5149933568, buffers=266301440, cached=6582366208, shared=838729728, slab=796618752)
2024-05-10 14:23:46,764:INFO:Physical Core: 12
2024-05-10 14:23:46,764:INFO:Logical Core: 16
2024-05-10 14:23:46,764:INFO:Checking libraries
2024-05-10 14:23:46,764:INFO:System:
2024-05-10 14:23:46,764:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:23:46,764:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:23:46,764:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:23:46,764:INFO:PyCaret required dependencies:
2024-05-10 14:23:46,764:INFO:                 pip: 23.3.1
2024-05-10 14:23:46,764:INFO:          setuptools: 68.2.2
2024-05-10 14:23:46,764:INFO:             pycaret: 3.3.2
2024-05-10 14:23:46,764:INFO:             IPython: 8.15.0
2024-05-10 14:23:46,764:INFO:          ipywidgets: 7.6.5
2024-05-10 14:23:46,764:INFO:                tqdm: 4.65.0
2024-05-10 14:23:46,764:INFO:               numpy: 1.26.4
2024-05-10 14:23:46,764:INFO:              pandas: 2.1.4
2024-05-10 14:23:46,764:INFO:              jinja2: 3.1.3
2024-05-10 14:23:46,764:INFO:               scipy: 1.11.4
2024-05-10 14:23:46,764:INFO:              joblib: 1.2.0
2024-05-10 14:23:46,764:INFO:             sklearn: 1.4.2
2024-05-10 14:23:46,764:INFO:                pyod: 1.1.3
2024-05-10 14:23:46,764:INFO:            imblearn: 0.12.2
2024-05-10 14:23:46,764:INFO:   category_encoders: 2.6.3
2024-05-10 14:23:46,764:INFO:            lightgbm: 4.3.0
2024-05-10 14:23:46,764:INFO:               numba: 0.59.1
2024-05-10 14:23:46,764:INFO:            requests: 2.31.0
2024-05-10 14:23:46,764:INFO:          matplotlib: 3.7.5
2024-05-10 14:23:46,764:INFO:          scikitplot: 0.3.7
2024-05-10 14:23:46,764:INFO:         yellowbrick: 1.5
2024-05-10 14:23:46,764:INFO:              plotly: 5.19.0
2024-05-10 14:23:46,764:INFO:    plotly-resampler: Not installed
2024-05-10 14:23:46,764:INFO:             kaleido: 0.2.1
2024-05-10 14:23:46,764:INFO:           schemdraw: 0.15
2024-05-10 14:23:46,764:INFO:         statsmodels: 0.14.0
2024-05-10 14:23:46,764:INFO:              sktime: 0.26.0
2024-05-10 14:23:46,764:INFO:               tbats: 1.1.3
2024-05-10 14:23:46,764:INFO:            pmdarima: 2.0.4
2024-05-10 14:23:46,764:INFO:              psutil: 5.9.0
2024-05-10 14:23:46,764:INFO:          markupsafe: 2.1.3
2024-05-10 14:23:46,765:INFO:             pickle5: Not installed
2024-05-10 14:23:46,765:INFO:         cloudpickle: 2.2.1
2024-05-10 14:23:46,765:INFO:         deprecation: 2.1.0
2024-05-10 14:23:46,765:INFO:              xxhash: 3.4.1
2024-05-10 14:23:46,765:INFO:           wurlitzer: 3.0.2
2024-05-10 14:23:46,765:INFO:PyCaret optional dependencies:
2024-05-10 14:23:46,765:INFO:                shap: Not installed
2024-05-10 14:23:46,765:INFO:           interpret: Not installed
2024-05-10 14:23:46,765:INFO:                umap: Not installed
2024-05-10 14:23:46,765:INFO:     ydata_profiling: Not installed
2024-05-10 14:23:46,765:INFO:  explainerdashboard: Not installed
2024-05-10 14:23:46,765:INFO:             autoviz: Not installed
2024-05-10 14:23:46,765:INFO:           fairlearn: Not installed
2024-05-10 14:23:46,765:INFO:          deepchecks: Not installed
2024-05-10 14:23:46,765:INFO:             xgboost: Not installed
2024-05-10 14:23:46,765:INFO:            catboost: Not installed
2024-05-10 14:23:46,765:INFO:              kmodes: Not installed
2024-05-10 14:23:46,765:INFO:             mlxtend: Not installed
2024-05-10 14:23:46,765:INFO:       statsforecast: Not installed
2024-05-10 14:23:46,765:INFO:        tune_sklearn: Not installed
2024-05-10 14:23:46,765:INFO:                 ray: Not installed
2024-05-10 14:23:46,765:INFO:            hyperopt: Not installed
2024-05-10 14:23:46,765:INFO:              optuna: Not installed
2024-05-10 14:23:46,765:INFO:               skopt: Not installed
2024-05-10 14:23:46,765:INFO:              mlflow: Not installed
2024-05-10 14:23:46,765:INFO:              gradio: Not installed
2024-05-10 14:23:46,765:INFO:             fastapi: Not installed
2024-05-10 14:23:46,765:INFO:             uvicorn: Not installed
2024-05-10 14:23:46,765:INFO:              m2cgen: Not installed
2024-05-10 14:23:46,765:INFO:           evidently: Not installed
2024-05-10 14:23:46,765:INFO:               fugue: Not installed
2024-05-10 14:23:46,765:INFO:           streamlit: 1.32.0
2024-05-10 14:23:46,765:INFO:             prophet: Not installed
2024-05-10 14:23:46,765:INFO:None
2024-05-10 14:23:46,765:INFO:Set up data.
2024-05-10 14:23:46,768:INFO:Set up folding strategy.
2024-05-10 14:23:46,768:INFO:Set up train/test split.
2024-05-10 14:23:46,770:INFO:Set up index.
2024-05-10 14:23:46,770:INFO:Assigning column types.
2024-05-10 14:23:46,771:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:23:46,772:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,774:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,777:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,823:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:46,824:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:46,824:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,826:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,828:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,853:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:46,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:46,873:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:23:46,876:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,877:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,903:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,922:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,923:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:46,923:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:46,925:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,927:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,953:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,973:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:23:46,973:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:46,974:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:46,974:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:23:46,978:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,004:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,024:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,024:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,024:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,029:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,076:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,077:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,077:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,077:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:23:47,107:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,127:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,157:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,177:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,177:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,178:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,178:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:23:47,207:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,228:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,228:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,258:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:23:47,279:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,279:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,279:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:23:47,329:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,330:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,380:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,380:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,381:INFO:Preparing preprocessing pipeline...
2024-05-10 14:23:47,381:INFO:Set up simple imputation.
2024-05-10 14:23:47,382:INFO:Set up column name cleaning.
2024-05-10 14:23:47,392:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:23:47,394:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:23:47,394:INFO:Creating final display dataframe.
2024-05-10 14:23:47,429:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (576, 7)
4        Transformed data shape          (576, 7)
5   Transformed train set shape          (345, 7)
6    Transformed test set shape          (231, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d861
2024-05-10 14:23:47,489:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,490:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:23:47,541:INFO:setup() successfully completed in 0.78s...............
2024-05-10 14:23:47,541:INFO:Initializing compare_models()
2024-05-10 14:23:47,541:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:23:47,541:INFO:Checking exceptions
2024-05-10 14:23:47,542:INFO:Preparing display monitor
2024-05-10 14:23:47,555:INFO:Initializing Linear Regression
2024-05-10 14:23:47,555:INFO:Total runtime is 2.193450927734375e-06 minutes
2024-05-10 14:23:47,557:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:47,557:INFO:Initializing create_model()
2024-05-10 14:23:47,557:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:47,557:INFO:Checking exceptions
2024-05-10 14:23:47,557:INFO:Importing libraries
2024-05-10 14:23:47,557:INFO:Copying training dataset
2024-05-10 14:23:47,560:INFO:Defining folds
2024-05-10 14:23:47,560:INFO:Declaring metric variables
2024-05-10 14:23:47,562:INFO:Importing untrained model
2024-05-10 14:23:47,564:INFO:Linear Regression Imported successfully
2024-05-10 14:23:47,567:INFO:Starting cross validation
2024-05-10 14:23:47,568:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:47,614:INFO:Calculating mean and std
2024-05-10 14:23:47,614:INFO:Creating metrics dataframe
2024-05-10 14:23:47,616:INFO:Uploading results into container
2024-05-10 14:23:47,616:INFO:Uploading model into container now
2024-05-10 14:23:47,617:INFO:_master_model_container: 1
2024-05-10 14:23:47,617:INFO:_display_container: 2
2024-05-10 14:23:47,617:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:23:47,617:INFO:create_model() successfully completed......................................
2024-05-10 14:23:47,693:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:47,693:INFO:Creating metrics dataframe
2024-05-10 14:23:47,697:INFO:Initializing Lasso Regression
2024-05-10 14:23:47,697:INFO:Total runtime is 0.0023676435152689616 minutes
2024-05-10 14:23:47,699:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:47,699:INFO:Initializing create_model()
2024-05-10 14:23:47,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:47,699:INFO:Checking exceptions
2024-05-10 14:23:47,699:INFO:Importing libraries
2024-05-10 14:23:47,699:INFO:Copying training dataset
2024-05-10 14:23:47,701:INFO:Defining folds
2024-05-10 14:23:47,701:INFO:Declaring metric variables
2024-05-10 14:23:47,704:INFO:Importing untrained model
2024-05-10 14:23:47,706:INFO:Lasso Regression Imported successfully
2024-05-10 14:23:47,709:INFO:Starting cross validation
2024-05-10 14:23:47,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:47,754:INFO:Calculating mean and std
2024-05-10 14:23:47,754:INFO:Creating metrics dataframe
2024-05-10 14:23:47,755:INFO:Uploading results into container
2024-05-10 14:23:47,755:INFO:Uploading model into container now
2024-05-10 14:23:47,756:INFO:_master_model_container: 2
2024-05-10 14:23:47,756:INFO:_display_container: 2
2024-05-10 14:23:47,756:INFO:Lasso(random_state=123)
2024-05-10 14:23:47,756:INFO:create_model() successfully completed......................................
2024-05-10 14:23:47,828:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:47,828:INFO:Creating metrics dataframe
2024-05-10 14:23:47,832:INFO:Initializing Ridge Regression
2024-05-10 14:23:47,832:INFO:Total runtime is 0.004627494017283122 minutes
2024-05-10 14:23:47,834:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:47,834:INFO:Initializing create_model()
2024-05-10 14:23:47,834:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:47,835:INFO:Checking exceptions
2024-05-10 14:23:47,835:INFO:Importing libraries
2024-05-10 14:23:47,835:INFO:Copying training dataset
2024-05-10 14:23:47,837:INFO:Defining folds
2024-05-10 14:23:47,837:INFO:Declaring metric variables
2024-05-10 14:23:47,839:INFO:Importing untrained model
2024-05-10 14:23:47,841:INFO:Ridge Regression Imported successfully
2024-05-10 14:23:47,844:INFO:Starting cross validation
2024-05-10 14:23:47,845:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:47,902:INFO:Calculating mean and std
2024-05-10 14:23:47,902:INFO:Creating metrics dataframe
2024-05-10 14:23:47,904:INFO:Uploading results into container
2024-05-10 14:23:47,904:INFO:Uploading model into container now
2024-05-10 14:23:47,904:INFO:_master_model_container: 3
2024-05-10 14:23:47,904:INFO:_display_container: 2
2024-05-10 14:23:47,905:INFO:Ridge(random_state=123)
2024-05-10 14:23:47,905:INFO:create_model() successfully completed......................................
2024-05-10 14:23:47,977:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:47,978:INFO:Creating metrics dataframe
2024-05-10 14:23:47,983:INFO:Initializing Elastic Net
2024-05-10 14:23:47,983:INFO:Total runtime is 0.007145245869954428 minutes
2024-05-10 14:23:47,986:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:47,986:INFO:Initializing create_model()
2024-05-10 14:23:47,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:47,987:INFO:Checking exceptions
2024-05-10 14:23:47,987:INFO:Importing libraries
2024-05-10 14:23:47,987:INFO:Copying training dataset
2024-05-10 14:23:47,989:INFO:Defining folds
2024-05-10 14:23:47,989:INFO:Declaring metric variables
2024-05-10 14:23:47,991:INFO:Importing untrained model
2024-05-10 14:23:47,993:INFO:Elastic Net Imported successfully
2024-05-10 14:23:47,996:INFO:Starting cross validation
2024-05-10 14:23:47,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:48,048:INFO:Calculating mean and std
2024-05-10 14:23:48,048:INFO:Creating metrics dataframe
2024-05-10 14:23:48,050:INFO:Uploading results into container
2024-05-10 14:23:48,050:INFO:Uploading model into container now
2024-05-10 14:23:48,050:INFO:_master_model_container: 4
2024-05-10 14:23:48,050:INFO:_display_container: 2
2024-05-10 14:23:48,051:INFO:ElasticNet(random_state=123)
2024-05-10 14:23:48,051:INFO:create_model() successfully completed......................................
2024-05-10 14:23:48,123:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:48,123:INFO:Creating metrics dataframe
2024-05-10 14:23:48,127:INFO:Initializing Least Angle Regression
2024-05-10 14:23:48,127:INFO:Total runtime is 0.009535590807596844 minutes
2024-05-10 14:23:48,129:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:48,129:INFO:Initializing create_model()
2024-05-10 14:23:48,129:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:48,129:INFO:Checking exceptions
2024-05-10 14:23:48,129:INFO:Importing libraries
2024-05-10 14:23:48,129:INFO:Copying training dataset
2024-05-10 14:23:48,131:INFO:Defining folds
2024-05-10 14:23:48,132:INFO:Declaring metric variables
2024-05-10 14:23:48,133:INFO:Importing untrained model
2024-05-10 14:23:48,135:INFO:Least Angle Regression Imported successfully
2024-05-10 14:23:48,140:INFO:Starting cross validation
2024-05-10 14:23:48,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:48,187:INFO:Calculating mean and std
2024-05-10 14:23:48,187:INFO:Creating metrics dataframe
2024-05-10 14:23:48,188:INFO:Uploading results into container
2024-05-10 14:23:48,188:INFO:Uploading model into container now
2024-05-10 14:23:48,189:INFO:_master_model_container: 5
2024-05-10 14:23:48,189:INFO:_display_container: 2
2024-05-10 14:23:48,189:INFO:Lars(random_state=123)
2024-05-10 14:23:48,189:INFO:create_model() successfully completed......................................
2024-05-10 14:23:48,264:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:48,265:INFO:Creating metrics dataframe
2024-05-10 14:23:48,269:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:23:48,269:INFO:Total runtime is 0.011911304791768393 minutes
2024-05-10 14:23:48,272:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:48,272:INFO:Initializing create_model()
2024-05-10 14:23:48,272:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:48,272:INFO:Checking exceptions
2024-05-10 14:23:48,272:INFO:Importing libraries
2024-05-10 14:23:48,272:INFO:Copying training dataset
2024-05-10 14:23:48,274:INFO:Defining folds
2024-05-10 14:23:48,274:INFO:Declaring metric variables
2024-05-10 14:23:48,276:INFO:Importing untrained model
2024-05-10 14:23:48,277:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:23:48,282:INFO:Starting cross validation
2024-05-10 14:23:48,283:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:48,326:INFO:Calculating mean and std
2024-05-10 14:23:48,326:INFO:Creating metrics dataframe
2024-05-10 14:23:48,327:INFO:Uploading results into container
2024-05-10 14:23:48,328:INFO:Uploading model into container now
2024-05-10 14:23:48,328:INFO:_master_model_container: 6
2024-05-10 14:23:48,328:INFO:_display_container: 2
2024-05-10 14:23:48,328:INFO:LassoLars(random_state=123)
2024-05-10 14:23:48,328:INFO:create_model() successfully completed......................................
2024-05-10 14:23:48,398:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:48,399:INFO:Creating metrics dataframe
2024-05-10 14:23:48,403:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:23:48,403:INFO:Total runtime is 0.014139954249064128 minutes
2024-05-10 14:23:48,405:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:48,405:INFO:Initializing create_model()
2024-05-10 14:23:48,405:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:48,405:INFO:Checking exceptions
2024-05-10 14:23:48,405:INFO:Importing libraries
2024-05-10 14:23:48,405:INFO:Copying training dataset
2024-05-10 14:23:48,407:INFO:Defining folds
2024-05-10 14:23:48,407:INFO:Declaring metric variables
2024-05-10 14:23:48,409:INFO:Importing untrained model
2024-05-10 14:23:48,411:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:23:48,415:INFO:Starting cross validation
2024-05-10 14:23:48,415:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:48,460:INFO:Calculating mean and std
2024-05-10 14:23:48,460:INFO:Creating metrics dataframe
2024-05-10 14:23:48,461:INFO:Uploading results into container
2024-05-10 14:23:48,461:INFO:Uploading model into container now
2024-05-10 14:23:48,461:INFO:_master_model_container: 7
2024-05-10 14:23:48,461:INFO:_display_container: 2
2024-05-10 14:23:48,462:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:23:48,462:INFO:create_model() successfully completed......................................
2024-05-10 14:23:48,534:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:48,535:INFO:Creating metrics dataframe
2024-05-10 14:23:48,539:INFO:Initializing Bayesian Ridge
2024-05-10 14:23:48,539:INFO:Total runtime is 0.01641204357147217 minutes
2024-05-10 14:23:48,541:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:48,542:INFO:Initializing create_model()
2024-05-10 14:23:48,542:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:48,542:INFO:Checking exceptions
2024-05-10 14:23:48,542:INFO:Importing libraries
2024-05-10 14:23:48,542:INFO:Copying training dataset
2024-05-10 14:23:48,544:INFO:Defining folds
2024-05-10 14:23:48,544:INFO:Declaring metric variables
2024-05-10 14:23:48,545:INFO:Importing untrained model
2024-05-10 14:23:48,547:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:23:48,550:INFO:Starting cross validation
2024-05-10 14:23:48,551:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:48,599:INFO:Calculating mean and std
2024-05-10 14:23:48,599:INFO:Creating metrics dataframe
2024-05-10 14:23:48,600:INFO:Uploading results into container
2024-05-10 14:23:48,600:INFO:Uploading model into container now
2024-05-10 14:23:48,601:INFO:_master_model_container: 8
2024-05-10 14:23:48,601:INFO:_display_container: 2
2024-05-10 14:23:48,601:INFO:BayesianRidge()
2024-05-10 14:23:48,601:INFO:create_model() successfully completed......................................
2024-05-10 14:23:48,678:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:48,678:INFO:Creating metrics dataframe
2024-05-10 14:23:48,683:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:23:48,683:INFO:Total runtime is 0.018808058897654217 minutes
2024-05-10 14:23:48,685:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:48,685:INFO:Initializing create_model()
2024-05-10 14:23:48,686:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:48,686:INFO:Checking exceptions
2024-05-10 14:23:48,686:INFO:Importing libraries
2024-05-10 14:23:48,686:INFO:Copying training dataset
2024-05-10 14:23:48,688:INFO:Defining folds
2024-05-10 14:23:48,688:INFO:Declaring metric variables
2024-05-10 14:23:48,690:INFO:Importing untrained model
2024-05-10 14:23:48,692:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:23:48,695:INFO:Starting cross validation
2024-05-10 14:23:48,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:48,742:INFO:Calculating mean and std
2024-05-10 14:23:48,742:INFO:Creating metrics dataframe
2024-05-10 14:23:48,743:INFO:Uploading results into container
2024-05-10 14:23:48,744:INFO:Uploading model into container now
2024-05-10 14:23:48,744:INFO:_master_model_container: 9
2024-05-10 14:23:48,744:INFO:_display_container: 2
2024-05-10 14:23:48,744:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:23:48,744:INFO:create_model() successfully completed......................................
2024-05-10 14:23:48,817:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:48,817:INFO:Creating metrics dataframe
2024-05-10 14:23:48,822:INFO:Initializing Huber Regressor
2024-05-10 14:23:48,822:INFO:Total runtime is 0.021126023928324383 minutes
2024-05-10 14:23:48,824:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:48,825:INFO:Initializing create_model()
2024-05-10 14:23:48,825:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:48,825:INFO:Checking exceptions
2024-05-10 14:23:48,825:INFO:Importing libraries
2024-05-10 14:23:48,825:INFO:Copying training dataset
2024-05-10 14:23:48,827:INFO:Defining folds
2024-05-10 14:23:48,827:INFO:Declaring metric variables
2024-05-10 14:23:48,828:INFO:Importing untrained model
2024-05-10 14:23:48,830:INFO:Huber Regressor Imported successfully
2024-05-10 14:23:48,833:INFO:Starting cross validation
2024-05-10 14:23:48,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:48,865:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:23:48,875:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:23:48,876:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:23:48,880:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:23:48,881:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:23:48,887:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:23:48,889:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:23:48,894:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:23:48,899:INFO:Calculating mean and std
2024-05-10 14:23:48,899:INFO:Creating metrics dataframe
2024-05-10 14:23:48,901:INFO:Uploading results into container
2024-05-10 14:23:48,901:INFO:Uploading model into container now
2024-05-10 14:23:48,902:INFO:_master_model_container: 10
2024-05-10 14:23:48,902:INFO:_display_container: 2
2024-05-10 14:23:48,902:INFO:HuberRegressor()
2024-05-10 14:23:48,902:INFO:create_model() successfully completed......................................
2024-05-10 14:23:48,980:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:48,980:INFO:Creating metrics dataframe
2024-05-10 14:23:48,985:INFO:Initializing K Neighbors Regressor
2024-05-10 14:23:48,986:INFO:Total runtime is 0.023846741517384848 minutes
2024-05-10 14:23:48,988:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:48,988:INFO:Initializing create_model()
2024-05-10 14:23:48,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:48,988:INFO:Checking exceptions
2024-05-10 14:23:48,988:INFO:Importing libraries
2024-05-10 14:23:48,988:INFO:Copying training dataset
2024-05-10 14:23:48,992:INFO:Defining folds
2024-05-10 14:23:48,993:INFO:Declaring metric variables
2024-05-10 14:23:48,995:INFO:Importing untrained model
2024-05-10 14:23:48,998:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:23:49,004:INFO:Starting cross validation
2024-05-10 14:23:49,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:49,059:INFO:Calculating mean and std
2024-05-10 14:23:49,060:INFO:Creating metrics dataframe
2024-05-10 14:23:49,061:INFO:Uploading results into container
2024-05-10 14:23:49,061:INFO:Uploading model into container now
2024-05-10 14:23:49,061:INFO:_master_model_container: 11
2024-05-10 14:23:49,061:INFO:_display_container: 2
2024-05-10 14:23:49,061:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:23:49,061:INFO:create_model() successfully completed......................................
2024-05-10 14:23:49,133:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:49,133:INFO:Creating metrics dataframe
2024-05-10 14:23:49,138:INFO:Initializing Decision Tree Regressor
2024-05-10 14:23:49,138:INFO:Total runtime is 0.026385573546091716 minutes
2024-05-10 14:23:49,140:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:49,140:INFO:Initializing create_model()
2024-05-10 14:23:49,141:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:49,141:INFO:Checking exceptions
2024-05-10 14:23:49,141:INFO:Importing libraries
2024-05-10 14:23:49,141:INFO:Copying training dataset
2024-05-10 14:23:49,143:INFO:Defining folds
2024-05-10 14:23:49,143:INFO:Declaring metric variables
2024-05-10 14:23:49,145:INFO:Importing untrained model
2024-05-10 14:23:49,147:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:23:49,150:INFO:Starting cross validation
2024-05-10 14:23:49,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:49,192:INFO:Calculating mean and std
2024-05-10 14:23:49,192:INFO:Creating metrics dataframe
2024-05-10 14:23:49,193:INFO:Uploading results into container
2024-05-10 14:23:49,193:INFO:Uploading model into container now
2024-05-10 14:23:49,194:INFO:_master_model_container: 12
2024-05-10 14:23:49,194:INFO:_display_container: 2
2024-05-10 14:23:49,194:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:23:49,194:INFO:create_model() successfully completed......................................
2024-05-10 14:23:49,267:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:49,267:INFO:Creating metrics dataframe
2024-05-10 14:23:49,272:INFO:Initializing Random Forest Regressor
2024-05-10 14:23:49,273:INFO:Total runtime is 0.02862924337387085 minutes
2024-05-10 14:23:49,275:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:49,275:INFO:Initializing create_model()
2024-05-10 14:23:49,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:49,275:INFO:Checking exceptions
2024-05-10 14:23:49,275:INFO:Importing libraries
2024-05-10 14:23:49,275:INFO:Copying training dataset
2024-05-10 14:23:49,277:INFO:Defining folds
2024-05-10 14:23:49,277:INFO:Declaring metric variables
2024-05-10 14:23:49,279:INFO:Importing untrained model
2024-05-10 14:23:49,281:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:23:49,285:INFO:Starting cross validation
2024-05-10 14:23:49,285:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:49,545:INFO:Calculating mean and std
2024-05-10 14:23:49,545:INFO:Creating metrics dataframe
2024-05-10 14:23:49,547:INFO:Uploading results into container
2024-05-10 14:23:49,547:INFO:Uploading model into container now
2024-05-10 14:23:49,548:INFO:_master_model_container: 13
2024-05-10 14:23:49,548:INFO:_display_container: 2
2024-05-10 14:23:49,548:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:23:49,548:INFO:create_model() successfully completed......................................
2024-05-10 14:23:49,623:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:49,623:INFO:Creating metrics dataframe
2024-05-10 14:23:49,629:INFO:Initializing Extra Trees Regressor
2024-05-10 14:23:49,629:INFO:Total runtime is 0.03457072575887044 minutes
2024-05-10 14:23:49,631:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:49,631:INFO:Initializing create_model()
2024-05-10 14:23:49,631:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:49,631:INFO:Checking exceptions
2024-05-10 14:23:49,631:INFO:Importing libraries
2024-05-10 14:23:49,631:INFO:Copying training dataset
2024-05-10 14:23:49,633:INFO:Defining folds
2024-05-10 14:23:49,633:INFO:Declaring metric variables
2024-05-10 14:23:49,635:INFO:Importing untrained model
2024-05-10 14:23:49,637:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:23:49,642:INFO:Starting cross validation
2024-05-10 14:23:49,642:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:49,807:INFO:Calculating mean and std
2024-05-10 14:23:49,808:INFO:Creating metrics dataframe
2024-05-10 14:23:49,809:INFO:Uploading results into container
2024-05-10 14:23:49,809:INFO:Uploading model into container now
2024-05-10 14:23:49,810:INFO:_master_model_container: 14
2024-05-10 14:23:49,810:INFO:_display_container: 2
2024-05-10 14:23:49,810:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:23:49,810:INFO:create_model() successfully completed......................................
2024-05-10 14:23:49,883:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:49,883:INFO:Creating metrics dataframe
2024-05-10 14:23:49,889:INFO:Initializing AdaBoost Regressor
2024-05-10 14:23:49,889:INFO:Total runtime is 0.038908012708028156 minutes
2024-05-10 14:23:49,892:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:49,892:INFO:Initializing create_model()
2024-05-10 14:23:49,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:49,892:INFO:Checking exceptions
2024-05-10 14:23:49,892:INFO:Importing libraries
2024-05-10 14:23:49,892:INFO:Copying training dataset
2024-05-10 14:23:49,894:INFO:Defining folds
2024-05-10 14:23:49,894:INFO:Declaring metric variables
2024-05-10 14:23:49,896:INFO:Importing untrained model
2024-05-10 14:23:49,898:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:23:49,901:INFO:Starting cross validation
2024-05-10 14:23:49,902:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:49,988:INFO:Calculating mean and std
2024-05-10 14:23:49,989:INFO:Creating metrics dataframe
2024-05-10 14:23:49,991:INFO:Uploading results into container
2024-05-10 14:23:49,991:INFO:Uploading model into container now
2024-05-10 14:23:49,992:INFO:_master_model_container: 15
2024-05-10 14:23:49,992:INFO:_display_container: 2
2024-05-10 14:23:49,992:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:23:49,992:INFO:create_model() successfully completed......................................
2024-05-10 14:23:50,066:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:50,066:INFO:Creating metrics dataframe
2024-05-10 14:23:50,072:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:23:50,072:INFO:Total runtime is 0.04194910923639933 minutes
2024-05-10 14:23:50,073:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:50,074:INFO:Initializing create_model()
2024-05-10 14:23:50,074:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:50,074:INFO:Checking exceptions
2024-05-10 14:23:50,074:INFO:Importing libraries
2024-05-10 14:23:50,074:INFO:Copying training dataset
2024-05-10 14:23:50,076:INFO:Defining folds
2024-05-10 14:23:50,076:INFO:Declaring metric variables
2024-05-10 14:23:50,078:INFO:Importing untrained model
2024-05-10 14:23:50,079:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:23:50,083:INFO:Starting cross validation
2024-05-10 14:23:50,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:50,236:INFO:Calculating mean and std
2024-05-10 14:23:50,236:INFO:Creating metrics dataframe
2024-05-10 14:23:50,238:INFO:Uploading results into container
2024-05-10 14:23:50,238:INFO:Uploading model into container now
2024-05-10 14:23:50,238:INFO:_master_model_container: 16
2024-05-10 14:23:50,238:INFO:_display_container: 2
2024-05-10 14:23:50,239:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:23:50,239:INFO:create_model() successfully completed......................................
2024-05-10 14:23:50,312:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:50,312:INFO:Creating metrics dataframe
2024-05-10 14:23:50,318:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:23:50,318:INFO:Total runtime is 0.046047306060791014 minutes
2024-05-10 14:23:50,319:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:50,320:INFO:Initializing create_model()
2024-05-10 14:23:50,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:50,320:INFO:Checking exceptions
2024-05-10 14:23:50,320:INFO:Importing libraries
2024-05-10 14:23:50,320:INFO:Copying training dataset
2024-05-10 14:23:50,322:INFO:Defining folds
2024-05-10 14:23:50,322:INFO:Declaring metric variables
2024-05-10 14:23:50,324:INFO:Importing untrained model
2024-05-10 14:23:50,326:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:23:50,330:INFO:Starting cross validation
2024-05-10 14:23:50,330:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:50,854:INFO:Calculating mean and std
2024-05-10 14:23:50,855:INFO:Creating metrics dataframe
2024-05-10 14:23:50,857:INFO:Uploading results into container
2024-05-10 14:23:50,857:INFO:Uploading model into container now
2024-05-10 14:23:50,857:INFO:_master_model_container: 17
2024-05-10 14:23:50,857:INFO:_display_container: 2
2024-05-10 14:23:50,858:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:23:50,858:INFO:create_model() successfully completed......................................
2024-05-10 14:23:50,931:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:50,931:INFO:Creating metrics dataframe
2024-05-10 14:23:50,937:INFO:Initializing Dummy Regressor
2024-05-10 14:23:50,938:INFO:Total runtime is 0.056380617618560794 minutes
2024-05-10 14:23:50,940:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:50,941:INFO:Initializing create_model()
2024-05-10 14:23:50,941:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc9467c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:50,941:INFO:Checking exceptions
2024-05-10 14:23:50,941:INFO:Importing libraries
2024-05-10 14:23:50,941:INFO:Copying training dataset
2024-05-10 14:23:50,943:INFO:Defining folds
2024-05-10 14:23:50,943:INFO:Declaring metric variables
2024-05-10 14:23:50,945:INFO:Importing untrained model
2024-05-10 14:23:50,947:INFO:Dummy Regressor Imported successfully
2024-05-10 14:23:50,950:INFO:Starting cross validation
2024-05-10 14:23:50,951:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:50,994:INFO:Calculating mean and std
2024-05-10 14:23:50,995:INFO:Creating metrics dataframe
2024-05-10 14:23:50,996:INFO:Uploading results into container
2024-05-10 14:23:50,996:INFO:Uploading model into container now
2024-05-10 14:23:50,997:INFO:_master_model_container: 18
2024-05-10 14:23:50,997:INFO:_display_container: 2
2024-05-10 14:23:50,997:INFO:DummyRegressor()
2024-05-10 14:23:50,997:INFO:create_model() successfully completed......................................
2024-05-10 14:23:51,068:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:51,068:INFO:Creating metrics dataframe
2024-05-10 14:23:51,074:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:23:51,078:INFO:Initializing create_model()
2024-05-10 14:23:51,078:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:51,078:INFO:Checking exceptions
2024-05-10 14:23:51,079:INFO:Importing libraries
2024-05-10 14:23:51,079:INFO:Copying training dataset
2024-05-10 14:23:51,081:INFO:Defining folds
2024-05-10 14:23:51,081:INFO:Declaring metric variables
2024-05-10 14:23:51,081:INFO:Importing untrained model
2024-05-10 14:23:51,081:INFO:Declaring custom model
2024-05-10 14:23:51,081:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:23:51,082:INFO:Cross validation set to False
2024-05-10 14:23:51,082:INFO:Fitting Model
2024-05-10 14:23:51,136:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:23:51,136:INFO:create_model() successfully completed......................................
2024-05-10 14:23:51,226:INFO:_master_model_container: 18
2024-05-10 14:23:51,226:INFO:_display_container: 2
2024-05-10 14:23:51,226:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:23:51,226:INFO:compare_models() successfully completed......................................
2024-05-10 14:23:51,226:INFO:Initializing tune_model()
2024-05-10 14:23:51,227:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>)
2024-05-10 14:23:51,227:INFO:Checking exceptions
2024-05-10 14:23:51,235:INFO:Copying training dataset
2024-05-10 14:23:51,237:INFO:Checking base model
2024-05-10 14:23:51,237:INFO:Base model : Extra Trees Regressor
2024-05-10 14:23:51,241:INFO:Declaring metric variables
2024-05-10 14:23:51,244:INFO:Defining Hyperparameters
2024-05-10 14:23:51,335:INFO:Tuning with n_jobs=-1
2024-05-10 14:23:51,335:INFO:Initializing RandomizedSearchCV
2024-05-10 14:23:53,129:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:23:53,130:INFO:Hyperparameter search completed
2024-05-10 14:23:53,130:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:53,130:INFO:Initializing create_model()
2024-05-10 14:23:53,130:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc3615b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:23:53,131:INFO:Checking exceptions
2024-05-10 14:23:53,131:INFO:Importing libraries
2024-05-10 14:23:53,131:INFO:Copying training dataset
2024-05-10 14:23:53,133:INFO:Defining folds
2024-05-10 14:23:53,133:INFO:Declaring metric variables
2024-05-10 14:23:53,136:INFO:Importing untrained model
2024-05-10 14:23:53,136:INFO:Declaring custom model
2024-05-10 14:23:53,139:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:23:53,142:INFO:Starting cross validation
2024-05-10 14:23:53,143:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:53,407:INFO:Calculating mean and std
2024-05-10 14:23:53,408:INFO:Creating metrics dataframe
2024-05-10 14:23:53,413:INFO:Finalizing model
2024-05-10 14:23:53,545:INFO:Uploading results into container
2024-05-10 14:23:53,545:INFO:Uploading model into container now
2024-05-10 14:23:53,545:INFO:_master_model_container: 19
2024-05-10 14:23:53,545:INFO:_display_container: 3
2024-05-10 14:23:53,546:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:23:53,546:INFO:create_model() successfully completed......................................
2024-05-10 14:23:53,619:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:53,619:INFO:choose_better activated
2024-05-10 14:23:53,622:INFO:SubProcess create_model() called ==================================
2024-05-10 14:23:53,622:INFO:Initializing create_model()
2024-05-10 14:23:53,622:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:23:53,622:INFO:Checking exceptions
2024-05-10 14:23:53,623:INFO:Importing libraries
2024-05-10 14:23:53,624:INFO:Copying training dataset
2024-05-10 14:23:53,626:INFO:Defining folds
2024-05-10 14:23:53,626:INFO:Declaring metric variables
2024-05-10 14:23:53,626:INFO:Importing untrained model
2024-05-10 14:23:53,626:INFO:Declaring custom model
2024-05-10 14:23:53,626:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:23:53,627:INFO:Starting cross validation
2024-05-10 14:23:53,627:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:23:53,796:INFO:Calculating mean and std
2024-05-10 14:23:53,796:INFO:Creating metrics dataframe
2024-05-10 14:23:53,798:INFO:Finalizing model
2024-05-10 14:23:53,850:INFO:Uploading results into container
2024-05-10 14:23:53,851:INFO:Uploading model into container now
2024-05-10 14:23:53,851:INFO:_master_model_container: 20
2024-05-10 14:23:53,851:INFO:_display_container: 4
2024-05-10 14:23:53,851:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:23:53,851:INFO:create_model() successfully completed......................................
2024-05-10 14:23:53,926:INFO:SubProcess create_model() end ==================================
2024-05-10 14:23:53,926:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.6944
2024-05-10 14:23:53,927:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6552
2024-05-10 14:23:53,927:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:23:53,927:INFO:choose_better completed
2024-05-10 14:23:53,927:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:23:53,933:INFO:_master_model_container: 20
2024-05-10 14:23:53,933:INFO:_display_container: 3
2024-05-10 14:23:53,933:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:23:53,933:INFO:tune_model() successfully completed......................................
2024-05-10 14:23:54,014:INFO:Initializing evaluate_model()
2024-05-10 14:23:54,015:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:23:54,021:INFO:Initializing plot_model()
2024-05-10 14:23:54,021:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, system=True)
2024-05-10 14:23:54,021:INFO:Checking exceptions
2024-05-10 14:23:54,035:INFO:Preloading libraries
2024-05-10 14:23:54,042:INFO:Copying training dataset
2024-05-10 14:23:54,042:INFO:Plot type: pipeline
2024-05-10 14:23:54,105:INFO:Visual Rendered Successfully
2024-05-10 14:23:54,184:INFO:plot_model() successfully completed......................................
2024-05-10 14:23:59,956:INFO:Initializing plot_model()
2024-05-10 14:23:59,956:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, system=True)
2024-05-10 14:23:59,956:INFO:Checking exceptions
2024-05-10 14:23:59,968:INFO:Preloading libraries
2024-05-10 14:23:59,973:INFO:Copying training dataset
2024-05-10 14:23:59,973:INFO:Plot type: parameter
2024-05-10 14:23:59,976:INFO:Visual Rendered Successfully
2024-05-10 14:24:00,051:INFO:plot_model() successfully completed......................................
2024-05-10 14:24:00,605:INFO:Initializing plot_model()
2024-05-10 14:24:00,605:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, system=True)
2024-05-10 14:24:00,605:INFO:Checking exceptions
2024-05-10 14:24:00,619:INFO:Preloading libraries
2024-05-10 14:24:00,625:INFO:Copying training dataset
2024-05-10 14:24:00,625:INFO:Plot type: residuals
2024-05-10 14:24:00,670:INFO:Fitting Model
2024-05-10 14:24:00,670:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:24:00,709:INFO:Scoring test/hold-out set
2024-05-10 14:24:00,902:INFO:Visual Rendered Successfully
2024-05-10 14:24:00,981:INFO:plot_model() successfully completed......................................
2024-05-10 14:24:04,375:INFO:Initializing plot_model()
2024-05-10 14:24:04,375:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767ccad633a0>, system=True)
2024-05-10 14:24:04,375:INFO:Checking exceptions
2024-05-10 14:24:04,392:INFO:Preloading libraries
2024-05-10 14:24:04,398:INFO:Copying training dataset
2024-05-10 14:24:04,398:INFO:Plot type: error
2024-05-10 14:24:04,430:INFO:Fitting Model
2024-05-10 14:24:04,430:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:24:04,431:INFO:Scoring test/hold-out set
2024-05-10 14:24:04,553:INFO:Visual Rendered Successfully
2024-05-10 14:24:04,614:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:12,655:INFO:PyCaret RegressionExperiment
2024-05-10 14:27:12,655:INFO:Logging name: reg-default-name
2024-05-10 14:27:12,656:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:27:12,656:INFO:version 3.3.2
2024-05-10 14:27:12,656:INFO:Initializing setup()
2024-05-10 14:27:12,656:INFO:self.USI: 2338
2024-05-10 14:27:12,656:INFO:self._variable_keys: {'X', 'target_param', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'n_jobs_param', 'USI', 'pipeline', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'data', '_ml_usecase', 'fold_shuffle_param', 'X_test', '_available_plots', 'exp_id', 'logging_param', 'transform_target_param', 'fold_generator', 'memory', 'html_param', 'gpu_param', 'y_test', 'seed', 'y'}
2024-05-10 14:27:12,656:INFO:Checking environment
2024-05-10 14:27:12,656:INFO:python_version: 3.9.18
2024-05-10 14:27:12,656:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:27:12,656:INFO:machine: x86_64
2024-05-10 14:27:12,656:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:27:12,656:INFO:Memory: svmem(total=16429797376, available=5895241728, percent=64.1, used=9377505280, free=407859200, active=9104195584, inactive=5538164736, buffers=256880640, cached=6387552256, shared=816574464, slab=795381760)
2024-05-10 14:27:12,657:INFO:Physical Core: 12
2024-05-10 14:27:12,657:INFO:Logical Core: 16
2024-05-10 14:27:12,657:INFO:Checking libraries
2024-05-10 14:27:12,657:INFO:System:
2024-05-10 14:27:12,657:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:27:12,657:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:27:12,657:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:27:12,657:INFO:PyCaret required dependencies:
2024-05-10 14:27:12,657:INFO:                 pip: 23.3.1
2024-05-10 14:27:12,657:INFO:          setuptools: 68.2.2
2024-05-10 14:27:12,657:INFO:             pycaret: 3.3.2
2024-05-10 14:27:12,657:INFO:             IPython: 8.15.0
2024-05-10 14:27:12,657:INFO:          ipywidgets: 7.6.5
2024-05-10 14:27:12,657:INFO:                tqdm: 4.65.0
2024-05-10 14:27:12,657:INFO:               numpy: 1.26.4
2024-05-10 14:27:12,657:INFO:              pandas: 2.1.4
2024-05-10 14:27:12,657:INFO:              jinja2: 3.1.3
2024-05-10 14:27:12,657:INFO:               scipy: 1.11.4
2024-05-10 14:27:12,657:INFO:              joblib: 1.2.0
2024-05-10 14:27:12,657:INFO:             sklearn: 1.4.2
2024-05-10 14:27:12,657:INFO:                pyod: 1.1.3
2024-05-10 14:27:12,657:INFO:            imblearn: 0.12.2
2024-05-10 14:27:12,657:INFO:   category_encoders: 2.6.3
2024-05-10 14:27:12,657:INFO:            lightgbm: 4.3.0
2024-05-10 14:27:12,657:INFO:               numba: 0.59.1
2024-05-10 14:27:12,657:INFO:            requests: 2.31.0
2024-05-10 14:27:12,657:INFO:          matplotlib: 3.7.5
2024-05-10 14:27:12,657:INFO:          scikitplot: 0.3.7
2024-05-10 14:27:12,657:INFO:         yellowbrick: 1.5
2024-05-10 14:27:12,657:INFO:              plotly: 5.19.0
2024-05-10 14:27:12,657:INFO:    plotly-resampler: Not installed
2024-05-10 14:27:12,658:INFO:             kaleido: 0.2.1
2024-05-10 14:27:12,658:INFO:           schemdraw: 0.15
2024-05-10 14:27:12,658:INFO:         statsmodels: 0.14.0
2024-05-10 14:27:12,658:INFO:              sktime: 0.26.0
2024-05-10 14:27:12,658:INFO:               tbats: 1.1.3
2024-05-10 14:27:12,658:INFO:            pmdarima: 2.0.4
2024-05-10 14:27:12,658:INFO:              psutil: 5.9.0
2024-05-10 14:27:12,658:INFO:          markupsafe: 2.1.3
2024-05-10 14:27:12,658:INFO:             pickle5: Not installed
2024-05-10 14:27:12,658:INFO:         cloudpickle: 2.2.1
2024-05-10 14:27:12,658:INFO:         deprecation: 2.1.0
2024-05-10 14:27:12,658:INFO:              xxhash: 3.4.1
2024-05-10 14:27:12,658:INFO:           wurlitzer: 3.0.2
2024-05-10 14:27:12,658:INFO:PyCaret optional dependencies:
2024-05-10 14:27:12,658:INFO:                shap: Not installed
2024-05-10 14:27:12,658:INFO:           interpret: Not installed
2024-05-10 14:27:12,658:INFO:                umap: Not installed
2024-05-10 14:27:12,658:INFO:     ydata_profiling: Not installed
2024-05-10 14:27:12,658:INFO:  explainerdashboard: Not installed
2024-05-10 14:27:12,658:INFO:             autoviz: Not installed
2024-05-10 14:27:12,658:INFO:           fairlearn: Not installed
2024-05-10 14:27:12,658:INFO:          deepchecks: Not installed
2024-05-10 14:27:12,658:INFO:             xgboost: Not installed
2024-05-10 14:27:12,658:INFO:            catboost: Not installed
2024-05-10 14:27:12,658:INFO:              kmodes: Not installed
2024-05-10 14:27:12,658:INFO:             mlxtend: Not installed
2024-05-10 14:27:12,658:INFO:       statsforecast: Not installed
2024-05-10 14:27:12,658:INFO:        tune_sklearn: Not installed
2024-05-10 14:27:12,658:INFO:                 ray: Not installed
2024-05-10 14:27:12,658:INFO:            hyperopt: Not installed
2024-05-10 14:27:12,658:INFO:              optuna: Not installed
2024-05-10 14:27:12,658:INFO:               skopt: Not installed
2024-05-10 14:27:12,658:INFO:              mlflow: Not installed
2024-05-10 14:27:12,658:INFO:              gradio: Not installed
2024-05-10 14:27:12,658:INFO:             fastapi: Not installed
2024-05-10 14:27:12,658:INFO:             uvicorn: Not installed
2024-05-10 14:27:12,658:INFO:              m2cgen: Not installed
2024-05-10 14:27:12,659:INFO:           evidently: Not installed
2024-05-10 14:27:12,659:INFO:               fugue: Not installed
2024-05-10 14:27:12,659:INFO:           streamlit: 1.32.0
2024-05-10 14:27:12,659:INFO:             prophet: Not installed
2024-05-10 14:27:12,659:INFO:None
2024-05-10 14:27:12,659:INFO:Set up data.
2024-05-10 14:27:12,662:INFO:Set up folding strategy.
2024-05-10 14:27:12,662:INFO:Set up train/test split.
2024-05-10 14:27:12,664:INFO:Set up index.
2024-05-10 14:27:12,664:INFO:Assigning column types.
2024-05-10 14:27:12,666:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:27:12,666:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,668:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,671:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,697:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,716:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,717:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,717:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,719:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,721:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,746:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,773:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,774:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,774:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:27:12,776:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,778:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,806:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,827:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,827:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,829:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,831:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,857:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,878:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,878:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,878:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:27:12,883:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,909:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,929:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,930:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,934:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,983:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:27:12,983:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,983:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:12,984:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:27:13,014:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:13,035:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:27:13,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,067:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:13,089:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:27:13,090:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,090:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,090:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:27:13,122:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:13,142:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,143:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,174:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:27:13,195:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,195:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,195:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:27:13,246:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,299:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,299:INFO:Preparing preprocessing pipeline...
2024-05-10 14:27:13,299:INFO:Set up simple imputation.
2024-05-10 14:27:13,300:INFO:Set up column name cleaning.
2024-05-10 14:27:13,310:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:27:13,312:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:27:13,312:INFO:Creating final display dataframe.
2024-05-10 14:27:13,348:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (576, 7)
4        Transformed data shape          (576, 7)
5   Transformed train set shape          (345, 7)
6    Transformed test set shape          (231, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              2338
2024-05-10 14:27:13,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,403:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:27:13,455:INFO:setup() successfully completed in 0.8s...............
2024-05-10 14:27:13,455:INFO:Initializing compare_models()
2024-05-10 14:27:13,455:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:27:13,455:INFO:Checking exceptions
2024-05-10 14:27:13,456:INFO:Preparing display monitor
2024-05-10 14:27:13,469:INFO:Initializing Linear Regression
2024-05-10 14:27:13,469:INFO:Total runtime is 1.990795135498047e-06 minutes
2024-05-10 14:27:13,471:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:13,471:INFO:Initializing create_model()
2024-05-10 14:27:13,471:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:13,471:INFO:Checking exceptions
2024-05-10 14:27:13,471:INFO:Importing libraries
2024-05-10 14:27:13,471:INFO:Copying training dataset
2024-05-10 14:27:13,473:INFO:Defining folds
2024-05-10 14:27:13,473:INFO:Declaring metric variables
2024-05-10 14:27:13,475:INFO:Importing untrained model
2024-05-10 14:27:13,477:INFO:Linear Regression Imported successfully
2024-05-10 14:27:13,481:INFO:Starting cross validation
2024-05-10 14:27:13,481:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:13,526:INFO:Calculating mean and std
2024-05-10 14:27:13,527:INFO:Creating metrics dataframe
2024-05-10 14:27:13,528:INFO:Uploading results into container
2024-05-10 14:27:13,529:INFO:Uploading model into container now
2024-05-10 14:27:13,529:INFO:_master_model_container: 1
2024-05-10 14:27:13,529:INFO:_display_container: 2
2024-05-10 14:27:13,529:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:27:13,529:INFO:create_model() successfully completed......................................
2024-05-10 14:27:13,608:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:13,608:INFO:Creating metrics dataframe
2024-05-10 14:27:13,612:INFO:Initializing Lasso Regression
2024-05-10 14:27:13,612:INFO:Total runtime is 0.0023903767267862957 minutes
2024-05-10 14:27:13,614:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:13,614:INFO:Initializing create_model()
2024-05-10 14:27:13,614:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:13,614:INFO:Checking exceptions
2024-05-10 14:27:13,614:INFO:Importing libraries
2024-05-10 14:27:13,614:INFO:Copying training dataset
2024-05-10 14:27:13,617:INFO:Defining folds
2024-05-10 14:27:13,617:INFO:Declaring metric variables
2024-05-10 14:27:13,619:INFO:Importing untrained model
2024-05-10 14:27:13,621:INFO:Lasso Regression Imported successfully
2024-05-10 14:27:13,624:INFO:Starting cross validation
2024-05-10 14:27:13,625:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:13,667:INFO:Calculating mean and std
2024-05-10 14:27:13,667:INFO:Creating metrics dataframe
2024-05-10 14:27:13,669:INFO:Uploading results into container
2024-05-10 14:27:13,669:INFO:Uploading model into container now
2024-05-10 14:27:13,670:INFO:_master_model_container: 2
2024-05-10 14:27:13,670:INFO:_display_container: 2
2024-05-10 14:27:13,670:INFO:Lasso(random_state=123)
2024-05-10 14:27:13,670:INFO:create_model() successfully completed......................................
2024-05-10 14:27:13,749:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:13,749:INFO:Creating metrics dataframe
2024-05-10 14:27:13,754:INFO:Initializing Ridge Regression
2024-05-10 14:27:13,754:INFO:Total runtime is 0.004758989810943604 minutes
2024-05-10 14:27:13,756:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:13,756:INFO:Initializing create_model()
2024-05-10 14:27:13,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:13,756:INFO:Checking exceptions
2024-05-10 14:27:13,756:INFO:Importing libraries
2024-05-10 14:27:13,756:INFO:Copying training dataset
2024-05-10 14:27:13,759:INFO:Defining folds
2024-05-10 14:27:13,759:INFO:Declaring metric variables
2024-05-10 14:27:13,761:INFO:Importing untrained model
2024-05-10 14:27:13,763:INFO:Ridge Regression Imported successfully
2024-05-10 14:27:13,766:INFO:Starting cross validation
2024-05-10 14:27:13,767:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:13,812:INFO:Calculating mean and std
2024-05-10 14:27:13,813:INFO:Creating metrics dataframe
2024-05-10 14:27:13,815:INFO:Uploading results into container
2024-05-10 14:27:13,816:INFO:Uploading model into container now
2024-05-10 14:27:13,816:INFO:_master_model_container: 3
2024-05-10 14:27:13,816:INFO:_display_container: 2
2024-05-10 14:27:13,817:INFO:Ridge(random_state=123)
2024-05-10 14:27:13,817:INFO:create_model() successfully completed......................................
2024-05-10 14:27:13,898:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:13,898:INFO:Creating metrics dataframe
2024-05-10 14:27:13,903:INFO:Initializing Elastic Net
2024-05-10 14:27:13,903:INFO:Total runtime is 0.007232769330342611 minutes
2024-05-10 14:27:13,905:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:13,905:INFO:Initializing create_model()
2024-05-10 14:27:13,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:13,905:INFO:Checking exceptions
2024-05-10 14:27:13,905:INFO:Importing libraries
2024-05-10 14:27:13,905:INFO:Copying training dataset
2024-05-10 14:27:13,907:INFO:Defining folds
2024-05-10 14:27:13,907:INFO:Declaring metric variables
2024-05-10 14:27:13,909:INFO:Importing untrained model
2024-05-10 14:27:13,911:INFO:Elastic Net Imported successfully
2024-05-10 14:27:13,914:INFO:Starting cross validation
2024-05-10 14:27:13,915:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:13,957:INFO:Calculating mean and std
2024-05-10 14:27:13,957:INFO:Creating metrics dataframe
2024-05-10 14:27:13,959:INFO:Uploading results into container
2024-05-10 14:27:13,959:INFO:Uploading model into container now
2024-05-10 14:27:13,960:INFO:_master_model_container: 4
2024-05-10 14:27:13,960:INFO:_display_container: 2
2024-05-10 14:27:13,960:INFO:ElasticNet(random_state=123)
2024-05-10 14:27:13,960:INFO:create_model() successfully completed......................................
2024-05-10 14:27:14,037:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:14,037:INFO:Creating metrics dataframe
2024-05-10 14:27:14,041:INFO:Initializing Least Angle Regression
2024-05-10 14:27:14,041:INFO:Total runtime is 0.009541813532511394 minutes
2024-05-10 14:27:14,043:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:14,043:INFO:Initializing create_model()
2024-05-10 14:27:14,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:14,043:INFO:Checking exceptions
2024-05-10 14:27:14,043:INFO:Importing libraries
2024-05-10 14:27:14,043:INFO:Copying training dataset
2024-05-10 14:27:14,045:INFO:Defining folds
2024-05-10 14:27:14,046:INFO:Declaring metric variables
2024-05-10 14:27:14,047:INFO:Importing untrained model
2024-05-10 14:27:14,049:INFO:Least Angle Regression Imported successfully
2024-05-10 14:27:14,054:INFO:Starting cross validation
2024-05-10 14:27:14,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:14,097:INFO:Calculating mean and std
2024-05-10 14:27:14,097:INFO:Creating metrics dataframe
2024-05-10 14:27:14,098:INFO:Uploading results into container
2024-05-10 14:27:14,098:INFO:Uploading model into container now
2024-05-10 14:27:14,099:INFO:_master_model_container: 5
2024-05-10 14:27:14,099:INFO:_display_container: 2
2024-05-10 14:27:14,099:INFO:Lars(random_state=123)
2024-05-10 14:27:14,099:INFO:create_model() successfully completed......................................
2024-05-10 14:27:14,172:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:14,172:INFO:Creating metrics dataframe
2024-05-10 14:27:14,177:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:27:14,177:INFO:Total runtime is 0.01179795265197754 minutes
2024-05-10 14:27:14,179:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:14,179:INFO:Initializing create_model()
2024-05-10 14:27:14,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:14,179:INFO:Checking exceptions
2024-05-10 14:27:14,179:INFO:Importing libraries
2024-05-10 14:27:14,179:INFO:Copying training dataset
2024-05-10 14:27:14,181:INFO:Defining folds
2024-05-10 14:27:14,181:INFO:Declaring metric variables
2024-05-10 14:27:14,183:INFO:Importing untrained model
2024-05-10 14:27:14,185:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:27:14,189:INFO:Starting cross validation
2024-05-10 14:27:14,189:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:14,231:INFO:Calculating mean and std
2024-05-10 14:27:14,232:INFO:Creating metrics dataframe
2024-05-10 14:27:14,234:INFO:Uploading results into container
2024-05-10 14:27:14,234:INFO:Uploading model into container now
2024-05-10 14:27:14,234:INFO:_master_model_container: 6
2024-05-10 14:27:14,234:INFO:_display_container: 2
2024-05-10 14:27:14,234:INFO:LassoLars(random_state=123)
2024-05-10 14:27:14,234:INFO:create_model() successfully completed......................................
2024-05-10 14:27:14,313:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:14,314:INFO:Creating metrics dataframe
2024-05-10 14:27:14,319:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:27:14,319:INFO:Total runtime is 0.014173821608225506 minutes
2024-05-10 14:27:14,322:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:14,322:INFO:Initializing create_model()
2024-05-10 14:27:14,322:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:14,322:INFO:Checking exceptions
2024-05-10 14:27:14,322:INFO:Importing libraries
2024-05-10 14:27:14,322:INFO:Copying training dataset
2024-05-10 14:27:14,325:INFO:Defining folds
2024-05-10 14:27:14,325:INFO:Declaring metric variables
2024-05-10 14:27:14,327:INFO:Importing untrained model
2024-05-10 14:27:14,330:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:27:14,336:INFO:Starting cross validation
2024-05-10 14:27:14,337:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:14,381:INFO:Calculating mean and std
2024-05-10 14:27:14,381:INFO:Creating metrics dataframe
2024-05-10 14:27:14,382:INFO:Uploading results into container
2024-05-10 14:27:14,383:INFO:Uploading model into container now
2024-05-10 14:27:14,383:INFO:_master_model_container: 7
2024-05-10 14:27:14,383:INFO:_display_container: 2
2024-05-10 14:27:14,383:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:27:14,383:INFO:create_model() successfully completed......................................
2024-05-10 14:27:14,459:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:14,459:INFO:Creating metrics dataframe
2024-05-10 14:27:14,463:INFO:Initializing Bayesian Ridge
2024-05-10 14:27:14,464:INFO:Total runtime is 0.01657923460006714 minutes
2024-05-10 14:27:14,466:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:14,466:INFO:Initializing create_model()
2024-05-10 14:27:14,466:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:14,466:INFO:Checking exceptions
2024-05-10 14:27:14,466:INFO:Importing libraries
2024-05-10 14:27:14,466:INFO:Copying training dataset
2024-05-10 14:27:14,469:INFO:Defining folds
2024-05-10 14:27:14,469:INFO:Declaring metric variables
2024-05-10 14:27:14,471:INFO:Importing untrained model
2024-05-10 14:27:14,473:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:27:14,477:INFO:Starting cross validation
2024-05-10 14:27:14,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:14,524:INFO:Calculating mean and std
2024-05-10 14:27:14,525:INFO:Creating metrics dataframe
2024-05-10 14:27:14,526:INFO:Uploading results into container
2024-05-10 14:27:14,527:INFO:Uploading model into container now
2024-05-10 14:27:14,527:INFO:_master_model_container: 8
2024-05-10 14:27:14,527:INFO:_display_container: 2
2024-05-10 14:27:14,527:INFO:BayesianRidge()
2024-05-10 14:27:14,527:INFO:create_model() successfully completed......................................
2024-05-10 14:27:14,601:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:14,601:INFO:Creating metrics dataframe
2024-05-10 14:27:14,606:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:27:14,606:INFO:Total runtime is 0.018960893154144287 minutes
2024-05-10 14:27:14,609:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:14,609:INFO:Initializing create_model()
2024-05-10 14:27:14,609:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:14,610:INFO:Checking exceptions
2024-05-10 14:27:14,610:INFO:Importing libraries
2024-05-10 14:27:14,610:INFO:Copying training dataset
2024-05-10 14:27:14,613:INFO:Defining folds
2024-05-10 14:27:14,613:INFO:Declaring metric variables
2024-05-10 14:27:14,616:INFO:Importing untrained model
2024-05-10 14:27:14,618:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:27:14,623:INFO:Starting cross validation
2024-05-10 14:27:14,624:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:14,670:INFO:Calculating mean and std
2024-05-10 14:27:14,670:INFO:Creating metrics dataframe
2024-05-10 14:27:14,671:INFO:Uploading results into container
2024-05-10 14:27:14,672:INFO:Uploading model into container now
2024-05-10 14:27:14,672:INFO:_master_model_container: 9
2024-05-10 14:27:14,672:INFO:_display_container: 2
2024-05-10 14:27:14,672:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:27:14,672:INFO:create_model() successfully completed......................................
2024-05-10 14:27:14,746:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:14,746:INFO:Creating metrics dataframe
2024-05-10 14:27:14,751:INFO:Initializing Huber Regressor
2024-05-10 14:27:14,752:INFO:Total runtime is 0.021378469467163087 minutes
2024-05-10 14:27:14,754:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:14,754:INFO:Initializing create_model()
2024-05-10 14:27:14,754:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:14,754:INFO:Checking exceptions
2024-05-10 14:27:14,754:INFO:Importing libraries
2024-05-10 14:27:14,754:INFO:Copying training dataset
2024-05-10 14:27:14,756:INFO:Defining folds
2024-05-10 14:27:14,757:INFO:Declaring metric variables
2024-05-10 14:27:14,758:INFO:Importing untrained model
2024-05-10 14:27:14,760:INFO:Huber Regressor Imported successfully
2024-05-10 14:27:14,764:INFO:Starting cross validation
2024-05-10 14:27:14,764:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:14,802:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:27:14,805:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:27:14,806:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:27:14,812:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:27:14,817:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:27:14,821:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:27:14,824:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:27:14,825:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:27:14,832:INFO:Calculating mean and std
2024-05-10 14:27:14,832:INFO:Creating metrics dataframe
2024-05-10 14:27:14,834:INFO:Uploading results into container
2024-05-10 14:27:14,834:INFO:Uploading model into container now
2024-05-10 14:27:14,834:INFO:_master_model_container: 10
2024-05-10 14:27:14,834:INFO:_display_container: 2
2024-05-10 14:27:14,835:INFO:HuberRegressor()
2024-05-10 14:27:14,835:INFO:create_model() successfully completed......................................
2024-05-10 14:27:14,916:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:14,916:INFO:Creating metrics dataframe
2024-05-10 14:27:14,921:INFO:Initializing K Neighbors Regressor
2024-05-10 14:27:14,921:INFO:Total runtime is 0.02421101729075114 minutes
2024-05-10 14:27:14,923:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:14,924:INFO:Initializing create_model()
2024-05-10 14:27:14,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:14,924:INFO:Checking exceptions
2024-05-10 14:27:14,924:INFO:Importing libraries
2024-05-10 14:27:14,924:INFO:Copying training dataset
2024-05-10 14:27:14,927:INFO:Defining folds
2024-05-10 14:27:14,927:INFO:Declaring metric variables
2024-05-10 14:27:14,929:INFO:Importing untrained model
2024-05-10 14:27:14,931:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:27:14,937:INFO:Starting cross validation
2024-05-10 14:27:14,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:15,002:INFO:Calculating mean and std
2024-05-10 14:27:15,002:INFO:Creating metrics dataframe
2024-05-10 14:27:15,003:INFO:Uploading results into container
2024-05-10 14:27:15,004:INFO:Uploading model into container now
2024-05-10 14:27:15,004:INFO:_master_model_container: 11
2024-05-10 14:27:15,004:INFO:_display_container: 2
2024-05-10 14:27:15,004:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:27:15,004:INFO:create_model() successfully completed......................................
2024-05-10 14:27:15,078:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:15,078:INFO:Creating metrics dataframe
2024-05-10 14:27:15,084:INFO:Initializing Decision Tree Regressor
2024-05-10 14:27:15,084:INFO:Total runtime is 0.026913563410441082 minutes
2024-05-10 14:27:15,086:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:15,086:INFO:Initializing create_model()
2024-05-10 14:27:15,086:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:15,086:INFO:Checking exceptions
2024-05-10 14:27:15,086:INFO:Importing libraries
2024-05-10 14:27:15,086:INFO:Copying training dataset
2024-05-10 14:27:15,089:INFO:Defining folds
2024-05-10 14:27:15,089:INFO:Declaring metric variables
2024-05-10 14:27:15,091:INFO:Importing untrained model
2024-05-10 14:27:15,094:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:27:15,099:INFO:Starting cross validation
2024-05-10 14:27:15,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:15,151:INFO:Calculating mean and std
2024-05-10 14:27:15,151:INFO:Creating metrics dataframe
2024-05-10 14:27:15,153:INFO:Uploading results into container
2024-05-10 14:27:15,153:INFO:Uploading model into container now
2024-05-10 14:27:15,153:INFO:_master_model_container: 12
2024-05-10 14:27:15,153:INFO:_display_container: 2
2024-05-10 14:27:15,153:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:27:15,153:INFO:create_model() successfully completed......................................
2024-05-10 14:27:15,228:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:15,228:INFO:Creating metrics dataframe
2024-05-10 14:27:15,234:INFO:Initializing Random Forest Regressor
2024-05-10 14:27:15,234:INFO:Total runtime is 0.029421703020731608 minutes
2024-05-10 14:27:15,237:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:15,237:INFO:Initializing create_model()
2024-05-10 14:27:15,237:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:15,237:INFO:Checking exceptions
2024-05-10 14:27:15,237:INFO:Importing libraries
2024-05-10 14:27:15,237:INFO:Copying training dataset
2024-05-10 14:27:15,240:INFO:Defining folds
2024-05-10 14:27:15,240:INFO:Declaring metric variables
2024-05-10 14:27:15,243:INFO:Importing untrained model
2024-05-10 14:27:15,245:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:27:15,250:INFO:Starting cross validation
2024-05-10 14:27:15,252:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:15,520:INFO:Calculating mean and std
2024-05-10 14:27:15,521:INFO:Creating metrics dataframe
2024-05-10 14:27:15,523:INFO:Uploading results into container
2024-05-10 14:27:15,524:INFO:Uploading model into container now
2024-05-10 14:27:15,524:INFO:_master_model_container: 13
2024-05-10 14:27:15,524:INFO:_display_container: 2
2024-05-10 14:27:15,524:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:27:15,524:INFO:create_model() successfully completed......................................
2024-05-10 14:27:15,602:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:15,602:INFO:Creating metrics dataframe
2024-05-10 14:27:15,610:INFO:Initializing Extra Trees Regressor
2024-05-10 14:27:15,610:INFO:Total runtime is 0.0356868306795756 minutes
2024-05-10 14:27:15,613:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:15,613:INFO:Initializing create_model()
2024-05-10 14:27:15,613:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:15,613:INFO:Checking exceptions
2024-05-10 14:27:15,613:INFO:Importing libraries
2024-05-10 14:27:15,613:INFO:Copying training dataset
2024-05-10 14:27:15,617:INFO:Defining folds
2024-05-10 14:27:15,617:INFO:Declaring metric variables
2024-05-10 14:27:15,620:INFO:Importing untrained model
2024-05-10 14:27:15,623:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:27:15,629:INFO:Starting cross validation
2024-05-10 14:27:15,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:15,800:INFO:Calculating mean and std
2024-05-10 14:27:15,802:INFO:Creating metrics dataframe
2024-05-10 14:27:15,804:INFO:Uploading results into container
2024-05-10 14:27:15,804:INFO:Uploading model into container now
2024-05-10 14:27:15,805:INFO:_master_model_container: 14
2024-05-10 14:27:15,805:INFO:_display_container: 2
2024-05-10 14:27:15,805:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:27:15,805:INFO:create_model() successfully completed......................................
2024-05-10 14:27:15,880:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:15,880:INFO:Creating metrics dataframe
2024-05-10 14:27:15,886:INFO:Initializing AdaBoost Regressor
2024-05-10 14:27:15,886:INFO:Total runtime is 0.04029026428858439 minutes
2024-05-10 14:27:15,888:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:15,888:INFO:Initializing create_model()
2024-05-10 14:27:15,889:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:15,889:INFO:Checking exceptions
2024-05-10 14:27:15,889:INFO:Importing libraries
2024-05-10 14:27:15,889:INFO:Copying training dataset
2024-05-10 14:27:15,891:INFO:Defining folds
2024-05-10 14:27:15,891:INFO:Declaring metric variables
2024-05-10 14:27:15,892:INFO:Importing untrained model
2024-05-10 14:27:15,894:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:27:15,897:INFO:Starting cross validation
2024-05-10 14:27:15,898:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:15,979:INFO:Calculating mean and std
2024-05-10 14:27:15,979:INFO:Creating metrics dataframe
2024-05-10 14:27:15,980:INFO:Uploading results into container
2024-05-10 14:27:15,981:INFO:Uploading model into container now
2024-05-10 14:27:15,981:INFO:_master_model_container: 15
2024-05-10 14:27:15,981:INFO:_display_container: 2
2024-05-10 14:27:15,981:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:27:15,981:INFO:create_model() successfully completed......................................
2024-05-10 14:27:16,066:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:16,066:INFO:Creating metrics dataframe
2024-05-10 14:27:16,072:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:27:16,072:INFO:Total runtime is 0.04339318672815959 minutes
2024-05-10 14:27:16,075:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:16,076:INFO:Initializing create_model()
2024-05-10 14:27:16,076:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:16,076:INFO:Checking exceptions
2024-05-10 14:27:16,076:INFO:Importing libraries
2024-05-10 14:27:16,076:INFO:Copying training dataset
2024-05-10 14:27:16,078:INFO:Defining folds
2024-05-10 14:27:16,078:INFO:Declaring metric variables
2024-05-10 14:27:16,080:INFO:Importing untrained model
2024-05-10 14:27:16,082:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:27:16,088:INFO:Starting cross validation
2024-05-10 14:27:16,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:16,237:INFO:Calculating mean and std
2024-05-10 14:27:16,238:INFO:Creating metrics dataframe
2024-05-10 14:27:16,239:INFO:Uploading results into container
2024-05-10 14:27:16,239:INFO:Uploading model into container now
2024-05-10 14:27:16,239:INFO:_master_model_container: 16
2024-05-10 14:27:16,239:INFO:_display_container: 2
2024-05-10 14:27:16,239:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:27:16,239:INFO:create_model() successfully completed......................................
2024-05-10 14:27:16,329:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:16,330:INFO:Creating metrics dataframe
2024-05-10 14:27:16,336:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:27:16,336:INFO:Total runtime is 0.04779306650161744 minutes
2024-05-10 14:27:16,339:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:16,339:INFO:Initializing create_model()
2024-05-10 14:27:16,339:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:16,339:INFO:Checking exceptions
2024-05-10 14:27:16,339:INFO:Importing libraries
2024-05-10 14:27:16,339:INFO:Copying training dataset
2024-05-10 14:27:16,342:INFO:Defining folds
2024-05-10 14:27:16,342:INFO:Declaring metric variables
2024-05-10 14:27:16,343:INFO:Importing untrained model
2024-05-10 14:27:16,347:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:27:16,352:INFO:Starting cross validation
2024-05-10 14:27:16,353:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:16,897:INFO:Calculating mean and std
2024-05-10 14:27:16,897:INFO:Creating metrics dataframe
2024-05-10 14:27:16,899:INFO:Uploading results into container
2024-05-10 14:27:16,899:INFO:Uploading model into container now
2024-05-10 14:27:16,900:INFO:_master_model_container: 17
2024-05-10 14:27:16,900:INFO:_display_container: 2
2024-05-10 14:27:16,900:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:27:16,900:INFO:create_model() successfully completed......................................
2024-05-10 14:27:16,977:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:16,977:INFO:Creating metrics dataframe
2024-05-10 14:27:16,985:INFO:Initializing Dummy Regressor
2024-05-10 14:27:16,985:INFO:Total runtime is 0.058602698644002284 minutes
2024-05-10 14:27:16,987:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:16,988:INFO:Initializing create_model()
2024-05-10 14:27:16,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc8320d0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:16,988:INFO:Checking exceptions
2024-05-10 14:27:16,988:INFO:Importing libraries
2024-05-10 14:27:16,988:INFO:Copying training dataset
2024-05-10 14:27:16,991:INFO:Defining folds
2024-05-10 14:27:16,992:INFO:Declaring metric variables
2024-05-10 14:27:16,994:INFO:Importing untrained model
2024-05-10 14:27:16,997:INFO:Dummy Regressor Imported successfully
2024-05-10 14:27:17,001:INFO:Starting cross validation
2024-05-10 14:27:17,002:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:17,050:INFO:Calculating mean and std
2024-05-10 14:27:17,051:INFO:Creating metrics dataframe
2024-05-10 14:27:17,053:INFO:Uploading results into container
2024-05-10 14:27:17,053:INFO:Uploading model into container now
2024-05-10 14:27:17,054:INFO:_master_model_container: 18
2024-05-10 14:27:17,054:INFO:_display_container: 2
2024-05-10 14:27:17,054:INFO:DummyRegressor()
2024-05-10 14:27:17,054:INFO:create_model() successfully completed......................................
2024-05-10 14:27:17,129:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:17,129:INFO:Creating metrics dataframe
2024-05-10 14:27:17,135:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:27:17,139:INFO:Initializing create_model()
2024-05-10 14:27:17,139:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:17,139:INFO:Checking exceptions
2024-05-10 14:27:17,140:INFO:Importing libraries
2024-05-10 14:27:17,140:INFO:Copying training dataset
2024-05-10 14:27:17,142:INFO:Defining folds
2024-05-10 14:27:17,142:INFO:Declaring metric variables
2024-05-10 14:27:17,142:INFO:Importing untrained model
2024-05-10 14:27:17,142:INFO:Declaring custom model
2024-05-10 14:27:17,142:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:27:17,143:INFO:Cross validation set to False
2024-05-10 14:27:17,143:INFO:Fitting Model
2024-05-10 14:27:17,197:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:27:17,197:INFO:create_model() successfully completed......................................
2024-05-10 14:27:17,302:INFO:_master_model_container: 18
2024-05-10 14:27:17,302:INFO:_display_container: 2
2024-05-10 14:27:17,303:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:27:17,303:INFO:compare_models() successfully completed......................................
2024-05-10 14:27:17,304:INFO:Initializing tune_model()
2024-05-10 14:27:17,304:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>)
2024-05-10 14:27:17,304:INFO:Checking exceptions
2024-05-10 14:27:17,324:INFO:Copying training dataset
2024-05-10 14:27:17,327:INFO:Checking base model
2024-05-10 14:27:17,327:INFO:Base model : Extra Trees Regressor
2024-05-10 14:27:17,329:INFO:Declaring metric variables
2024-05-10 14:27:17,332:INFO:Defining Hyperparameters
2024-05-10 14:27:17,418:INFO:Tuning with n_jobs=-1
2024-05-10 14:27:17,418:INFO:Initializing RandomizedSearchCV
2024-05-10 14:27:19,199:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:27:19,199:INFO:Hyperparameter search completed
2024-05-10 14:27:19,200:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:19,200:INFO:Initializing create_model()
2024-05-10 14:27:19,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767cbc3baf40>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:27:19,200:INFO:Checking exceptions
2024-05-10 14:27:19,200:INFO:Importing libraries
2024-05-10 14:27:19,200:INFO:Copying training dataset
2024-05-10 14:27:19,203:INFO:Defining folds
2024-05-10 14:27:19,203:INFO:Declaring metric variables
2024-05-10 14:27:19,205:INFO:Importing untrained model
2024-05-10 14:27:19,205:INFO:Declaring custom model
2024-05-10 14:27:19,207:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:27:19,211:INFO:Starting cross validation
2024-05-10 14:27:19,211:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:19,444:INFO:Calculating mean and std
2024-05-10 14:27:19,445:INFO:Creating metrics dataframe
2024-05-10 14:27:19,449:INFO:Finalizing model
2024-05-10 14:27:19,557:INFO:Uploading results into container
2024-05-10 14:27:19,558:INFO:Uploading model into container now
2024-05-10 14:27:19,559:INFO:_master_model_container: 19
2024-05-10 14:27:19,559:INFO:_display_container: 3
2024-05-10 14:27:19,559:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:27:19,559:INFO:create_model() successfully completed......................................
2024-05-10 14:27:19,634:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:19,634:INFO:choose_better activated
2024-05-10 14:27:19,637:INFO:SubProcess create_model() called ==================================
2024-05-10 14:27:19,637:INFO:Initializing create_model()
2024-05-10 14:27:19,637:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:27:19,637:INFO:Checking exceptions
2024-05-10 14:27:19,638:INFO:Importing libraries
2024-05-10 14:27:19,638:INFO:Copying training dataset
2024-05-10 14:27:19,640:INFO:Defining folds
2024-05-10 14:27:19,640:INFO:Declaring metric variables
2024-05-10 14:27:19,640:INFO:Importing untrained model
2024-05-10 14:27:19,640:INFO:Declaring custom model
2024-05-10 14:27:19,641:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:27:19,641:INFO:Starting cross validation
2024-05-10 14:27:19,641:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:27:19,812:INFO:Calculating mean and std
2024-05-10 14:27:19,812:INFO:Creating metrics dataframe
2024-05-10 14:27:19,813:INFO:Finalizing model
2024-05-10 14:27:19,869:INFO:Uploading results into container
2024-05-10 14:27:19,870:INFO:Uploading model into container now
2024-05-10 14:27:19,870:INFO:_master_model_container: 20
2024-05-10 14:27:19,870:INFO:_display_container: 4
2024-05-10 14:27:19,870:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:27:19,870:INFO:create_model() successfully completed......................................
2024-05-10 14:27:19,944:INFO:SubProcess create_model() end ==================================
2024-05-10 14:27:19,945:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.6944
2024-05-10 14:27:19,945:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6552
2024-05-10 14:27:19,945:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:27:19,945:INFO:choose_better completed
2024-05-10 14:27:19,945:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:27:19,951:INFO:_master_model_container: 20
2024-05-10 14:27:19,951:INFO:_display_container: 3
2024-05-10 14:27:19,951:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:27:19,951:INFO:tune_model() successfully completed......................................
2024-05-10 14:27:20,031:INFO:Initializing evaluate_model()
2024-05-10 14:27:20,031:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:27:20,038:INFO:Initializing plot_model()
2024-05-10 14:27:20,038:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:20,038:INFO:Checking exceptions
2024-05-10 14:27:20,050:INFO:Preloading libraries
2024-05-10 14:27:20,062:INFO:Copying training dataset
2024-05-10 14:27:20,062:INFO:Plot type: pipeline
2024-05-10 14:27:20,112:INFO:Visual Rendered Successfully
2024-05-10 14:27:20,191:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:22,658:INFO:Initializing plot_model()
2024-05-10 14:27:22,658:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:22,658:INFO:Checking exceptions
2024-05-10 14:27:22,674:INFO:Preloading libraries
2024-05-10 14:27:22,684:INFO:Copying training dataset
2024-05-10 14:27:22,684:INFO:Plot type: residuals
2024-05-10 14:27:22,731:INFO:Fitting Model
2024-05-10 14:27:22,731:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:27:22,769:INFO:Scoring test/hold-out set
2024-05-10 14:27:22,968:INFO:Visual Rendered Successfully
2024-05-10 14:27:23,052:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:37,846:INFO:Initializing plot_model()
2024-05-10 14:27:37,846:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:37,846:INFO:Checking exceptions
2024-05-10 14:27:37,858:INFO:Preloading libraries
2024-05-10 14:27:37,863:INFO:Copying training dataset
2024-05-10 14:27:37,863:INFO:Plot type: error
2024-05-10 14:27:37,897:INFO:Fitting Model
2024-05-10 14:27:37,897:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:27:37,898:INFO:Scoring test/hold-out set
2024-05-10 14:27:38,023:INFO:Visual Rendered Successfully
2024-05-10 14:27:38,111:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:40,192:INFO:Initializing plot_model()
2024-05-10 14:27:40,192:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:40,192:INFO:Checking exceptions
2024-05-10 14:27:40,206:INFO:Preloading libraries
2024-05-10 14:27:40,215:INFO:Copying training dataset
2024-05-10 14:27:40,215:INFO:Plot type: feature
2024-05-10 14:27:40,215:WARNING:No coef_ found. Trying feature_importances_
2024-05-10 14:27:40,304:INFO:Visual Rendered Successfully
2024-05-10 14:27:40,383:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:40,845:INFO:Initializing plot_model()
2024-05-10 14:27:40,845:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:40,845:INFO:Checking exceptions
2024-05-10 14:27:40,859:INFO:Preloading libraries
2024-05-10 14:27:40,865:INFO:Copying training dataset
2024-05-10 14:27:40,865:INFO:Plot type: vc
2024-05-10 14:27:40,866:INFO:Determining param_name
2024-05-10 14:27:40,866:INFO:param_name: max_depth
2024-05-10 14:27:40,899:INFO:Fitting Model
2024-05-10 14:27:43,187:INFO:Visual Rendered Successfully
2024-05-10 14:27:43,269:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:47,036:INFO:Initializing plot_model()
2024-05-10 14:27:47,036:INFO:plot_model(plot=manifold, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:47,036:INFO:Checking exceptions
2024-05-10 14:27:47,050:INFO:Preloading libraries
2024-05-10 14:27:47,058:INFO:Copying training dataset
2024-05-10 14:27:47,058:INFO:Plot type: manifold
2024-05-10 14:27:47,100:INFO:Fitting & Transforming Model
2024-05-10 14:27:47,613:INFO:Visual Rendered Successfully
2024-05-10 14:27:47,695:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:49,764:INFO:Initializing plot_model()
2024-05-10 14:27:49,764:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:49,764:INFO:Checking exceptions
2024-05-10 14:27:49,778:INFO:Preloading libraries
2024-05-10 14:27:49,785:INFO:Copying training dataset
2024-05-10 14:27:49,785:INFO:Plot type: feature
2024-05-10 14:27:49,786:WARNING:No coef_ found. Trying feature_importances_
2024-05-10 14:27:49,874:INFO:Visual Rendered Successfully
2024-05-10 14:27:49,955:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:50,499:INFO:Initializing plot_model()
2024-05-10 14:27:50,500:INFO:plot_model(plot=feature_all, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:50,500:INFO:Checking exceptions
2024-05-10 14:27:50,515:INFO:Preloading libraries
2024-05-10 14:27:50,526:INFO:Copying training dataset
2024-05-10 14:27:50,526:INFO:Plot type: feature_all
2024-05-10 14:27:50,539:WARNING:No coef_ found. Trying feature_importances_
2024-05-10 14:27:50,595:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/matplotlib/_tight_bbox.py:67: RuntimeWarning: divide by zero encountered in scalar divide
  fig.patch.set_bounds(x0 / w1, y0 / h1,

2024-05-10 14:27:50,595:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/matplotlib/_tight_bbox.py:68: RuntimeWarning: divide by zero encountered in scalar divide
  fig.bbox.width / w1, fig.bbox.height / h1)

2024-05-10 14:27:50,595:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/matplotlib/patches.py:739: RuntimeWarning: invalid value encountered in scalar add
  y1 = self.convert_yunits(self._y0 + self._height)

2024-05-10 14:27:50,595:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/matplotlib/transforms.py:2050: RuntimeWarning: invalid value encountered in scalar add
  self._mtx[1, 2] += ty

2024-05-10 14:27:50,611:INFO:Visual Rendered Successfully
2024-05-10 14:27:50,697:INFO:plot_model() successfully completed......................................
2024-05-10 14:27:51,460:INFO:Initializing plot_model()
2024-05-10 14:27:51,460:INFO:plot_model(plot=tree, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:27:51,460:INFO:Checking exceptions
2024-05-10 14:27:51,475:INFO:Preloading libraries
2024-05-10 14:27:51,480:INFO:Copying training dataset
2024-05-10 14:27:51,480:INFO:Plot type: tree
2024-05-10 14:27:52,269:INFO:Plotting decision trees
2024-05-10 14:27:52,278:INFO:Plotting tree 0
2024-05-10 14:27:53,294:INFO:Plotting tree 1
2024-05-10 14:27:53,947:INFO:Plotting tree 2
2024-05-10 14:27:54,590:INFO:Plotting tree 3
2024-05-10 14:27:55,323:INFO:Plotting tree 4
2024-05-10 14:27:55,951:INFO:Plotting tree 5
2024-05-10 14:27:56,576:INFO:Plotting tree 6
2024-05-10 14:27:57,201:INFO:Plotting tree 7
2024-05-10 14:27:57,950:INFO:Plotting tree 8
2024-05-10 14:27:58,576:INFO:Plotting tree 9
2024-05-10 14:27:59,199:INFO:Plotting tree 10
2024-05-10 14:27:59,821:INFO:Plotting tree 11
2024-05-10 14:28:00,443:INFO:Plotting tree 12
2024-05-10 14:28:01,067:INFO:Plotting tree 13
2024-05-10 14:28:01,826:INFO:Plotting tree 14
2024-05-10 14:28:02,453:INFO:Plotting tree 15
2024-05-10 14:28:03,082:INFO:Plotting tree 16
2024-05-10 14:28:03,723:INFO:Plotting tree 17
2024-05-10 14:28:04,362:INFO:Plotting tree 18
2024-05-10 14:28:04,992:INFO:Plotting tree 19
2024-05-10 14:28:05,798:INFO:Plotting tree 20
2024-05-10 14:28:06,427:INFO:Plotting tree 21
2024-05-10 14:28:07,058:INFO:Plotting tree 22
2024-05-10 14:28:07,684:INFO:Plotting tree 23
2024-05-10 14:28:08,334:INFO:Plotting tree 24
2024-05-10 14:28:08,999:INFO:Plotting tree 25
2024-05-10 14:28:09,650:INFO:Plotting tree 26
2024-05-10 14:28:10,489:INFO:Plotting tree 27
2024-05-10 14:28:11,149:INFO:Plotting tree 28
2024-05-10 14:28:11,813:INFO:Plotting tree 29
2024-05-10 14:28:12,489:INFO:Plotting tree 30
2024-05-10 14:28:13,129:INFO:Plotting tree 31
2024-05-10 14:28:13,783:INFO:Plotting tree 32
2024-05-10 14:28:14,468:INFO:Plotting tree 33
2024-05-10 14:28:15,133:INFO:Plotting tree 34
2024-05-10 14:28:15,788:INFO:Plotting tree 35
2024-05-10 14:28:17,342:INFO:Plotting tree 36
2024-05-10 14:28:18,223:INFO:Plotting tree 37
2024-05-10 14:28:18,899:INFO:Plotting tree 38
2024-05-10 14:28:19,573:INFO:Plotting tree 39
2024-05-10 14:28:20,245:INFO:Plotting tree 40
2024-05-10 14:28:20,909:INFO:Plotting tree 41
2024-05-10 14:28:21,581:INFO:Plotting tree 42
2024-05-10 14:28:22,266:INFO:Plotting tree 43
2024-05-10 14:28:22,990:INFO:Plotting tree 44
2024-05-10 14:28:23,822:INFO:Plotting tree 45
2024-05-10 14:28:24,582:INFO:Plotting tree 46
2024-05-10 14:28:25,713:INFO:Plotting tree 47
2024-05-10 14:28:26,525:INFO:Plotting tree 48
2024-05-10 14:28:27,259:INFO:Plotting tree 49
2024-05-10 14:28:28,070:INFO:Plotting tree 50
2024-05-10 14:28:28,766:INFO:Plotting tree 51
2024-05-10 14:28:29,469:INFO:Plotting tree 52
2024-05-10 14:28:30,153:INFO:Plotting tree 53
2024-05-10 14:28:30,855:INFO:Plotting tree 54
2024-05-10 14:28:31,537:INFO:Plotting tree 55
2024-05-10 14:28:32,231:INFO:Plotting tree 56
2024-05-10 14:28:32,958:INFO:Plotting tree 57
2024-05-10 14:28:33,791:INFO:Plotting tree 58
2024-05-10 14:28:34,905:INFO:Plotting tree 59
2024-05-10 14:28:35,678:INFO:Plotting tree 60
2024-05-10 14:28:36,389:INFO:Plotting tree 61
2024-05-10 14:28:37,077:INFO:Plotting tree 62
2024-05-10 14:28:37,740:INFO:Plotting tree 63
2024-05-10 14:28:38,406:INFO:Plotting tree 64
2024-05-10 14:28:39,062:INFO:Plotting tree 65
2024-05-10 14:28:39,712:INFO:Plotting tree 66
2024-05-10 14:28:40,358:INFO:Plotting tree 67
2024-05-10 14:28:41,016:INFO:Plotting tree 68
2024-05-10 14:28:41,682:INFO:Plotting tree 69
2024-05-10 14:28:42,320:INFO:Plotting tree 70
2024-05-10 14:28:42,958:INFO:Plotting tree 71
2024-05-10 14:28:43,595:INFO:Plotting tree 72
2024-05-10 14:28:44,238:INFO:Plotting tree 73
2024-05-10 14:28:45,374:INFO:Plotting tree 74
2024-05-10 14:28:46,047:INFO:Plotting tree 75
2024-05-10 14:28:46,707:INFO:Plotting tree 76
2024-05-10 14:28:47,348:INFO:Plotting tree 77
2024-05-10 14:28:47,991:INFO:Plotting tree 78
2024-05-10 14:28:48,628:INFO:Plotting tree 79
2024-05-10 14:28:49,268:INFO:Plotting tree 80
2024-05-10 14:28:49,905:INFO:Plotting tree 81
2024-05-10 14:28:50,546:INFO:Plotting tree 82
2024-05-10 14:28:51,186:INFO:Plotting tree 83
2024-05-10 14:28:51,827:INFO:Plotting tree 84
2024-05-10 14:28:52,465:INFO:Plotting tree 85
2024-05-10 14:28:53,122:INFO:Plotting tree 86
2024-05-10 14:28:53,767:INFO:Plotting tree 87
2024-05-10 14:28:54,401:INFO:Plotting tree 88
2024-05-10 14:28:55,033:INFO:Plotting tree 89
2024-05-10 14:28:55,666:INFO:Plotting tree 90
2024-05-10 14:28:56,721:INFO:Plotting tree 91
2024-05-10 14:28:57,351:INFO:Plotting tree 92
2024-05-10 14:28:57,984:INFO:Plotting tree 93
2024-05-10 14:28:58,620:INFO:Plotting tree 94
2024-05-10 14:28:59,254:INFO:Plotting tree 95
2024-05-10 14:28:59,892:INFO:Plotting tree 96
2024-05-10 14:29:00,526:INFO:Plotting tree 97
2024-05-10 14:29:01,158:INFO:Plotting tree 98
2024-05-10 14:29:01,799:INFO:Plotting tree 99
2024-05-10 14:39:10,750:INFO:Initializing plot_model()
2024-05-10 14:39:10,751:INFO:plot_model(plot=cooks, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767cbca3ff10>, system=True)
2024-05-10 14:39:10,751:INFO:Checking exceptions
2024-05-10 14:39:10,767:INFO:Preloading libraries
2024-05-10 14:39:10,778:INFO:Copying training dataset
2024-05-10 14:39:10,778:INFO:Plot type: cooks
2024-05-10 14:39:10,818:INFO:Fitting Model
2024-05-10 14:39:10,927:INFO:Visual Rendered Successfully
2024-05-10 14:39:12,302:INFO:plot_model() successfully completed......................................
2024-05-10 14:40:55,223:INFO:PyCaret RegressionExperiment
2024-05-10 14:40:55,223:INFO:Logging name: reg-default-name
2024-05-10 14:40:55,223:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:40:55,223:INFO:version 3.3.2
2024-05-10 14:40:55,223:INFO:Initializing setup()
2024-05-10 14:40:55,223:INFO:self.USI: 0cd8
2024-05-10 14:40:55,223:INFO:self._variable_keys: {'X', 'target_param', 'X_train', 'log_plots_param', 'gpu_n_jobs_param', 'n_jobs_param', 'USI', 'pipeline', 'idx', 'exp_name_log', 'y_train', 'fold_groups_param', 'data', '_ml_usecase', 'fold_shuffle_param', 'X_test', '_available_plots', 'exp_id', 'logging_param', 'transform_target_param', 'fold_generator', 'memory', 'html_param', 'gpu_param', 'y_test', 'seed', 'y'}
2024-05-10 14:40:55,223:INFO:Checking environment
2024-05-10 14:40:55,223:INFO:python_version: 3.9.18
2024-05-10 14:40:55,223:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:40:55,223:INFO:machine: x86_64
2024-05-10 14:40:55,223:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:40:55,223:INFO:Memory: svmem(total=16429797376, available=4852805632, percent=70.5, used=10460213248, free=1858527232, active=8584835072, inactive=4661194752, buffers=166346752, cached=3944710144, shared=770220032, slab=757469184)
2024-05-10 14:40:55,224:INFO:Physical Core: 12
2024-05-10 14:40:55,224:INFO:Logical Core: 16
2024-05-10 14:40:55,224:INFO:Checking libraries
2024-05-10 14:40:55,224:INFO:System:
2024-05-10 14:40:55,224:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:40:55,224:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:40:55,224:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:40:55,224:INFO:PyCaret required dependencies:
2024-05-10 14:40:55,224:INFO:                 pip: 23.3.1
2024-05-10 14:40:55,224:INFO:          setuptools: 68.2.2
2024-05-10 14:40:55,224:INFO:             pycaret: 3.3.2
2024-05-10 14:40:55,224:INFO:             IPython: 8.15.0
2024-05-10 14:40:55,224:INFO:          ipywidgets: 7.6.5
2024-05-10 14:40:55,224:INFO:                tqdm: 4.65.0
2024-05-10 14:40:55,224:INFO:               numpy: 1.26.4
2024-05-10 14:40:55,224:INFO:              pandas: 2.1.4
2024-05-10 14:40:55,224:INFO:              jinja2: 3.1.3
2024-05-10 14:40:55,224:INFO:               scipy: 1.11.4
2024-05-10 14:40:55,224:INFO:              joblib: 1.2.0
2024-05-10 14:40:55,224:INFO:             sklearn: 1.4.2
2024-05-10 14:40:55,224:INFO:                pyod: 1.1.3
2024-05-10 14:40:55,224:INFO:            imblearn: 0.12.2
2024-05-10 14:40:55,224:INFO:   category_encoders: 2.6.3
2024-05-10 14:40:55,224:INFO:            lightgbm: 4.3.0
2024-05-10 14:40:55,224:INFO:               numba: 0.59.1
2024-05-10 14:40:55,224:INFO:            requests: 2.31.0
2024-05-10 14:40:55,225:INFO:          matplotlib: 3.7.5
2024-05-10 14:40:55,225:INFO:          scikitplot: 0.3.7
2024-05-10 14:40:55,225:INFO:         yellowbrick: 1.5
2024-05-10 14:40:55,225:INFO:              plotly: 5.19.0
2024-05-10 14:40:55,225:INFO:    plotly-resampler: Not installed
2024-05-10 14:40:55,225:INFO:             kaleido: 0.2.1
2024-05-10 14:40:55,225:INFO:           schemdraw: 0.15
2024-05-10 14:40:55,225:INFO:         statsmodels: 0.14.0
2024-05-10 14:40:55,225:INFO:              sktime: 0.26.0
2024-05-10 14:40:55,225:INFO:               tbats: 1.1.3
2024-05-10 14:40:55,225:INFO:            pmdarima: 2.0.4
2024-05-10 14:40:55,225:INFO:              psutil: 5.9.0
2024-05-10 14:40:55,225:INFO:          markupsafe: 2.1.3
2024-05-10 14:40:55,225:INFO:             pickle5: Not installed
2024-05-10 14:40:55,225:INFO:         cloudpickle: 2.2.1
2024-05-10 14:40:55,225:INFO:         deprecation: 2.1.0
2024-05-10 14:40:55,225:INFO:              xxhash: 3.4.1
2024-05-10 14:40:55,225:INFO:           wurlitzer: 3.0.2
2024-05-10 14:40:55,225:INFO:PyCaret optional dependencies:
2024-05-10 14:40:55,225:INFO:                shap: Not installed
2024-05-10 14:40:55,225:INFO:           interpret: Not installed
2024-05-10 14:40:55,225:INFO:                umap: Not installed
2024-05-10 14:40:55,225:INFO:     ydata_profiling: Not installed
2024-05-10 14:40:55,225:INFO:  explainerdashboard: Not installed
2024-05-10 14:40:55,225:INFO:             autoviz: Not installed
2024-05-10 14:40:55,225:INFO:           fairlearn: Not installed
2024-05-10 14:40:55,225:INFO:          deepchecks: Not installed
2024-05-10 14:40:55,225:INFO:             xgboost: Not installed
2024-05-10 14:40:55,225:INFO:            catboost: Not installed
2024-05-10 14:40:55,225:INFO:              kmodes: Not installed
2024-05-10 14:40:55,225:INFO:             mlxtend: Not installed
2024-05-10 14:40:55,225:INFO:       statsforecast: Not installed
2024-05-10 14:40:55,225:INFO:        tune_sklearn: Not installed
2024-05-10 14:40:55,225:INFO:                 ray: Not installed
2024-05-10 14:40:55,225:INFO:            hyperopt: Not installed
2024-05-10 14:40:55,225:INFO:              optuna: Not installed
2024-05-10 14:40:55,225:INFO:               skopt: Not installed
2024-05-10 14:40:55,225:INFO:              mlflow: Not installed
2024-05-10 14:40:55,225:INFO:              gradio: Not installed
2024-05-10 14:40:55,225:INFO:             fastapi: Not installed
2024-05-10 14:40:55,225:INFO:             uvicorn: Not installed
2024-05-10 14:40:55,225:INFO:              m2cgen: Not installed
2024-05-10 14:40:55,225:INFO:           evidently: Not installed
2024-05-10 14:40:55,225:INFO:               fugue: Not installed
2024-05-10 14:40:55,225:INFO:           streamlit: 1.32.0
2024-05-10 14:40:55,225:INFO:             prophet: Not installed
2024-05-10 14:40:55,225:INFO:None
2024-05-10 14:40:55,225:INFO:Set up data.
2024-05-10 14:40:55,228:INFO:Set up folding strategy.
2024-05-10 14:40:55,228:INFO:Set up train/test split.
2024-05-10 14:40:55,230:INFO:Set up index.
2024-05-10 14:40:55,230:INFO:Assigning column types.
2024-05-10 14:40:55,232:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:40:55,232:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,234:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,237:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,276:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,305:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,306:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,306:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,308:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,310:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,339:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,361:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:40:55,363:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,365:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,393:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,414:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,414:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,414:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,417:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,419:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,445:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,465:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,465:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,465:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,465:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:40:55,469:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,494:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,514:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,518:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,564:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,565:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,565:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,565:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:40:55,594:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,614:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,614:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,614:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,643:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,663:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,663:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,664:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,664:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:40:55,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,712:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,712:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,742:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:40:55,762:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,762:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,763:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:40:55,816:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,816:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,866:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,866:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,867:INFO:Preparing preprocessing pipeline...
2024-05-10 14:40:55,867:INFO:Set up simple imputation.
2024-05-10 14:40:55,867:INFO:Set up column name cleaning.
2024-05-10 14:40:55,880:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:40:55,882:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:40:55,882:INFO:Creating final display dataframe.
2024-05-10 14:40:55,919:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 7)
4        Transformed data shape          (600, 7)
5   Transformed train set shape          (360, 7)
6    Transformed test set shape          (240, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              0cd8
2024-05-10 14:40:55,975:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:55,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:56,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:56,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:40:56,027:INFO:setup() successfully completed in 0.8s...............
2024-05-10 14:40:56,027:INFO:Initializing compare_models()
2024-05-10 14:40:56,027:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:40:56,027:INFO:Checking exceptions
2024-05-10 14:40:56,028:INFO:Preparing display monitor
2024-05-10 14:40:56,041:INFO:Initializing Linear Regression
2024-05-10 14:40:56,041:INFO:Total runtime is 2.3722648620605467e-06 minutes
2024-05-10 14:40:56,043:INFO:SubProcess create_model() called ==================================
2024-05-10 14:40:56,043:INFO:Initializing create_model()
2024-05-10 14:40:56,043:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:40:56,043:INFO:Checking exceptions
2024-05-10 14:40:56,043:INFO:Importing libraries
2024-05-10 14:40:56,043:INFO:Copying training dataset
2024-05-10 14:40:56,045:INFO:Defining folds
2024-05-10 14:40:56,046:INFO:Declaring metric variables
2024-05-10 14:40:56,047:INFO:Importing untrained model
2024-05-10 14:40:56,049:INFO:Linear Regression Imported successfully
2024-05-10 14:40:56,053:INFO:Starting cross validation
2024-05-10 14:40:56,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:40:58,872:INFO:Calculating mean and std
2024-05-10 14:40:58,873:INFO:Creating metrics dataframe
2024-05-10 14:40:58,875:INFO:Uploading results into container
2024-05-10 14:40:58,875:INFO:Uploading model into container now
2024-05-10 14:40:58,875:INFO:_master_model_container: 1
2024-05-10 14:40:58,875:INFO:_display_container: 2
2024-05-10 14:40:58,876:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:40:58,876:INFO:create_model() successfully completed......................................
2024-05-10 14:41:00,403:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:00,403:INFO:Creating metrics dataframe
2024-05-10 14:41:00,408:INFO:Initializing Lasso Regression
2024-05-10 14:41:00,408:INFO:Total runtime is 0.072780974706014 minutes
2024-05-10 14:41:00,410:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:00,410:INFO:Initializing create_model()
2024-05-10 14:41:00,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:00,410:INFO:Checking exceptions
2024-05-10 14:41:00,410:INFO:Importing libraries
2024-05-10 14:41:00,410:INFO:Copying training dataset
2024-05-10 14:41:00,413:INFO:Defining folds
2024-05-10 14:41:00,413:INFO:Declaring metric variables
2024-05-10 14:41:00,415:INFO:Importing untrained model
2024-05-10 14:41:00,417:INFO:Lasso Regression Imported successfully
2024-05-10 14:41:00,421:INFO:Starting cross validation
2024-05-10 14:41:00,421:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:01,977:INFO:Calculating mean and std
2024-05-10 14:41:01,978:INFO:Creating metrics dataframe
2024-05-10 14:41:01,979:INFO:Uploading results into container
2024-05-10 14:41:01,980:INFO:Uploading model into container now
2024-05-10 14:41:01,980:INFO:_master_model_container: 2
2024-05-10 14:41:01,980:INFO:_display_container: 2
2024-05-10 14:41:01,980:INFO:Lasso(random_state=123)
2024-05-10 14:41:01,981:INFO:create_model() successfully completed......................................
2024-05-10 14:41:03,423:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:03,423:INFO:Creating metrics dataframe
2024-05-10 14:41:03,428:INFO:Initializing Ridge Regression
2024-05-10 14:41:03,428:INFO:Total runtime is 0.1231099287668864 minutes
2024-05-10 14:41:03,430:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:03,430:INFO:Initializing create_model()
2024-05-10 14:41:03,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:03,430:INFO:Checking exceptions
2024-05-10 14:41:03,430:INFO:Importing libraries
2024-05-10 14:41:03,430:INFO:Copying training dataset
2024-05-10 14:41:03,433:INFO:Defining folds
2024-05-10 14:41:03,434:INFO:Declaring metric variables
2024-05-10 14:41:03,436:INFO:Importing untrained model
2024-05-10 14:41:03,438:INFO:Ridge Regression Imported successfully
2024-05-10 14:41:03,442:INFO:Starting cross validation
2024-05-10 14:41:03,442:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:03,481:INFO:Calculating mean and std
2024-05-10 14:41:03,482:INFO:Creating metrics dataframe
2024-05-10 14:41:03,483:INFO:Uploading results into container
2024-05-10 14:41:03,483:INFO:Uploading model into container now
2024-05-10 14:41:03,483:INFO:_master_model_container: 3
2024-05-10 14:41:03,484:INFO:_display_container: 2
2024-05-10 14:41:03,484:INFO:Ridge(random_state=123)
2024-05-10 14:41:03,484:INFO:create_model() successfully completed......................................
2024-05-10 14:41:04,955:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:04,955:INFO:Creating metrics dataframe
2024-05-10 14:41:04,960:INFO:Initializing Elastic Net
2024-05-10 14:41:04,960:INFO:Total runtime is 0.14865055481592815 minutes
2024-05-10 14:41:04,962:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:04,962:INFO:Initializing create_model()
2024-05-10 14:41:04,962:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:04,962:INFO:Checking exceptions
2024-05-10 14:41:04,962:INFO:Importing libraries
2024-05-10 14:41:04,962:INFO:Copying training dataset
2024-05-10 14:41:04,965:INFO:Defining folds
2024-05-10 14:41:04,965:INFO:Declaring metric variables
2024-05-10 14:41:04,967:INFO:Importing untrained model
2024-05-10 14:41:04,969:INFO:Elastic Net Imported successfully
2024-05-10 14:41:04,973:INFO:Starting cross validation
2024-05-10 14:41:04,974:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:05,019:INFO:Calculating mean and std
2024-05-10 14:41:05,019:INFO:Creating metrics dataframe
2024-05-10 14:41:05,020:INFO:Uploading results into container
2024-05-10 14:41:05,020:INFO:Uploading model into container now
2024-05-10 14:41:05,021:INFO:_master_model_container: 4
2024-05-10 14:41:05,021:INFO:_display_container: 2
2024-05-10 14:41:05,021:INFO:ElasticNet(random_state=123)
2024-05-10 14:41:05,021:INFO:create_model() successfully completed......................................
2024-05-10 14:41:06,428:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:06,428:INFO:Creating metrics dataframe
2024-05-10 14:41:06,432:INFO:Initializing Least Angle Regression
2024-05-10 14:41:06,432:INFO:Total runtime is 0.17318454186121623 minutes
2024-05-10 14:41:06,434:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:06,434:INFO:Initializing create_model()
2024-05-10 14:41:06,434:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:06,434:INFO:Checking exceptions
2024-05-10 14:41:06,434:INFO:Importing libraries
2024-05-10 14:41:06,434:INFO:Copying training dataset
2024-05-10 14:41:06,437:INFO:Defining folds
2024-05-10 14:41:06,437:INFO:Declaring metric variables
2024-05-10 14:41:06,439:INFO:Importing untrained model
2024-05-10 14:41:06,441:INFO:Least Angle Regression Imported successfully
2024-05-10 14:41:06,444:INFO:Starting cross validation
2024-05-10 14:41:06,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:06,500:INFO:Calculating mean and std
2024-05-10 14:41:06,500:INFO:Creating metrics dataframe
2024-05-10 14:41:06,502:INFO:Uploading results into container
2024-05-10 14:41:06,502:INFO:Uploading model into container now
2024-05-10 14:41:06,503:INFO:_master_model_container: 5
2024-05-10 14:41:06,503:INFO:_display_container: 2
2024-05-10 14:41:06,503:INFO:Lars(random_state=123)
2024-05-10 14:41:06,503:INFO:create_model() successfully completed......................................
2024-05-10 14:41:07,959:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:07,959:INFO:Creating metrics dataframe
2024-05-10 14:41:07,964:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:41:07,964:INFO:Total runtime is 0.19871422449747722 minutes
2024-05-10 14:41:07,966:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:07,967:INFO:Initializing create_model()
2024-05-10 14:41:07,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:07,967:INFO:Checking exceptions
2024-05-10 14:41:07,967:INFO:Importing libraries
2024-05-10 14:41:07,967:INFO:Copying training dataset
2024-05-10 14:41:07,969:INFO:Defining folds
2024-05-10 14:41:07,969:INFO:Declaring metric variables
2024-05-10 14:41:07,972:INFO:Importing untrained model
2024-05-10 14:41:07,974:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:41:07,978:INFO:Starting cross validation
2024-05-10 14:41:07,978:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:08,052:INFO:Calculating mean and std
2024-05-10 14:41:08,052:INFO:Creating metrics dataframe
2024-05-10 14:41:08,053:INFO:Uploading results into container
2024-05-10 14:41:08,053:INFO:Uploading model into container now
2024-05-10 14:41:08,054:INFO:_master_model_container: 6
2024-05-10 14:41:08,054:INFO:_display_container: 2
2024-05-10 14:41:08,054:INFO:LassoLars(random_state=123)
2024-05-10 14:41:08,054:INFO:create_model() successfully completed......................................
2024-05-10 14:41:09,514:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:09,514:INFO:Creating metrics dataframe
2024-05-10 14:41:09,519:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:41:09,519:INFO:Total runtime is 0.22463842630386355 minutes
2024-05-10 14:41:09,521:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:09,521:INFO:Initializing create_model()
2024-05-10 14:41:09,522:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:09,522:INFO:Checking exceptions
2024-05-10 14:41:09,522:INFO:Importing libraries
2024-05-10 14:41:09,522:INFO:Copying training dataset
2024-05-10 14:41:09,524:INFO:Defining folds
2024-05-10 14:41:09,524:INFO:Declaring metric variables
2024-05-10 14:41:09,526:INFO:Importing untrained model
2024-05-10 14:41:09,528:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:41:09,531:INFO:Starting cross validation
2024-05-10 14:41:09,532:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:09,573:INFO:Calculating mean and std
2024-05-10 14:41:09,574:INFO:Creating metrics dataframe
2024-05-10 14:41:09,575:INFO:Uploading results into container
2024-05-10 14:41:09,575:INFO:Uploading model into container now
2024-05-10 14:41:09,575:INFO:_master_model_container: 7
2024-05-10 14:41:09,575:INFO:_display_container: 2
2024-05-10 14:41:09,575:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:41:09,575:INFO:create_model() successfully completed......................................
2024-05-10 14:41:10,979:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:10,979:INFO:Creating metrics dataframe
2024-05-10 14:41:10,984:INFO:Initializing Bayesian Ridge
2024-05-10 14:41:10,984:INFO:Total runtime is 0.2490476409594218 minutes
2024-05-10 14:41:10,986:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:10,986:INFO:Initializing create_model()
2024-05-10 14:41:10,986:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:10,986:INFO:Checking exceptions
2024-05-10 14:41:10,986:INFO:Importing libraries
2024-05-10 14:41:10,986:INFO:Copying training dataset
2024-05-10 14:41:10,989:INFO:Defining folds
2024-05-10 14:41:10,989:INFO:Declaring metric variables
2024-05-10 14:41:10,991:INFO:Importing untrained model
2024-05-10 14:41:10,993:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:41:10,997:INFO:Starting cross validation
2024-05-10 14:41:10,997:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:11,043:INFO:Calculating mean and std
2024-05-10 14:41:11,043:INFO:Creating metrics dataframe
2024-05-10 14:41:11,044:INFO:Uploading results into container
2024-05-10 14:41:11,045:INFO:Uploading model into container now
2024-05-10 14:41:11,045:INFO:_master_model_container: 8
2024-05-10 14:41:11,045:INFO:_display_container: 2
2024-05-10 14:41:11,045:INFO:BayesianRidge()
2024-05-10 14:41:11,045:INFO:create_model() successfully completed......................................
2024-05-10 14:41:12,453:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:12,453:INFO:Creating metrics dataframe
2024-05-10 14:41:12,458:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:41:12,458:INFO:Total runtime is 0.27361824115117395 minutes
2024-05-10 14:41:12,460:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:12,460:INFO:Initializing create_model()
2024-05-10 14:41:12,460:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:12,461:INFO:Checking exceptions
2024-05-10 14:41:12,461:INFO:Importing libraries
2024-05-10 14:41:12,461:INFO:Copying training dataset
2024-05-10 14:41:12,465:INFO:Defining folds
2024-05-10 14:41:12,465:INFO:Declaring metric variables
2024-05-10 14:41:12,468:INFO:Importing untrained model
2024-05-10 14:41:12,471:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:41:12,475:INFO:Starting cross validation
2024-05-10 14:41:12,476:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:12,523:INFO:Calculating mean and std
2024-05-10 14:41:12,523:INFO:Creating metrics dataframe
2024-05-10 14:41:12,524:INFO:Uploading results into container
2024-05-10 14:41:12,524:INFO:Uploading model into container now
2024-05-10 14:41:12,524:INFO:_master_model_container: 9
2024-05-10 14:41:12,524:INFO:_display_container: 2
2024-05-10 14:41:12,525:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:41:12,525:INFO:create_model() successfully completed......................................
2024-05-10 14:41:13,992:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:13,992:INFO:Creating metrics dataframe
2024-05-10 14:41:13,997:INFO:Initializing Huber Regressor
2024-05-10 14:41:13,997:INFO:Total runtime is 0.29927381674448655 minutes
2024-05-10 14:41:14,000:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:14,000:INFO:Initializing create_model()
2024-05-10 14:41:14,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:14,000:INFO:Checking exceptions
2024-05-10 14:41:14,000:INFO:Importing libraries
2024-05-10 14:41:14,000:INFO:Copying training dataset
2024-05-10 14:41:14,004:INFO:Defining folds
2024-05-10 14:41:14,004:INFO:Declaring metric variables
2024-05-10 14:41:14,006:INFO:Importing untrained model
2024-05-10 14:41:14,008:INFO:Huber Regressor Imported successfully
2024-05-10 14:41:14,012:INFO:Starting cross validation
2024-05-10 14:41:14,013:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:14,059:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:41:14,062:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:41:14,069:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:41:14,071:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:41:14,077:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:41:14,089:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:41:14,097:INFO:Calculating mean and std
2024-05-10 14:41:14,097:INFO:Creating metrics dataframe
2024-05-10 14:41:14,098:INFO:Uploading results into container
2024-05-10 14:41:14,099:INFO:Uploading model into container now
2024-05-10 14:41:14,099:INFO:_master_model_container: 10
2024-05-10 14:41:14,099:INFO:_display_container: 2
2024-05-10 14:41:14,099:INFO:HuberRegressor()
2024-05-10 14:41:14,099:INFO:create_model() successfully completed......................................
2024-05-10 14:41:15,567:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:15,567:INFO:Creating metrics dataframe
2024-05-10 14:41:15,573:INFO:Initializing K Neighbors Regressor
2024-05-10 14:41:15,573:INFO:Total runtime is 0.32553376356760666 minutes
2024-05-10 14:41:15,575:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:15,575:INFO:Initializing create_model()
2024-05-10 14:41:15,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:15,575:INFO:Checking exceptions
2024-05-10 14:41:15,575:INFO:Importing libraries
2024-05-10 14:41:15,575:INFO:Copying training dataset
2024-05-10 14:41:15,578:INFO:Defining folds
2024-05-10 14:41:15,578:INFO:Declaring metric variables
2024-05-10 14:41:15,580:INFO:Importing untrained model
2024-05-10 14:41:15,582:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:41:15,586:INFO:Starting cross validation
2024-05-10 14:41:15,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:15,643:INFO:Calculating mean and std
2024-05-10 14:41:15,644:INFO:Creating metrics dataframe
2024-05-10 14:41:15,645:INFO:Uploading results into container
2024-05-10 14:41:15,645:INFO:Uploading model into container now
2024-05-10 14:41:15,645:INFO:_master_model_container: 11
2024-05-10 14:41:15,645:INFO:_display_container: 2
2024-05-10 14:41:15,646:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:41:15,646:INFO:create_model() successfully completed......................................
2024-05-10 14:41:17,119:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:17,119:INFO:Creating metrics dataframe
2024-05-10 14:41:17,124:INFO:Initializing Decision Tree Regressor
2024-05-10 14:41:17,124:INFO:Total runtime is 0.35138349930445356 minutes
2024-05-10 14:41:17,126:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:17,127:INFO:Initializing create_model()
2024-05-10 14:41:17,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:17,127:INFO:Checking exceptions
2024-05-10 14:41:17,127:INFO:Importing libraries
2024-05-10 14:41:17,127:INFO:Copying training dataset
2024-05-10 14:41:17,129:INFO:Defining folds
2024-05-10 14:41:17,129:INFO:Declaring metric variables
2024-05-10 14:41:17,131:INFO:Importing untrained model
2024-05-10 14:41:17,134:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:41:17,139:INFO:Starting cross validation
2024-05-10 14:41:17,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:17,180:INFO:Calculating mean and std
2024-05-10 14:41:17,180:INFO:Creating metrics dataframe
2024-05-10 14:41:17,181:INFO:Uploading results into container
2024-05-10 14:41:17,182:INFO:Uploading model into container now
2024-05-10 14:41:17,182:INFO:_master_model_container: 12
2024-05-10 14:41:17,182:INFO:_display_container: 2
2024-05-10 14:41:17,182:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:41:17,182:INFO:create_model() successfully completed......................................
2024-05-10 14:41:18,664:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:18,664:INFO:Creating metrics dataframe
2024-05-10 14:41:18,670:INFO:Initializing Random Forest Regressor
2024-05-10 14:41:18,670:INFO:Total runtime is 0.377149776617686 minutes
2024-05-10 14:41:18,672:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:18,672:INFO:Initializing create_model()
2024-05-10 14:41:18,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:18,672:INFO:Checking exceptions
2024-05-10 14:41:18,672:INFO:Importing libraries
2024-05-10 14:41:18,672:INFO:Copying training dataset
2024-05-10 14:41:18,675:INFO:Defining folds
2024-05-10 14:41:18,675:INFO:Declaring metric variables
2024-05-10 14:41:18,677:INFO:Importing untrained model
2024-05-10 14:41:18,679:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:41:18,682:INFO:Starting cross validation
2024-05-10 14:41:18,683:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:18,938:INFO:Calculating mean and std
2024-05-10 14:41:18,939:INFO:Creating metrics dataframe
2024-05-10 14:41:18,940:INFO:Uploading results into container
2024-05-10 14:41:18,941:INFO:Uploading model into container now
2024-05-10 14:41:18,941:INFO:_master_model_container: 13
2024-05-10 14:41:18,941:INFO:_display_container: 2
2024-05-10 14:41:18,941:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:41:18,941:INFO:create_model() successfully completed......................................
2024-05-10 14:41:20,408:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:20,408:INFO:Creating metrics dataframe
2024-05-10 14:41:20,413:INFO:Initializing Extra Trees Regressor
2024-05-10 14:41:20,413:INFO:Total runtime is 0.4062059084574382 minutes
2024-05-10 14:41:20,416:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:20,416:INFO:Initializing create_model()
2024-05-10 14:41:20,416:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:20,416:INFO:Checking exceptions
2024-05-10 14:41:20,416:INFO:Importing libraries
2024-05-10 14:41:20,416:INFO:Copying training dataset
2024-05-10 14:41:20,419:INFO:Defining folds
2024-05-10 14:41:20,419:INFO:Declaring metric variables
2024-05-10 14:41:20,421:INFO:Importing untrained model
2024-05-10 14:41:20,423:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:41:20,426:INFO:Starting cross validation
2024-05-10 14:41:20,427:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:20,594:INFO:Calculating mean and std
2024-05-10 14:41:20,594:INFO:Creating metrics dataframe
2024-05-10 14:41:20,596:INFO:Uploading results into container
2024-05-10 14:41:20,596:INFO:Uploading model into container now
2024-05-10 14:41:20,596:INFO:_master_model_container: 14
2024-05-10 14:41:20,596:INFO:_display_container: 2
2024-05-10 14:41:20,597:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:41:20,597:INFO:create_model() successfully completed......................................
2024-05-10 14:41:22,077:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:22,077:INFO:Creating metrics dataframe
2024-05-10 14:41:22,084:INFO:Initializing AdaBoost Regressor
2024-05-10 14:41:22,085:INFO:Total runtime is 0.4340571324030559 minutes
2024-05-10 14:41:22,087:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:22,087:INFO:Initializing create_model()
2024-05-10 14:41:22,087:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:22,087:INFO:Checking exceptions
2024-05-10 14:41:22,087:INFO:Importing libraries
2024-05-10 14:41:22,087:INFO:Copying training dataset
2024-05-10 14:41:22,090:INFO:Defining folds
2024-05-10 14:41:22,090:INFO:Declaring metric variables
2024-05-10 14:41:22,092:INFO:Importing untrained model
2024-05-10 14:41:22,094:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:41:22,099:INFO:Starting cross validation
2024-05-10 14:41:22,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:22,219:INFO:Calculating mean and std
2024-05-10 14:41:22,220:INFO:Creating metrics dataframe
2024-05-10 14:41:22,221:INFO:Uploading results into container
2024-05-10 14:41:22,221:INFO:Uploading model into container now
2024-05-10 14:41:22,222:INFO:_master_model_container: 15
2024-05-10 14:41:22,222:INFO:_display_container: 2
2024-05-10 14:41:22,222:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:41:22,222:INFO:create_model() successfully completed......................................
2024-05-10 14:41:23,696:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:23,697:INFO:Creating metrics dataframe
2024-05-10 14:41:23,703:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:41:23,703:INFO:Total runtime is 0.46102888186772667 minutes
2024-05-10 14:41:23,705:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:23,705:INFO:Initializing create_model()
2024-05-10 14:41:23,705:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:23,705:INFO:Checking exceptions
2024-05-10 14:41:23,705:INFO:Importing libraries
2024-05-10 14:41:23,705:INFO:Copying training dataset
2024-05-10 14:41:23,708:INFO:Defining folds
2024-05-10 14:41:23,708:INFO:Declaring metric variables
2024-05-10 14:41:23,710:INFO:Importing untrained model
2024-05-10 14:41:23,712:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:41:23,715:INFO:Starting cross validation
2024-05-10 14:41:23,716:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:23,866:INFO:Calculating mean and std
2024-05-10 14:41:23,867:INFO:Creating metrics dataframe
2024-05-10 14:41:23,868:INFO:Uploading results into container
2024-05-10 14:41:23,869:INFO:Uploading model into container now
2024-05-10 14:41:23,869:INFO:_master_model_container: 16
2024-05-10 14:41:23,869:INFO:_display_container: 2
2024-05-10 14:41:23,870:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:41:23,870:INFO:create_model() successfully completed......................................
2024-05-10 14:41:25,351:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:25,351:INFO:Creating metrics dataframe
2024-05-10 14:41:25,357:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:41:25,357:INFO:Total runtime is 0.48860164880752566 minutes
2024-05-10 14:41:25,359:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:25,359:INFO:Initializing create_model()
2024-05-10 14:41:25,359:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:25,359:INFO:Checking exceptions
2024-05-10 14:41:25,359:INFO:Importing libraries
2024-05-10 14:41:25,359:INFO:Copying training dataset
2024-05-10 14:41:25,362:INFO:Defining folds
2024-05-10 14:41:25,362:INFO:Declaring metric variables
2024-05-10 14:41:25,364:INFO:Importing untrained model
2024-05-10 14:41:25,367:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:41:25,371:INFO:Starting cross validation
2024-05-10 14:41:25,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:25,929:INFO:Calculating mean and std
2024-05-10 14:41:25,930:INFO:Creating metrics dataframe
2024-05-10 14:41:25,932:INFO:Uploading results into container
2024-05-10 14:41:25,933:INFO:Uploading model into container now
2024-05-10 14:41:25,933:INFO:_master_model_container: 17
2024-05-10 14:41:25,933:INFO:_display_container: 2
2024-05-10 14:41:25,934:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:41:25,934:INFO:create_model() successfully completed......................................
2024-05-10 14:41:27,411:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:27,412:INFO:Creating metrics dataframe
2024-05-10 14:41:27,418:INFO:Initializing Dummy Regressor
2024-05-10 14:41:27,418:INFO:Total runtime is 0.5229482928911845 minutes
2024-05-10 14:41:27,420:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:27,420:INFO:Initializing create_model()
2024-05-10 14:41:27,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767bb6496fa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:27,420:INFO:Checking exceptions
2024-05-10 14:41:27,420:INFO:Importing libraries
2024-05-10 14:41:27,420:INFO:Copying training dataset
2024-05-10 14:41:27,423:INFO:Defining folds
2024-05-10 14:41:27,423:INFO:Declaring metric variables
2024-05-10 14:41:27,425:INFO:Importing untrained model
2024-05-10 14:41:27,427:INFO:Dummy Regressor Imported successfully
2024-05-10 14:41:27,432:INFO:Starting cross validation
2024-05-10 14:41:27,433:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:27,475:INFO:Calculating mean and std
2024-05-10 14:41:27,476:INFO:Creating metrics dataframe
2024-05-10 14:41:27,477:INFO:Uploading results into container
2024-05-10 14:41:27,478:INFO:Uploading model into container now
2024-05-10 14:41:27,478:INFO:_master_model_container: 18
2024-05-10 14:41:27,478:INFO:_display_container: 2
2024-05-10 14:41:27,478:INFO:DummyRegressor()
2024-05-10 14:41:27,478:INFO:create_model() successfully completed......................................
2024-05-10 14:41:28,978:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:28,978:INFO:Creating metrics dataframe
2024-05-10 14:41:28,986:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:41:28,993:INFO:Initializing create_model()
2024-05-10 14:41:28,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:28,993:INFO:Checking exceptions
2024-05-10 14:41:28,995:INFO:Importing libraries
2024-05-10 14:41:28,995:INFO:Copying training dataset
2024-05-10 14:41:28,998:INFO:Defining folds
2024-05-10 14:41:28,998:INFO:Declaring metric variables
2024-05-10 14:41:28,998:INFO:Importing untrained model
2024-05-10 14:41:28,998:INFO:Declaring custom model
2024-05-10 14:41:28,999:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:41:28,999:INFO:Cross validation set to False
2024-05-10 14:41:28,999:INFO:Fitting Model
2024-05-10 14:41:29,054:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:41:29,054:INFO:create_model() successfully completed......................................
2024-05-10 14:41:30,544:INFO:_master_model_container: 18
2024-05-10 14:41:30,544:INFO:_display_container: 2
2024-05-10 14:41:30,544:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:41:30,545:INFO:compare_models() successfully completed......................................
2024-05-10 14:41:30,545:INFO:Initializing tune_model()
2024-05-10 14:41:30,545:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>)
2024-05-10 14:41:30,545:INFO:Checking exceptions
2024-05-10 14:41:30,555:INFO:Copying training dataset
2024-05-10 14:41:30,557:INFO:Checking base model
2024-05-10 14:41:30,557:INFO:Base model : Extra Trees Regressor
2024-05-10 14:41:30,559:INFO:Declaring metric variables
2024-05-10 14:41:30,561:INFO:Defining Hyperparameters
2024-05-10 14:41:32,074:INFO:Tuning with n_jobs=-1
2024-05-10 14:41:32,074:INFO:Initializing RandomizedSearchCV
2024-05-10 14:41:33,879:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:41:33,880:INFO:Hyperparameter search completed
2024-05-10 14:41:33,880:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:33,880:INFO:Initializing create_model()
2024-05-10 14:41:33,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x767ccb34a7c0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:41:33,880:INFO:Checking exceptions
2024-05-10 14:41:33,880:INFO:Importing libraries
2024-05-10 14:41:33,880:INFO:Copying training dataset
2024-05-10 14:41:33,883:INFO:Defining folds
2024-05-10 14:41:33,883:INFO:Declaring metric variables
2024-05-10 14:41:33,885:INFO:Importing untrained model
2024-05-10 14:41:33,886:INFO:Declaring custom model
2024-05-10 14:41:33,888:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:41:33,892:INFO:Starting cross validation
2024-05-10 14:41:33,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:34,135:INFO:Calculating mean and std
2024-05-10 14:41:34,136:INFO:Creating metrics dataframe
2024-05-10 14:41:34,139:INFO:Finalizing model
2024-05-10 14:41:34,250:INFO:Uploading results into container
2024-05-10 14:41:34,251:INFO:Uploading model into container now
2024-05-10 14:41:34,251:INFO:_master_model_container: 19
2024-05-10 14:41:34,251:INFO:_display_container: 3
2024-05-10 14:41:34,252:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:41:34,252:INFO:create_model() successfully completed......................................
2024-05-10 14:41:35,721:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:35,721:INFO:choose_better activated
2024-05-10 14:41:35,723:INFO:SubProcess create_model() called ==================================
2024-05-10 14:41:35,724:INFO:Initializing create_model()
2024-05-10 14:41:35,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:41:35,724:INFO:Checking exceptions
2024-05-10 14:41:35,725:INFO:Importing libraries
2024-05-10 14:41:35,725:INFO:Copying training dataset
2024-05-10 14:41:35,727:INFO:Defining folds
2024-05-10 14:41:35,727:INFO:Declaring metric variables
2024-05-10 14:41:35,727:INFO:Importing untrained model
2024-05-10 14:41:35,727:INFO:Declaring custom model
2024-05-10 14:41:35,728:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:41:35,728:INFO:Starting cross validation
2024-05-10 14:41:35,728:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:41:35,900:INFO:Calculating mean and std
2024-05-10 14:41:35,900:INFO:Creating metrics dataframe
2024-05-10 14:41:35,902:INFO:Finalizing model
2024-05-10 14:41:35,960:INFO:Uploading results into container
2024-05-10 14:41:35,960:INFO:Uploading model into container now
2024-05-10 14:41:35,961:INFO:_master_model_container: 20
2024-05-10 14:41:35,961:INFO:_display_container: 4
2024-05-10 14:41:35,961:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:41:35,961:INFO:create_model() successfully completed......................................
2024-05-10 14:41:37,451:INFO:SubProcess create_model() end ==================================
2024-05-10 14:41:37,452:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7495
2024-05-10 14:41:37,452:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6916
2024-05-10 14:41:37,453:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:41:37,453:INFO:choose_better completed
2024-05-10 14:41:37,453:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:41:37,459:INFO:_master_model_container: 20
2024-05-10 14:41:37,459:INFO:_display_container: 3
2024-05-10 14:41:37,459:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:41:37,459:INFO:tune_model() successfully completed......................................
2024-05-10 14:41:38,949:INFO:Initializing evaluate_model()
2024-05-10 14:41:38,949:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:41:38,956:INFO:Initializing plot_model()
2024-05-10 14:41:38,956:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, system=True)
2024-05-10 14:41:38,956:INFO:Checking exceptions
2024-05-10 14:41:38,966:INFO:Preloading libraries
2024-05-10 14:41:38,975:INFO:Copying training dataset
2024-05-10 14:41:38,975:INFO:Plot type: pipeline
2024-05-10 14:41:39,037:INFO:Visual Rendered Successfully
2024-05-10 14:41:40,529:INFO:plot_model() successfully completed......................................
2024-05-10 14:41:42,752:INFO:Initializing plot_model()
2024-05-10 14:41:42,752:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, system=True)
2024-05-10 14:41:42,752:INFO:Checking exceptions
2024-05-10 14:41:42,762:INFO:Preloading libraries
2024-05-10 14:41:42,768:INFO:Copying training dataset
2024-05-10 14:41:42,768:INFO:Plot type: residuals
2024-05-10 14:41:42,815:INFO:Fitting Model
2024-05-10 14:41:42,815:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:41:42,857:INFO:Scoring test/hold-out set
2024-05-10 14:41:43,058:INFO:Visual Rendered Successfully
2024-05-10 14:41:44,343:INFO:plot_model() successfully completed......................................
2024-05-10 14:41:48,043:INFO:Initializing plot_model()
2024-05-10 14:41:48,043:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, system=True)
2024-05-10 14:41:48,043:INFO:Checking exceptions
2024-05-10 14:41:48,057:INFO:Preloading libraries
2024-05-10 14:41:48,064:INFO:Copying training dataset
2024-05-10 14:41:48,064:INFO:Plot type: parameter
2024-05-10 14:41:48,066:INFO:Visual Rendered Successfully
2024-05-10 14:41:49,297:INFO:plot_model() successfully completed......................................
2024-05-10 14:41:49,304:INFO:Initializing plot_model()
2024-05-10 14:41:49,304:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, system=True)
2024-05-10 14:41:49,304:INFO:Checking exceptions
2024-05-10 14:41:49,314:INFO:Preloading libraries
2024-05-10 14:41:49,321:INFO:Copying training dataset
2024-05-10 14:41:49,321:INFO:Plot type: residuals
2024-05-10 14:41:49,367:INFO:Fitting Model
2024-05-10 14:41:49,367:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:41:49,409:INFO:Scoring test/hold-out set
2024-05-10 14:41:49,625:INFO:Visual Rendered Successfully
2024-05-10 14:41:50,880:INFO:plot_model() successfully completed......................................
2024-05-10 14:41:50,887:INFO:Initializing plot_model()
2024-05-10 14:41:50,887:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, system=True)
2024-05-10 14:41:50,887:INFO:Checking exceptions
2024-05-10 14:41:50,898:INFO:Preloading libraries
2024-05-10 14:41:50,904:INFO:Copying training dataset
2024-05-10 14:41:50,904:INFO:Plot type: error
2024-05-10 14:41:50,939:INFO:Fitting Model
2024-05-10 14:41:50,940:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:41:50,940:INFO:Scoring test/hold-out set
2024-05-10 14:41:51,067:INFO:Visual Rendered Successfully
2024-05-10 14:41:52,329:INFO:plot_model() successfully completed......................................
2024-05-10 14:42:06,278:INFO:Initializing plot_model()
2024-05-10 14:42:06,278:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x767bad584d00>, system=True)
2024-05-10 14:42:06,278:INFO:Checking exceptions
2024-05-10 14:42:06,298:INFO:Preloading libraries
2024-05-10 14:42:06,304:INFO:Copying training dataset
2024-05-10 14:42:06,304:INFO:Plot type: residuals
2024-05-10 14:42:06,350:INFO:Fitting Model
2024-05-10 14:42:06,350:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:42:06,390:INFO:Scoring test/hold-out set
2024-05-10 14:42:06,588:INFO:Visual Rendered Successfully
2024-05-10 14:42:07,882:INFO:plot_model() successfully completed......................................
2024-05-10 14:46:54,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 14:46:54,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 14:46:54,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 14:46:54,840:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 14:48:21,263:INFO:PyCaret RegressionExperiment
2024-05-10 14:48:21,263:INFO:Logging name: reg-default-name
2024-05-10 14:48:21,263:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:48:21,263:INFO:version 3.3.2
2024-05-10 14:48:21,263:INFO:Initializing setup()
2024-05-10 14:48:21,263:INFO:self.USI: 5c69
2024-05-10 14:48:21,263:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 14:48:21,264:INFO:Checking environment
2024-05-10 14:48:21,264:INFO:python_version: 3.9.18
2024-05-10 14:48:21,264:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:48:21,264:INFO:machine: x86_64
2024-05-10 14:48:21,264:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:48:21,264:INFO:Memory: svmem(total=16429797376, available=8758710272, percent=46.7, used=6609711104, free=6658162688, active=4073250816, inactive=4383723520, buffers=162144256, cached=2999779328, shared=714784768, slab=728543232)
2024-05-10 14:48:21,264:INFO:Physical Core: 12
2024-05-10 14:48:21,264:INFO:Logical Core: 16
2024-05-10 14:48:21,264:INFO:Checking libraries
2024-05-10 14:48:21,264:INFO:System:
2024-05-10 14:48:21,264:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:48:21,264:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:48:21,264:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:48:21,264:INFO:PyCaret required dependencies:
2024-05-10 14:48:21,466:INFO:                 pip: 23.3.1
2024-05-10 14:48:21,466:INFO:          setuptools: 68.2.2
2024-05-10 14:48:21,466:INFO:             pycaret: 3.3.2
2024-05-10 14:48:21,466:INFO:             IPython: 8.15.0
2024-05-10 14:48:21,466:INFO:          ipywidgets: 7.6.5
2024-05-10 14:48:21,466:INFO:                tqdm: 4.65.0
2024-05-10 14:48:21,466:INFO:               numpy: 1.26.4
2024-05-10 14:48:21,466:INFO:              pandas: 2.1.4
2024-05-10 14:48:21,466:INFO:              jinja2: 3.1.3
2024-05-10 14:48:21,466:INFO:               scipy: 1.11.4
2024-05-10 14:48:21,466:INFO:              joblib: 1.2.0
2024-05-10 14:48:21,466:INFO:             sklearn: 1.4.2
2024-05-10 14:48:21,466:INFO:                pyod: 1.1.3
2024-05-10 14:48:21,466:INFO:            imblearn: 0.12.2
2024-05-10 14:48:21,466:INFO:   category_encoders: 2.6.3
2024-05-10 14:48:21,466:INFO:            lightgbm: 4.3.0
2024-05-10 14:48:21,466:INFO:               numba: 0.59.1
2024-05-10 14:48:21,466:INFO:            requests: 2.31.0
2024-05-10 14:48:21,466:INFO:          matplotlib: 3.7.5
2024-05-10 14:48:21,466:INFO:          scikitplot: 0.3.7
2024-05-10 14:48:21,466:INFO:         yellowbrick: 1.5
2024-05-10 14:48:21,466:INFO:              plotly: 5.19.0
2024-05-10 14:48:21,466:INFO:    plotly-resampler: Not installed
2024-05-10 14:48:21,466:INFO:             kaleido: 0.2.1
2024-05-10 14:48:21,466:INFO:           schemdraw: 0.15
2024-05-10 14:48:21,466:INFO:         statsmodels: 0.14.0
2024-05-10 14:48:21,466:INFO:              sktime: 0.26.0
2024-05-10 14:48:21,466:INFO:               tbats: 1.1.3
2024-05-10 14:48:21,466:INFO:            pmdarima: 2.0.4
2024-05-10 14:48:21,466:INFO:              psutil: 5.9.0
2024-05-10 14:48:21,466:INFO:          markupsafe: 2.1.3
2024-05-10 14:48:21,466:INFO:             pickle5: Not installed
2024-05-10 14:48:21,466:INFO:         cloudpickle: 2.2.1
2024-05-10 14:48:21,466:INFO:         deprecation: 2.1.0
2024-05-10 14:48:21,466:INFO:              xxhash: 3.4.1
2024-05-10 14:48:21,466:INFO:           wurlitzer: 3.0.2
2024-05-10 14:48:21,466:INFO:PyCaret optional dependencies:
2024-05-10 14:48:21,476:INFO:                shap: Not installed
2024-05-10 14:48:21,476:INFO:           interpret: Not installed
2024-05-10 14:48:21,476:INFO:                umap: Not installed
2024-05-10 14:48:21,476:INFO:     ydata_profiling: Not installed
2024-05-10 14:48:21,476:INFO:  explainerdashboard: Not installed
2024-05-10 14:48:21,476:INFO:             autoviz: Not installed
2024-05-10 14:48:21,476:INFO:           fairlearn: Not installed
2024-05-10 14:48:21,476:INFO:          deepchecks: Not installed
2024-05-10 14:48:21,476:INFO:             xgboost: Not installed
2024-05-10 14:48:21,476:INFO:            catboost: Not installed
2024-05-10 14:48:21,476:INFO:              kmodes: Not installed
2024-05-10 14:48:21,476:INFO:             mlxtend: Not installed
2024-05-10 14:48:21,476:INFO:       statsforecast: Not installed
2024-05-10 14:48:21,476:INFO:        tune_sklearn: Not installed
2024-05-10 14:48:21,476:INFO:                 ray: Not installed
2024-05-10 14:48:21,476:INFO:            hyperopt: Not installed
2024-05-10 14:48:21,476:INFO:              optuna: Not installed
2024-05-10 14:48:21,476:INFO:               skopt: Not installed
2024-05-10 14:48:21,476:INFO:              mlflow: Not installed
2024-05-10 14:48:21,476:INFO:              gradio: Not installed
2024-05-10 14:48:21,476:INFO:             fastapi: Not installed
2024-05-10 14:48:21,476:INFO:             uvicorn: Not installed
2024-05-10 14:48:21,476:INFO:              m2cgen: Not installed
2024-05-10 14:48:21,476:INFO:           evidently: Not installed
2024-05-10 14:48:21,476:INFO:               fugue: Not installed
2024-05-10 14:48:21,476:INFO:           streamlit: 1.32.0
2024-05-10 14:48:21,476:INFO:             prophet: Not installed
2024-05-10 14:48:21,476:INFO:None
2024-05-10 14:48:21,476:INFO:Set up data.
2024-05-10 14:48:21,479:INFO:Set up folding strategy.
2024-05-10 14:48:21,479:INFO:Set up train/test split.
2024-05-10 14:48:21,481:INFO:Set up index.
2024-05-10 14:48:21,481:INFO:Assigning column types.
2024-05-10 14:48:21,482:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:48:21,483:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,485:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,488:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,525:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,544:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,544:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,547:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,549:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,575:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,596:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,596:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,596:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,596:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:48:21,599:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,601:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,628:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,649:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,652:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,654:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,680:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,700:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,700:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,700:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:48:21,704:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,728:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,748:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,748:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,752:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,777:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,796:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,797:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:48:21,826:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,846:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,846:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,846:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,875:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,898:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,898:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,898:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,899:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:48:21,928:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:21,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:21,979:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:48:22,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,000:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,000:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:48:22,050:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,101:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,101:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,103:INFO:Preparing preprocessing pipeline...
2024-05-10 14:48:22,103:INFO:Set up simple imputation.
2024-05-10 14:48:22,103:INFO:Set up column name cleaning.
2024-05-10 14:48:22,122:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:48:22,133:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:48:22,133:INFO:Creating final display dataframe.
2024-05-10 14:48:22,177:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (407, 7)
4        Transformed data shape          (407, 7)
5   Transformed train set shape          (244, 7)
6    Transformed test set shape          (163, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              5c69
2024-05-10 14:48:22,261:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,262:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,321:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,321:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:48:22,321:INFO:setup() successfully completed in 1.06s...............
2024-05-10 14:48:22,322:INFO:Initializing compare_models()
2024-05-10 14:48:22,322:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:48:22,322:INFO:Checking exceptions
2024-05-10 14:48:22,323:INFO:Preparing display monitor
2024-05-10 14:48:22,353:INFO:Initializing Linear Regression
2024-05-10 14:48:22,354:INFO:Total runtime is 2.976258595784505e-06 minutes
2024-05-10 14:48:22,357:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:22,357:INFO:Initializing create_model()
2024-05-10 14:48:22,357:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:22,357:INFO:Checking exceptions
2024-05-10 14:48:22,357:INFO:Importing libraries
2024-05-10 14:48:22,357:INFO:Copying training dataset
2024-05-10 14:48:22,361:INFO:Defining folds
2024-05-10 14:48:22,361:INFO:Declaring metric variables
2024-05-10 14:48:22,364:INFO:Importing untrained model
2024-05-10 14:48:22,368:INFO:Linear Regression Imported successfully
2024-05-10 14:48:22,375:INFO:Starting cross validation
2024-05-10 14:48:22,379:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:24,793:INFO:Calculating mean and std
2024-05-10 14:48:24,794:INFO:Creating metrics dataframe
2024-05-10 14:48:24,797:INFO:Uploading results into container
2024-05-10 14:48:24,797:INFO:Uploading model into container now
2024-05-10 14:48:24,798:INFO:_master_model_container: 1
2024-05-10 14:48:24,798:INFO:_display_container: 2
2024-05-10 14:48:24,798:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:48:24,798:INFO:create_model() successfully completed......................................
2024-05-10 14:48:24,913:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:24,913:INFO:Creating metrics dataframe
2024-05-10 14:48:24,918:INFO:Initializing Lasso Regression
2024-05-10 14:48:24,918:INFO:Total runtime is 0.04273966550827026 minutes
2024-05-10 14:48:24,920:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:24,921:INFO:Initializing create_model()
2024-05-10 14:48:24,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:24,921:INFO:Checking exceptions
2024-05-10 14:48:24,921:INFO:Importing libraries
2024-05-10 14:48:24,921:INFO:Copying training dataset
2024-05-10 14:48:24,924:INFO:Defining folds
2024-05-10 14:48:24,924:INFO:Declaring metric variables
2024-05-10 14:48:24,925:INFO:Importing untrained model
2024-05-10 14:48:24,927:INFO:Lasso Regression Imported successfully
2024-05-10 14:48:24,931:INFO:Starting cross validation
2024-05-10 14:48:24,931:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:26,537:INFO:Calculating mean and std
2024-05-10 14:48:26,537:INFO:Creating metrics dataframe
2024-05-10 14:48:26,539:INFO:Uploading results into container
2024-05-10 14:48:26,540:INFO:Uploading model into container now
2024-05-10 14:48:26,540:INFO:_master_model_container: 2
2024-05-10 14:48:26,540:INFO:_display_container: 2
2024-05-10 14:48:26,540:INFO:Lasso(random_state=123)
2024-05-10 14:48:26,540:INFO:create_model() successfully completed......................................
2024-05-10 14:48:26,646:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:26,647:INFO:Creating metrics dataframe
2024-05-10 14:48:26,652:INFO:Initializing Ridge Regression
2024-05-10 14:48:26,652:INFO:Total runtime is 0.0716453472773234 minutes
2024-05-10 14:48:26,654:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:26,655:INFO:Initializing create_model()
2024-05-10 14:48:26,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:26,655:INFO:Checking exceptions
2024-05-10 14:48:26,655:INFO:Importing libraries
2024-05-10 14:48:26,655:INFO:Copying training dataset
2024-05-10 14:48:26,657:INFO:Defining folds
2024-05-10 14:48:26,657:INFO:Declaring metric variables
2024-05-10 14:48:26,659:INFO:Importing untrained model
2024-05-10 14:48:26,661:INFO:Ridge Regression Imported successfully
2024-05-10 14:48:26,664:INFO:Starting cross validation
2024-05-10 14:48:26,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:26,715:INFO:Calculating mean and std
2024-05-10 14:48:26,715:INFO:Creating metrics dataframe
2024-05-10 14:48:26,717:INFO:Uploading results into container
2024-05-10 14:48:26,717:INFO:Uploading model into container now
2024-05-10 14:48:26,717:INFO:_master_model_container: 3
2024-05-10 14:48:26,717:INFO:_display_container: 2
2024-05-10 14:48:26,718:INFO:Ridge(random_state=123)
2024-05-10 14:48:26,718:INFO:create_model() successfully completed......................................
2024-05-10 14:48:26,814:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:26,814:INFO:Creating metrics dataframe
2024-05-10 14:48:26,819:INFO:Initializing Elastic Net
2024-05-10 14:48:26,819:INFO:Total runtime is 0.07442277669906616 minutes
2024-05-10 14:48:26,821:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:26,821:INFO:Initializing create_model()
2024-05-10 14:48:26,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:26,821:INFO:Checking exceptions
2024-05-10 14:48:26,821:INFO:Importing libraries
2024-05-10 14:48:26,821:INFO:Copying training dataset
2024-05-10 14:48:26,823:INFO:Defining folds
2024-05-10 14:48:26,823:INFO:Declaring metric variables
2024-05-10 14:48:26,825:INFO:Importing untrained model
2024-05-10 14:48:26,827:INFO:Elastic Net Imported successfully
2024-05-10 14:48:26,833:INFO:Starting cross validation
2024-05-10 14:48:26,834:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:26,879:INFO:Calculating mean and std
2024-05-10 14:48:26,879:INFO:Creating metrics dataframe
2024-05-10 14:48:26,880:INFO:Uploading results into container
2024-05-10 14:48:26,881:INFO:Uploading model into container now
2024-05-10 14:48:26,881:INFO:_master_model_container: 4
2024-05-10 14:48:26,881:INFO:_display_container: 2
2024-05-10 14:48:26,881:INFO:ElasticNet(random_state=123)
2024-05-10 14:48:26,881:INFO:create_model() successfully completed......................................
2024-05-10 14:48:26,977:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:26,977:INFO:Creating metrics dataframe
2024-05-10 14:48:26,981:INFO:Initializing Least Angle Regression
2024-05-10 14:48:26,981:INFO:Total runtime is 0.07712266047795614 minutes
2024-05-10 14:48:26,983:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:26,983:INFO:Initializing create_model()
2024-05-10 14:48:26,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:26,983:INFO:Checking exceptions
2024-05-10 14:48:26,983:INFO:Importing libraries
2024-05-10 14:48:26,983:INFO:Copying training dataset
2024-05-10 14:48:26,986:INFO:Defining folds
2024-05-10 14:48:26,986:INFO:Declaring metric variables
2024-05-10 14:48:26,988:INFO:Importing untrained model
2024-05-10 14:48:26,991:INFO:Least Angle Regression Imported successfully
2024-05-10 14:48:27,004:INFO:Starting cross validation
2024-05-10 14:48:27,005:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:27,084:INFO:Calculating mean and std
2024-05-10 14:48:27,085:INFO:Creating metrics dataframe
2024-05-10 14:48:27,087:INFO:Uploading results into container
2024-05-10 14:48:27,088:INFO:Uploading model into container now
2024-05-10 14:48:27,088:INFO:_master_model_container: 5
2024-05-10 14:48:27,088:INFO:_display_container: 2
2024-05-10 14:48:27,088:INFO:Lars(random_state=123)
2024-05-10 14:48:27,088:INFO:create_model() successfully completed......................................
2024-05-10 14:48:27,181:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:27,181:INFO:Creating metrics dataframe
2024-05-10 14:48:27,186:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:48:27,186:INFO:Total runtime is 0.08054896990458171 minutes
2024-05-10 14:48:27,188:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:27,188:INFO:Initializing create_model()
2024-05-10 14:48:27,188:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:27,188:INFO:Checking exceptions
2024-05-10 14:48:27,188:INFO:Importing libraries
2024-05-10 14:48:27,188:INFO:Copying training dataset
2024-05-10 14:48:27,191:INFO:Defining folds
2024-05-10 14:48:27,191:INFO:Declaring metric variables
2024-05-10 14:48:27,192:INFO:Importing untrained model
2024-05-10 14:48:27,194:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:48:27,197:INFO:Starting cross validation
2024-05-10 14:48:27,197:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:27,247:INFO:Calculating mean and std
2024-05-10 14:48:27,248:INFO:Creating metrics dataframe
2024-05-10 14:48:27,249:INFO:Uploading results into container
2024-05-10 14:48:27,250:INFO:Uploading model into container now
2024-05-10 14:48:27,250:INFO:_master_model_container: 6
2024-05-10 14:48:27,250:INFO:_display_container: 2
2024-05-10 14:48:27,251:INFO:LassoLars(random_state=123)
2024-05-10 14:48:27,251:INFO:create_model() successfully completed......................................
2024-05-10 14:48:27,346:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:27,346:INFO:Creating metrics dataframe
2024-05-10 14:48:27,351:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:48:27,351:INFO:Total runtime is 0.08328700860341391 minutes
2024-05-10 14:48:27,353:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:27,353:INFO:Initializing create_model()
2024-05-10 14:48:27,353:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:27,353:INFO:Checking exceptions
2024-05-10 14:48:27,353:INFO:Importing libraries
2024-05-10 14:48:27,353:INFO:Copying training dataset
2024-05-10 14:48:27,355:INFO:Defining folds
2024-05-10 14:48:27,355:INFO:Declaring metric variables
2024-05-10 14:48:27,357:INFO:Importing untrained model
2024-05-10 14:48:27,358:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:48:27,362:INFO:Starting cross validation
2024-05-10 14:48:27,363:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:27,405:INFO:Calculating mean and std
2024-05-10 14:48:27,406:INFO:Creating metrics dataframe
2024-05-10 14:48:27,407:INFO:Uploading results into container
2024-05-10 14:48:27,408:INFO:Uploading model into container now
2024-05-10 14:48:27,408:INFO:_master_model_container: 7
2024-05-10 14:48:27,408:INFO:_display_container: 2
2024-05-10 14:48:27,408:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:48:27,408:INFO:create_model() successfully completed......................................
2024-05-10 14:48:27,501:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:27,501:INFO:Creating metrics dataframe
2024-05-10 14:48:27,506:INFO:Initializing Bayesian Ridge
2024-05-10 14:48:27,506:INFO:Total runtime is 0.08588024377822877 minutes
2024-05-10 14:48:27,508:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:27,508:INFO:Initializing create_model()
2024-05-10 14:48:27,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:27,508:INFO:Checking exceptions
2024-05-10 14:48:27,508:INFO:Importing libraries
2024-05-10 14:48:27,508:INFO:Copying training dataset
2024-05-10 14:48:27,511:INFO:Defining folds
2024-05-10 14:48:27,511:INFO:Declaring metric variables
2024-05-10 14:48:27,512:INFO:Importing untrained model
2024-05-10 14:48:27,514:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:48:27,519:INFO:Starting cross validation
2024-05-10 14:48:27,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:27,562:INFO:Calculating mean and std
2024-05-10 14:48:27,562:INFO:Creating metrics dataframe
2024-05-10 14:48:27,563:INFO:Uploading results into container
2024-05-10 14:48:27,563:INFO:Uploading model into container now
2024-05-10 14:48:27,564:INFO:_master_model_container: 8
2024-05-10 14:48:27,564:INFO:_display_container: 2
2024-05-10 14:48:27,564:INFO:BayesianRidge()
2024-05-10 14:48:27,564:INFO:create_model() successfully completed......................................
2024-05-10 14:48:27,657:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:27,657:INFO:Creating metrics dataframe
2024-05-10 14:48:27,662:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:48:27,662:INFO:Total runtime is 0.08848197062810263 minutes
2024-05-10 14:48:27,664:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:27,665:INFO:Initializing create_model()
2024-05-10 14:48:27,665:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:27,665:INFO:Checking exceptions
2024-05-10 14:48:27,665:INFO:Importing libraries
2024-05-10 14:48:27,665:INFO:Copying training dataset
2024-05-10 14:48:27,668:INFO:Defining folds
2024-05-10 14:48:27,668:INFO:Declaring metric variables
2024-05-10 14:48:27,670:INFO:Importing untrained model
2024-05-10 14:48:27,673:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:48:27,676:INFO:Starting cross validation
2024-05-10 14:48:27,677:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:27,723:INFO:Calculating mean and std
2024-05-10 14:48:27,723:INFO:Creating metrics dataframe
2024-05-10 14:48:27,724:INFO:Uploading results into container
2024-05-10 14:48:27,724:INFO:Uploading model into container now
2024-05-10 14:48:27,725:INFO:_master_model_container: 9
2024-05-10 14:48:27,725:INFO:_display_container: 2
2024-05-10 14:48:27,725:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:48:27,725:INFO:create_model() successfully completed......................................
2024-05-10 14:48:27,817:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:27,817:INFO:Creating metrics dataframe
2024-05-10 14:48:27,822:INFO:Initializing Huber Regressor
2024-05-10 14:48:27,822:INFO:Total runtime is 0.09114498297373455 minutes
2024-05-10 14:48:27,824:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:27,824:INFO:Initializing create_model()
2024-05-10 14:48:27,824:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:27,824:INFO:Checking exceptions
2024-05-10 14:48:27,824:INFO:Importing libraries
2024-05-10 14:48:27,824:INFO:Copying training dataset
2024-05-10 14:48:27,827:INFO:Defining folds
2024-05-10 14:48:27,827:INFO:Declaring metric variables
2024-05-10 14:48:27,828:INFO:Importing untrained model
2024-05-10 14:48:27,830:INFO:Huber Regressor Imported successfully
2024-05-10 14:48:27,835:INFO:Starting cross validation
2024-05-10 14:48:27,835:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:27,875:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:48:27,879:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:48:27,880:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:48:27,890:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:48:27,892:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:48:27,896:INFO:Calculating mean and std
2024-05-10 14:48:27,897:INFO:Creating metrics dataframe
2024-05-10 14:48:27,898:INFO:Uploading results into container
2024-05-10 14:48:27,898:INFO:Uploading model into container now
2024-05-10 14:48:27,898:INFO:_master_model_container: 10
2024-05-10 14:48:27,898:INFO:_display_container: 2
2024-05-10 14:48:27,899:INFO:HuberRegressor()
2024-05-10 14:48:27,899:INFO:create_model() successfully completed......................................
2024-05-10 14:48:27,992:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:27,992:INFO:Creating metrics dataframe
2024-05-10 14:48:27,997:INFO:Initializing K Neighbors Regressor
2024-05-10 14:48:27,998:INFO:Total runtime is 0.09406984647115073 minutes
2024-05-10 14:48:28,000:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:28,001:INFO:Initializing create_model()
2024-05-10 14:48:28,001:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:28,001:INFO:Checking exceptions
2024-05-10 14:48:28,001:INFO:Importing libraries
2024-05-10 14:48:28,001:INFO:Copying training dataset
2024-05-10 14:48:28,005:INFO:Defining folds
2024-05-10 14:48:28,005:INFO:Declaring metric variables
2024-05-10 14:48:28,007:INFO:Importing untrained model
2024-05-10 14:48:28,010:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:48:28,013:INFO:Starting cross validation
2024-05-10 14:48:28,014:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:28,075:INFO:Calculating mean and std
2024-05-10 14:48:28,075:INFO:Creating metrics dataframe
2024-05-10 14:48:28,077:INFO:Uploading results into container
2024-05-10 14:48:28,077:INFO:Uploading model into container now
2024-05-10 14:48:28,077:INFO:_master_model_container: 11
2024-05-10 14:48:28,077:INFO:_display_container: 2
2024-05-10 14:48:28,077:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:48:28,077:INFO:create_model() successfully completed......................................
2024-05-10 14:48:28,171:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:28,171:INFO:Creating metrics dataframe
2024-05-10 14:48:28,176:INFO:Initializing Decision Tree Regressor
2024-05-10 14:48:28,176:INFO:Total runtime is 0.09704733292261761 minutes
2024-05-10 14:48:28,178:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:28,178:INFO:Initializing create_model()
2024-05-10 14:48:28,179:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:28,179:INFO:Checking exceptions
2024-05-10 14:48:28,179:INFO:Importing libraries
2024-05-10 14:48:28,179:INFO:Copying training dataset
2024-05-10 14:48:28,181:INFO:Defining folds
2024-05-10 14:48:28,181:INFO:Declaring metric variables
2024-05-10 14:48:28,183:INFO:Importing untrained model
2024-05-10 14:48:28,187:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:48:28,192:INFO:Starting cross validation
2024-05-10 14:48:28,193:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:28,243:INFO:Calculating mean and std
2024-05-10 14:48:28,244:INFO:Creating metrics dataframe
2024-05-10 14:48:28,245:INFO:Uploading results into container
2024-05-10 14:48:28,246:INFO:Uploading model into container now
2024-05-10 14:48:28,246:INFO:_master_model_container: 12
2024-05-10 14:48:28,246:INFO:_display_container: 2
2024-05-10 14:48:28,246:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:48:28,246:INFO:create_model() successfully completed......................................
2024-05-10 14:48:28,340:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:28,340:INFO:Creating metrics dataframe
2024-05-10 14:48:28,345:INFO:Initializing Random Forest Regressor
2024-05-10 14:48:28,345:INFO:Total runtime is 0.09986039797465007 minutes
2024-05-10 14:48:28,347:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:28,347:INFO:Initializing create_model()
2024-05-10 14:48:28,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:28,347:INFO:Checking exceptions
2024-05-10 14:48:28,347:INFO:Importing libraries
2024-05-10 14:48:28,347:INFO:Copying training dataset
2024-05-10 14:48:28,350:INFO:Defining folds
2024-05-10 14:48:28,350:INFO:Declaring metric variables
2024-05-10 14:48:28,352:INFO:Importing untrained model
2024-05-10 14:48:28,354:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:48:28,358:INFO:Starting cross validation
2024-05-10 14:48:28,358:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:28,588:INFO:Calculating mean and std
2024-05-10 14:48:28,589:INFO:Creating metrics dataframe
2024-05-10 14:48:28,591:INFO:Uploading results into container
2024-05-10 14:48:28,591:INFO:Uploading model into container now
2024-05-10 14:48:28,592:INFO:_master_model_container: 13
2024-05-10 14:48:28,592:INFO:_display_container: 2
2024-05-10 14:48:28,592:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:48:28,592:INFO:create_model() successfully completed......................................
2024-05-10 14:48:28,685:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:28,685:INFO:Creating metrics dataframe
2024-05-10 14:48:28,690:INFO:Initializing Extra Trees Regressor
2024-05-10 14:48:28,690:INFO:Total runtime is 0.10561506350835165 minutes
2024-05-10 14:48:28,692:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:28,692:INFO:Initializing create_model()
2024-05-10 14:48:28,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:28,692:INFO:Checking exceptions
2024-05-10 14:48:28,692:INFO:Importing libraries
2024-05-10 14:48:28,692:INFO:Copying training dataset
2024-05-10 14:48:28,695:INFO:Defining folds
2024-05-10 14:48:28,695:INFO:Declaring metric variables
2024-05-10 14:48:28,696:INFO:Importing untrained model
2024-05-10 14:48:28,698:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:48:28,702:INFO:Starting cross validation
2024-05-10 14:48:28,702:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:28,886:INFO:Calculating mean and std
2024-05-10 14:48:28,887:INFO:Creating metrics dataframe
2024-05-10 14:48:28,889:INFO:Uploading results into container
2024-05-10 14:48:28,889:INFO:Uploading model into container now
2024-05-10 14:48:28,889:INFO:_master_model_container: 14
2024-05-10 14:48:28,889:INFO:_display_container: 2
2024-05-10 14:48:28,890:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:48:28,890:INFO:create_model() successfully completed......................................
2024-05-10 14:48:28,981:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:28,981:INFO:Creating metrics dataframe
2024-05-10 14:48:28,986:INFO:Initializing AdaBoost Regressor
2024-05-10 14:48:28,986:INFO:Total runtime is 0.11054366827011108 minutes
2024-05-10 14:48:28,988:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:28,988:INFO:Initializing create_model()
2024-05-10 14:48:28,988:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:28,988:INFO:Checking exceptions
2024-05-10 14:48:28,988:INFO:Importing libraries
2024-05-10 14:48:28,988:INFO:Copying training dataset
2024-05-10 14:48:28,991:INFO:Defining folds
2024-05-10 14:48:28,991:INFO:Declaring metric variables
2024-05-10 14:48:28,993:INFO:Importing untrained model
2024-05-10 14:48:28,995:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:48:28,999:INFO:Starting cross validation
2024-05-10 14:48:29,000:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:29,119:INFO:Calculating mean and std
2024-05-10 14:48:29,120:INFO:Creating metrics dataframe
2024-05-10 14:48:29,121:INFO:Uploading results into container
2024-05-10 14:48:29,122:INFO:Uploading model into container now
2024-05-10 14:48:29,122:INFO:_master_model_container: 15
2024-05-10 14:48:29,122:INFO:_display_container: 2
2024-05-10 14:48:29,122:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:48:29,122:INFO:create_model() successfully completed......................................
2024-05-10 14:48:29,214:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:29,215:INFO:Creating metrics dataframe
2024-05-10 14:48:29,220:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:48:29,220:INFO:Total runtime is 0.11444690624872843 minutes
2024-05-10 14:48:29,222:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:29,222:INFO:Initializing create_model()
2024-05-10 14:48:29,222:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:29,222:INFO:Checking exceptions
2024-05-10 14:48:29,222:INFO:Importing libraries
2024-05-10 14:48:29,222:INFO:Copying training dataset
2024-05-10 14:48:29,225:INFO:Defining folds
2024-05-10 14:48:29,225:INFO:Declaring metric variables
2024-05-10 14:48:29,227:INFO:Importing untrained model
2024-05-10 14:48:29,229:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:48:29,233:INFO:Starting cross validation
2024-05-10 14:48:29,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:29,371:INFO:Calculating mean and std
2024-05-10 14:48:29,372:INFO:Creating metrics dataframe
2024-05-10 14:48:29,374:INFO:Uploading results into container
2024-05-10 14:48:29,374:INFO:Uploading model into container now
2024-05-10 14:48:29,374:INFO:_master_model_container: 16
2024-05-10 14:48:29,374:INFO:_display_container: 2
2024-05-10 14:48:29,375:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:48:29,375:INFO:create_model() successfully completed......................................
2024-05-10 14:48:29,466:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:29,466:INFO:Creating metrics dataframe
2024-05-10 14:48:29,472:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:48:29,472:INFO:Total runtime is 0.11863893667856852 minutes
2024-05-10 14:48:29,474:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:29,474:INFO:Initializing create_model()
2024-05-10 14:48:29,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:29,474:INFO:Checking exceptions
2024-05-10 14:48:29,474:INFO:Importing libraries
2024-05-10 14:48:29,474:INFO:Copying training dataset
2024-05-10 14:48:29,477:INFO:Defining folds
2024-05-10 14:48:29,477:INFO:Declaring metric variables
2024-05-10 14:48:29,479:INFO:Importing untrained model
2024-05-10 14:48:29,482:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:48:29,486:INFO:Starting cross validation
2024-05-10 14:48:29,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:29,842:INFO:Calculating mean and std
2024-05-10 14:48:29,843:INFO:Creating metrics dataframe
2024-05-10 14:48:29,845:INFO:Uploading results into container
2024-05-10 14:48:29,845:INFO:Uploading model into container now
2024-05-10 14:48:29,845:INFO:_master_model_container: 17
2024-05-10 14:48:29,845:INFO:_display_container: 2
2024-05-10 14:48:29,846:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:48:29,846:INFO:create_model() successfully completed......................................
2024-05-10 14:48:29,939:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:29,939:INFO:Creating metrics dataframe
2024-05-10 14:48:29,944:INFO:Initializing Dummy Regressor
2024-05-10 14:48:29,945:INFO:Total runtime is 0.12651774485905964 minutes
2024-05-10 14:48:29,946:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:29,947:INFO:Initializing create_model()
2024-05-10 14:48:29,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c7bfa0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:29,947:INFO:Checking exceptions
2024-05-10 14:48:29,947:INFO:Importing libraries
2024-05-10 14:48:29,947:INFO:Copying training dataset
2024-05-10 14:48:29,949:INFO:Defining folds
2024-05-10 14:48:29,950:INFO:Declaring metric variables
2024-05-10 14:48:29,952:INFO:Importing untrained model
2024-05-10 14:48:29,954:INFO:Dummy Regressor Imported successfully
2024-05-10 14:48:29,958:INFO:Starting cross validation
2024-05-10 14:48:29,958:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:29,997:INFO:Calculating mean and std
2024-05-10 14:48:29,997:INFO:Creating metrics dataframe
2024-05-10 14:48:29,998:INFO:Uploading results into container
2024-05-10 14:48:29,999:INFO:Uploading model into container now
2024-05-10 14:48:29,999:INFO:_master_model_container: 18
2024-05-10 14:48:29,999:INFO:_display_container: 2
2024-05-10 14:48:29,999:INFO:DummyRegressor()
2024-05-10 14:48:29,999:INFO:create_model() successfully completed......................................
2024-05-10 14:48:30,092:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:30,092:INFO:Creating metrics dataframe
2024-05-10 14:48:30,099:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:48:30,105:INFO:Initializing create_model()
2024-05-10 14:48:30,105:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:30,106:INFO:Checking exceptions
2024-05-10 14:48:30,107:INFO:Importing libraries
2024-05-10 14:48:30,107:INFO:Copying training dataset
2024-05-10 14:48:30,110:INFO:Defining folds
2024-05-10 14:48:30,110:INFO:Declaring metric variables
2024-05-10 14:48:30,110:INFO:Importing untrained model
2024-05-10 14:48:30,110:INFO:Declaring custom model
2024-05-10 14:48:30,111:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:48:30,111:INFO:Cross validation set to False
2024-05-10 14:48:30,112:INFO:Fitting Model
2024-05-10 14:48:30,168:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:48:30,168:INFO:create_model() successfully completed......................................
2024-05-10 14:48:30,276:INFO:_master_model_container: 18
2024-05-10 14:48:30,276:INFO:_display_container: 2
2024-05-10 14:48:30,276:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:48:30,277:INFO:compare_models() successfully completed......................................
2024-05-10 14:48:30,277:INFO:Initializing tune_model()
2024-05-10 14:48:30,277:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>)
2024-05-10 14:48:30,277:INFO:Checking exceptions
2024-05-10 14:48:30,291:INFO:Copying training dataset
2024-05-10 14:48:30,293:INFO:Checking base model
2024-05-10 14:48:30,293:INFO:Base model : Extra Trees Regressor
2024-05-10 14:48:30,296:INFO:Declaring metric variables
2024-05-10 14:48:30,298:INFO:Defining Hyperparameters
2024-05-10 14:48:30,428:INFO:Tuning with n_jobs=-1
2024-05-10 14:48:30,428:INFO:Initializing RandomizedSearchCV
2024-05-10 14:48:32,155:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:48:32,156:INFO:Hyperparameter search completed
2024-05-10 14:48:32,156:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:32,157:INFO:Initializing create_model()
2024-05-10 14:48:32,157:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c18b0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:48:32,157:INFO:Checking exceptions
2024-05-10 14:48:32,157:INFO:Importing libraries
2024-05-10 14:48:32,157:INFO:Copying training dataset
2024-05-10 14:48:32,161:INFO:Defining folds
2024-05-10 14:48:32,161:INFO:Declaring metric variables
2024-05-10 14:48:32,164:INFO:Importing untrained model
2024-05-10 14:48:32,164:INFO:Declaring custom model
2024-05-10 14:48:32,166:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:48:32,170:INFO:Starting cross validation
2024-05-10 14:48:32,171:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:32,429:INFO:Calculating mean and std
2024-05-10 14:48:32,430:INFO:Creating metrics dataframe
2024-05-10 14:48:32,435:INFO:Finalizing model
2024-05-10 14:48:32,560:INFO:Uploading results into container
2024-05-10 14:48:32,561:INFO:Uploading model into container now
2024-05-10 14:48:32,561:INFO:_master_model_container: 19
2024-05-10 14:48:32,561:INFO:_display_container: 3
2024-05-10 14:48:32,562:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:48:32,562:INFO:create_model() successfully completed......................................
2024-05-10 14:48:32,658:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:32,658:INFO:choose_better activated
2024-05-10 14:48:32,661:INFO:SubProcess create_model() called ==================================
2024-05-10 14:48:32,661:INFO:Initializing create_model()
2024-05-10 14:48:32,661:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:32,661:INFO:Checking exceptions
2024-05-10 14:48:32,662:INFO:Importing libraries
2024-05-10 14:48:32,662:INFO:Copying training dataset
2024-05-10 14:48:32,664:INFO:Defining folds
2024-05-10 14:48:32,664:INFO:Declaring metric variables
2024-05-10 14:48:32,664:INFO:Importing untrained model
2024-05-10 14:48:32,664:INFO:Declaring custom model
2024-05-10 14:48:32,664:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:48:32,665:INFO:Starting cross validation
2024-05-10 14:48:32,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:48:32,820:INFO:Calculating mean and std
2024-05-10 14:48:32,820:INFO:Creating metrics dataframe
2024-05-10 14:48:32,822:INFO:Finalizing model
2024-05-10 14:48:32,872:INFO:Uploading results into container
2024-05-10 14:48:32,873:INFO:Uploading model into container now
2024-05-10 14:48:32,873:INFO:_master_model_container: 20
2024-05-10 14:48:32,873:INFO:_display_container: 4
2024-05-10 14:48:32,873:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:48:32,873:INFO:create_model() successfully completed......................................
2024-05-10 14:48:32,965:INFO:SubProcess create_model() end ==================================
2024-05-10 14:48:32,965:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7173
2024-05-10 14:48:32,966:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6765
2024-05-10 14:48:32,966:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:48:32,966:INFO:choose_better completed
2024-05-10 14:48:32,966:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:48:32,972:INFO:_master_model_container: 20
2024-05-10 14:48:32,972:INFO:_display_container: 3
2024-05-10 14:48:32,972:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:48:32,972:INFO:tune_model() successfully completed......................................
2024-05-10 14:48:33,067:INFO:Initializing evaluate_model()
2024-05-10 14:48:33,067:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:48:33,073:INFO:Initializing plot_model()
2024-05-10 14:48:33,074:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, system=True)
2024-05-10 14:48:33,074:INFO:Checking exceptions
2024-05-10 14:48:33,084:INFO:Preloading libraries
2024-05-10 14:48:33,091:INFO:Copying training dataset
2024-05-10 14:48:33,091:INFO:Plot type: pipeline
2024-05-10 14:48:33,204:INFO:Visual Rendered Successfully
2024-05-10 14:48:33,302:INFO:plot_model() successfully completed......................................
2024-05-10 14:48:36,940:INFO:Initializing plot_model()
2024-05-10 14:48:36,940:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, system=True)
2024-05-10 14:48:36,940:INFO:Checking exceptions
2024-05-10 14:48:36,952:INFO:Preloading libraries
2024-05-10 14:48:36,956:INFO:Copying training dataset
2024-05-10 14:48:36,956:INFO:Plot type: residuals
2024-05-10 14:48:37,021:INFO:Fitting Model
2024-05-10 14:48:37,021:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:48:37,058:INFO:Scoring test/hold-out set
2024-05-10 14:48:37,329:INFO:Visual Rendered Successfully
2024-05-10 14:48:37,428:INFO:plot_model() successfully completed......................................
2024-05-10 14:48:39,253:INFO:Initializing plot_model()
2024-05-10 14:48:39,253:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, system=True)
2024-05-10 14:48:39,253:INFO:Checking exceptions
2024-05-10 14:48:39,264:INFO:Preloading libraries
2024-05-10 14:48:39,269:INFO:Copying training dataset
2024-05-10 14:48:39,269:INFO:Plot type: error
2024-05-10 14:48:39,305:INFO:Fitting Model
2024-05-10 14:48:39,305:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:48:39,306:INFO:Scoring test/hold-out set
2024-05-10 14:48:39,436:INFO:Visual Rendered Successfully
2024-05-10 14:48:39,551:INFO:plot_model() successfully completed......................................
2024-05-10 14:48:40,931:INFO:Initializing plot_model()
2024-05-10 14:48:40,931:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, system=True)
2024-05-10 14:48:40,931:INFO:Checking exceptions
2024-05-10 14:48:40,947:INFO:Preloading libraries
2024-05-10 14:48:40,951:INFO:Copying training dataset
2024-05-10 14:48:40,951:INFO:Plot type: residuals
2024-05-10 14:48:40,996:INFO:Fitting Model
2024-05-10 14:48:40,997:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:48:41,035:INFO:Scoring test/hold-out set
2024-05-10 14:48:41,240:INFO:Visual Rendered Successfully
2024-05-10 14:48:41,335:INFO:plot_model() successfully completed......................................
2024-05-10 14:48:44,053:INFO:Initializing finalize_model()
2024-05-10 14:48:44,054:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-10 14:48:44,054:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:48:44,056:INFO:Initializing create_model()
2024-05-10 14:48:44,056:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:48:44,057:INFO:Checking exceptions
2024-05-10 14:48:44,058:INFO:Importing libraries
2024-05-10 14:48:44,058:INFO:Copying training dataset
2024-05-10 14:48:44,058:INFO:Defining folds
2024-05-10 14:48:44,058:INFO:Declaring metric variables
2024-05-10 14:48:44,058:INFO:Importing untrained model
2024-05-10 14:48:44,058:INFO:Declaring custom model
2024-05-10 14:48:44,058:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:48:44,059:INFO:Cross validation set to False
2024-05-10 14:48:44,059:INFO:Fitting Model
2024-05-10 14:48:44,116:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2024-05-10 14:48:44,116:INFO:create_model() successfully completed......................................
2024-05-10 14:48:44,209:INFO:_master_model_container: 20
2024-05-10 14:48:44,209:INFO:_display_container: 3
2024-05-10 14:48:44,212:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2024-05-10 14:48:44,212:INFO:finalize_model() successfully completed......................................
2024-05-10 14:48:44,312:INFO:Initializing predict_model()
2024-05-10 14:48:44,312:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d3879d640>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x701d33268550>)
2024-05-10 14:48:44,312:INFO:Checking exceptions
2024-05-10 14:48:44,312:INFO:Preloading libraries
2024-05-10 14:48:44,313:INFO:Set up data.
2024-05-10 14:48:44,316:INFO:Set up index.
2024-05-10 14:48:44,340:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-10 14:49:12,186:INFO:PyCaret RegressionExperiment
2024-05-10 14:49:12,186:INFO:Logging name: reg-default-name
2024-05-10 14:49:12,186:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:49:12,186:INFO:version 3.3.2
2024-05-10 14:49:12,186:INFO:Initializing setup()
2024-05-10 14:49:12,186:INFO:self.USI: d27c
2024-05-10 14:49:12,186:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 14:49:12,186:INFO:Checking environment
2024-05-10 14:49:12,186:INFO:python_version: 3.9.18
2024-05-10 14:49:12,186:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:49:12,186:INFO:machine: x86_64
2024-05-10 14:49:12,186:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:49:12,186:INFO:Memory: svmem(total=16429797376, available=6127706112, percent=62.7, used=9188200448, free=4023832576, active=6626775040, inactive=4386324480, buffers=162738176, cached=3055026176, shared=767332352, slab=738521088)
2024-05-10 14:49:12,187:INFO:Physical Core: 12
2024-05-10 14:49:12,187:INFO:Logical Core: 16
2024-05-10 14:49:12,187:INFO:Checking libraries
2024-05-10 14:49:12,187:INFO:System:
2024-05-10 14:49:12,187:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:49:12,187:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:49:12,187:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:49:12,187:INFO:PyCaret required dependencies:
2024-05-10 14:49:12,187:INFO:                 pip: 23.3.1
2024-05-10 14:49:12,187:INFO:          setuptools: 68.2.2
2024-05-10 14:49:12,187:INFO:             pycaret: 3.3.2
2024-05-10 14:49:12,187:INFO:             IPython: 8.15.0
2024-05-10 14:49:12,187:INFO:          ipywidgets: 7.6.5
2024-05-10 14:49:12,187:INFO:                tqdm: 4.65.0
2024-05-10 14:49:12,187:INFO:               numpy: 1.26.4
2024-05-10 14:49:12,187:INFO:              pandas: 2.1.4
2024-05-10 14:49:12,187:INFO:              jinja2: 3.1.3
2024-05-10 14:49:12,187:INFO:               scipy: 1.11.4
2024-05-10 14:49:12,188:INFO:              joblib: 1.2.0
2024-05-10 14:49:12,188:INFO:             sklearn: 1.4.2
2024-05-10 14:49:12,188:INFO:                pyod: 1.1.3
2024-05-10 14:49:12,188:INFO:            imblearn: 0.12.2
2024-05-10 14:49:12,188:INFO:   category_encoders: 2.6.3
2024-05-10 14:49:12,188:INFO:            lightgbm: 4.3.0
2024-05-10 14:49:12,188:INFO:               numba: 0.59.1
2024-05-10 14:49:12,188:INFO:            requests: 2.31.0
2024-05-10 14:49:12,188:INFO:          matplotlib: 3.7.5
2024-05-10 14:49:12,188:INFO:          scikitplot: 0.3.7
2024-05-10 14:49:12,188:INFO:         yellowbrick: 1.5
2024-05-10 14:49:12,188:INFO:              plotly: 5.19.0
2024-05-10 14:49:12,188:INFO:    plotly-resampler: Not installed
2024-05-10 14:49:12,188:INFO:             kaleido: 0.2.1
2024-05-10 14:49:12,188:INFO:           schemdraw: 0.15
2024-05-10 14:49:12,188:INFO:         statsmodels: 0.14.0
2024-05-10 14:49:12,188:INFO:              sktime: 0.26.0
2024-05-10 14:49:12,188:INFO:               tbats: 1.1.3
2024-05-10 14:49:12,188:INFO:            pmdarima: 2.0.4
2024-05-10 14:49:12,188:INFO:              psutil: 5.9.0
2024-05-10 14:49:12,188:INFO:          markupsafe: 2.1.3
2024-05-10 14:49:12,188:INFO:             pickle5: Not installed
2024-05-10 14:49:12,188:INFO:         cloudpickle: 2.2.1
2024-05-10 14:49:12,188:INFO:         deprecation: 2.1.0
2024-05-10 14:49:12,188:INFO:              xxhash: 3.4.1
2024-05-10 14:49:12,188:INFO:           wurlitzer: 3.0.2
2024-05-10 14:49:12,188:INFO:PyCaret optional dependencies:
2024-05-10 14:49:12,188:INFO:                shap: Not installed
2024-05-10 14:49:12,188:INFO:           interpret: Not installed
2024-05-10 14:49:12,188:INFO:                umap: Not installed
2024-05-10 14:49:12,188:INFO:     ydata_profiling: Not installed
2024-05-10 14:49:12,188:INFO:  explainerdashboard: Not installed
2024-05-10 14:49:12,188:INFO:             autoviz: Not installed
2024-05-10 14:49:12,189:INFO:           fairlearn: Not installed
2024-05-10 14:49:12,189:INFO:          deepchecks: Not installed
2024-05-10 14:49:12,189:INFO:             xgboost: Not installed
2024-05-10 14:49:12,189:INFO:            catboost: Not installed
2024-05-10 14:49:12,189:INFO:              kmodes: Not installed
2024-05-10 14:49:12,189:INFO:             mlxtend: Not installed
2024-05-10 14:49:12,189:INFO:       statsforecast: Not installed
2024-05-10 14:49:12,189:INFO:        tune_sklearn: Not installed
2024-05-10 14:49:12,189:INFO:                 ray: Not installed
2024-05-10 14:49:12,189:INFO:            hyperopt: Not installed
2024-05-10 14:49:12,189:INFO:              optuna: Not installed
2024-05-10 14:49:12,189:INFO:               skopt: Not installed
2024-05-10 14:49:12,189:INFO:              mlflow: Not installed
2024-05-10 14:49:12,189:INFO:              gradio: Not installed
2024-05-10 14:49:12,189:INFO:             fastapi: Not installed
2024-05-10 14:49:12,189:INFO:             uvicorn: Not installed
2024-05-10 14:49:12,189:INFO:              m2cgen: Not installed
2024-05-10 14:49:12,189:INFO:           evidently: Not installed
2024-05-10 14:49:12,189:INFO:               fugue: Not installed
2024-05-10 14:49:12,189:INFO:           streamlit: 1.32.0
2024-05-10 14:49:12,189:INFO:             prophet: Not installed
2024-05-10 14:49:12,189:INFO:None
2024-05-10 14:49:12,189:INFO:Set up data.
2024-05-10 14:49:12,192:INFO:Set up folding strategy.
2024-05-10 14:49:12,192:INFO:Set up train/test split.
2024-05-10 14:49:12,194:INFO:Set up index.
2024-05-10 14:49:12,194:INFO:Assigning column types.
2024-05-10 14:49:12,197:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:49:12,197:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,200:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,206:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,236:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,263:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,264:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,264:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,266:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,268:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,292:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,311:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,311:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,311:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,311:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:49:12,313:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,315:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,340:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,360:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,362:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,364:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,389:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,409:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,409:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,410:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:49:12,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,439:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,459:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,460:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,464:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,489:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,509:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,510:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,510:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,510:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:49:12,541:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,562:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,563:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,595:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,616:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,616:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,616:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,616:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:49:12,646:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,667:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,697:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:49:12,717:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,718:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:49:12,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,768:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,818:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,818:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,819:INFO:Preparing preprocessing pipeline...
2024-05-10 14:49:12,819:INFO:Set up simple imputation.
2024-05-10 14:49:12,820:INFO:Set up column name cleaning.
2024-05-10 14:49:12,831:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:49:12,833:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:49:12,833:INFO:Creating final display dataframe.
2024-05-10 14:49:12,869:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (407, 7)
4        Transformed data shape          (407, 7)
5   Transformed train set shape          (284, 7)
6    Transformed test set shape          (123, 7)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              d27c
2024-05-10 14:49:12,928:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,928:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:49:12,980:INFO:setup() successfully completed in 0.8s...............
2024-05-10 14:49:12,981:INFO:Initializing compare_models()
2024-05-10 14:49:12,981:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:49:12,981:INFO:Checking exceptions
2024-05-10 14:49:12,982:INFO:Preparing display monitor
2024-05-10 14:49:12,995:INFO:Initializing Linear Regression
2024-05-10 14:49:12,995:INFO:Total runtime is 2.610683441162109e-06 minutes
2024-05-10 14:49:12,997:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:12,997:INFO:Initializing create_model()
2024-05-10 14:49:12,997:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:12,997:INFO:Checking exceptions
2024-05-10 14:49:12,997:INFO:Importing libraries
2024-05-10 14:49:12,997:INFO:Copying training dataset
2024-05-10 14:49:13,000:INFO:Defining folds
2024-05-10 14:49:13,000:INFO:Declaring metric variables
2024-05-10 14:49:13,003:INFO:Importing untrained model
2024-05-10 14:49:13,005:INFO:Linear Regression Imported successfully
2024-05-10 14:49:13,009:INFO:Starting cross validation
2024-05-10 14:49:13,009:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:13,057:INFO:Calculating mean and std
2024-05-10 14:49:13,057:INFO:Creating metrics dataframe
2024-05-10 14:49:13,058:INFO:Uploading results into container
2024-05-10 14:49:13,059:INFO:Uploading model into container now
2024-05-10 14:49:13,059:INFO:_master_model_container: 1
2024-05-10 14:49:13,059:INFO:_display_container: 2
2024-05-10 14:49:13,059:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:49:13,059:INFO:create_model() successfully completed......................................
2024-05-10 14:49:13,184:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:13,184:INFO:Creating metrics dataframe
2024-05-10 14:49:13,188:INFO:Initializing Lasso Regression
2024-05-10 14:49:13,188:INFO:Total runtime is 0.0032231807708740234 minutes
2024-05-10 14:49:13,190:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:13,190:INFO:Initializing create_model()
2024-05-10 14:49:13,191:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:13,191:INFO:Checking exceptions
2024-05-10 14:49:13,191:INFO:Importing libraries
2024-05-10 14:49:13,191:INFO:Copying training dataset
2024-05-10 14:49:13,193:INFO:Defining folds
2024-05-10 14:49:13,193:INFO:Declaring metric variables
2024-05-10 14:49:13,194:INFO:Importing untrained model
2024-05-10 14:49:13,196:INFO:Lasso Regression Imported successfully
2024-05-10 14:49:13,200:INFO:Starting cross validation
2024-05-10 14:49:13,201:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:13,242:INFO:Calculating mean and std
2024-05-10 14:49:13,242:INFO:Creating metrics dataframe
2024-05-10 14:49:13,244:INFO:Uploading results into container
2024-05-10 14:49:13,244:INFO:Uploading model into container now
2024-05-10 14:49:13,245:INFO:_master_model_container: 2
2024-05-10 14:49:13,245:INFO:_display_container: 2
2024-05-10 14:49:13,245:INFO:Lasso(random_state=123)
2024-05-10 14:49:13,245:INFO:create_model() successfully completed......................................
2024-05-10 14:49:13,340:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:13,340:INFO:Creating metrics dataframe
2024-05-10 14:49:13,345:INFO:Initializing Ridge Regression
2024-05-10 14:49:13,345:INFO:Total runtime is 0.005834142367045084 minutes
2024-05-10 14:49:13,346:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:13,347:INFO:Initializing create_model()
2024-05-10 14:49:13,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:13,347:INFO:Checking exceptions
2024-05-10 14:49:13,347:INFO:Importing libraries
2024-05-10 14:49:13,347:INFO:Copying training dataset
2024-05-10 14:49:13,350:INFO:Defining folds
2024-05-10 14:49:13,350:INFO:Declaring metric variables
2024-05-10 14:49:13,353:INFO:Importing untrained model
2024-05-10 14:49:13,355:INFO:Ridge Regression Imported successfully
2024-05-10 14:49:13,358:INFO:Starting cross validation
2024-05-10 14:49:13,359:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:13,398:INFO:Calculating mean and std
2024-05-10 14:49:13,398:INFO:Creating metrics dataframe
2024-05-10 14:49:13,400:INFO:Uploading results into container
2024-05-10 14:49:13,400:INFO:Uploading model into container now
2024-05-10 14:49:13,401:INFO:_master_model_container: 3
2024-05-10 14:49:13,401:INFO:_display_container: 2
2024-05-10 14:49:13,401:INFO:Ridge(random_state=123)
2024-05-10 14:49:13,401:INFO:create_model() successfully completed......................................
2024-05-10 14:49:13,500:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:13,500:INFO:Creating metrics dataframe
2024-05-10 14:49:13,505:INFO:Initializing Elastic Net
2024-05-10 14:49:13,505:INFO:Total runtime is 0.008501148223876952 minutes
2024-05-10 14:49:13,507:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:13,507:INFO:Initializing create_model()
2024-05-10 14:49:13,507:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:13,507:INFO:Checking exceptions
2024-05-10 14:49:13,507:INFO:Importing libraries
2024-05-10 14:49:13,507:INFO:Copying training dataset
2024-05-10 14:49:13,509:INFO:Defining folds
2024-05-10 14:49:13,509:INFO:Declaring metric variables
2024-05-10 14:49:13,511:INFO:Importing untrained model
2024-05-10 14:49:13,513:INFO:Elastic Net Imported successfully
2024-05-10 14:49:13,516:INFO:Starting cross validation
2024-05-10 14:49:13,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:13,557:INFO:Calculating mean and std
2024-05-10 14:49:13,558:INFO:Creating metrics dataframe
2024-05-10 14:49:13,559:INFO:Uploading results into container
2024-05-10 14:49:13,559:INFO:Uploading model into container now
2024-05-10 14:49:13,559:INFO:_master_model_container: 4
2024-05-10 14:49:13,559:INFO:_display_container: 2
2024-05-10 14:49:13,560:INFO:ElasticNet(random_state=123)
2024-05-10 14:49:13,560:INFO:create_model() successfully completed......................................
2024-05-10 14:49:13,657:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:13,657:INFO:Creating metrics dataframe
2024-05-10 14:49:13,662:INFO:Initializing Least Angle Regression
2024-05-10 14:49:13,662:INFO:Total runtime is 0.011122540632883706 minutes
2024-05-10 14:49:13,664:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:13,664:INFO:Initializing create_model()
2024-05-10 14:49:13,664:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:13,664:INFO:Checking exceptions
2024-05-10 14:49:13,664:INFO:Importing libraries
2024-05-10 14:49:13,664:INFO:Copying training dataset
2024-05-10 14:49:13,667:INFO:Defining folds
2024-05-10 14:49:13,667:INFO:Declaring metric variables
2024-05-10 14:49:13,669:INFO:Importing untrained model
2024-05-10 14:49:13,672:INFO:Least Angle Regression Imported successfully
2024-05-10 14:49:13,676:INFO:Starting cross validation
2024-05-10 14:49:13,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:13,716:INFO:Calculating mean and std
2024-05-10 14:49:13,717:INFO:Creating metrics dataframe
2024-05-10 14:49:13,718:INFO:Uploading results into container
2024-05-10 14:49:13,718:INFO:Uploading model into container now
2024-05-10 14:49:13,718:INFO:_master_model_container: 5
2024-05-10 14:49:13,718:INFO:_display_container: 2
2024-05-10 14:49:13,719:INFO:Lars(random_state=123)
2024-05-10 14:49:13,719:INFO:create_model() successfully completed......................................
2024-05-10 14:49:13,813:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:13,813:INFO:Creating metrics dataframe
2024-05-10 14:49:13,818:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:49:13,818:INFO:Total runtime is 0.01372478405634562 minutes
2024-05-10 14:49:13,821:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:13,821:INFO:Initializing create_model()
2024-05-10 14:49:13,821:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:13,821:INFO:Checking exceptions
2024-05-10 14:49:13,821:INFO:Importing libraries
2024-05-10 14:49:13,821:INFO:Copying training dataset
2024-05-10 14:49:13,823:INFO:Defining folds
2024-05-10 14:49:13,823:INFO:Declaring metric variables
2024-05-10 14:49:13,825:INFO:Importing untrained model
2024-05-10 14:49:13,827:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:49:13,829:INFO:Starting cross validation
2024-05-10 14:49:13,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:13,878:INFO:Calculating mean and std
2024-05-10 14:49:13,878:INFO:Creating metrics dataframe
2024-05-10 14:49:13,879:INFO:Uploading results into container
2024-05-10 14:49:13,880:INFO:Uploading model into container now
2024-05-10 14:49:13,880:INFO:_master_model_container: 6
2024-05-10 14:49:13,880:INFO:_display_container: 2
2024-05-10 14:49:13,880:INFO:LassoLars(random_state=123)
2024-05-10 14:49:13,880:INFO:create_model() successfully completed......................................
2024-05-10 14:49:13,978:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:13,978:INFO:Creating metrics dataframe
2024-05-10 14:49:13,982:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:49:13,982:INFO:Total runtime is 0.016460311412811277 minutes
2024-05-10 14:49:13,984:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:13,985:INFO:Initializing create_model()
2024-05-10 14:49:13,985:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:13,985:INFO:Checking exceptions
2024-05-10 14:49:13,985:INFO:Importing libraries
2024-05-10 14:49:13,985:INFO:Copying training dataset
2024-05-10 14:49:13,987:INFO:Defining folds
2024-05-10 14:49:13,987:INFO:Declaring metric variables
2024-05-10 14:49:13,989:INFO:Importing untrained model
2024-05-10 14:49:13,991:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:49:13,994:INFO:Starting cross validation
2024-05-10 14:49:13,995:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:14,034:INFO:Calculating mean and std
2024-05-10 14:49:14,034:INFO:Creating metrics dataframe
2024-05-10 14:49:14,035:INFO:Uploading results into container
2024-05-10 14:49:14,036:INFO:Uploading model into container now
2024-05-10 14:49:14,036:INFO:_master_model_container: 7
2024-05-10 14:49:14,036:INFO:_display_container: 2
2024-05-10 14:49:14,036:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:49:14,036:INFO:create_model() successfully completed......................................
2024-05-10 14:49:14,132:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:14,132:INFO:Creating metrics dataframe
2024-05-10 14:49:14,137:INFO:Initializing Bayesian Ridge
2024-05-10 14:49:14,138:INFO:Total runtime is 0.019047772884368895 minutes
2024-05-10 14:49:14,139:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:14,140:INFO:Initializing create_model()
2024-05-10 14:49:14,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:14,140:INFO:Checking exceptions
2024-05-10 14:49:14,140:INFO:Importing libraries
2024-05-10 14:49:14,140:INFO:Copying training dataset
2024-05-10 14:49:14,142:INFO:Defining folds
2024-05-10 14:49:14,142:INFO:Declaring metric variables
2024-05-10 14:49:14,144:INFO:Importing untrained model
2024-05-10 14:49:14,146:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:49:14,150:INFO:Starting cross validation
2024-05-10 14:49:14,151:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:14,193:INFO:Calculating mean and std
2024-05-10 14:49:14,194:INFO:Creating metrics dataframe
2024-05-10 14:49:14,195:INFO:Uploading results into container
2024-05-10 14:49:14,195:INFO:Uploading model into container now
2024-05-10 14:49:14,195:INFO:_master_model_container: 8
2024-05-10 14:49:14,195:INFO:_display_container: 2
2024-05-10 14:49:14,195:INFO:BayesianRidge()
2024-05-10 14:49:14,196:INFO:create_model() successfully completed......................................
2024-05-10 14:49:14,294:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:14,294:INFO:Creating metrics dataframe
2024-05-10 14:49:14,299:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:49:14,299:INFO:Total runtime is 0.021734118461608887 minutes
2024-05-10 14:49:14,301:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:14,301:INFO:Initializing create_model()
2024-05-10 14:49:14,301:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:14,301:INFO:Checking exceptions
2024-05-10 14:49:14,301:INFO:Importing libraries
2024-05-10 14:49:14,301:INFO:Copying training dataset
2024-05-10 14:49:14,304:INFO:Defining folds
2024-05-10 14:49:14,304:INFO:Declaring metric variables
2024-05-10 14:49:14,306:INFO:Importing untrained model
2024-05-10 14:49:14,308:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:49:14,311:INFO:Starting cross validation
2024-05-10 14:49:14,311:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:14,353:INFO:Calculating mean and std
2024-05-10 14:49:14,354:INFO:Creating metrics dataframe
2024-05-10 14:49:14,355:INFO:Uploading results into container
2024-05-10 14:49:14,355:INFO:Uploading model into container now
2024-05-10 14:49:14,355:INFO:_master_model_container: 9
2024-05-10 14:49:14,355:INFO:_display_container: 2
2024-05-10 14:49:14,355:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:49:14,355:INFO:create_model() successfully completed......................................
2024-05-10 14:49:14,452:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:14,452:INFO:Creating metrics dataframe
2024-05-10 14:49:14,457:INFO:Initializing Huber Regressor
2024-05-10 14:49:14,457:INFO:Total runtime is 0.024375418821970623 minutes
2024-05-10 14:49:14,459:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:14,459:INFO:Initializing create_model()
2024-05-10 14:49:14,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:14,459:INFO:Checking exceptions
2024-05-10 14:49:14,459:INFO:Importing libraries
2024-05-10 14:49:14,459:INFO:Copying training dataset
2024-05-10 14:49:14,461:INFO:Defining folds
2024-05-10 14:49:14,461:INFO:Declaring metric variables
2024-05-10 14:49:14,463:INFO:Importing untrained model
2024-05-10 14:49:14,465:INFO:Huber Regressor Imported successfully
2024-05-10 14:49:14,470:INFO:Starting cross validation
2024-05-10 14:49:14,470:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:14,505:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:49:14,506:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:49:14,518:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:49:14,526:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:49:14,530:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:49:14,534:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:49:14,540:INFO:Calculating mean and std
2024-05-10 14:49:14,540:INFO:Creating metrics dataframe
2024-05-10 14:49:14,542:INFO:Uploading results into container
2024-05-10 14:49:14,542:INFO:Uploading model into container now
2024-05-10 14:49:14,542:INFO:_master_model_container: 10
2024-05-10 14:49:14,543:INFO:_display_container: 2
2024-05-10 14:49:14,543:INFO:HuberRegressor()
2024-05-10 14:49:14,543:INFO:create_model() successfully completed......................................
2024-05-10 14:49:14,637:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:14,637:INFO:Creating metrics dataframe
2024-05-10 14:49:14,642:INFO:Initializing K Neighbors Regressor
2024-05-10 14:49:14,642:INFO:Total runtime is 0.027461405595143637 minutes
2024-05-10 14:49:14,644:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:14,645:INFO:Initializing create_model()
2024-05-10 14:49:14,645:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:14,645:INFO:Checking exceptions
2024-05-10 14:49:14,645:INFO:Importing libraries
2024-05-10 14:49:14,645:INFO:Copying training dataset
2024-05-10 14:49:14,647:INFO:Defining folds
2024-05-10 14:49:14,647:INFO:Declaring metric variables
2024-05-10 14:49:14,649:INFO:Importing untrained model
2024-05-10 14:49:14,651:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:49:14,655:INFO:Starting cross validation
2024-05-10 14:49:14,656:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:14,713:INFO:Calculating mean and std
2024-05-10 14:49:14,713:INFO:Creating metrics dataframe
2024-05-10 14:49:14,714:INFO:Uploading results into container
2024-05-10 14:49:14,715:INFO:Uploading model into container now
2024-05-10 14:49:14,715:INFO:_master_model_container: 11
2024-05-10 14:49:14,715:INFO:_display_container: 2
2024-05-10 14:49:14,715:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:49:14,715:INFO:create_model() successfully completed......................................
2024-05-10 14:49:14,812:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:14,812:INFO:Creating metrics dataframe
2024-05-10 14:49:14,817:INFO:Initializing Decision Tree Regressor
2024-05-10 14:49:14,817:INFO:Total runtime is 0.03037408192952474 minutes
2024-05-10 14:49:14,819:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:14,819:INFO:Initializing create_model()
2024-05-10 14:49:14,819:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:14,819:INFO:Checking exceptions
2024-05-10 14:49:14,819:INFO:Importing libraries
2024-05-10 14:49:14,819:INFO:Copying training dataset
2024-05-10 14:49:14,822:INFO:Defining folds
2024-05-10 14:49:14,822:INFO:Declaring metric variables
2024-05-10 14:49:14,824:INFO:Importing untrained model
2024-05-10 14:49:14,826:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:49:14,836:INFO:Starting cross validation
2024-05-10 14:49:14,837:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:14,897:INFO:Calculating mean and std
2024-05-10 14:49:14,897:INFO:Creating metrics dataframe
2024-05-10 14:49:14,899:INFO:Uploading results into container
2024-05-10 14:49:14,900:INFO:Uploading model into container now
2024-05-10 14:49:14,900:INFO:_master_model_container: 12
2024-05-10 14:49:14,900:INFO:_display_container: 2
2024-05-10 14:49:14,900:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:49:14,900:INFO:create_model() successfully completed......................................
2024-05-10 14:49:15,004:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:15,004:INFO:Creating metrics dataframe
2024-05-10 14:49:15,009:INFO:Initializing Random Forest Regressor
2024-05-10 14:49:15,010:INFO:Total runtime is 0.03358306884765625 minutes
2024-05-10 14:49:15,012:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:15,012:INFO:Initializing create_model()
2024-05-10 14:49:15,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:15,012:INFO:Checking exceptions
2024-05-10 14:49:15,012:INFO:Importing libraries
2024-05-10 14:49:15,012:INFO:Copying training dataset
2024-05-10 14:49:15,015:INFO:Defining folds
2024-05-10 14:49:15,015:INFO:Declaring metric variables
2024-05-10 14:49:15,017:INFO:Importing untrained model
2024-05-10 14:49:15,019:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:49:15,023:INFO:Starting cross validation
2024-05-10 14:49:15,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:15,254:INFO:Calculating mean and std
2024-05-10 14:49:15,255:INFO:Creating metrics dataframe
2024-05-10 14:49:15,257:INFO:Uploading results into container
2024-05-10 14:49:15,257:INFO:Uploading model into container now
2024-05-10 14:49:15,257:INFO:_master_model_container: 13
2024-05-10 14:49:15,257:INFO:_display_container: 2
2024-05-10 14:49:15,258:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:49:15,258:INFO:create_model() successfully completed......................................
2024-05-10 14:49:15,354:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:15,355:INFO:Creating metrics dataframe
2024-05-10 14:49:15,360:INFO:Initializing Extra Trees Regressor
2024-05-10 14:49:15,360:INFO:Total runtime is 0.03942062854766846 minutes
2024-05-10 14:49:15,362:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:15,362:INFO:Initializing create_model()
2024-05-10 14:49:15,362:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:15,362:INFO:Checking exceptions
2024-05-10 14:49:15,362:INFO:Importing libraries
2024-05-10 14:49:15,362:INFO:Copying training dataset
2024-05-10 14:49:15,365:INFO:Defining folds
2024-05-10 14:49:15,365:INFO:Declaring metric variables
2024-05-10 14:49:15,367:INFO:Importing untrained model
2024-05-10 14:49:15,369:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:49:15,375:INFO:Starting cross validation
2024-05-10 14:49:15,375:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:15,536:INFO:Calculating mean and std
2024-05-10 14:49:15,536:INFO:Creating metrics dataframe
2024-05-10 14:49:15,538:INFO:Uploading results into container
2024-05-10 14:49:15,539:INFO:Uploading model into container now
2024-05-10 14:49:15,539:INFO:_master_model_container: 14
2024-05-10 14:49:15,539:INFO:_display_container: 2
2024-05-10 14:49:15,540:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:49:15,540:INFO:create_model() successfully completed......................................
2024-05-10 14:49:15,635:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:15,635:INFO:Creating metrics dataframe
2024-05-10 14:49:15,641:INFO:Initializing AdaBoost Regressor
2024-05-10 14:49:15,641:INFO:Total runtime is 0.04410313367843628 minutes
2024-05-10 14:49:15,643:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:15,643:INFO:Initializing create_model()
2024-05-10 14:49:15,643:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:15,643:INFO:Checking exceptions
2024-05-10 14:49:15,643:INFO:Importing libraries
2024-05-10 14:49:15,643:INFO:Copying training dataset
2024-05-10 14:49:15,645:INFO:Defining folds
2024-05-10 14:49:15,645:INFO:Declaring metric variables
2024-05-10 14:49:15,648:INFO:Importing untrained model
2024-05-10 14:49:15,650:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:49:15,655:INFO:Starting cross validation
2024-05-10 14:49:15,655:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:15,774:INFO:Calculating mean and std
2024-05-10 14:49:15,775:INFO:Creating metrics dataframe
2024-05-10 14:49:15,776:INFO:Uploading results into container
2024-05-10 14:49:15,776:INFO:Uploading model into container now
2024-05-10 14:49:15,777:INFO:_master_model_container: 15
2024-05-10 14:49:15,777:INFO:_display_container: 2
2024-05-10 14:49:15,777:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:49:15,777:INFO:create_model() successfully completed......................................
2024-05-10 14:49:15,871:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:15,871:INFO:Creating metrics dataframe
2024-05-10 14:49:15,876:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:49:15,876:INFO:Total runtime is 0.04802929957707723 minutes
2024-05-10 14:49:15,878:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:15,878:INFO:Initializing create_model()
2024-05-10 14:49:15,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:15,879:INFO:Checking exceptions
2024-05-10 14:49:15,879:INFO:Importing libraries
2024-05-10 14:49:15,879:INFO:Copying training dataset
2024-05-10 14:49:15,881:INFO:Defining folds
2024-05-10 14:49:15,881:INFO:Declaring metric variables
2024-05-10 14:49:15,883:INFO:Importing untrained model
2024-05-10 14:49:15,885:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:49:15,890:INFO:Starting cross validation
2024-05-10 14:49:15,890:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:16,026:INFO:Calculating mean and std
2024-05-10 14:49:16,026:INFO:Creating metrics dataframe
2024-05-10 14:49:16,028:INFO:Uploading results into container
2024-05-10 14:49:16,028:INFO:Uploading model into container now
2024-05-10 14:49:16,029:INFO:_master_model_container: 16
2024-05-10 14:49:16,029:INFO:_display_container: 2
2024-05-10 14:49:16,029:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:49:16,029:INFO:create_model() successfully completed......................................
2024-05-10 14:49:16,126:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:16,127:INFO:Creating metrics dataframe
2024-05-10 14:49:16,132:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:49:16,132:INFO:Total runtime is 0.05229188998540243 minutes
2024-05-10 14:49:16,134:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:16,135:INFO:Initializing create_model()
2024-05-10 14:49:16,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:16,135:INFO:Checking exceptions
2024-05-10 14:49:16,135:INFO:Importing libraries
2024-05-10 14:49:16,135:INFO:Copying training dataset
2024-05-10 14:49:16,137:INFO:Defining folds
2024-05-10 14:49:16,137:INFO:Declaring metric variables
2024-05-10 14:49:16,138:INFO:Importing untrained model
2024-05-10 14:49:16,140:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:49:16,144:INFO:Starting cross validation
2024-05-10 14:49:16,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:16,576:INFO:Calculating mean and std
2024-05-10 14:49:16,576:INFO:Creating metrics dataframe
2024-05-10 14:49:16,577:INFO:Uploading results into container
2024-05-10 14:49:16,578:INFO:Uploading model into container now
2024-05-10 14:49:16,578:INFO:_master_model_container: 17
2024-05-10 14:49:16,578:INFO:_display_container: 2
2024-05-10 14:49:16,578:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:49:16,579:INFO:create_model() successfully completed......................................
2024-05-10 14:49:16,676:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:16,676:INFO:Creating metrics dataframe
2024-05-10 14:49:16,682:INFO:Initializing Dummy Regressor
2024-05-10 14:49:16,682:INFO:Total runtime is 0.061450441678365074 minutes
2024-05-10 14:49:16,685:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:16,685:INFO:Initializing create_model()
2024-05-10 14:49:16,685:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32abddf0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:16,685:INFO:Checking exceptions
2024-05-10 14:49:16,685:INFO:Importing libraries
2024-05-10 14:49:16,685:INFO:Copying training dataset
2024-05-10 14:49:16,688:INFO:Defining folds
2024-05-10 14:49:16,688:INFO:Declaring metric variables
2024-05-10 14:49:16,689:INFO:Importing untrained model
2024-05-10 14:49:16,691:INFO:Dummy Regressor Imported successfully
2024-05-10 14:49:16,695:INFO:Starting cross validation
2024-05-10 14:49:16,696:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:16,742:INFO:Calculating mean and std
2024-05-10 14:49:16,743:INFO:Creating metrics dataframe
2024-05-10 14:49:16,744:INFO:Uploading results into container
2024-05-10 14:49:16,744:INFO:Uploading model into container now
2024-05-10 14:49:16,744:INFO:_master_model_container: 18
2024-05-10 14:49:16,744:INFO:_display_container: 2
2024-05-10 14:49:16,745:INFO:DummyRegressor()
2024-05-10 14:49:16,745:INFO:create_model() successfully completed......................................
2024-05-10 14:49:16,838:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:16,838:INFO:Creating metrics dataframe
2024-05-10 14:49:16,843:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:49:16,847:INFO:Initializing create_model()
2024-05-10 14:49:16,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:16,848:INFO:Checking exceptions
2024-05-10 14:49:16,849:INFO:Importing libraries
2024-05-10 14:49:16,849:INFO:Copying training dataset
2024-05-10 14:49:16,852:INFO:Defining folds
2024-05-10 14:49:16,852:INFO:Declaring metric variables
2024-05-10 14:49:16,852:INFO:Importing untrained model
2024-05-10 14:49:16,852:INFO:Declaring custom model
2024-05-10 14:49:16,853:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:49:16,853:INFO:Cross validation set to False
2024-05-10 14:49:16,853:INFO:Fitting Model
2024-05-10 14:49:16,904:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:49:16,904:INFO:create_model() successfully completed......................................
2024-05-10 14:49:17,024:INFO:_master_model_container: 18
2024-05-10 14:49:17,024:INFO:_display_container: 2
2024-05-10 14:49:17,024:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:49:17,024:INFO:compare_models() successfully completed......................................
2024-05-10 14:49:17,025:INFO:Initializing tune_model()
2024-05-10 14:49:17,025:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>)
2024-05-10 14:49:17,025:INFO:Checking exceptions
2024-05-10 14:49:17,038:INFO:Copying training dataset
2024-05-10 14:49:17,040:INFO:Checking base model
2024-05-10 14:49:17,040:INFO:Base model : Extra Trees Regressor
2024-05-10 14:49:17,043:INFO:Declaring metric variables
2024-05-10 14:49:17,046:INFO:Defining Hyperparameters
2024-05-10 14:49:17,155:INFO:Tuning with n_jobs=-1
2024-05-10 14:49:17,155:INFO:Initializing RandomizedSearchCV
2024-05-10 14:49:18,877:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:49:18,877:INFO:Hyperparameter search completed
2024-05-10 14:49:18,878:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:18,878:INFO:Initializing create_model()
2024-05-10 14:49:18,878:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32ea1ee0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:49:18,878:INFO:Checking exceptions
2024-05-10 14:49:18,878:INFO:Importing libraries
2024-05-10 14:49:18,878:INFO:Copying training dataset
2024-05-10 14:49:18,883:INFO:Defining folds
2024-05-10 14:49:18,883:INFO:Declaring metric variables
2024-05-10 14:49:18,885:INFO:Importing untrained model
2024-05-10 14:49:18,885:INFO:Declaring custom model
2024-05-10 14:49:18,888:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:49:18,891:INFO:Starting cross validation
2024-05-10 14:49:18,892:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:19,140:INFO:Calculating mean and std
2024-05-10 14:49:19,141:INFO:Creating metrics dataframe
2024-05-10 14:49:19,144:INFO:Finalizing model
2024-05-10 14:49:19,295:INFO:Uploading results into container
2024-05-10 14:49:19,295:INFO:Uploading model into container now
2024-05-10 14:49:19,296:INFO:_master_model_container: 19
2024-05-10 14:49:19,296:INFO:_display_container: 3
2024-05-10 14:49:19,296:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:49:19,296:INFO:create_model() successfully completed......................................
2024-05-10 14:49:19,392:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:19,392:INFO:choose_better activated
2024-05-10 14:49:19,395:INFO:SubProcess create_model() called ==================================
2024-05-10 14:49:19,395:INFO:Initializing create_model()
2024-05-10 14:49:19,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:19,395:INFO:Checking exceptions
2024-05-10 14:49:19,396:INFO:Importing libraries
2024-05-10 14:49:19,396:INFO:Copying training dataset
2024-05-10 14:49:19,398:INFO:Defining folds
2024-05-10 14:49:19,398:INFO:Declaring metric variables
2024-05-10 14:49:19,398:INFO:Importing untrained model
2024-05-10 14:49:19,398:INFO:Declaring custom model
2024-05-10 14:49:19,399:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:49:19,399:INFO:Starting cross validation
2024-05-10 14:49:19,400:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:49:19,561:INFO:Calculating mean and std
2024-05-10 14:49:19,561:INFO:Creating metrics dataframe
2024-05-10 14:49:19,563:INFO:Finalizing model
2024-05-10 14:49:19,614:INFO:Uploading results into container
2024-05-10 14:49:19,615:INFO:Uploading model into container now
2024-05-10 14:49:19,615:INFO:_master_model_container: 20
2024-05-10 14:49:19,615:INFO:_display_container: 4
2024-05-10 14:49:19,616:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:49:19,616:INFO:create_model() successfully completed......................................
2024-05-10 14:49:19,713:INFO:SubProcess create_model() end ==================================
2024-05-10 14:49:19,714:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7429
2024-05-10 14:49:19,714:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6964
2024-05-10 14:49:19,714:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:49:19,714:INFO:choose_better completed
2024-05-10 14:49:19,714:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:49:19,720:INFO:_master_model_container: 20
2024-05-10 14:49:19,720:INFO:_display_container: 3
2024-05-10 14:49:19,720:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:49:19,720:INFO:tune_model() successfully completed......................................
2024-05-10 14:49:19,815:INFO:Initializing evaluate_model()
2024-05-10 14:49:19,816:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:49:19,821:INFO:Initializing plot_model()
2024-05-10 14:49:19,821:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, system=True)
2024-05-10 14:49:19,822:INFO:Checking exceptions
2024-05-10 14:49:19,831:INFO:Preloading libraries
2024-05-10 14:49:19,837:INFO:Copying training dataset
2024-05-10 14:49:19,838:INFO:Plot type: pipeline
2024-05-10 14:49:19,901:INFO:Visual Rendered Successfully
2024-05-10 14:49:20,002:INFO:plot_model() successfully completed......................................
2024-05-10 14:49:24,798:INFO:Initializing plot_model()
2024-05-10 14:49:24,799:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, system=True)
2024-05-10 14:49:24,799:INFO:Checking exceptions
2024-05-10 14:49:24,814:INFO:Preloading libraries
2024-05-10 14:49:24,821:INFO:Copying training dataset
2024-05-10 14:49:24,821:INFO:Plot type: residuals
2024-05-10 14:49:24,867:INFO:Fitting Model
2024-05-10 14:49:24,867:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:49:24,906:INFO:Scoring test/hold-out set
2024-05-10 14:49:25,102:INFO:Visual Rendered Successfully
2024-05-10 14:49:25,200:INFO:plot_model() successfully completed......................................
2024-05-10 14:49:28,752:INFO:Initializing plot_model()
2024-05-10 14:49:28,752:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, system=True)
2024-05-10 14:49:28,752:INFO:Checking exceptions
2024-05-10 14:49:28,770:INFO:Preloading libraries
2024-05-10 14:49:28,777:INFO:Copying training dataset
2024-05-10 14:49:28,777:INFO:Plot type: error
2024-05-10 14:49:28,812:INFO:Fitting Model
2024-05-10 14:49:28,812:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:49:28,812:INFO:Scoring test/hold-out set
2024-05-10 14:49:28,935:INFO:Visual Rendered Successfully
2024-05-10 14:49:29,033:INFO:plot_model() successfully completed......................................
2024-05-10 14:49:48,567:INFO:Initializing finalize_model()
2024-05-10 14:49:48,567:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-10 14:49:48,567:INFO:Finalizing ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:49:48,569:INFO:Initializing create_model()
2024-05-10 14:49:48,569:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:49:48,569:INFO:Checking exceptions
2024-05-10 14:49:48,570:INFO:Importing libraries
2024-05-10 14:49:48,570:INFO:Copying training dataset
2024-05-10 14:49:48,571:INFO:Defining folds
2024-05-10 14:49:48,571:INFO:Declaring metric variables
2024-05-10 14:49:48,571:INFO:Importing untrained model
2024-05-10 14:49:48,571:INFO:Declaring custom model
2024-05-10 14:49:48,572:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:49:48,572:INFO:Cross validation set to False
2024-05-10 14:49:48,572:INFO:Fitting Model
2024-05-10 14:49:48,630:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2024-05-10 14:49:48,630:INFO:create_model() successfully completed......................................
2024-05-10 14:49:48,729:INFO:_master_model_container: 20
2024-05-10 14:49:48,729:INFO:_display_container: 3
2024-05-10 14:49:48,732:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))])
2024-05-10 14:49:48,732:INFO:finalize_model() successfully completed......................................
2024-05-10 14:49:48,830:INFO:Initializing predict_model()
2024-05-10 14:49:48,830:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32d76550>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 ExtraTreesRegressor(n_jobs=-1, random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x701d33268550>)
2024-05-10 14:49:48,830:INFO:Checking exceptions
2024-05-10 14:49:48,830:INFO:Preloading libraries
2024-05-10 14:49:48,832:INFO:Set up data.
2024-05-10 14:49:48,834:INFO:Set up index.
2024-05-10 14:49:48,851:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-10 14:54:38,014:INFO:PyCaret RegressionExperiment
2024-05-10 14:54:38,014:INFO:Logging name: reg-default-name
2024-05-10 14:54:38,014:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:54:38,014:INFO:version 3.3.2
2024-05-10 14:54:38,014:INFO:Initializing setup()
2024-05-10 14:54:38,014:INFO:self.USI: 92fc
2024-05-10 14:54:38,014:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 14:54:38,014:INFO:Checking environment
2024-05-10 14:54:38,014:INFO:python_version: 3.9.18
2024-05-10 14:54:38,014:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:54:38,014:INFO:machine: x86_64
2024-05-10 14:54:38,014:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:54:38,014:INFO:Memory: svmem(total=16429797376, available=8591499264, percent=47.7, used=6730805248, free=6474940416, active=4217946112, inactive=4374659072, buffers=167063552, cached=3056988160, shared=760950784, slab=731156480)
2024-05-10 14:54:38,014:INFO:Physical Core: 12
2024-05-10 14:54:38,015:INFO:Logical Core: 16
2024-05-10 14:54:38,015:INFO:Checking libraries
2024-05-10 14:54:38,015:INFO:System:
2024-05-10 14:54:38,015:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:54:38,015:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:54:38,015:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:54:38,015:INFO:PyCaret required dependencies:
2024-05-10 14:54:38,015:INFO:                 pip: 23.3.1
2024-05-10 14:54:38,015:INFO:          setuptools: 68.2.2
2024-05-10 14:54:38,015:INFO:             pycaret: 3.3.2
2024-05-10 14:54:38,015:INFO:             IPython: 8.15.0
2024-05-10 14:54:38,015:INFO:          ipywidgets: 7.6.5
2024-05-10 14:54:38,015:INFO:                tqdm: 4.65.0
2024-05-10 14:54:38,015:INFO:               numpy: 1.26.4
2024-05-10 14:54:38,015:INFO:              pandas: 2.1.4
2024-05-10 14:54:38,015:INFO:              jinja2: 3.1.3
2024-05-10 14:54:38,015:INFO:               scipy: 1.11.4
2024-05-10 14:54:38,015:INFO:              joblib: 1.2.0
2024-05-10 14:54:38,015:INFO:             sklearn: 1.4.2
2024-05-10 14:54:38,015:INFO:                pyod: 1.1.3
2024-05-10 14:54:38,015:INFO:            imblearn: 0.12.2
2024-05-10 14:54:38,015:INFO:   category_encoders: 2.6.3
2024-05-10 14:54:38,015:INFO:            lightgbm: 4.3.0
2024-05-10 14:54:38,015:INFO:               numba: 0.59.1
2024-05-10 14:54:38,015:INFO:            requests: 2.31.0
2024-05-10 14:54:38,015:INFO:          matplotlib: 3.7.5
2024-05-10 14:54:38,015:INFO:          scikitplot: 0.3.7
2024-05-10 14:54:38,015:INFO:         yellowbrick: 1.5
2024-05-10 14:54:38,015:INFO:              plotly: 5.19.0
2024-05-10 14:54:38,015:INFO:    plotly-resampler: Not installed
2024-05-10 14:54:38,015:INFO:             kaleido: 0.2.1
2024-05-10 14:54:38,015:INFO:           schemdraw: 0.15
2024-05-10 14:54:38,015:INFO:         statsmodels: 0.14.0
2024-05-10 14:54:38,015:INFO:              sktime: 0.26.0
2024-05-10 14:54:38,015:INFO:               tbats: 1.1.3
2024-05-10 14:54:38,015:INFO:            pmdarima: 2.0.4
2024-05-10 14:54:38,015:INFO:              psutil: 5.9.0
2024-05-10 14:54:38,015:INFO:          markupsafe: 2.1.3
2024-05-10 14:54:38,016:INFO:             pickle5: Not installed
2024-05-10 14:54:38,016:INFO:         cloudpickle: 2.2.1
2024-05-10 14:54:38,016:INFO:         deprecation: 2.1.0
2024-05-10 14:54:38,016:INFO:              xxhash: 3.4.1
2024-05-10 14:54:38,016:INFO:           wurlitzer: 3.0.2
2024-05-10 14:54:38,016:INFO:PyCaret optional dependencies:
2024-05-10 14:54:38,016:INFO:                shap: Not installed
2024-05-10 14:54:38,016:INFO:           interpret: Not installed
2024-05-10 14:54:38,016:INFO:                umap: Not installed
2024-05-10 14:54:38,016:INFO:     ydata_profiling: Not installed
2024-05-10 14:54:38,016:INFO:  explainerdashboard: Not installed
2024-05-10 14:54:38,016:INFO:             autoviz: Not installed
2024-05-10 14:54:38,016:INFO:           fairlearn: Not installed
2024-05-10 14:54:38,016:INFO:          deepchecks: Not installed
2024-05-10 14:54:38,016:INFO:             xgboost: Not installed
2024-05-10 14:54:38,016:INFO:            catboost: Not installed
2024-05-10 14:54:38,016:INFO:              kmodes: Not installed
2024-05-10 14:54:38,016:INFO:             mlxtend: Not installed
2024-05-10 14:54:38,016:INFO:       statsforecast: Not installed
2024-05-10 14:54:38,016:INFO:        tune_sklearn: Not installed
2024-05-10 14:54:38,016:INFO:                 ray: Not installed
2024-05-10 14:54:38,016:INFO:            hyperopt: Not installed
2024-05-10 14:54:38,016:INFO:              optuna: Not installed
2024-05-10 14:54:38,016:INFO:               skopt: Not installed
2024-05-10 14:54:38,016:INFO:              mlflow: Not installed
2024-05-10 14:54:38,016:INFO:              gradio: Not installed
2024-05-10 14:54:38,016:INFO:             fastapi: Not installed
2024-05-10 14:54:38,016:INFO:             uvicorn: Not installed
2024-05-10 14:54:38,016:INFO:              m2cgen: Not installed
2024-05-10 14:54:38,016:INFO:           evidently: Not installed
2024-05-10 14:54:38,016:INFO:               fugue: Not installed
2024-05-10 14:54:38,016:INFO:           streamlit: 1.32.0
2024-05-10 14:54:38,016:INFO:             prophet: Not installed
2024-05-10 14:54:38,016:INFO:None
2024-05-10 14:54:38,016:INFO:Set up data.
2024-05-10 14:54:38,019:INFO:Set up folding strategy.
2024-05-10 14:54:38,019:INFO:Set up train/test split.
2024-05-10 14:54:38,021:INFO:Set up index.
2024-05-10 14:54:38,021:INFO:Assigning column types.
2024-05-10 14:54:38,023:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:54:38,023:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,025:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,027:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,061:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,080:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,080:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,080:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,080:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,082:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,084:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,108:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,126:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,127:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,127:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,127:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:54:38,129:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,131:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,155:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,174:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,175:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,175:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,177:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,179:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,204:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,224:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,224:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,224:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:54:38,228:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,254:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,275:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,276:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,276:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,280:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,316:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,335:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,336:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,336:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:54:38,365:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,416:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,435:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,436:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,436:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,436:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:54:38,466:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,517:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:54:38,538:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,538:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,538:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:54:38,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,639:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,639:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:38,640:INFO:Preparing preprocessing pipeline...
2024-05-10 14:54:38,640:INFO:Set up simple imputation.
2024-05-10 14:54:38,640:INFO:Set up polynomial features.
2024-05-10 14:54:38,640:INFO:Set up removing outliers.
2024-05-10 14:54:38,640:INFO:Set up feature normalization.
2024-05-10 14:54:38,640:INFO:Set up column name cleaning.
2024-05-10 14:54:38,724:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:54:38,728:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:54:38,728:INFO:Creating final display dataframe.
2024-05-10 14:54:39,049:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (407, 7)
4        Transformed data shape         (392, 28)
5   Transformed train set shape         (269, 28)
6    Transformed test set shape         (123, 28)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              92fc
2024-05-10 14:54:39,102:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:39,102:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:39,151:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:39,152:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:54:39,152:INFO:setup() successfully completed in 1.14s...............
2024-05-10 14:54:39,152:INFO:Initializing compare_models()
2024-05-10 14:54:39,152:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:54:39,152:INFO:Checking exceptions
2024-05-10 14:54:39,153:INFO:Preparing display monitor
2024-05-10 14:54:39,166:INFO:Initializing Linear Regression
2024-05-10 14:54:39,166:INFO:Total runtime is 2.845128377278646e-06 minutes
2024-05-10 14:54:39,168:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:39,168:INFO:Initializing create_model()
2024-05-10 14:54:39,168:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:39,168:INFO:Checking exceptions
2024-05-10 14:54:39,168:INFO:Importing libraries
2024-05-10 14:54:39,168:INFO:Copying training dataset
2024-05-10 14:54:39,170:INFO:Defining folds
2024-05-10 14:54:39,170:INFO:Declaring metric variables
2024-05-10 14:54:39,172:INFO:Importing untrained model
2024-05-10 14:54:39,174:INFO:Linear Regression Imported successfully
2024-05-10 14:54:39,177:INFO:Starting cross validation
2024-05-10 14:54:39,182:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:41,659:INFO:Calculating mean and std
2024-05-10 14:54:41,661:INFO:Creating metrics dataframe
2024-05-10 14:54:41,664:INFO:Uploading results into container
2024-05-10 14:54:41,666:INFO:Uploading model into container now
2024-05-10 14:54:41,667:INFO:_master_model_container: 1
2024-05-10 14:54:41,667:INFO:_display_container: 2
2024-05-10 14:54:41,667:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:54:41,667:INFO:create_model() successfully completed......................................
2024-05-10 14:54:41,788:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:41,788:INFO:Creating metrics dataframe
2024-05-10 14:54:41,792:INFO:Initializing Lasso Regression
2024-05-10 14:54:41,792:INFO:Total runtime is 0.0437790036201477 minutes
2024-05-10 14:54:41,794:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:41,794:INFO:Initializing create_model()
2024-05-10 14:54:41,794:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:41,794:INFO:Checking exceptions
2024-05-10 14:54:41,794:INFO:Importing libraries
2024-05-10 14:54:41,794:INFO:Copying training dataset
2024-05-10 14:54:41,797:INFO:Defining folds
2024-05-10 14:54:41,797:INFO:Declaring metric variables
2024-05-10 14:54:41,800:INFO:Importing untrained model
2024-05-10 14:54:41,803:INFO:Lasso Regression Imported successfully
2024-05-10 14:54:41,807:INFO:Starting cross validation
2024-05-10 14:54:41,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:43,462:INFO:Calculating mean and std
2024-05-10 14:54:43,463:INFO:Creating metrics dataframe
2024-05-10 14:54:43,464:INFO:Uploading results into container
2024-05-10 14:54:43,465:INFO:Uploading model into container now
2024-05-10 14:54:43,465:INFO:_master_model_container: 2
2024-05-10 14:54:43,465:INFO:_display_container: 2
2024-05-10 14:54:43,465:INFO:Lasso(random_state=123)
2024-05-10 14:54:43,465:INFO:create_model() successfully completed......................................
2024-05-10 14:54:43,568:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:43,569:INFO:Creating metrics dataframe
2024-05-10 14:54:43,573:INFO:Initializing Ridge Regression
2024-05-10 14:54:43,573:INFO:Total runtime is 0.07346176703770955 minutes
2024-05-10 14:54:43,575:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:43,575:INFO:Initializing create_model()
2024-05-10 14:54:43,575:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:43,575:INFO:Checking exceptions
2024-05-10 14:54:43,575:INFO:Importing libraries
2024-05-10 14:54:43,575:INFO:Copying training dataset
2024-05-10 14:54:43,578:INFO:Defining folds
2024-05-10 14:54:43,578:INFO:Declaring metric variables
2024-05-10 14:54:43,580:INFO:Importing untrained model
2024-05-10 14:54:43,582:INFO:Ridge Regression Imported successfully
2024-05-10 14:54:43,586:INFO:Starting cross validation
2024-05-10 14:54:43,590:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:43,778:INFO:Calculating mean and std
2024-05-10 14:54:43,779:INFO:Creating metrics dataframe
2024-05-10 14:54:43,780:INFO:Uploading results into container
2024-05-10 14:54:43,781:INFO:Uploading model into container now
2024-05-10 14:54:43,781:INFO:_master_model_container: 3
2024-05-10 14:54:43,781:INFO:_display_container: 2
2024-05-10 14:54:43,782:INFO:Ridge(random_state=123)
2024-05-10 14:54:43,782:INFO:create_model() successfully completed......................................
2024-05-10 14:54:43,885:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:43,885:INFO:Creating metrics dataframe
2024-05-10 14:54:43,890:INFO:Initializing Elastic Net
2024-05-10 14:54:43,890:INFO:Total runtime is 0.07873788674672445 minutes
2024-05-10 14:54:43,892:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:43,892:INFO:Initializing create_model()
2024-05-10 14:54:43,892:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:43,892:INFO:Checking exceptions
2024-05-10 14:54:43,892:INFO:Importing libraries
2024-05-10 14:54:43,892:INFO:Copying training dataset
2024-05-10 14:54:43,894:INFO:Defining folds
2024-05-10 14:54:43,895:INFO:Declaring metric variables
2024-05-10 14:54:43,897:INFO:Importing untrained model
2024-05-10 14:54:43,899:INFO:Elastic Net Imported successfully
2024-05-10 14:54:43,903:INFO:Starting cross validation
2024-05-10 14:54:43,907:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:44,104:INFO:Calculating mean and std
2024-05-10 14:54:44,105:INFO:Creating metrics dataframe
2024-05-10 14:54:44,106:INFO:Uploading results into container
2024-05-10 14:54:44,106:INFO:Uploading model into container now
2024-05-10 14:54:44,106:INFO:_master_model_container: 4
2024-05-10 14:54:44,107:INFO:_display_container: 2
2024-05-10 14:54:44,107:INFO:ElasticNet(random_state=123)
2024-05-10 14:54:44,107:INFO:create_model() successfully completed......................................
2024-05-10 14:54:44,206:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:44,206:INFO:Creating metrics dataframe
2024-05-10 14:54:44,210:INFO:Initializing Least Angle Regression
2024-05-10 14:54:44,210:INFO:Total runtime is 0.08407706419626873 minutes
2024-05-10 14:54:44,212:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:44,212:INFO:Initializing create_model()
2024-05-10 14:54:44,212:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:44,212:INFO:Checking exceptions
2024-05-10 14:54:44,212:INFO:Importing libraries
2024-05-10 14:54:44,212:INFO:Copying training dataset
2024-05-10 14:54:44,215:INFO:Defining folds
2024-05-10 14:54:44,215:INFO:Declaring metric variables
2024-05-10 14:54:44,218:INFO:Importing untrained model
2024-05-10 14:54:44,220:INFO:Least Angle Regression Imported successfully
2024-05-10 14:54:44,223:INFO:Starting cross validation
2024-05-10 14:54:44,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:44,428:INFO:Calculating mean and std
2024-05-10 14:54:44,429:INFO:Creating metrics dataframe
2024-05-10 14:54:44,430:INFO:Uploading results into container
2024-05-10 14:54:44,431:INFO:Uploading model into container now
2024-05-10 14:54:44,432:INFO:_master_model_container: 5
2024-05-10 14:54:44,432:INFO:_display_container: 2
2024-05-10 14:54:44,432:INFO:Lars(random_state=123)
2024-05-10 14:54:44,432:INFO:create_model() successfully completed......................................
2024-05-10 14:54:44,530:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:44,530:INFO:Creating metrics dataframe
2024-05-10 14:54:44,535:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:54:44,535:INFO:Total runtime is 0.08948863744735719 minutes
2024-05-10 14:54:44,537:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:44,537:INFO:Initializing create_model()
2024-05-10 14:54:44,537:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:44,537:INFO:Checking exceptions
2024-05-10 14:54:44,537:INFO:Importing libraries
2024-05-10 14:54:44,537:INFO:Copying training dataset
2024-05-10 14:54:44,539:INFO:Defining folds
2024-05-10 14:54:44,540:INFO:Declaring metric variables
2024-05-10 14:54:44,541:INFO:Importing untrained model
2024-05-10 14:54:44,543:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:54:44,548:INFO:Starting cross validation
2024-05-10 14:54:44,553:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:44,748:INFO:Calculating mean and std
2024-05-10 14:54:44,750:INFO:Creating metrics dataframe
2024-05-10 14:54:44,751:INFO:Uploading results into container
2024-05-10 14:54:44,752:INFO:Uploading model into container now
2024-05-10 14:54:44,752:INFO:_master_model_container: 6
2024-05-10 14:54:44,753:INFO:_display_container: 2
2024-05-10 14:54:44,753:INFO:LassoLars(random_state=123)
2024-05-10 14:54:44,753:INFO:create_model() successfully completed......................................
2024-05-10 14:54:44,859:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:44,859:INFO:Creating metrics dataframe
2024-05-10 14:54:44,864:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:54:44,864:INFO:Total runtime is 0.09496878782908123 minutes
2024-05-10 14:54:44,866:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:44,866:INFO:Initializing create_model()
2024-05-10 14:54:44,866:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:44,866:INFO:Checking exceptions
2024-05-10 14:54:44,866:INFO:Importing libraries
2024-05-10 14:54:44,866:INFO:Copying training dataset
2024-05-10 14:54:44,869:INFO:Defining folds
2024-05-10 14:54:44,869:INFO:Declaring metric variables
2024-05-10 14:54:44,871:INFO:Importing untrained model
2024-05-10 14:54:44,873:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:54:44,876:INFO:Starting cross validation
2024-05-10 14:54:44,882:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:45,065:INFO:Calculating mean and std
2024-05-10 14:54:45,066:INFO:Creating metrics dataframe
2024-05-10 14:54:45,067:INFO:Uploading results into container
2024-05-10 14:54:45,067:INFO:Uploading model into container now
2024-05-10 14:54:45,068:INFO:_master_model_container: 7
2024-05-10 14:54:45,068:INFO:_display_container: 2
2024-05-10 14:54:45,068:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:54:45,068:INFO:create_model() successfully completed......................................
2024-05-10 14:54:45,164:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:45,165:INFO:Creating metrics dataframe
2024-05-10 14:54:45,169:INFO:Initializing Bayesian Ridge
2024-05-10 14:54:45,169:INFO:Total runtime is 0.10006094773610434 minutes
2024-05-10 14:54:45,171:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:45,171:INFO:Initializing create_model()
2024-05-10 14:54:45,171:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:45,171:INFO:Checking exceptions
2024-05-10 14:54:45,171:INFO:Importing libraries
2024-05-10 14:54:45,171:INFO:Copying training dataset
2024-05-10 14:54:45,173:INFO:Defining folds
2024-05-10 14:54:45,173:INFO:Declaring metric variables
2024-05-10 14:54:45,175:INFO:Importing untrained model
2024-05-10 14:54:45,177:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:54:45,182:INFO:Starting cross validation
2024-05-10 14:54:45,187:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:45,375:INFO:Calculating mean and std
2024-05-10 14:54:45,376:INFO:Creating metrics dataframe
2024-05-10 14:54:45,377:INFO:Uploading results into container
2024-05-10 14:54:45,378:INFO:Uploading model into container now
2024-05-10 14:54:45,378:INFO:_master_model_container: 8
2024-05-10 14:54:45,378:INFO:_display_container: 2
2024-05-10 14:54:45,378:INFO:BayesianRidge()
2024-05-10 14:54:45,378:INFO:create_model() successfully completed......................................
2024-05-10 14:54:45,475:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:45,475:INFO:Creating metrics dataframe
2024-05-10 14:54:45,480:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:54:45,480:INFO:Total runtime is 0.10524423122406007 minutes
2024-05-10 14:54:45,482:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:45,483:INFO:Initializing create_model()
2024-05-10 14:54:45,483:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:45,483:INFO:Checking exceptions
2024-05-10 14:54:45,483:INFO:Importing libraries
2024-05-10 14:54:45,483:INFO:Copying training dataset
2024-05-10 14:54:45,485:INFO:Defining folds
2024-05-10 14:54:45,485:INFO:Declaring metric variables
2024-05-10 14:54:45,487:INFO:Importing untrained model
2024-05-10 14:54:45,489:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:54:45,493:INFO:Starting cross validation
2024-05-10 14:54:45,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:45,689:INFO:Calculating mean and std
2024-05-10 14:54:45,690:INFO:Creating metrics dataframe
2024-05-10 14:54:45,691:INFO:Uploading results into container
2024-05-10 14:54:45,691:INFO:Uploading model into container now
2024-05-10 14:54:45,692:INFO:_master_model_container: 9
2024-05-10 14:54:45,692:INFO:_display_container: 2
2024-05-10 14:54:45,692:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:54:45,692:INFO:create_model() successfully completed......................................
2024-05-10 14:54:45,789:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:45,789:INFO:Creating metrics dataframe
2024-05-10 14:54:45,794:INFO:Initializing Huber Regressor
2024-05-10 14:54:45,794:INFO:Total runtime is 0.11047153075536094 minutes
2024-05-10 14:54:45,796:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:45,796:INFO:Initializing create_model()
2024-05-10 14:54:45,796:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:45,796:INFO:Checking exceptions
2024-05-10 14:54:45,796:INFO:Importing libraries
2024-05-10 14:54:45,796:INFO:Copying training dataset
2024-05-10 14:54:45,799:INFO:Defining folds
2024-05-10 14:54:45,799:INFO:Declaring metric variables
2024-05-10 14:54:45,801:INFO:Importing untrained model
2024-05-10 14:54:45,803:INFO:Huber Regressor Imported successfully
2024-05-10 14:54:45,806:INFO:Starting cross validation
2024-05-10 14:54:45,810:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:45,926:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:45,936:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:45,962:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:45,972:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:45,974:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:45,978:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:45,994:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:45,999:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:46,009:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:46,009:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:54:46,019:INFO:Calculating mean and std
2024-05-10 14:54:46,019:INFO:Creating metrics dataframe
2024-05-10 14:54:46,021:INFO:Uploading results into container
2024-05-10 14:54:46,021:INFO:Uploading model into container now
2024-05-10 14:54:46,021:INFO:_master_model_container: 10
2024-05-10 14:54:46,021:INFO:_display_container: 2
2024-05-10 14:54:46,022:INFO:HuberRegressor()
2024-05-10 14:54:46,022:INFO:create_model() successfully completed......................................
2024-05-10 14:54:46,120:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:46,120:INFO:Creating metrics dataframe
2024-05-10 14:54:46,125:INFO:Initializing K Neighbors Regressor
2024-05-10 14:54:46,125:INFO:Total runtime is 0.11598674456278485 minutes
2024-05-10 14:54:46,126:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:46,127:INFO:Initializing create_model()
2024-05-10 14:54:46,127:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:46,127:INFO:Checking exceptions
2024-05-10 14:54:46,127:INFO:Importing libraries
2024-05-10 14:54:46,127:INFO:Copying training dataset
2024-05-10 14:54:46,129:INFO:Defining folds
2024-05-10 14:54:46,129:INFO:Declaring metric variables
2024-05-10 14:54:46,131:INFO:Importing untrained model
2024-05-10 14:54:46,134:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:54:46,137:INFO:Starting cross validation
2024-05-10 14:54:46,141:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:46,366:INFO:Calculating mean and std
2024-05-10 14:54:46,366:INFO:Creating metrics dataframe
2024-05-10 14:54:46,368:INFO:Uploading results into container
2024-05-10 14:54:46,368:INFO:Uploading model into container now
2024-05-10 14:54:46,369:INFO:_master_model_container: 11
2024-05-10 14:54:46,369:INFO:_display_container: 2
2024-05-10 14:54:46,369:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:54:46,369:INFO:create_model() successfully completed......................................
2024-05-10 14:54:46,466:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:46,466:INFO:Creating metrics dataframe
2024-05-10 14:54:46,471:INFO:Initializing Decision Tree Regressor
2024-05-10 14:54:46,471:INFO:Total runtime is 0.12176067431767783 minutes
2024-05-10 14:54:46,473:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:46,473:INFO:Initializing create_model()
2024-05-10 14:54:46,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:46,473:INFO:Checking exceptions
2024-05-10 14:54:46,473:INFO:Importing libraries
2024-05-10 14:54:46,473:INFO:Copying training dataset
2024-05-10 14:54:46,475:INFO:Defining folds
2024-05-10 14:54:46,476:INFO:Declaring metric variables
2024-05-10 14:54:46,477:INFO:Importing untrained model
2024-05-10 14:54:46,479:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:54:46,483:INFO:Starting cross validation
2024-05-10 14:54:46,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:46,689:INFO:Calculating mean and std
2024-05-10 14:54:46,690:INFO:Creating metrics dataframe
2024-05-10 14:54:46,691:INFO:Uploading results into container
2024-05-10 14:54:46,692:INFO:Uploading model into container now
2024-05-10 14:54:46,692:INFO:_master_model_container: 12
2024-05-10 14:54:46,692:INFO:_display_container: 2
2024-05-10 14:54:46,692:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:54:46,692:INFO:create_model() successfully completed......................................
2024-05-10 14:54:46,795:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:46,795:INFO:Creating metrics dataframe
2024-05-10 14:54:46,801:INFO:Initializing Random Forest Regressor
2024-05-10 14:54:46,801:INFO:Total runtime is 0.1272540807723999 minutes
2024-05-10 14:54:46,803:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:46,803:INFO:Initializing create_model()
2024-05-10 14:54:46,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:46,803:INFO:Checking exceptions
2024-05-10 14:54:46,803:INFO:Importing libraries
2024-05-10 14:54:46,803:INFO:Copying training dataset
2024-05-10 14:54:46,805:INFO:Defining folds
2024-05-10 14:54:46,805:INFO:Declaring metric variables
2024-05-10 14:54:46,807:INFO:Importing untrained model
2024-05-10 14:54:46,809:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:54:46,812:INFO:Starting cross validation
2024-05-10 14:54:46,817:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:47,371:INFO:Calculating mean and std
2024-05-10 14:54:47,371:INFO:Creating metrics dataframe
2024-05-10 14:54:47,373:INFO:Uploading results into container
2024-05-10 14:54:47,373:INFO:Uploading model into container now
2024-05-10 14:54:47,373:INFO:_master_model_container: 13
2024-05-10 14:54:47,373:INFO:_display_container: 2
2024-05-10 14:54:47,373:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:54:47,373:INFO:create_model() successfully completed......................................
2024-05-10 14:54:47,477:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:47,477:INFO:Creating metrics dataframe
2024-05-10 14:54:47,484:INFO:Initializing Extra Trees Regressor
2024-05-10 14:54:47,484:INFO:Total runtime is 0.13863303263982138 minutes
2024-05-10 14:54:47,485:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:47,485:INFO:Initializing create_model()
2024-05-10 14:54:47,486:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:47,486:INFO:Checking exceptions
2024-05-10 14:54:47,486:INFO:Importing libraries
2024-05-10 14:54:47,486:INFO:Copying training dataset
2024-05-10 14:54:47,488:INFO:Defining folds
2024-05-10 14:54:47,488:INFO:Declaring metric variables
2024-05-10 14:54:47,490:INFO:Importing untrained model
2024-05-10 14:54:47,491:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:54:47,495:INFO:Starting cross validation
2024-05-10 14:54:47,500:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:47,853:INFO:Calculating mean and std
2024-05-10 14:54:47,854:INFO:Creating metrics dataframe
2024-05-10 14:54:47,855:INFO:Uploading results into container
2024-05-10 14:54:47,856:INFO:Uploading model into container now
2024-05-10 14:54:47,856:INFO:_master_model_container: 14
2024-05-10 14:54:47,856:INFO:_display_container: 2
2024-05-10 14:54:47,856:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:54:47,856:INFO:create_model() successfully completed......................................
2024-05-10 14:54:47,957:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:47,957:INFO:Creating metrics dataframe
2024-05-10 14:54:47,964:INFO:Initializing AdaBoost Regressor
2024-05-10 14:54:47,964:INFO:Total runtime is 0.1466354211171468 minutes
2024-05-10 14:54:47,966:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:47,966:INFO:Initializing create_model()
2024-05-10 14:54:47,967:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:47,967:INFO:Checking exceptions
2024-05-10 14:54:47,967:INFO:Importing libraries
2024-05-10 14:54:47,967:INFO:Copying training dataset
2024-05-10 14:54:47,971:INFO:Defining folds
2024-05-10 14:54:47,971:INFO:Declaring metric variables
2024-05-10 14:54:47,974:INFO:Importing untrained model
2024-05-10 14:54:47,976:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:54:47,982:INFO:Starting cross validation
2024-05-10 14:54:47,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:48,310:INFO:Calculating mean and std
2024-05-10 14:54:48,310:INFO:Creating metrics dataframe
2024-05-10 14:54:48,312:INFO:Uploading results into container
2024-05-10 14:54:48,312:INFO:Uploading model into container now
2024-05-10 14:54:48,312:INFO:_master_model_container: 15
2024-05-10 14:54:48,313:INFO:_display_container: 2
2024-05-10 14:54:48,313:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:54:48,313:INFO:create_model() successfully completed......................................
2024-05-10 14:54:48,412:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:48,412:INFO:Creating metrics dataframe
2024-05-10 14:54:48,418:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:54:48,418:INFO:Total runtime is 0.15421096483866373 minutes
2024-05-10 14:54:48,420:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:48,420:INFO:Initializing create_model()
2024-05-10 14:54:48,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:48,420:INFO:Checking exceptions
2024-05-10 14:54:48,420:INFO:Importing libraries
2024-05-10 14:54:48,420:INFO:Copying training dataset
2024-05-10 14:54:48,423:INFO:Defining folds
2024-05-10 14:54:48,423:INFO:Declaring metric variables
2024-05-10 14:54:48,425:INFO:Importing untrained model
2024-05-10 14:54:48,427:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:54:48,430:INFO:Starting cross validation
2024-05-10 14:54:48,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:48,882:INFO:Calculating mean and std
2024-05-10 14:54:48,883:INFO:Creating metrics dataframe
2024-05-10 14:54:48,884:INFO:Uploading results into container
2024-05-10 14:54:48,885:INFO:Uploading model into container now
2024-05-10 14:54:48,885:INFO:_master_model_container: 16
2024-05-10 14:54:48,885:INFO:_display_container: 2
2024-05-10 14:54:48,886:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:54:48,886:INFO:create_model() successfully completed......................................
2024-05-10 14:54:48,986:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:48,986:INFO:Creating metrics dataframe
2024-05-10 14:54:48,991:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:54:48,991:INFO:Total runtime is 0.16375652154286702 minutes
2024-05-10 14:54:48,993:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:48,993:INFO:Initializing create_model()
2024-05-10 14:54:48,993:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:48,993:INFO:Checking exceptions
2024-05-10 14:54:48,993:INFO:Importing libraries
2024-05-10 14:54:48,993:INFO:Copying training dataset
2024-05-10 14:54:48,996:INFO:Defining folds
2024-05-10 14:54:48,996:INFO:Declaring metric variables
2024-05-10 14:54:48,999:INFO:Importing untrained model
2024-05-10 14:54:49,002:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:54:49,005:INFO:Starting cross validation
2024-05-10 14:54:49,009:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:49,577:INFO:Calculating mean and std
2024-05-10 14:54:49,578:INFO:Creating metrics dataframe
2024-05-10 14:54:49,581:INFO:Uploading results into container
2024-05-10 14:54:49,581:INFO:Uploading model into container now
2024-05-10 14:54:49,581:INFO:_master_model_container: 17
2024-05-10 14:54:49,582:INFO:_display_container: 2
2024-05-10 14:54:49,582:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:54:49,582:INFO:create_model() successfully completed......................................
2024-05-10 14:54:49,680:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:49,680:INFO:Creating metrics dataframe
2024-05-10 14:54:49,686:INFO:Initializing Dummy Regressor
2024-05-10 14:54:49,686:INFO:Total runtime is 0.17533214886983234 minutes
2024-05-10 14:54:49,687:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:49,687:INFO:Initializing create_model()
2024-05-10 14:54:49,687:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d330b4970>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:49,687:INFO:Checking exceptions
2024-05-10 14:54:49,687:INFO:Importing libraries
2024-05-10 14:54:49,688:INFO:Copying training dataset
2024-05-10 14:54:49,690:INFO:Defining folds
2024-05-10 14:54:49,690:INFO:Declaring metric variables
2024-05-10 14:54:49,691:INFO:Importing untrained model
2024-05-10 14:54:49,693:INFO:Dummy Regressor Imported successfully
2024-05-10 14:54:49,698:INFO:Starting cross validation
2024-05-10 14:54:49,703:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:49,886:INFO:Calculating mean and std
2024-05-10 14:54:49,887:INFO:Creating metrics dataframe
2024-05-10 14:54:49,888:INFO:Uploading results into container
2024-05-10 14:54:49,889:INFO:Uploading model into container now
2024-05-10 14:54:49,889:INFO:_master_model_container: 18
2024-05-10 14:54:49,889:INFO:_display_container: 2
2024-05-10 14:54:49,889:INFO:DummyRegressor()
2024-05-10 14:54:49,889:INFO:create_model() successfully completed......................................
2024-05-10 14:54:49,989:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:49,989:INFO:Creating metrics dataframe
2024-05-10 14:54:49,995:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:54:50,001:INFO:Initializing create_model()
2024-05-10 14:54:50,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:50,002:INFO:Checking exceptions
2024-05-10 14:54:50,003:INFO:Importing libraries
2024-05-10 14:54:50,003:INFO:Copying training dataset
2024-05-10 14:54:50,005:INFO:Defining folds
2024-05-10 14:54:50,005:INFO:Declaring metric variables
2024-05-10 14:54:50,005:INFO:Importing untrained model
2024-05-10 14:54:50,005:INFO:Declaring custom model
2024-05-10 14:54:50,006:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:54:50,009:INFO:Cross validation set to False
2024-05-10 14:54:50,010:INFO:Fitting Model
2024-05-10 14:54:50,270:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:54:50,270:INFO:create_model() successfully completed......................................
2024-05-10 14:54:50,384:INFO:_master_model_container: 18
2024-05-10 14:54:50,384:INFO:_display_container: 2
2024-05-10 14:54:50,385:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:54:50,385:INFO:compare_models() successfully completed......................................
2024-05-10 14:54:50,385:INFO:Initializing tune_model()
2024-05-10 14:54:50,385:INFO:tune_model(estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>)
2024-05-10 14:54:50,385:INFO:Checking exceptions
2024-05-10 14:54:50,395:INFO:Copying training dataset
2024-05-10 14:54:50,397:INFO:Checking base model
2024-05-10 14:54:50,397:INFO:Base model : Gradient Boosting Regressor
2024-05-10 14:54:50,400:INFO:Declaring metric variables
2024-05-10 14:54:50,402:INFO:Defining Hyperparameters
2024-05-10 14:54:50,515:INFO:Tuning with n_jobs=-1
2024-05-10 14:54:50,515:INFO:Initializing RandomizedSearchCV
2024-05-10 14:54:53,405:INFO:best_params: {'actual_estimator__subsample': 0.85, 'actual_estimator__n_estimators': 230, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 5, 'actual_estimator__min_impurity_decrease': 0.02, 'actual_estimator__max_features': 1.0, 'actual_estimator__max_depth': 7, 'actual_estimator__learning_rate': 0.15}
2024-05-10 14:54:53,405:INFO:Hyperparameter search completed
2024-05-10 14:54:53,405:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:53,406:INFO:Initializing create_model()
2024-05-10 14:54:53,406:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32d61c10>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'subsample': 0.85, 'n_estimators': 230, 'min_samples_split': 5, 'min_samples_leaf': 5, 'min_impurity_decrease': 0.02, 'max_features': 1.0, 'max_depth': 7, 'learning_rate': 0.15})
2024-05-10 14:54:53,406:INFO:Checking exceptions
2024-05-10 14:54:53,406:INFO:Importing libraries
2024-05-10 14:54:53,406:INFO:Copying training dataset
2024-05-10 14:54:53,408:INFO:Defining folds
2024-05-10 14:54:53,409:INFO:Declaring metric variables
2024-05-10 14:54:53,411:INFO:Importing untrained model
2024-05-10 14:54:53,411:INFO:Declaring custom model
2024-05-10 14:54:53,415:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:54:53,421:INFO:Starting cross validation
2024-05-10 14:54:53,429:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:54,039:INFO:Calculating mean and std
2024-05-10 14:54:54,040:INFO:Creating metrics dataframe
2024-05-10 14:54:54,043:INFO:Finalizing model
2024-05-10 14:54:54,377:INFO:Uploading results into container
2024-05-10 14:54:54,377:INFO:Uploading model into container now
2024-05-10 14:54:54,378:INFO:_master_model_container: 19
2024-05-10 14:54:54,378:INFO:_display_container: 3
2024-05-10 14:54:54,378:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85)
2024-05-10 14:54:54,378:INFO:create_model() successfully completed......................................
2024-05-10 14:54:54,479:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:54,479:INFO:choose_better activated
2024-05-10 14:54:54,481:INFO:SubProcess create_model() called ==================================
2024-05-10 14:54:54,482:INFO:Initializing create_model()
2024-05-10 14:54:54,482:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=GradientBoostingRegressor(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:54:54,482:INFO:Checking exceptions
2024-05-10 14:54:54,483:INFO:Importing libraries
2024-05-10 14:54:54,483:INFO:Copying training dataset
2024-05-10 14:54:54,485:INFO:Defining folds
2024-05-10 14:54:54,485:INFO:Declaring metric variables
2024-05-10 14:54:54,485:INFO:Importing untrained model
2024-05-10 14:54:54,485:INFO:Declaring custom model
2024-05-10 14:54:54,486:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:54:54,486:INFO:Starting cross validation
2024-05-10 14:54:54,490:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:54:54,931:INFO:Calculating mean and std
2024-05-10 14:54:54,931:INFO:Creating metrics dataframe
2024-05-10 14:54:54,932:INFO:Finalizing model
2024-05-10 14:54:55,199:INFO:Uploading results into container
2024-05-10 14:54:55,199:INFO:Uploading model into container now
2024-05-10 14:54:55,200:INFO:_master_model_container: 20
2024-05-10 14:54:55,200:INFO:_display_container: 4
2024-05-10 14:54:55,200:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:54:55,200:INFO:create_model() successfully completed......................................
2024-05-10 14:54:55,296:INFO:SubProcess create_model() end ==================================
2024-05-10 14:54:55,297:INFO:GradientBoostingRegressor(random_state=123) result for R2 is 0.7762
2024-05-10 14:54:55,297:INFO:GradientBoostingRegressor(learning_rate=0.15, max_depth=7, max_features=1.0,
                          min_impurity_decrease=0.02, min_samples_leaf=5,
                          min_samples_split=5, n_estimators=230,
                          random_state=123, subsample=0.85) result for R2 is 0.7738
2024-05-10 14:54:55,297:INFO:GradientBoostingRegressor(random_state=123) is best model
2024-05-10 14:54:55,297:INFO:choose_better completed
2024-05-10 14:54:55,297:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:54:55,302:INFO:_master_model_container: 20
2024-05-10 14:54:55,302:INFO:_display_container: 3
2024-05-10 14:54:55,303:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:54:55,303:INFO:tune_model() successfully completed......................................
2024-05-10 14:54:55,402:INFO:Initializing evaluate_model()
2024-05-10 14:54:55,402:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:54:55,408:INFO:Initializing plot_model()
2024-05-10 14:54:55,408:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, system=True)
2024-05-10 14:54:55,408:INFO:Checking exceptions
2024-05-10 14:54:55,410:INFO:Preloading libraries
2024-05-10 14:54:55,424:INFO:Copying training dataset
2024-05-10 14:54:55,424:INFO:Plot type: pipeline
2024-05-10 14:54:55,510:INFO:Visual Rendered Successfully
2024-05-10 14:54:55,611:INFO:plot_model() successfully completed......................................
2024-05-10 14:54:58,134:INFO:Initializing plot_model()
2024-05-10 14:54:58,134:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, system=True)
2024-05-10 14:54:58,134:INFO:Checking exceptions
2024-05-10 14:54:58,137:INFO:Preloading libraries
2024-05-10 14:54:58,142:INFO:Copying training dataset
2024-05-10 14:54:58,142:INFO:Plot type: residuals
2024-05-10 14:54:58,438:INFO:Fitting Model
2024-05-10 14:54:58,438:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:54:58,456:INFO:Scoring test/hold-out set
2024-05-10 14:54:58,632:INFO:Visual Rendered Successfully
2024-05-10 14:54:58,738:INFO:plot_model() successfully completed......................................
2024-05-10 14:55:09,483:INFO:Initializing plot_model()
2024-05-10 14:55:09,484:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, system=True)
2024-05-10 14:55:09,484:INFO:Checking exceptions
2024-05-10 14:55:09,487:INFO:Preloading libraries
2024-05-10 14:55:09,491:INFO:Copying training dataset
2024-05-10 14:55:09,492:INFO:Plot type: error
2024-05-10 14:55:09,621:INFO:Fitting Model
2024-05-10 14:55:09,621:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:55:09,621:INFO:Scoring test/hold-out set
2024-05-10 14:55:09,728:INFO:Visual Rendered Successfully
2024-05-10 14:55:09,833:INFO:plot_model() successfully completed......................................
2024-05-10 14:55:10,917:INFO:Initializing plot_model()
2024-05-10 14:55:10,917:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, system=True)
2024-05-10 14:55:10,917:INFO:Checking exceptions
2024-05-10 14:55:10,920:INFO:Preloading libraries
2024-05-10 14:55:10,924:INFO:Copying training dataset
2024-05-10 14:55:10,924:INFO:Plot type: residuals
2024-05-10 14:55:11,065:INFO:Fitting Model
2024-05-10 14:55:11,065:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:55:11,082:INFO:Scoring test/hold-out set
2024-05-10 14:55:11,250:INFO:Visual Rendered Successfully
2024-05-10 14:55:11,349:INFO:plot_model() successfully completed......................................
2024-05-10 14:55:11,667:INFO:Initializing plot_model()
2024-05-10 14:55:11,667:INFO:plot_model(plot=parameter, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, system=True)
2024-05-10 14:55:11,667:INFO:Checking exceptions
2024-05-10 14:55:11,671:INFO:Preloading libraries
2024-05-10 14:55:11,676:INFO:Copying training dataset
2024-05-10 14:55:11,676:INFO:Plot type: parameter
2024-05-10 14:55:11,679:INFO:Visual Rendered Successfully
2024-05-10 14:55:11,777:INFO:plot_model() successfully completed......................................
2024-05-10 14:55:12,328:INFO:Initializing plot_model()
2024-05-10 14:55:12,328:INFO:plot_model(plot=vc, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, system=True)
2024-05-10 14:55:12,328:INFO:Checking exceptions
2024-05-10 14:55:12,330:INFO:Preloading libraries
2024-05-10 14:55:12,335:INFO:Copying training dataset
2024-05-10 14:55:12,335:INFO:Plot type: vc
2024-05-10 14:55:12,335:INFO:Determining param_name
2024-05-10 14:55:12,335:INFO:param_name: alpha
2024-05-10 14:55:12,477:INFO:Fitting Model
2024-05-10 14:55:14,430:INFO:Visual Rendered Successfully
2024-05-10 14:55:14,555:INFO:plot_model() successfully completed......................................
2024-05-10 14:55:14,562:INFO:Initializing plot_model()
2024-05-10 14:55:14,562:INFO:plot_model(plot=feature, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, system=True)
2024-05-10 14:55:14,563:INFO:Checking exceptions
2024-05-10 14:55:14,565:INFO:Preloading libraries
2024-05-10 14:55:14,568:INFO:Copying training dataset
2024-05-10 14:55:14,568:INFO:Plot type: feature
2024-05-10 14:55:14,569:WARNING:No coef_ found. Trying feature_importances_
2024-05-10 14:55:14,680:INFO:Visual Rendered Successfully
2024-05-10 14:55:14,783:INFO:plot_model() successfully completed......................................
2024-05-10 14:55:14,789:INFO:Initializing plot_model()
2024-05-10 14:55:14,789:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=GradientBoostingRegressor(random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, system=True)
2024-05-10 14:55:14,789:INFO:Checking exceptions
2024-05-10 14:55:14,790:INFO:Preloading libraries
2024-05-10 14:55:14,794:INFO:Copying training dataset
2024-05-10 14:55:14,794:INFO:Plot type: residuals
2024-05-10 14:55:14,942:INFO:Fitting Model
2024-05-10 14:55:14,942:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but GradientBoostingRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:55:14,960:INFO:Scoring test/hold-out set
2024-05-10 14:55:15,130:INFO:Visual Rendered Successfully
2024-05-10 14:55:15,228:INFO:plot_model() successfully completed......................................
2024-05-10 14:55:47,205:INFO:Initializing finalize_model()
2024-05-10 14:55:47,205:INFO:finalize_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=GradientBoostingRegressor(random_state=123), fit_kwargs=None, groups=None, model_only=False, experiment_custom_tags=None)
2024-05-10 14:55:47,205:INFO:Finalizing GradientBoostingRegressor(random_state=123)
2024-05-10 14:55:47,207:INFO:Initializing create_model()
2024-05-10 14:55:47,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=GradientBoostingRegressor(random_state=123), fold=None, round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=False, metrics=None, display=None, model_only=False, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:55:47,207:INFO:Checking exceptions
2024-05-10 14:55:47,208:INFO:Importing libraries
2024-05-10 14:55:47,209:INFO:Copying training dataset
2024-05-10 14:55:47,209:INFO:Defining folds
2024-05-10 14:55:47,209:INFO:Declaring metric variables
2024-05-10 14:55:47,210:INFO:Importing untrained model
2024-05-10 14:55:47,210:INFO:Declaring custom model
2024-05-10 14:55:47,211:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:55:47,218:INFO:Cross validation set to False
2024-05-10 14:55:47,219:INFO:Fitting Model
2024-05-10 14:55:47,519:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2024-05-10 14:55:47,519:INFO:create_model() successfully completed......................................
2024-05-10 14:55:47,612:INFO:_master_model_container: 20
2024-05-10 14:55:47,613:INFO:_display_container: 3
2024-05-10 14:55:47,620:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))])
2024-05-10 14:55:47,620:INFO:finalize_model() successfully completed......................................
2024-05-10 14:55:47,717:INFO:Initializing predict_model()
2024-05-10 14:55:47,717:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32ff7dc0>, estimator=Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most...
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames())),
                ('actual_estimator',
                 GradientBoostingRegressor(random_state=123))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x701d4db68160>)
2024-05-10 14:55:47,717:INFO:Checking exceptions
2024-05-10 14:55:47,717:INFO:Preloading libraries
2024-05-10 14:55:47,718:INFO:Set up data.
2024-05-10 14:55:47,720:INFO:Set up index.
2024-05-10 14:55:47,726:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/metrics/_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2024-05-10 14:56:06,355:INFO:PyCaret RegressionExperiment
2024-05-10 14:56:06,355:INFO:Logging name: reg-default-name
2024-05-10 14:56:06,355:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:56:06,355:INFO:version 3.3.2
2024-05-10 14:56:06,355:INFO:Initializing setup()
2024-05-10 14:56:06,355:INFO:self.USI: 7a0f
2024-05-10 14:56:06,355:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 14:56:06,355:INFO:Checking environment
2024-05-10 14:56:06,355:INFO:python_version: 3.9.18
2024-05-10 14:56:06,355:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:56:06,355:INFO:machine: x86_64
2024-05-10 14:56:06,355:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:56:06,355:INFO:Memory: svmem(total=16429797376, available=5999472640, percent=63.5, used=9323958272, free=3877855232, active=6780092416, inactive=4376559616, buffers=168419328, cached=3059564544, shared=759824384, slab=738680832)
2024-05-10 14:56:06,355:INFO:Physical Core: 12
2024-05-10 14:56:06,355:INFO:Logical Core: 16
2024-05-10 14:56:06,356:INFO:Checking libraries
2024-05-10 14:56:06,356:INFO:System:
2024-05-10 14:56:06,356:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:56:06,356:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:56:06,356:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:56:06,356:INFO:PyCaret required dependencies:
2024-05-10 14:56:06,356:INFO:                 pip: 23.3.1
2024-05-10 14:56:06,356:INFO:          setuptools: 68.2.2
2024-05-10 14:56:06,356:INFO:             pycaret: 3.3.2
2024-05-10 14:56:06,356:INFO:             IPython: 8.15.0
2024-05-10 14:56:06,356:INFO:          ipywidgets: 7.6.5
2024-05-10 14:56:06,356:INFO:                tqdm: 4.65.0
2024-05-10 14:56:06,356:INFO:               numpy: 1.26.4
2024-05-10 14:56:06,356:INFO:              pandas: 2.1.4
2024-05-10 14:56:06,356:INFO:              jinja2: 3.1.3
2024-05-10 14:56:06,356:INFO:               scipy: 1.11.4
2024-05-10 14:56:06,356:INFO:              joblib: 1.2.0
2024-05-10 14:56:06,356:INFO:             sklearn: 1.4.2
2024-05-10 14:56:06,356:INFO:                pyod: 1.1.3
2024-05-10 14:56:06,356:INFO:            imblearn: 0.12.2
2024-05-10 14:56:06,356:INFO:   category_encoders: 2.6.3
2024-05-10 14:56:06,356:INFO:            lightgbm: 4.3.0
2024-05-10 14:56:06,356:INFO:               numba: 0.59.1
2024-05-10 14:56:06,356:INFO:            requests: 2.31.0
2024-05-10 14:56:06,356:INFO:          matplotlib: 3.7.5
2024-05-10 14:56:06,356:INFO:          scikitplot: 0.3.7
2024-05-10 14:56:06,356:INFO:         yellowbrick: 1.5
2024-05-10 14:56:06,356:INFO:              plotly: 5.19.0
2024-05-10 14:56:06,356:INFO:    plotly-resampler: Not installed
2024-05-10 14:56:06,356:INFO:             kaleido: 0.2.1
2024-05-10 14:56:06,356:INFO:           schemdraw: 0.15
2024-05-10 14:56:06,356:INFO:         statsmodels: 0.14.0
2024-05-10 14:56:06,356:INFO:              sktime: 0.26.0
2024-05-10 14:56:06,356:INFO:               tbats: 1.1.3
2024-05-10 14:56:06,356:INFO:            pmdarima: 2.0.4
2024-05-10 14:56:06,356:INFO:              psutil: 5.9.0
2024-05-10 14:56:06,356:INFO:          markupsafe: 2.1.3
2024-05-10 14:56:06,356:INFO:             pickle5: Not installed
2024-05-10 14:56:06,356:INFO:         cloudpickle: 2.2.1
2024-05-10 14:56:06,356:INFO:         deprecation: 2.1.0
2024-05-10 14:56:06,356:INFO:              xxhash: 3.4.1
2024-05-10 14:56:06,356:INFO:           wurlitzer: 3.0.2
2024-05-10 14:56:06,356:INFO:PyCaret optional dependencies:
2024-05-10 14:56:06,356:INFO:                shap: Not installed
2024-05-10 14:56:06,356:INFO:           interpret: Not installed
2024-05-10 14:56:06,356:INFO:                umap: Not installed
2024-05-10 14:56:06,356:INFO:     ydata_profiling: Not installed
2024-05-10 14:56:06,356:INFO:  explainerdashboard: Not installed
2024-05-10 14:56:06,356:INFO:             autoviz: Not installed
2024-05-10 14:56:06,356:INFO:           fairlearn: Not installed
2024-05-10 14:56:06,356:INFO:          deepchecks: Not installed
2024-05-10 14:56:06,356:INFO:             xgboost: Not installed
2024-05-10 14:56:06,356:INFO:            catboost: Not installed
2024-05-10 14:56:06,356:INFO:              kmodes: Not installed
2024-05-10 14:56:06,356:INFO:             mlxtend: Not installed
2024-05-10 14:56:06,356:INFO:       statsforecast: Not installed
2024-05-10 14:56:06,356:INFO:        tune_sklearn: Not installed
2024-05-10 14:56:06,356:INFO:                 ray: Not installed
2024-05-10 14:56:06,356:INFO:            hyperopt: Not installed
2024-05-10 14:56:06,356:INFO:              optuna: Not installed
2024-05-10 14:56:06,356:INFO:               skopt: Not installed
2024-05-10 14:56:06,356:INFO:              mlflow: Not installed
2024-05-10 14:56:06,356:INFO:              gradio: Not installed
2024-05-10 14:56:06,356:INFO:             fastapi: Not installed
2024-05-10 14:56:06,356:INFO:             uvicorn: Not installed
2024-05-10 14:56:06,356:INFO:              m2cgen: Not installed
2024-05-10 14:56:06,356:INFO:           evidently: Not installed
2024-05-10 14:56:06,356:INFO:               fugue: Not installed
2024-05-10 14:56:06,356:INFO:           streamlit: 1.32.0
2024-05-10 14:56:06,356:INFO:             prophet: Not installed
2024-05-10 14:56:06,356:INFO:None
2024-05-10 14:56:06,356:INFO:Set up data.
2024-05-10 14:56:06,359:INFO:Set up folding strategy.
2024-05-10 14:56:06,359:INFO:Set up train/test split.
2024-05-10 14:56:06,361:INFO:Set up index.
2024-05-10 14:56:06,361:INFO:Assigning column types.
2024-05-10 14:56:06,363:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:56:06,363:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,365:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,367:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,393:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,411:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,412:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,412:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,412:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,414:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,416:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,440:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,459:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,459:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,459:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,460:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:56:06,461:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,463:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,488:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,509:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,511:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,535:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,554:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,555:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,555:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,555:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:56:06,559:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,585:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,604:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,609:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,634:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,655:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,655:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,655:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,655:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:56:06,685:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,705:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,705:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,705:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,736:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,756:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,756:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,757:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,757:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:56:06,789:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,808:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,838:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:56:06,857:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,858:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,858:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:56:06,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,959:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,959:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:06,959:INFO:Preparing preprocessing pipeline...
2024-05-10 14:56:06,959:INFO:Set up simple imputation.
2024-05-10 14:56:06,959:INFO:Set up polynomial features.
2024-05-10 14:56:06,959:INFO:Set up removing outliers.
2024-05-10 14:56:06,959:INFO:Set up feature normalization.
2024-05-10 14:56:06,960:INFO:Set up column name cleaning.
2024-05-10 14:56:07,050:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:56:07,054:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_in_power(Wh)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:56:07,054:INFO:Creating final display dataframe.
2024-05-10 14:56:07,381:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 7)
4        Transformed data shape         (579, 28)
5   Transformed train set shape         (399, 28)
6    Transformed test set shape         (180, 28)
7              Numeric features                 6
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              7a0f
2024-05-10 14:56:07,437:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:07,437:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:07,487:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:07,487:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:56:07,487:INFO:setup() successfully completed in 1.13s...............
2024-05-10 14:56:07,487:INFO:Initializing compare_models()
2024-05-10 14:56:07,487:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:56:07,487:INFO:Checking exceptions
2024-05-10 14:56:07,489:INFO:Preparing display monitor
2024-05-10 14:56:07,501:INFO:Initializing Linear Regression
2024-05-10 14:56:07,501:INFO:Total runtime is 2.845128377278646e-06 minutes
2024-05-10 14:56:07,503:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:07,503:INFO:Initializing create_model()
2024-05-10 14:56:07,503:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:07,503:INFO:Checking exceptions
2024-05-10 14:56:07,503:INFO:Importing libraries
2024-05-10 14:56:07,503:INFO:Copying training dataset
2024-05-10 14:56:07,505:INFO:Defining folds
2024-05-10 14:56:07,505:INFO:Declaring metric variables
2024-05-10 14:56:07,507:INFO:Importing untrained model
2024-05-10 14:56:07,509:INFO:Linear Regression Imported successfully
2024-05-10 14:56:07,513:INFO:Starting cross validation
2024-05-10 14:56:07,519:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:07,732:INFO:Calculating mean and std
2024-05-10 14:56:07,732:INFO:Creating metrics dataframe
2024-05-10 14:56:07,733:INFO:Uploading results into container
2024-05-10 14:56:07,734:INFO:Uploading model into container now
2024-05-10 14:56:07,734:INFO:_master_model_container: 1
2024-05-10 14:56:07,734:INFO:_display_container: 2
2024-05-10 14:56:07,734:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:56:07,734:INFO:create_model() successfully completed......................................
2024-05-10 14:56:07,833:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:07,833:INFO:Creating metrics dataframe
2024-05-10 14:56:07,837:INFO:Initializing Lasso Regression
2024-05-10 14:56:07,837:INFO:Total runtime is 0.005592660109202068 minutes
2024-05-10 14:56:07,838:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:07,839:INFO:Initializing create_model()
2024-05-10 14:56:07,839:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:07,839:INFO:Checking exceptions
2024-05-10 14:56:07,839:INFO:Importing libraries
2024-05-10 14:56:07,839:INFO:Copying training dataset
2024-05-10 14:56:07,840:INFO:Defining folds
2024-05-10 14:56:07,841:INFO:Declaring metric variables
2024-05-10 14:56:07,842:INFO:Importing untrained model
2024-05-10 14:56:07,844:INFO:Lasso Regression Imported successfully
2024-05-10 14:56:07,848:INFO:Starting cross validation
2024-05-10 14:56:07,853:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:08,038:INFO:Calculating mean and std
2024-05-10 14:56:08,038:INFO:Creating metrics dataframe
2024-05-10 14:56:08,040:INFO:Uploading results into container
2024-05-10 14:56:08,040:INFO:Uploading model into container now
2024-05-10 14:56:08,040:INFO:_master_model_container: 2
2024-05-10 14:56:08,040:INFO:_display_container: 2
2024-05-10 14:56:08,040:INFO:Lasso(random_state=123)
2024-05-10 14:56:08,040:INFO:create_model() successfully completed......................................
2024-05-10 14:56:08,139:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:08,139:INFO:Creating metrics dataframe
2024-05-10 14:56:08,143:INFO:Initializing Ridge Regression
2024-05-10 14:56:08,143:INFO:Total runtime is 0.010698294639587403 minutes
2024-05-10 14:56:08,145:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:08,145:INFO:Initializing create_model()
2024-05-10 14:56:08,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:08,145:INFO:Checking exceptions
2024-05-10 14:56:08,145:INFO:Importing libraries
2024-05-10 14:56:08,145:INFO:Copying training dataset
2024-05-10 14:56:08,148:INFO:Defining folds
2024-05-10 14:56:08,148:INFO:Declaring metric variables
2024-05-10 14:56:08,150:INFO:Importing untrained model
2024-05-10 14:56:08,152:INFO:Ridge Regression Imported successfully
2024-05-10 14:56:08,155:INFO:Starting cross validation
2024-05-10 14:56:08,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:08,354:INFO:Calculating mean and std
2024-05-10 14:56:08,354:INFO:Creating metrics dataframe
2024-05-10 14:56:08,355:INFO:Uploading results into container
2024-05-10 14:56:08,356:INFO:Uploading model into container now
2024-05-10 14:56:08,356:INFO:_master_model_container: 3
2024-05-10 14:56:08,356:INFO:_display_container: 2
2024-05-10 14:56:08,356:INFO:Ridge(random_state=123)
2024-05-10 14:56:08,356:INFO:create_model() successfully completed......................................
2024-05-10 14:56:08,455:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:08,455:INFO:Creating metrics dataframe
2024-05-10 14:56:08,459:INFO:Initializing Elastic Net
2024-05-10 14:56:08,459:INFO:Total runtime is 0.01596938371658325 minutes
2024-05-10 14:56:08,461:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:08,461:INFO:Initializing create_model()
2024-05-10 14:56:08,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:08,461:INFO:Checking exceptions
2024-05-10 14:56:08,461:INFO:Importing libraries
2024-05-10 14:56:08,462:INFO:Copying training dataset
2024-05-10 14:56:08,464:INFO:Defining folds
2024-05-10 14:56:08,464:INFO:Declaring metric variables
2024-05-10 14:56:08,466:INFO:Importing untrained model
2024-05-10 14:56:08,468:INFO:Elastic Net Imported successfully
2024-05-10 14:56:08,470:INFO:Starting cross validation
2024-05-10 14:56:08,475:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:08,660:INFO:Calculating mean and std
2024-05-10 14:56:08,661:INFO:Creating metrics dataframe
2024-05-10 14:56:08,663:INFO:Uploading results into container
2024-05-10 14:56:08,663:INFO:Uploading model into container now
2024-05-10 14:56:08,664:INFO:_master_model_container: 4
2024-05-10 14:56:08,664:INFO:_display_container: 2
2024-05-10 14:56:08,664:INFO:ElasticNet(random_state=123)
2024-05-10 14:56:08,664:INFO:create_model() successfully completed......................................
2024-05-10 14:56:08,764:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:08,764:INFO:Creating metrics dataframe
2024-05-10 14:56:08,768:INFO:Initializing Least Angle Regression
2024-05-10 14:56:08,768:INFO:Total runtime is 0.021119741598765056 minutes
2024-05-10 14:56:08,770:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:08,770:INFO:Initializing create_model()
2024-05-10 14:56:08,770:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:08,770:INFO:Checking exceptions
2024-05-10 14:56:08,770:INFO:Importing libraries
2024-05-10 14:56:08,770:INFO:Copying training dataset
2024-05-10 14:56:08,773:INFO:Defining folds
2024-05-10 14:56:08,773:INFO:Declaring metric variables
2024-05-10 14:56:08,774:INFO:Importing untrained model
2024-05-10 14:56:08,776:INFO:Least Angle Regression Imported successfully
2024-05-10 14:56:08,779:INFO:Starting cross validation
2024-05-10 14:56:08,784:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:08,981:INFO:Calculating mean and std
2024-05-10 14:56:08,982:INFO:Creating metrics dataframe
2024-05-10 14:56:08,984:INFO:Uploading results into container
2024-05-10 14:56:08,984:INFO:Uploading model into container now
2024-05-10 14:56:08,984:INFO:_master_model_container: 5
2024-05-10 14:56:08,984:INFO:_display_container: 2
2024-05-10 14:56:08,985:INFO:Lars(random_state=123)
2024-05-10 14:56:08,985:INFO:create_model() successfully completed......................................
2024-05-10 14:56:09,084:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:09,084:INFO:Creating metrics dataframe
2024-05-10 14:56:09,089:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:56:09,089:INFO:Total runtime is 0.026461021105448405 minutes
2024-05-10 14:56:09,091:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:09,091:INFO:Initializing create_model()
2024-05-10 14:56:09,091:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:09,091:INFO:Checking exceptions
2024-05-10 14:56:09,091:INFO:Importing libraries
2024-05-10 14:56:09,091:INFO:Copying training dataset
2024-05-10 14:56:09,093:INFO:Defining folds
2024-05-10 14:56:09,093:INFO:Declaring metric variables
2024-05-10 14:56:09,095:INFO:Importing untrained model
2024-05-10 14:56:09,097:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:56:09,100:INFO:Starting cross validation
2024-05-10 14:56:09,105:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:09,293:INFO:Calculating mean and std
2024-05-10 14:56:09,293:INFO:Creating metrics dataframe
2024-05-10 14:56:09,294:INFO:Uploading results into container
2024-05-10 14:56:09,295:INFO:Uploading model into container now
2024-05-10 14:56:09,295:INFO:_master_model_container: 6
2024-05-10 14:56:09,295:INFO:_display_container: 2
2024-05-10 14:56:09,296:INFO:LassoLars(random_state=123)
2024-05-10 14:56:09,296:INFO:create_model() successfully completed......................................
2024-05-10 14:56:09,397:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:09,397:INFO:Creating metrics dataframe
2024-05-10 14:56:09,402:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:56:09,402:INFO:Total runtime is 0.03168006738026937 minutes
2024-05-10 14:56:09,404:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:09,404:INFO:Initializing create_model()
2024-05-10 14:56:09,404:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:09,404:INFO:Checking exceptions
2024-05-10 14:56:09,404:INFO:Importing libraries
2024-05-10 14:56:09,404:INFO:Copying training dataset
2024-05-10 14:56:09,406:INFO:Defining folds
2024-05-10 14:56:09,406:INFO:Declaring metric variables
2024-05-10 14:56:09,408:INFO:Importing untrained model
2024-05-10 14:56:09,409:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:56:09,413:INFO:Starting cross validation
2024-05-10 14:56:09,419:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:09,620:INFO:Calculating mean and std
2024-05-10 14:56:09,621:INFO:Creating metrics dataframe
2024-05-10 14:56:09,622:INFO:Uploading results into container
2024-05-10 14:56:09,622:INFO:Uploading model into container now
2024-05-10 14:56:09,623:INFO:_master_model_container: 7
2024-05-10 14:56:09,623:INFO:_display_container: 2
2024-05-10 14:56:09,623:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:56:09,623:INFO:create_model() successfully completed......................................
2024-05-10 14:56:09,723:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:09,723:INFO:Creating metrics dataframe
2024-05-10 14:56:09,728:INFO:Initializing Bayesian Ridge
2024-05-10 14:56:09,728:INFO:Total runtime is 0.037113718191782635 minutes
2024-05-10 14:56:09,730:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:09,730:INFO:Initializing create_model()
2024-05-10 14:56:09,730:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:09,730:INFO:Checking exceptions
2024-05-10 14:56:09,730:INFO:Importing libraries
2024-05-10 14:56:09,730:INFO:Copying training dataset
2024-05-10 14:56:09,733:INFO:Defining folds
2024-05-10 14:56:09,734:INFO:Declaring metric variables
2024-05-10 14:56:09,736:INFO:Importing untrained model
2024-05-10 14:56:09,737:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:56:09,741:INFO:Starting cross validation
2024-05-10 14:56:09,746:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:09,930:INFO:Calculating mean and std
2024-05-10 14:56:09,931:INFO:Creating metrics dataframe
2024-05-10 14:56:09,932:INFO:Uploading results into container
2024-05-10 14:56:09,933:INFO:Uploading model into container now
2024-05-10 14:56:09,933:INFO:_master_model_container: 8
2024-05-10 14:56:09,933:INFO:_display_container: 2
2024-05-10 14:56:09,934:INFO:BayesianRidge()
2024-05-10 14:56:09,934:INFO:create_model() successfully completed......................................
2024-05-10 14:56:10,032:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:10,032:INFO:Creating metrics dataframe
2024-05-10 14:56:10,037:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:56:10,037:INFO:Total runtime is 0.04226080973943075 minutes
2024-05-10 14:56:10,039:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:10,039:INFO:Initializing create_model()
2024-05-10 14:56:10,039:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:10,039:INFO:Checking exceptions
2024-05-10 14:56:10,039:INFO:Importing libraries
2024-05-10 14:56:10,039:INFO:Copying training dataset
2024-05-10 14:56:10,041:INFO:Defining folds
2024-05-10 14:56:10,041:INFO:Declaring metric variables
2024-05-10 14:56:10,043:INFO:Importing untrained model
2024-05-10 14:56:10,045:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:56:10,049:INFO:Starting cross validation
2024-05-10 14:56:10,054:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:10,275:INFO:Calculating mean and std
2024-05-10 14:56:10,275:INFO:Creating metrics dataframe
2024-05-10 14:56:10,277:INFO:Uploading results into container
2024-05-10 14:56:10,277:INFO:Uploading model into container now
2024-05-10 14:56:10,277:INFO:_master_model_container: 9
2024-05-10 14:56:10,278:INFO:_display_container: 2
2024-05-10 14:56:10,278:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:56:10,278:INFO:create_model() successfully completed......................................
2024-05-10 14:56:10,384:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:10,384:INFO:Creating metrics dataframe
2024-05-10 14:56:10,389:INFO:Initializing Huber Regressor
2024-05-10 14:56:10,389:INFO:Total runtime is 0.04813263416290284 minutes
2024-05-10 14:56:10,391:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:10,391:INFO:Initializing create_model()
2024-05-10 14:56:10,391:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:10,391:INFO:Checking exceptions
2024-05-10 14:56:10,391:INFO:Importing libraries
2024-05-10 14:56:10,391:INFO:Copying training dataset
2024-05-10 14:56:10,393:INFO:Defining folds
2024-05-10 14:56:10,394:INFO:Declaring metric variables
2024-05-10 14:56:10,396:INFO:Importing untrained model
2024-05-10 14:56:10,398:INFO:Huber Regressor Imported successfully
2024-05-10 14:56:10,402:INFO:Starting cross validation
2024-05-10 14:56:10,406:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:10,543:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,544:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,549:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,555:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,584:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,592:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,597:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,597:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,601:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,605:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:56:10,612:INFO:Calculating mean and std
2024-05-10 14:56:10,613:INFO:Creating metrics dataframe
2024-05-10 14:56:10,615:INFO:Uploading results into container
2024-05-10 14:56:10,616:INFO:Uploading model into container now
2024-05-10 14:56:10,616:INFO:_master_model_container: 10
2024-05-10 14:56:10,616:INFO:_display_container: 2
2024-05-10 14:56:10,616:INFO:HuberRegressor()
2024-05-10 14:56:10,616:INFO:create_model() successfully completed......................................
2024-05-10 14:56:10,717:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:10,717:INFO:Creating metrics dataframe
2024-05-10 14:56:10,722:INFO:Initializing K Neighbors Regressor
2024-05-10 14:56:10,722:INFO:Total runtime is 0.05368366241455079 minutes
2024-05-10 14:56:10,724:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:10,724:INFO:Initializing create_model()
2024-05-10 14:56:10,724:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:10,724:INFO:Checking exceptions
2024-05-10 14:56:10,724:INFO:Importing libraries
2024-05-10 14:56:10,724:INFO:Copying training dataset
2024-05-10 14:56:10,726:INFO:Defining folds
2024-05-10 14:56:10,726:INFO:Declaring metric variables
2024-05-10 14:56:10,728:INFO:Importing untrained model
2024-05-10 14:56:10,730:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:56:10,736:INFO:Starting cross validation
2024-05-10 14:56:10,744:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:10,951:INFO:Calculating mean and std
2024-05-10 14:56:10,952:INFO:Creating metrics dataframe
2024-05-10 14:56:10,954:INFO:Uploading results into container
2024-05-10 14:56:10,954:INFO:Uploading model into container now
2024-05-10 14:56:10,954:INFO:_master_model_container: 11
2024-05-10 14:56:10,954:INFO:_display_container: 2
2024-05-10 14:56:10,955:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:56:10,955:INFO:create_model() successfully completed......................................
2024-05-10 14:56:11,056:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:11,056:INFO:Creating metrics dataframe
2024-05-10 14:56:11,062:INFO:Initializing Decision Tree Regressor
2024-05-10 14:56:11,062:INFO:Total runtime is 0.059343516826629646 minutes
2024-05-10 14:56:11,064:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:11,064:INFO:Initializing create_model()
2024-05-10 14:56:11,064:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:11,064:INFO:Checking exceptions
2024-05-10 14:56:11,064:INFO:Importing libraries
2024-05-10 14:56:11,064:INFO:Copying training dataset
2024-05-10 14:56:11,066:INFO:Defining folds
2024-05-10 14:56:11,066:INFO:Declaring metric variables
2024-05-10 14:56:11,069:INFO:Importing untrained model
2024-05-10 14:56:11,071:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:56:11,074:INFO:Starting cross validation
2024-05-10 14:56:11,078:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:11,276:INFO:Calculating mean and std
2024-05-10 14:56:11,277:INFO:Creating metrics dataframe
2024-05-10 14:56:11,278:INFO:Uploading results into container
2024-05-10 14:56:11,278:INFO:Uploading model into container now
2024-05-10 14:56:11,279:INFO:_master_model_container: 12
2024-05-10 14:56:11,279:INFO:_display_container: 2
2024-05-10 14:56:11,280:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:56:11,280:INFO:create_model() successfully completed......................................
2024-05-10 14:56:11,381:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:11,381:INFO:Creating metrics dataframe
2024-05-10 14:56:11,386:INFO:Initializing Random Forest Regressor
2024-05-10 14:56:11,387:INFO:Total runtime is 0.06475658814112346 minutes
2024-05-10 14:56:11,388:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:11,389:INFO:Initializing create_model()
2024-05-10 14:56:11,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:11,389:INFO:Checking exceptions
2024-05-10 14:56:11,389:INFO:Importing libraries
2024-05-10 14:56:11,389:INFO:Copying training dataset
2024-05-10 14:56:11,391:INFO:Defining folds
2024-05-10 14:56:11,391:INFO:Declaring metric variables
2024-05-10 14:56:11,393:INFO:Importing untrained model
2024-05-10 14:56:11,394:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:56:11,398:INFO:Starting cross validation
2024-05-10 14:56:11,403:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:12,075:INFO:Calculating mean and std
2024-05-10 14:56:12,076:INFO:Creating metrics dataframe
2024-05-10 14:56:12,077:INFO:Uploading results into container
2024-05-10 14:56:12,078:INFO:Uploading model into container now
2024-05-10 14:56:12,078:INFO:_master_model_container: 13
2024-05-10 14:56:12,078:INFO:_display_container: 2
2024-05-10 14:56:12,078:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:56:12,078:INFO:create_model() successfully completed......................................
2024-05-10 14:56:12,177:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:12,177:INFO:Creating metrics dataframe
2024-05-10 14:56:12,183:INFO:Initializing Extra Trees Regressor
2024-05-10 14:56:12,183:INFO:Total runtime is 0.07802712519963584 minutes
2024-05-10 14:56:12,185:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:12,185:INFO:Initializing create_model()
2024-05-10 14:56:12,185:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:12,185:INFO:Checking exceptions
2024-05-10 14:56:12,185:INFO:Importing libraries
2024-05-10 14:56:12,185:INFO:Copying training dataset
2024-05-10 14:56:12,187:INFO:Defining folds
2024-05-10 14:56:12,187:INFO:Declaring metric variables
2024-05-10 14:56:12,189:INFO:Importing untrained model
2024-05-10 14:56:12,191:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:56:12,194:INFO:Starting cross validation
2024-05-10 14:56:12,199:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:12,600:INFO:Calculating mean and std
2024-05-10 14:56:12,601:INFO:Creating metrics dataframe
2024-05-10 14:56:12,603:INFO:Uploading results into container
2024-05-10 14:56:12,604:INFO:Uploading model into container now
2024-05-10 14:56:12,604:INFO:_master_model_container: 14
2024-05-10 14:56:12,604:INFO:_display_container: 2
2024-05-10 14:56:12,605:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:56:12,605:INFO:create_model() successfully completed......................................
2024-05-10 14:56:12,705:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:12,705:INFO:Creating metrics dataframe
2024-05-10 14:56:12,711:INFO:Initializing AdaBoost Regressor
2024-05-10 14:56:12,711:INFO:Total runtime is 0.08682698408762615 minutes
2024-05-10 14:56:12,713:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:12,713:INFO:Initializing create_model()
2024-05-10 14:56:12,713:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:12,713:INFO:Checking exceptions
2024-05-10 14:56:12,713:INFO:Importing libraries
2024-05-10 14:56:12,713:INFO:Copying training dataset
2024-05-10 14:56:12,716:INFO:Defining folds
2024-05-10 14:56:12,716:INFO:Declaring metric variables
2024-05-10 14:56:12,718:INFO:Importing untrained model
2024-05-10 14:56:12,720:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:56:12,723:INFO:Starting cross validation
2024-05-10 14:56:12,727:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:13,063:INFO:Calculating mean and std
2024-05-10 14:56:13,063:INFO:Creating metrics dataframe
2024-05-10 14:56:13,065:INFO:Uploading results into container
2024-05-10 14:56:13,065:INFO:Uploading model into container now
2024-05-10 14:56:13,066:INFO:_master_model_container: 15
2024-05-10 14:56:13,066:INFO:_display_container: 2
2024-05-10 14:56:13,066:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:56:13,066:INFO:create_model() successfully completed......................................
2024-05-10 14:56:13,166:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:13,166:INFO:Creating metrics dataframe
2024-05-10 14:56:13,171:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:56:13,171:INFO:Total runtime is 0.09450443983078004 minutes
2024-05-10 14:56:13,173:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:13,173:INFO:Initializing create_model()
2024-05-10 14:56:13,173:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:13,173:INFO:Checking exceptions
2024-05-10 14:56:13,173:INFO:Importing libraries
2024-05-10 14:56:13,173:INFO:Copying training dataset
2024-05-10 14:56:13,176:INFO:Defining folds
2024-05-10 14:56:13,176:INFO:Declaring metric variables
2024-05-10 14:56:13,178:INFO:Importing untrained model
2024-05-10 14:56:13,181:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:56:13,184:INFO:Starting cross validation
2024-05-10 14:56:13,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:13,745:INFO:Calculating mean and std
2024-05-10 14:56:13,745:INFO:Creating metrics dataframe
2024-05-10 14:56:13,747:INFO:Uploading results into container
2024-05-10 14:56:13,747:INFO:Uploading model into container now
2024-05-10 14:56:13,747:INFO:_master_model_container: 16
2024-05-10 14:56:13,747:INFO:_display_container: 2
2024-05-10 14:56:13,748:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:56:13,748:INFO:create_model() successfully completed......................................
2024-05-10 14:56:13,848:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:13,848:INFO:Creating metrics dataframe
2024-05-10 14:56:13,854:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:56:13,854:INFO:Total runtime is 0.10587875843048096 minutes
2024-05-10 14:56:13,856:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:13,856:INFO:Initializing create_model()
2024-05-10 14:56:13,856:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:13,856:INFO:Checking exceptions
2024-05-10 14:56:13,856:INFO:Importing libraries
2024-05-10 14:56:13,856:INFO:Copying training dataset
2024-05-10 14:56:13,858:INFO:Defining folds
2024-05-10 14:56:13,858:INFO:Declaring metric variables
2024-05-10 14:56:13,862:INFO:Importing untrained model
2024-05-10 14:56:13,864:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:56:13,869:INFO:Starting cross validation
2024-05-10 14:56:13,873:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:14,643:INFO:Calculating mean and std
2024-05-10 14:56:14,644:INFO:Creating metrics dataframe
2024-05-10 14:56:14,646:INFO:Uploading results into container
2024-05-10 14:56:14,646:INFO:Uploading model into container now
2024-05-10 14:56:14,646:INFO:_master_model_container: 17
2024-05-10 14:56:14,646:INFO:_display_container: 2
2024-05-10 14:56:14,647:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:56:14,647:INFO:create_model() successfully completed......................................
2024-05-10 14:56:14,749:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:14,749:INFO:Creating metrics dataframe
2024-05-10 14:56:14,754:INFO:Initializing Dummy Regressor
2024-05-10 14:56:14,754:INFO:Total runtime is 0.12088514566421509 minutes
2024-05-10 14:56:14,756:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:14,756:INFO:Initializing create_model()
2024-05-10 14:56:14,756:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd67850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:14,756:INFO:Checking exceptions
2024-05-10 14:56:14,756:INFO:Importing libraries
2024-05-10 14:56:14,756:INFO:Copying training dataset
2024-05-10 14:56:14,759:INFO:Defining folds
2024-05-10 14:56:14,759:INFO:Declaring metric variables
2024-05-10 14:56:14,761:INFO:Importing untrained model
2024-05-10 14:56:14,764:INFO:Dummy Regressor Imported successfully
2024-05-10 14:56:14,768:INFO:Starting cross validation
2024-05-10 14:56:14,772:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:14,959:INFO:Calculating mean and std
2024-05-10 14:56:14,959:INFO:Creating metrics dataframe
2024-05-10 14:56:14,960:INFO:Uploading results into container
2024-05-10 14:56:14,961:INFO:Uploading model into container now
2024-05-10 14:56:14,961:INFO:_master_model_container: 18
2024-05-10 14:56:14,961:INFO:_display_container: 2
2024-05-10 14:56:14,961:INFO:DummyRegressor()
2024-05-10 14:56:14,961:INFO:create_model() successfully completed......................................
2024-05-10 14:56:15,064:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:15,064:INFO:Creating metrics dataframe
2024-05-10 14:56:15,070:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:56:15,075:INFO:Initializing create_model()
2024-05-10 14:56:15,075:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:15,075:INFO:Checking exceptions
2024-05-10 14:56:15,076:INFO:Importing libraries
2024-05-10 14:56:15,076:INFO:Copying training dataset
2024-05-10 14:56:15,079:INFO:Defining folds
2024-05-10 14:56:15,079:INFO:Declaring metric variables
2024-05-10 14:56:15,079:INFO:Importing untrained model
2024-05-10 14:56:15,079:INFO:Declaring custom model
2024-05-10 14:56:15,079:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:56:15,084:INFO:Cross validation set to False
2024-05-10 14:56:15,084:INFO:Fitting Model
2024-05-10 14:56:15,216:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:56:15,216:INFO:create_model() successfully completed......................................
2024-05-10 14:56:15,339:INFO:_master_model_container: 18
2024-05-10 14:56:15,339:INFO:_display_container: 2
2024-05-10 14:56:15,339:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:56:15,339:INFO:compare_models() successfully completed......................................
2024-05-10 14:56:15,340:INFO:Initializing tune_model()
2024-05-10 14:56:15,340:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>)
2024-05-10 14:56:15,340:INFO:Checking exceptions
2024-05-10 14:56:15,349:INFO:Copying training dataset
2024-05-10 14:56:15,352:INFO:Checking base model
2024-05-10 14:56:15,352:INFO:Base model : Extra Trees Regressor
2024-05-10 14:56:15,354:INFO:Declaring metric variables
2024-05-10 14:56:15,356:INFO:Defining Hyperparameters
2024-05-10 14:56:15,474:INFO:Tuning with n_jobs=-1
2024-05-10 14:56:15,474:INFO:Initializing RandomizedSearchCV
2024-05-10 14:56:18,692:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:56:18,693:INFO:Hyperparameter search completed
2024-05-10 14:56:18,693:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:18,694:INFO:Initializing create_model()
2024-05-10 14:56:18,694:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dbf1ca0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:56:18,694:INFO:Checking exceptions
2024-05-10 14:56:18,694:INFO:Importing libraries
2024-05-10 14:56:18,694:INFO:Copying training dataset
2024-05-10 14:56:18,698:INFO:Defining folds
2024-05-10 14:56:18,698:INFO:Declaring metric variables
2024-05-10 14:56:18,700:INFO:Importing untrained model
2024-05-10 14:56:18,701:INFO:Declaring custom model
2024-05-10 14:56:18,703:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:56:18,708:INFO:Starting cross validation
2024-05-10 14:56:18,713:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:19,129:INFO:Calculating mean and std
2024-05-10 14:56:19,130:INFO:Creating metrics dataframe
2024-05-10 14:56:19,136:INFO:Finalizing model
2024-05-10 14:56:19,323:INFO:Uploading results into container
2024-05-10 14:56:19,324:INFO:Uploading model into container now
2024-05-10 14:56:19,324:INFO:_master_model_container: 19
2024-05-10 14:56:19,324:INFO:_display_container: 3
2024-05-10 14:56:19,325:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:56:19,325:INFO:create_model() successfully completed......................................
2024-05-10 14:56:19,427:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:19,427:INFO:choose_better activated
2024-05-10 14:56:19,430:INFO:SubProcess create_model() called ==================================
2024-05-10 14:56:19,430:INFO:Initializing create_model()
2024-05-10 14:56:19,430:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:56:19,430:INFO:Checking exceptions
2024-05-10 14:56:19,431:INFO:Importing libraries
2024-05-10 14:56:19,432:INFO:Copying training dataset
2024-05-10 14:56:19,434:INFO:Defining folds
2024-05-10 14:56:19,434:INFO:Declaring metric variables
2024-05-10 14:56:19,434:INFO:Importing untrained model
2024-05-10 14:56:19,434:INFO:Declaring custom model
2024-05-10 14:56:19,434:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:56:19,434:INFO:Starting cross validation
2024-05-10 14:56:19,438:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:56:19,830:INFO:Calculating mean and std
2024-05-10 14:56:19,830:INFO:Creating metrics dataframe
2024-05-10 14:56:19,831:INFO:Finalizing model
2024-05-10 14:56:19,967:INFO:Uploading results into container
2024-05-10 14:56:19,967:INFO:Uploading model into container now
2024-05-10 14:56:19,967:INFO:_master_model_container: 20
2024-05-10 14:56:19,967:INFO:_display_container: 4
2024-05-10 14:56:19,968:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:56:19,968:INFO:create_model() successfully completed......................................
2024-05-10 14:56:20,068:INFO:SubProcess create_model() end ==================================
2024-05-10 14:56:20,068:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7515
2024-05-10 14:56:20,069:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.7231
2024-05-10 14:56:20,069:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:56:20,069:INFO:choose_better completed
2024-05-10 14:56:20,069:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:56:20,074:INFO:_master_model_container: 20
2024-05-10 14:56:20,074:INFO:_display_container: 3
2024-05-10 14:56:20,075:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:56:20,075:INFO:tune_model() successfully completed......................................
2024-05-10 14:56:20,181:INFO:Initializing evaluate_model()
2024-05-10 14:56:20,181:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:56:20,187:INFO:Initializing plot_model()
2024-05-10 14:56:20,188:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, system=True)
2024-05-10 14:56:20,188:INFO:Checking exceptions
2024-05-10 14:56:20,198:INFO:Preloading libraries
2024-05-10 14:56:20,207:INFO:Copying training dataset
2024-05-10 14:56:20,207:INFO:Plot type: pipeline
2024-05-10 14:56:20,285:INFO:Visual Rendered Successfully
2024-05-10 14:56:20,390:INFO:plot_model() successfully completed......................................
2024-05-10 14:56:22,310:INFO:Initializing plot_model()
2024-05-10 14:56:22,311:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, system=True)
2024-05-10 14:56:22,311:INFO:Checking exceptions
2024-05-10 14:56:22,326:INFO:Preloading libraries
2024-05-10 14:56:22,333:INFO:Copying training dataset
2024-05-10 14:56:22,333:INFO:Plot type: residuals
2024-05-10 14:56:22,635:INFO:Fitting Model
2024-05-10 14:56:22,635:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:56:22,678:INFO:Scoring test/hold-out set
2024-05-10 14:56:22,888:INFO:Visual Rendered Successfully
2024-05-10 14:56:22,990:INFO:plot_model() successfully completed......................................
2024-05-10 14:56:26,756:INFO:Initializing plot_model()
2024-05-10 14:56:26,756:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, system=True)
2024-05-10 14:56:26,756:INFO:Checking exceptions
2024-05-10 14:56:26,769:INFO:Preloading libraries
2024-05-10 14:56:26,775:INFO:Copying training dataset
2024-05-10 14:56:26,775:INFO:Plot type: error
2024-05-10 14:56:26,907:INFO:Fitting Model
2024-05-10 14:56:26,907:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:56:26,907:INFO:Scoring test/hold-out set
2024-05-10 14:56:27,030:INFO:Visual Rendered Successfully
2024-05-10 14:56:27,140:INFO:plot_model() successfully completed......................................
2024-05-10 14:56:28,095:INFO:Initializing plot_model()
2024-05-10 14:56:28,095:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d32e9b700>, system=True)
2024-05-10 14:56:28,095:INFO:Checking exceptions
2024-05-10 14:56:28,113:INFO:Preloading libraries
2024-05-10 14:56:28,120:INFO:Copying training dataset
2024-05-10 14:56:28,120:INFO:Plot type: residuals
2024-05-10 14:56:28,261:INFO:Fitting Model
2024-05-10 14:56:28,261:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:56:28,304:INFO:Scoring test/hold-out set
2024-05-10 14:56:28,503:INFO:Visual Rendered Successfully
2024-05-10 14:56:28,602:INFO:plot_model() successfully completed......................................
2024-05-10 14:58:02,289:INFO:PyCaret RegressionExperiment
2024-05-10 14:58:02,289:INFO:Logging name: reg-default-name
2024-05-10 14:58:02,289:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:58:02,289:INFO:version 3.3.2
2024-05-10 14:58:02,289:INFO:Initializing setup()
2024-05-10 14:58:02,289:INFO:self.USI: ea3a
2024-05-10 14:58:02,289:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 14:58:02,289:INFO:Checking environment
2024-05-10 14:58:02,289:INFO:python_version: 3.9.18
2024-05-10 14:58:02,289:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:58:02,289:INFO:machine: x86_64
2024-05-10 14:58:02,289:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:58:02,289:INFO:Memory: svmem(total=16429797376, available=5843836928, percent=64.4, used=9484713984, free=3718918144, active=6926839808, inactive=4378451968, buffers=169955328, cached=3056209920, shared=754700288, slab=739598336)
2024-05-10 14:58:02,290:INFO:Physical Core: 12
2024-05-10 14:58:02,290:INFO:Logical Core: 16
2024-05-10 14:58:02,290:INFO:Checking libraries
2024-05-10 14:58:02,290:INFO:System:
2024-05-10 14:58:02,290:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:58:02,290:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:58:02,290:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:58:02,290:INFO:PyCaret required dependencies:
2024-05-10 14:58:02,290:INFO:                 pip: 23.3.1
2024-05-10 14:58:02,290:INFO:          setuptools: 68.2.2
2024-05-10 14:58:02,290:INFO:             pycaret: 3.3.2
2024-05-10 14:58:02,290:INFO:             IPython: 8.15.0
2024-05-10 14:58:02,290:INFO:          ipywidgets: 7.6.5
2024-05-10 14:58:02,290:INFO:                tqdm: 4.65.0
2024-05-10 14:58:02,290:INFO:               numpy: 1.26.4
2024-05-10 14:58:02,290:INFO:              pandas: 2.1.4
2024-05-10 14:58:02,290:INFO:              jinja2: 3.1.3
2024-05-10 14:58:02,290:INFO:               scipy: 1.11.4
2024-05-10 14:58:02,290:INFO:              joblib: 1.2.0
2024-05-10 14:58:02,290:INFO:             sklearn: 1.4.2
2024-05-10 14:58:02,290:INFO:                pyod: 1.1.3
2024-05-10 14:58:02,290:INFO:            imblearn: 0.12.2
2024-05-10 14:58:02,290:INFO:   category_encoders: 2.6.3
2024-05-10 14:58:02,290:INFO:            lightgbm: 4.3.0
2024-05-10 14:58:02,290:INFO:               numba: 0.59.1
2024-05-10 14:58:02,290:INFO:            requests: 2.31.0
2024-05-10 14:58:02,290:INFO:          matplotlib: 3.7.5
2024-05-10 14:58:02,290:INFO:          scikitplot: 0.3.7
2024-05-10 14:58:02,290:INFO:         yellowbrick: 1.5
2024-05-10 14:58:02,290:INFO:              plotly: 5.19.0
2024-05-10 14:58:02,290:INFO:    plotly-resampler: Not installed
2024-05-10 14:58:02,290:INFO:             kaleido: 0.2.1
2024-05-10 14:58:02,290:INFO:           schemdraw: 0.15
2024-05-10 14:58:02,290:INFO:         statsmodels: 0.14.0
2024-05-10 14:58:02,290:INFO:              sktime: 0.26.0
2024-05-10 14:58:02,290:INFO:               tbats: 1.1.3
2024-05-10 14:58:02,290:INFO:            pmdarima: 2.0.4
2024-05-10 14:58:02,290:INFO:              psutil: 5.9.0
2024-05-10 14:58:02,290:INFO:          markupsafe: 2.1.3
2024-05-10 14:58:02,290:INFO:             pickle5: Not installed
2024-05-10 14:58:02,290:INFO:         cloudpickle: 2.2.1
2024-05-10 14:58:02,290:INFO:         deprecation: 2.1.0
2024-05-10 14:58:02,290:INFO:              xxhash: 3.4.1
2024-05-10 14:58:02,290:INFO:           wurlitzer: 3.0.2
2024-05-10 14:58:02,290:INFO:PyCaret optional dependencies:
2024-05-10 14:58:02,290:INFO:                shap: Not installed
2024-05-10 14:58:02,290:INFO:           interpret: Not installed
2024-05-10 14:58:02,290:INFO:                umap: Not installed
2024-05-10 14:58:02,290:INFO:     ydata_profiling: Not installed
2024-05-10 14:58:02,290:INFO:  explainerdashboard: Not installed
2024-05-10 14:58:02,290:INFO:             autoviz: Not installed
2024-05-10 14:58:02,290:INFO:           fairlearn: Not installed
2024-05-10 14:58:02,291:INFO:          deepchecks: Not installed
2024-05-10 14:58:02,291:INFO:             xgboost: Not installed
2024-05-10 14:58:02,291:INFO:            catboost: Not installed
2024-05-10 14:58:02,291:INFO:              kmodes: Not installed
2024-05-10 14:58:02,291:INFO:             mlxtend: Not installed
2024-05-10 14:58:02,291:INFO:       statsforecast: Not installed
2024-05-10 14:58:02,291:INFO:        tune_sklearn: Not installed
2024-05-10 14:58:02,291:INFO:                 ray: Not installed
2024-05-10 14:58:02,291:INFO:            hyperopt: Not installed
2024-05-10 14:58:02,291:INFO:              optuna: Not installed
2024-05-10 14:58:02,291:INFO:               skopt: Not installed
2024-05-10 14:58:02,291:INFO:              mlflow: Not installed
2024-05-10 14:58:02,291:INFO:              gradio: Not installed
2024-05-10 14:58:02,291:INFO:             fastapi: Not installed
2024-05-10 14:58:02,291:INFO:             uvicorn: Not installed
2024-05-10 14:58:02,291:INFO:              m2cgen: Not installed
2024-05-10 14:58:02,291:INFO:           evidently: Not installed
2024-05-10 14:58:02,291:INFO:               fugue: Not installed
2024-05-10 14:58:02,291:INFO:           streamlit: 1.32.0
2024-05-10 14:58:02,291:INFO:             prophet: Not installed
2024-05-10 14:58:02,291:INFO:None
2024-05-10 14:58:02,291:INFO:Set up data.
2024-05-10 14:58:02,294:INFO:Set up folding strategy.
2024-05-10 14:58:02,294:INFO:Set up train/test split.
2024-05-10 14:58:02,296:INFO:Set up index.
2024-05-10 14:58:02,296:INFO:Assigning column types.
2024-05-10 14:58:02,298:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:58:02,298:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,300:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,302:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,327:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,346:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,346:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,346:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,348:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,350:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,375:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,393:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,394:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,394:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:58:02,396:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,398:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,423:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,442:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,445:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,447:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,472:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,491:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,491:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,491:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:58:02,495:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,521:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,540:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,544:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,570:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,590:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,591:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:58:02,620:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,640:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,641:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,670:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,688:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,689:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,689:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,689:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:58:02,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,737:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:02,784:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,784:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,784:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:58:02,831:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,879:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,879:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:02,880:INFO:Preparing preprocessing pipeline...
2024-05-10 14:58:02,880:INFO:Set up simple imputation.
2024-05-10 14:58:02,880:INFO:Set up polynomial features.
2024-05-10 14:58:02,880:INFO:Set up removing outliers.
2024-05-10 14:58:02,880:INFO:Set up feature normalization.
2024-05-10 14:58:02,881:INFO:Set up column name cleaning.
2024-05-10 14:58:02,969:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:58:02,972:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_temperature(C)',
                                             'average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:58:02,972:INFO:Creating final display dataframe.
2024-05-10 14:58:03,302:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 6)
4        Transformed data shape         (579, 21)
5   Transformed train set shape         (399, 21)
6    Transformed test set shape         (180, 21)
7              Numeric features                 5
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              ea3a
2024-05-10 14:58:03,357:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:03,357:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:03,407:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:03,407:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:03,407:INFO:setup() successfully completed in 1.12s...............
2024-05-10 14:58:03,407:INFO:Initializing compare_models()
2024-05-10 14:58:03,407:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:58:03,407:INFO:Checking exceptions
2024-05-10 14:58:03,408:INFO:Preparing display monitor
2024-05-10 14:58:03,422:INFO:Initializing Linear Regression
2024-05-10 14:58:03,422:INFO:Total runtime is 2.400080362955729e-06 minutes
2024-05-10 14:58:03,424:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:03,424:INFO:Initializing create_model()
2024-05-10 14:58:03,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:03,425:INFO:Checking exceptions
2024-05-10 14:58:03,425:INFO:Importing libraries
2024-05-10 14:58:03,425:INFO:Copying training dataset
2024-05-10 14:58:03,427:INFO:Defining folds
2024-05-10 14:58:03,427:INFO:Declaring metric variables
2024-05-10 14:58:03,429:INFO:Importing untrained model
2024-05-10 14:58:03,431:INFO:Linear Regression Imported successfully
2024-05-10 14:58:03,435:INFO:Starting cross validation
2024-05-10 14:58:03,445:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:03,654:INFO:Calculating mean and std
2024-05-10 14:58:03,655:INFO:Creating metrics dataframe
2024-05-10 14:58:03,656:INFO:Uploading results into container
2024-05-10 14:58:03,656:INFO:Uploading model into container now
2024-05-10 14:58:03,656:INFO:_master_model_container: 1
2024-05-10 14:58:03,656:INFO:_display_container: 2
2024-05-10 14:58:03,657:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:58:03,657:INFO:create_model() successfully completed......................................
2024-05-10 14:58:03,760:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:03,760:INFO:Creating metrics dataframe
2024-05-10 14:58:03,764:INFO:Initializing Lasso Regression
2024-05-10 14:58:03,764:INFO:Total runtime is 0.005695835749308268 minutes
2024-05-10 14:58:03,766:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:03,766:INFO:Initializing create_model()
2024-05-10 14:58:03,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:03,767:INFO:Checking exceptions
2024-05-10 14:58:03,767:INFO:Importing libraries
2024-05-10 14:58:03,767:INFO:Copying training dataset
2024-05-10 14:58:03,769:INFO:Defining folds
2024-05-10 14:58:03,769:INFO:Declaring metric variables
2024-05-10 14:58:03,771:INFO:Importing untrained model
2024-05-10 14:58:03,772:INFO:Lasso Regression Imported successfully
2024-05-10 14:58:03,776:INFO:Starting cross validation
2024-05-10 14:58:03,781:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:03,965:INFO:Calculating mean and std
2024-05-10 14:58:03,966:INFO:Creating metrics dataframe
2024-05-10 14:58:03,967:INFO:Uploading results into container
2024-05-10 14:58:03,967:INFO:Uploading model into container now
2024-05-10 14:58:03,968:INFO:_master_model_container: 2
2024-05-10 14:58:03,968:INFO:_display_container: 2
2024-05-10 14:58:03,968:INFO:Lasso(random_state=123)
2024-05-10 14:58:03,968:INFO:create_model() successfully completed......................................
2024-05-10 14:58:04,074:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:04,075:INFO:Creating metrics dataframe
2024-05-10 14:58:04,079:INFO:Initializing Ridge Regression
2024-05-10 14:58:04,079:INFO:Total runtime is 0.010952381292978923 minutes
2024-05-10 14:58:04,082:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:04,082:INFO:Initializing create_model()
2024-05-10 14:58:04,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:04,082:INFO:Checking exceptions
2024-05-10 14:58:04,082:INFO:Importing libraries
2024-05-10 14:58:04,082:INFO:Copying training dataset
2024-05-10 14:58:04,086:INFO:Defining folds
2024-05-10 14:58:04,086:INFO:Declaring metric variables
2024-05-10 14:58:04,088:INFO:Importing untrained model
2024-05-10 14:58:04,090:INFO:Ridge Regression Imported successfully
2024-05-10 14:58:04,093:INFO:Starting cross validation
2024-05-10 14:58:04,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:04,284:INFO:Calculating mean and std
2024-05-10 14:58:04,284:INFO:Creating metrics dataframe
2024-05-10 14:58:04,286:INFO:Uploading results into container
2024-05-10 14:58:04,286:INFO:Uploading model into container now
2024-05-10 14:58:04,286:INFO:_master_model_container: 3
2024-05-10 14:58:04,286:INFO:_display_container: 2
2024-05-10 14:58:04,286:INFO:Ridge(random_state=123)
2024-05-10 14:58:04,286:INFO:create_model() successfully completed......................................
2024-05-10 14:58:04,389:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:04,389:INFO:Creating metrics dataframe
2024-05-10 14:58:04,393:INFO:Initializing Elastic Net
2024-05-10 14:58:04,393:INFO:Total runtime is 0.01618340015411377 minutes
2024-05-10 14:58:04,395:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:04,395:INFO:Initializing create_model()
2024-05-10 14:58:04,395:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:04,395:INFO:Checking exceptions
2024-05-10 14:58:04,395:INFO:Importing libraries
2024-05-10 14:58:04,395:INFO:Copying training dataset
2024-05-10 14:58:04,398:INFO:Defining folds
2024-05-10 14:58:04,398:INFO:Declaring metric variables
2024-05-10 14:58:04,400:INFO:Importing untrained model
2024-05-10 14:58:04,401:INFO:Elastic Net Imported successfully
2024-05-10 14:58:04,405:INFO:Starting cross validation
2024-05-10 14:58:04,409:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:04,603:INFO:Calculating mean and std
2024-05-10 14:58:04,604:INFO:Creating metrics dataframe
2024-05-10 14:58:04,605:INFO:Uploading results into container
2024-05-10 14:58:04,605:INFO:Uploading model into container now
2024-05-10 14:58:04,605:INFO:_master_model_container: 4
2024-05-10 14:58:04,605:INFO:_display_container: 2
2024-05-10 14:58:04,606:INFO:ElasticNet(random_state=123)
2024-05-10 14:58:04,606:INFO:create_model() successfully completed......................................
2024-05-10 14:58:04,708:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:04,708:INFO:Creating metrics dataframe
2024-05-10 14:58:04,712:INFO:Initializing Least Angle Regression
2024-05-10 14:58:04,712:INFO:Total runtime is 0.021498815218607588 minutes
2024-05-10 14:58:04,714:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:04,714:INFO:Initializing create_model()
2024-05-10 14:58:04,715:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:04,715:INFO:Checking exceptions
2024-05-10 14:58:04,715:INFO:Importing libraries
2024-05-10 14:58:04,715:INFO:Copying training dataset
2024-05-10 14:58:04,717:INFO:Defining folds
2024-05-10 14:58:04,718:INFO:Declaring metric variables
2024-05-10 14:58:04,719:INFO:Importing untrained model
2024-05-10 14:58:04,722:INFO:Least Angle Regression Imported successfully
2024-05-10 14:58:04,725:INFO:Starting cross validation
2024-05-10 14:58:04,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:04,918:INFO:Calculating mean and std
2024-05-10 14:58:04,918:INFO:Creating metrics dataframe
2024-05-10 14:58:04,920:INFO:Uploading results into container
2024-05-10 14:58:04,920:INFO:Uploading model into container now
2024-05-10 14:58:04,920:INFO:_master_model_container: 5
2024-05-10 14:58:04,920:INFO:_display_container: 2
2024-05-10 14:58:04,921:INFO:Lars(random_state=123)
2024-05-10 14:58:04,921:INFO:create_model() successfully completed......................................
2024-05-10 14:58:05,023:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:05,023:INFO:Creating metrics dataframe
2024-05-10 14:58:05,028:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:58:05,028:INFO:Total runtime is 0.02676593065261841 minutes
2024-05-10 14:58:05,030:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:05,031:INFO:Initializing create_model()
2024-05-10 14:58:05,031:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:05,031:INFO:Checking exceptions
2024-05-10 14:58:05,031:INFO:Importing libraries
2024-05-10 14:58:05,031:INFO:Copying training dataset
2024-05-10 14:58:05,036:INFO:Defining folds
2024-05-10 14:58:05,036:INFO:Declaring metric variables
2024-05-10 14:58:05,038:INFO:Importing untrained model
2024-05-10 14:58:05,040:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:58:05,045:INFO:Starting cross validation
2024-05-10 14:58:05,052:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:05,237:INFO:Calculating mean and std
2024-05-10 14:58:05,237:INFO:Creating metrics dataframe
2024-05-10 14:58:05,238:INFO:Uploading results into container
2024-05-10 14:58:05,239:INFO:Uploading model into container now
2024-05-10 14:58:05,239:INFO:_master_model_container: 6
2024-05-10 14:58:05,239:INFO:_display_container: 2
2024-05-10 14:58:05,239:INFO:LassoLars(random_state=123)
2024-05-10 14:58:05,239:INFO:create_model() successfully completed......................................
2024-05-10 14:58:05,340:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:05,340:INFO:Creating metrics dataframe
2024-05-10 14:58:05,345:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:58:05,345:INFO:Total runtime is 0.03204351266225179 minutes
2024-05-10 14:58:05,347:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:05,347:INFO:Initializing create_model()
2024-05-10 14:58:05,347:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:05,347:INFO:Checking exceptions
2024-05-10 14:58:05,347:INFO:Importing libraries
2024-05-10 14:58:05,347:INFO:Copying training dataset
2024-05-10 14:58:05,350:INFO:Defining folds
2024-05-10 14:58:05,350:INFO:Declaring metric variables
2024-05-10 14:58:05,352:INFO:Importing untrained model
2024-05-10 14:58:05,354:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:58:05,357:INFO:Starting cross validation
2024-05-10 14:58:05,361:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:05,556:INFO:Calculating mean and std
2024-05-10 14:58:05,557:INFO:Creating metrics dataframe
2024-05-10 14:58:05,558:INFO:Uploading results into container
2024-05-10 14:58:05,558:INFO:Uploading model into container now
2024-05-10 14:58:05,558:INFO:_master_model_container: 7
2024-05-10 14:58:05,559:INFO:_display_container: 2
2024-05-10 14:58:05,559:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:58:05,559:INFO:create_model() successfully completed......................................
2024-05-10 14:58:05,664:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:05,665:INFO:Creating metrics dataframe
2024-05-10 14:58:05,670:INFO:Initializing Bayesian Ridge
2024-05-10 14:58:05,670:INFO:Total runtime is 0.03745424747467041 minutes
2024-05-10 14:58:05,672:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:05,672:INFO:Initializing create_model()
2024-05-10 14:58:05,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:05,672:INFO:Checking exceptions
2024-05-10 14:58:05,672:INFO:Importing libraries
2024-05-10 14:58:05,672:INFO:Copying training dataset
2024-05-10 14:58:05,674:INFO:Defining folds
2024-05-10 14:58:05,674:INFO:Declaring metric variables
2024-05-10 14:58:05,676:INFO:Importing untrained model
2024-05-10 14:58:05,678:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:58:05,682:INFO:Starting cross validation
2024-05-10 14:58:05,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:05,871:INFO:Calculating mean and std
2024-05-10 14:58:05,872:INFO:Creating metrics dataframe
2024-05-10 14:58:05,873:INFO:Uploading results into container
2024-05-10 14:58:05,873:INFO:Uploading model into container now
2024-05-10 14:58:05,874:INFO:_master_model_container: 8
2024-05-10 14:58:05,874:INFO:_display_container: 2
2024-05-10 14:58:05,874:INFO:BayesianRidge()
2024-05-10 14:58:05,874:INFO:create_model() successfully completed......................................
2024-05-10 14:58:05,976:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:05,976:INFO:Creating metrics dataframe
2024-05-10 14:58:05,981:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:58:05,981:INFO:Total runtime is 0.0426422913869222 minutes
2024-05-10 14:58:05,983:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:05,983:INFO:Initializing create_model()
2024-05-10 14:58:05,983:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:05,983:INFO:Checking exceptions
2024-05-10 14:58:05,983:INFO:Importing libraries
2024-05-10 14:58:05,983:INFO:Copying training dataset
2024-05-10 14:58:05,986:INFO:Defining folds
2024-05-10 14:58:05,986:INFO:Declaring metric variables
2024-05-10 14:58:05,988:INFO:Importing untrained model
2024-05-10 14:58:05,990:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:58:05,993:INFO:Starting cross validation
2024-05-10 14:58:05,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:06,201:INFO:Calculating mean and std
2024-05-10 14:58:06,202:INFO:Creating metrics dataframe
2024-05-10 14:58:06,204:INFO:Uploading results into container
2024-05-10 14:58:06,204:INFO:Uploading model into container now
2024-05-10 14:58:06,205:INFO:_master_model_container: 9
2024-05-10 14:58:06,205:INFO:_display_container: 2
2024-05-10 14:58:06,205:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:58:06,205:INFO:create_model() successfully completed......................................
2024-05-10 14:58:06,308:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:06,308:INFO:Creating metrics dataframe
2024-05-10 14:58:06,313:INFO:Initializing Huber Regressor
2024-05-10 14:58:06,313:INFO:Total runtime is 0.04817517201105754 minutes
2024-05-10 14:58:06,315:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:06,315:INFO:Initializing create_model()
2024-05-10 14:58:06,315:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:06,315:INFO:Checking exceptions
2024-05-10 14:58:06,315:INFO:Importing libraries
2024-05-10 14:58:06,315:INFO:Copying training dataset
2024-05-10 14:58:06,318:INFO:Defining folds
2024-05-10 14:58:06,318:INFO:Declaring metric variables
2024-05-10 14:58:06,320:INFO:Importing untrained model
2024-05-10 14:58:06,322:INFO:Huber Regressor Imported successfully
2024-05-10 14:58:06,328:INFO:Starting cross validation
2024-05-10 14:58:06,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:06,459:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,464:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,471:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,505:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,512:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,515:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,526:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,532:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,539:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,540:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:06,547:INFO:Calculating mean and std
2024-05-10 14:58:06,548:INFO:Creating metrics dataframe
2024-05-10 14:58:06,550:INFO:Uploading results into container
2024-05-10 14:58:06,550:INFO:Uploading model into container now
2024-05-10 14:58:06,551:INFO:_master_model_container: 10
2024-05-10 14:58:06,551:INFO:_display_container: 2
2024-05-10 14:58:06,551:INFO:HuberRegressor()
2024-05-10 14:58:06,551:INFO:create_model() successfully completed......................................
2024-05-10 14:58:06,653:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:06,653:INFO:Creating metrics dataframe
2024-05-10 14:58:06,658:INFO:Initializing K Neighbors Regressor
2024-05-10 14:58:06,658:INFO:Total runtime is 0.053933187325795495 minutes
2024-05-10 14:58:06,660:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:06,660:INFO:Initializing create_model()
2024-05-10 14:58:06,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:06,661:INFO:Checking exceptions
2024-05-10 14:58:06,661:INFO:Importing libraries
2024-05-10 14:58:06,661:INFO:Copying training dataset
2024-05-10 14:58:06,664:INFO:Defining folds
2024-05-10 14:58:06,664:INFO:Declaring metric variables
2024-05-10 14:58:06,666:INFO:Importing untrained model
2024-05-10 14:58:06,668:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:58:06,672:INFO:Starting cross validation
2024-05-10 14:58:06,676:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:06,866:INFO:Calculating mean and std
2024-05-10 14:58:06,867:INFO:Creating metrics dataframe
2024-05-10 14:58:06,869:INFO:Uploading results into container
2024-05-10 14:58:06,869:INFO:Uploading model into container now
2024-05-10 14:58:06,869:INFO:_master_model_container: 11
2024-05-10 14:58:06,869:INFO:_display_container: 2
2024-05-10 14:58:06,870:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:58:06,870:INFO:create_model() successfully completed......................................
2024-05-10 14:58:06,972:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:06,972:INFO:Creating metrics dataframe
2024-05-10 14:58:06,977:INFO:Initializing Decision Tree Regressor
2024-05-10 14:58:06,977:INFO:Total runtime is 0.05924563010533651 minutes
2024-05-10 14:58:06,979:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:06,979:INFO:Initializing create_model()
2024-05-10 14:58:06,979:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:06,980:INFO:Checking exceptions
2024-05-10 14:58:06,980:INFO:Importing libraries
2024-05-10 14:58:06,980:INFO:Copying training dataset
2024-05-10 14:58:06,984:INFO:Defining folds
2024-05-10 14:58:06,984:INFO:Declaring metric variables
2024-05-10 14:58:06,986:INFO:Importing untrained model
2024-05-10 14:58:06,988:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:58:06,992:INFO:Starting cross validation
2024-05-10 14:58:06,998:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:07,191:INFO:Calculating mean and std
2024-05-10 14:58:07,192:INFO:Creating metrics dataframe
2024-05-10 14:58:07,193:INFO:Uploading results into container
2024-05-10 14:58:07,193:INFO:Uploading model into container now
2024-05-10 14:58:07,194:INFO:_master_model_container: 12
2024-05-10 14:58:07,194:INFO:_display_container: 2
2024-05-10 14:58:07,194:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:58:07,194:INFO:create_model() successfully completed......................................
2024-05-10 14:58:07,298:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:07,298:INFO:Creating metrics dataframe
2024-05-10 14:58:07,303:INFO:Initializing Random Forest Regressor
2024-05-10 14:58:07,303:INFO:Total runtime is 0.0646816611289978 minutes
2024-05-10 14:58:07,305:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:07,305:INFO:Initializing create_model()
2024-05-10 14:58:07,305:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:07,305:INFO:Checking exceptions
2024-05-10 14:58:07,305:INFO:Importing libraries
2024-05-10 14:58:07,306:INFO:Copying training dataset
2024-05-10 14:58:07,308:INFO:Defining folds
2024-05-10 14:58:07,308:INFO:Declaring metric variables
2024-05-10 14:58:07,310:INFO:Importing untrained model
2024-05-10 14:58:07,312:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:58:07,318:INFO:Starting cross validation
2024-05-10 14:58:07,322:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:07,899:INFO:Calculating mean and std
2024-05-10 14:58:07,899:INFO:Creating metrics dataframe
2024-05-10 14:58:07,901:INFO:Uploading results into container
2024-05-10 14:58:07,901:INFO:Uploading model into container now
2024-05-10 14:58:07,901:INFO:_master_model_container: 13
2024-05-10 14:58:07,901:INFO:_display_container: 2
2024-05-10 14:58:07,902:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:07,902:INFO:create_model() successfully completed......................................
2024-05-10 14:58:08,001:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:08,001:INFO:Creating metrics dataframe
2024-05-10 14:58:08,006:INFO:Initializing Extra Trees Regressor
2024-05-10 14:58:08,006:INFO:Total runtime is 0.07640130122502645 minutes
2024-05-10 14:58:08,009:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:08,009:INFO:Initializing create_model()
2024-05-10 14:58:08,009:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:08,009:INFO:Checking exceptions
2024-05-10 14:58:08,009:INFO:Importing libraries
2024-05-10 14:58:08,009:INFO:Copying training dataset
2024-05-10 14:58:08,012:INFO:Defining folds
2024-05-10 14:58:08,012:INFO:Declaring metric variables
2024-05-10 14:58:08,014:INFO:Importing untrained model
2024-05-10 14:58:08,016:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:58:08,020:INFO:Starting cross validation
2024-05-10 14:58:08,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:08,392:INFO:Calculating mean and std
2024-05-10 14:58:08,393:INFO:Creating metrics dataframe
2024-05-10 14:58:08,395:INFO:Uploading results into container
2024-05-10 14:58:08,396:INFO:Uploading model into container now
2024-05-10 14:58:08,396:INFO:_master_model_container: 14
2024-05-10 14:58:08,396:INFO:_display_container: 2
2024-05-10 14:58:08,396:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:08,396:INFO:create_model() successfully completed......................................
2024-05-10 14:58:08,500:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:08,500:INFO:Creating metrics dataframe
2024-05-10 14:58:08,506:INFO:Initializing AdaBoost Regressor
2024-05-10 14:58:08,506:INFO:Total runtime is 0.08472675085067749 minutes
2024-05-10 14:58:08,508:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:08,508:INFO:Initializing create_model()
2024-05-10 14:58:08,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:08,508:INFO:Checking exceptions
2024-05-10 14:58:08,508:INFO:Importing libraries
2024-05-10 14:58:08,508:INFO:Copying training dataset
2024-05-10 14:58:08,511:INFO:Defining folds
2024-05-10 14:58:08,511:INFO:Declaring metric variables
2024-05-10 14:58:08,513:INFO:Importing untrained model
2024-05-10 14:58:08,516:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:58:08,520:INFO:Starting cross validation
2024-05-10 14:58:08,524:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:08,844:INFO:Calculating mean and std
2024-05-10 14:58:08,844:INFO:Creating metrics dataframe
2024-05-10 14:58:08,845:INFO:Uploading results into container
2024-05-10 14:58:08,846:INFO:Uploading model into container now
2024-05-10 14:58:08,846:INFO:_master_model_container: 15
2024-05-10 14:58:08,846:INFO:_display_container: 2
2024-05-10 14:58:08,847:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:58:08,847:INFO:create_model() successfully completed......................................
2024-05-10 14:58:08,948:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:08,948:INFO:Creating metrics dataframe
2024-05-10 14:58:08,954:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:58:08,954:INFO:Total runtime is 0.09218990405400594 minutes
2024-05-10 14:58:08,955:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:08,956:INFO:Initializing create_model()
2024-05-10 14:58:08,956:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:08,956:INFO:Checking exceptions
2024-05-10 14:58:08,956:INFO:Importing libraries
2024-05-10 14:58:08,956:INFO:Copying training dataset
2024-05-10 14:58:08,958:INFO:Defining folds
2024-05-10 14:58:08,958:INFO:Declaring metric variables
2024-05-10 14:58:08,960:INFO:Importing untrained model
2024-05-10 14:58:08,962:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:58:08,966:INFO:Starting cross validation
2024-05-10 14:58:08,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:09,446:INFO:Calculating mean and std
2024-05-10 14:58:09,447:INFO:Creating metrics dataframe
2024-05-10 14:58:09,448:INFO:Uploading results into container
2024-05-10 14:58:09,449:INFO:Uploading model into container now
2024-05-10 14:58:09,449:INFO:_master_model_container: 16
2024-05-10 14:58:09,449:INFO:_display_container: 2
2024-05-10 14:58:09,450:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:58:09,450:INFO:create_model() successfully completed......................................
2024-05-10 14:58:09,548:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:09,548:INFO:Creating metrics dataframe
2024-05-10 14:58:09,553:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:58:09,554:INFO:Total runtime is 0.10218632221221924 minutes
2024-05-10 14:58:09,555:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:09,556:INFO:Initializing create_model()
2024-05-10 14:58:09,556:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:09,556:INFO:Checking exceptions
2024-05-10 14:58:09,556:INFO:Importing libraries
2024-05-10 14:58:09,556:INFO:Copying training dataset
2024-05-10 14:58:09,558:INFO:Defining folds
2024-05-10 14:58:09,558:INFO:Declaring metric variables
2024-05-10 14:58:09,560:INFO:Importing untrained model
2024-05-10 14:58:09,563:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:58:09,570:INFO:Starting cross validation
2024-05-10 14:58:09,577:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:10,344:INFO:Calculating mean and std
2024-05-10 14:58:10,345:INFO:Creating metrics dataframe
2024-05-10 14:58:10,347:INFO:Uploading results into container
2024-05-10 14:58:10,348:INFO:Uploading model into container now
2024-05-10 14:58:10,348:INFO:_master_model_container: 17
2024-05-10 14:58:10,349:INFO:_display_container: 2
2024-05-10 14:58:10,349:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:10,349:INFO:create_model() successfully completed......................................
2024-05-10 14:58:10,453:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:10,454:INFO:Creating metrics dataframe
2024-05-10 14:58:10,459:INFO:Initializing Dummy Regressor
2024-05-10 14:58:10,460:INFO:Total runtime is 0.11728891928990681 minutes
2024-05-10 14:58:10,462:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:10,462:INFO:Initializing create_model()
2024-05-10 14:58:10,463:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31731df0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:10,463:INFO:Checking exceptions
2024-05-10 14:58:10,463:INFO:Importing libraries
2024-05-10 14:58:10,463:INFO:Copying training dataset
2024-05-10 14:58:10,467:INFO:Defining folds
2024-05-10 14:58:10,468:INFO:Declaring metric variables
2024-05-10 14:58:10,470:INFO:Importing untrained model
2024-05-10 14:58:10,474:INFO:Dummy Regressor Imported successfully
2024-05-10 14:58:10,479:INFO:Starting cross validation
2024-05-10 14:58:10,488:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:10,669:INFO:Calculating mean and std
2024-05-10 14:58:10,670:INFO:Creating metrics dataframe
2024-05-10 14:58:10,672:INFO:Uploading results into container
2024-05-10 14:58:10,672:INFO:Uploading model into container now
2024-05-10 14:58:10,673:INFO:_master_model_container: 18
2024-05-10 14:58:10,673:INFO:_display_container: 2
2024-05-10 14:58:10,673:INFO:DummyRegressor()
2024-05-10 14:58:10,673:INFO:create_model() successfully completed......................................
2024-05-10 14:58:10,774:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:10,774:INFO:Creating metrics dataframe
2024-05-10 14:58:10,780:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:58:10,785:INFO:Initializing create_model()
2024-05-10 14:58:10,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:10,785:INFO:Checking exceptions
2024-05-10 14:58:10,786:INFO:Importing libraries
2024-05-10 14:58:10,786:INFO:Copying training dataset
2024-05-10 14:58:10,788:INFO:Defining folds
2024-05-10 14:58:10,788:INFO:Declaring metric variables
2024-05-10 14:58:10,788:INFO:Importing untrained model
2024-05-10 14:58:10,788:INFO:Declaring custom model
2024-05-10 14:58:10,789:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:58:10,793:INFO:Cross validation set to False
2024-05-10 14:58:10,793:INFO:Fitting Model
2024-05-10 14:58:10,927:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:10,927:INFO:create_model() successfully completed......................................
2024-05-10 14:58:11,051:INFO:_master_model_container: 18
2024-05-10 14:58:11,051:INFO:_display_container: 2
2024-05-10 14:58:11,052:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:11,052:INFO:compare_models() successfully completed......................................
2024-05-10 14:58:11,052:INFO:Initializing tune_model()
2024-05-10 14:58:11,052:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>)
2024-05-10 14:58:11,052:INFO:Checking exceptions
2024-05-10 14:58:11,061:INFO:Copying training dataset
2024-05-10 14:58:11,063:INFO:Checking base model
2024-05-10 14:58:11,063:INFO:Base model : Extra Trees Regressor
2024-05-10 14:58:11,065:INFO:Declaring metric variables
2024-05-10 14:58:11,067:INFO:Defining Hyperparameters
2024-05-10 14:58:11,195:INFO:Tuning with n_jobs=-1
2024-05-10 14:58:11,195:INFO:Initializing RandomizedSearchCV
2024-05-10 14:58:14,315:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:58:14,316:INFO:Hyperparameter search completed
2024-05-10 14:58:14,316:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:14,316:INFO:Initializing create_model()
2024-05-10 14:58:14,317:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd237f0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:58:14,317:INFO:Checking exceptions
2024-05-10 14:58:14,317:INFO:Importing libraries
2024-05-10 14:58:14,317:INFO:Copying training dataset
2024-05-10 14:58:14,320:INFO:Defining folds
2024-05-10 14:58:14,320:INFO:Declaring metric variables
2024-05-10 14:58:14,322:INFO:Importing untrained model
2024-05-10 14:58:14,323:INFO:Declaring custom model
2024-05-10 14:58:14,326:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:58:14,329:INFO:Starting cross validation
2024-05-10 14:58:14,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:14,742:INFO:Calculating mean and std
2024-05-10 14:58:14,743:INFO:Creating metrics dataframe
2024-05-10 14:58:14,746:INFO:Finalizing model
2024-05-10 14:58:14,929:INFO:Uploading results into container
2024-05-10 14:58:14,929:INFO:Uploading model into container now
2024-05-10 14:58:14,930:INFO:_master_model_container: 19
2024-05-10 14:58:14,930:INFO:_display_container: 3
2024-05-10 14:58:14,930:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:58:14,930:INFO:create_model() successfully completed......................................
2024-05-10 14:58:15,032:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:15,032:INFO:choose_better activated
2024-05-10 14:58:15,035:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:15,035:INFO:Initializing create_model()
2024-05-10 14:58:15,035:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:15,035:INFO:Checking exceptions
2024-05-10 14:58:15,036:INFO:Importing libraries
2024-05-10 14:58:15,036:INFO:Copying training dataset
2024-05-10 14:58:15,038:INFO:Defining folds
2024-05-10 14:58:15,038:INFO:Declaring metric variables
2024-05-10 14:58:15,038:INFO:Importing untrained model
2024-05-10 14:58:15,038:INFO:Declaring custom model
2024-05-10 14:58:15,038:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:58:15,038:INFO:Starting cross validation
2024-05-10 14:58:15,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:15,406:INFO:Calculating mean and std
2024-05-10 14:58:15,406:INFO:Creating metrics dataframe
2024-05-10 14:58:15,407:INFO:Finalizing model
2024-05-10 14:58:15,544:INFO:Uploading results into container
2024-05-10 14:58:15,545:INFO:Uploading model into container now
2024-05-10 14:58:15,545:INFO:_master_model_container: 20
2024-05-10 14:58:15,545:INFO:_display_container: 4
2024-05-10 14:58:15,546:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:15,546:INFO:create_model() successfully completed......................................
2024-05-10 14:58:15,648:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:15,649:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7472
2024-05-10 14:58:15,649:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.717
2024-05-10 14:58:15,649:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:58:15,649:INFO:choose_better completed
2024-05-10 14:58:15,649:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:58:15,656:INFO:_master_model_container: 20
2024-05-10 14:58:15,656:INFO:_display_container: 3
2024-05-10 14:58:15,657:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:15,657:INFO:tune_model() successfully completed......................................
2024-05-10 14:58:15,762:INFO:Initializing evaluate_model()
2024-05-10 14:58:15,763:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:58:15,769:INFO:Initializing plot_model()
2024-05-10 14:58:15,769:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, system=True)
2024-05-10 14:58:15,769:INFO:Checking exceptions
2024-05-10 14:58:15,780:INFO:Preloading libraries
2024-05-10 14:58:15,786:INFO:Copying training dataset
2024-05-10 14:58:15,786:INFO:Plot type: pipeline
2024-05-10 14:58:15,874:INFO:Visual Rendered Successfully
2024-05-10 14:58:15,980:INFO:plot_model() successfully completed......................................
2024-05-10 14:58:18,840:INFO:Initializing plot_model()
2024-05-10 14:58:18,841:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, system=True)
2024-05-10 14:58:18,841:INFO:Checking exceptions
2024-05-10 14:58:18,852:INFO:Preloading libraries
2024-05-10 14:58:18,857:INFO:Copying training dataset
2024-05-10 14:58:18,858:INFO:Plot type: residuals
2024-05-10 14:58:19,203:INFO:Fitting Model
2024-05-10 14:58:19,203:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:58:19,242:INFO:Scoring test/hold-out set
2024-05-10 14:58:19,455:INFO:Visual Rendered Successfully
2024-05-10 14:58:19,560:INFO:plot_model() successfully completed......................................
2024-05-10 14:58:28,719:INFO:Initializing plot_model()
2024-05-10 14:58:28,719:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, system=True)
2024-05-10 14:58:28,719:INFO:Checking exceptions
2024-05-10 14:58:28,731:INFO:Preloading libraries
2024-05-10 14:58:28,738:INFO:Copying training dataset
2024-05-10 14:58:28,738:INFO:Plot type: error
2024-05-10 14:58:29,061:INFO:Fitting Model
2024-05-10 14:58:29,061:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:58:29,061:INFO:Scoring test/hold-out set
2024-05-10 14:58:29,182:INFO:Visual Rendered Successfully
2024-05-10 14:58:29,282:INFO:plot_model() successfully completed......................................
2024-05-10 14:58:30,324:INFO:Initializing plot_model()
2024-05-10 14:58:30,325:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dc28c40>, system=True)
2024-05-10 14:58:30,325:INFO:Checking exceptions
2024-05-10 14:58:30,343:INFO:Preloading libraries
2024-05-10 14:58:30,350:INFO:Copying training dataset
2024-05-10 14:58:30,350:INFO:Plot type: residuals
2024-05-10 14:58:30,680:INFO:Fitting Model
2024-05-10 14:58:30,680:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:58:30,719:INFO:Scoring test/hold-out set
2024-05-10 14:58:30,910:INFO:Visual Rendered Successfully
2024-05-10 14:58:31,011:INFO:plot_model() successfully completed......................................
2024-05-10 14:58:50,637:INFO:PyCaret RegressionExperiment
2024-05-10 14:58:50,637:INFO:Logging name: reg-default-name
2024-05-10 14:58:50,637:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:58:50,638:INFO:version 3.3.2
2024-05-10 14:58:50,638:INFO:Initializing setup()
2024-05-10 14:58:50,638:INFO:self.USI: fae2
2024-05-10 14:58:50,638:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 14:58:50,638:INFO:Checking environment
2024-05-10 14:58:50,638:INFO:python_version: 3.9.18
2024-05-10 14:58:50,638:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:58:50,638:INFO:machine: x86_64
2024-05-10 14:58:50,638:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:58:50,638:INFO:Memory: svmem(total=16429797376, available=5787197440, percent=64.8, used=9518792704, free=3660681216, active=6967541760, inactive=4379889664, buffers=170536960, cached=3079786496, shared=777256960, slab=739753984)
2024-05-10 14:58:50,638:INFO:Physical Core: 12
2024-05-10 14:58:50,638:INFO:Logical Core: 16
2024-05-10 14:58:50,638:INFO:Checking libraries
2024-05-10 14:58:50,638:INFO:System:
2024-05-10 14:58:50,638:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:58:50,638:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:58:50,638:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:58:50,638:INFO:PyCaret required dependencies:
2024-05-10 14:58:50,638:INFO:                 pip: 23.3.1
2024-05-10 14:58:50,638:INFO:          setuptools: 68.2.2
2024-05-10 14:58:50,638:INFO:             pycaret: 3.3.2
2024-05-10 14:58:50,638:INFO:             IPython: 8.15.0
2024-05-10 14:58:50,638:INFO:          ipywidgets: 7.6.5
2024-05-10 14:58:50,638:INFO:                tqdm: 4.65.0
2024-05-10 14:58:50,638:INFO:               numpy: 1.26.4
2024-05-10 14:58:50,638:INFO:              pandas: 2.1.4
2024-05-10 14:58:50,638:INFO:              jinja2: 3.1.3
2024-05-10 14:58:50,638:INFO:               scipy: 1.11.4
2024-05-10 14:58:50,638:INFO:              joblib: 1.2.0
2024-05-10 14:58:50,638:INFO:             sklearn: 1.4.2
2024-05-10 14:58:50,638:INFO:                pyod: 1.1.3
2024-05-10 14:58:50,638:INFO:            imblearn: 0.12.2
2024-05-10 14:58:50,638:INFO:   category_encoders: 2.6.3
2024-05-10 14:58:50,638:INFO:            lightgbm: 4.3.0
2024-05-10 14:58:50,638:INFO:               numba: 0.59.1
2024-05-10 14:58:50,638:INFO:            requests: 2.31.0
2024-05-10 14:58:50,638:INFO:          matplotlib: 3.7.5
2024-05-10 14:58:50,638:INFO:          scikitplot: 0.3.7
2024-05-10 14:58:50,638:INFO:         yellowbrick: 1.5
2024-05-10 14:58:50,638:INFO:              plotly: 5.19.0
2024-05-10 14:58:50,638:INFO:    plotly-resampler: Not installed
2024-05-10 14:58:50,638:INFO:             kaleido: 0.2.1
2024-05-10 14:58:50,638:INFO:           schemdraw: 0.15
2024-05-10 14:58:50,639:INFO:         statsmodels: 0.14.0
2024-05-10 14:58:50,639:INFO:              sktime: 0.26.0
2024-05-10 14:58:50,639:INFO:               tbats: 1.1.3
2024-05-10 14:58:50,639:INFO:            pmdarima: 2.0.4
2024-05-10 14:58:50,639:INFO:              psutil: 5.9.0
2024-05-10 14:58:50,639:INFO:          markupsafe: 2.1.3
2024-05-10 14:58:50,639:INFO:             pickle5: Not installed
2024-05-10 14:58:50,639:INFO:         cloudpickle: 2.2.1
2024-05-10 14:58:50,639:INFO:         deprecation: 2.1.0
2024-05-10 14:58:50,639:INFO:              xxhash: 3.4.1
2024-05-10 14:58:50,639:INFO:           wurlitzer: 3.0.2
2024-05-10 14:58:50,639:INFO:PyCaret optional dependencies:
2024-05-10 14:58:50,639:INFO:                shap: Not installed
2024-05-10 14:58:50,639:INFO:           interpret: Not installed
2024-05-10 14:58:50,639:INFO:                umap: Not installed
2024-05-10 14:58:50,639:INFO:     ydata_profiling: Not installed
2024-05-10 14:58:50,639:INFO:  explainerdashboard: Not installed
2024-05-10 14:58:50,639:INFO:             autoviz: Not installed
2024-05-10 14:58:50,639:INFO:           fairlearn: Not installed
2024-05-10 14:58:50,639:INFO:          deepchecks: Not installed
2024-05-10 14:58:50,639:INFO:             xgboost: Not installed
2024-05-10 14:58:50,639:INFO:            catboost: Not installed
2024-05-10 14:58:50,639:INFO:              kmodes: Not installed
2024-05-10 14:58:50,639:INFO:             mlxtend: Not installed
2024-05-10 14:58:50,639:INFO:       statsforecast: Not installed
2024-05-10 14:58:50,639:INFO:        tune_sklearn: Not installed
2024-05-10 14:58:50,639:INFO:                 ray: Not installed
2024-05-10 14:58:50,639:INFO:            hyperopt: Not installed
2024-05-10 14:58:50,639:INFO:              optuna: Not installed
2024-05-10 14:58:50,639:INFO:               skopt: Not installed
2024-05-10 14:58:50,639:INFO:              mlflow: Not installed
2024-05-10 14:58:50,639:INFO:              gradio: Not installed
2024-05-10 14:58:50,639:INFO:             fastapi: Not installed
2024-05-10 14:58:50,639:INFO:             uvicorn: Not installed
2024-05-10 14:58:50,639:INFO:              m2cgen: Not installed
2024-05-10 14:58:50,639:INFO:           evidently: Not installed
2024-05-10 14:58:50,639:INFO:               fugue: Not installed
2024-05-10 14:58:50,639:INFO:           streamlit: 1.32.0
2024-05-10 14:58:50,639:INFO:             prophet: Not installed
2024-05-10 14:58:50,639:INFO:None
2024-05-10 14:58:50,639:INFO:Set up data.
2024-05-10 14:58:50,641:INFO:Set up folding strategy.
2024-05-10 14:58:50,641:INFO:Set up train/test split.
2024-05-10 14:58:50,643:INFO:Set up index.
2024-05-10 14:58:50,643:INFO:Assigning column types.
2024-05-10 14:58:50,645:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:58:50,645:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,647:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,649:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,677:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,695:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,696:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,698:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,700:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,724:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,743:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,744:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,744:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,744:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:58:50,746:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,748:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,773:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,791:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,794:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,796:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,821:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,841:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,841:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:58:50,845:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,871:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,891:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,891:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,891:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,895:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,921:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,941:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,941:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,942:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:58:50,971:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,991:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:50,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:50,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,021:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:51,041:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:58:51,041:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,041:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,042:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:58:51,071:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:51,091:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,091:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,120:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:58:51,140:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,140:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:58:51,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,237:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,238:INFO:Preparing preprocessing pipeline...
2024-05-10 14:58:51,238:INFO:Set up simple imputation.
2024-05-10 14:58:51,238:INFO:Set up polynomial features.
2024-05-10 14:58:51,238:INFO:Set up removing outliers.
2024-05-10 14:58:51,238:INFO:Set up feature normalization.
2024-05-10 14:58:51,238:INFO:Set up column name cleaning.
2024-05-10 14:58:51,327:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:58:51,331:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)',
                                             'ac_out_power(Wh)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:58:51,331:INFO:Creating final display dataframe.
2024-05-10 14:58:51,660:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 5)
4        Transformed data shape         (579, 15)
5   Transformed train set shape         (399, 15)
6    Transformed test set shape         (180, 15)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              fae2
2024-05-10 14:58:51,718:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,718:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,768:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,769:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:58:51,769:INFO:setup() successfully completed in 1.13s...............
2024-05-10 14:58:51,769:INFO:Initializing compare_models()
2024-05-10 14:58:51,769:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:58:51,769:INFO:Checking exceptions
2024-05-10 14:58:51,770:INFO:Preparing display monitor
2024-05-10 14:58:51,784:INFO:Initializing Linear Regression
2024-05-10 14:58:51,784:INFO:Total runtime is 3.111362457275391e-06 minutes
2024-05-10 14:58:51,787:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:51,788:INFO:Initializing create_model()
2024-05-10 14:58:51,788:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:51,788:INFO:Checking exceptions
2024-05-10 14:58:51,788:INFO:Importing libraries
2024-05-10 14:58:51,788:INFO:Copying training dataset
2024-05-10 14:58:51,791:INFO:Defining folds
2024-05-10 14:58:51,791:INFO:Declaring metric variables
2024-05-10 14:58:51,794:INFO:Importing untrained model
2024-05-10 14:58:51,797:INFO:Linear Regression Imported successfully
2024-05-10 14:58:51,805:INFO:Starting cross validation
2024-05-10 14:58:51,814:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:52,018:INFO:Calculating mean and std
2024-05-10 14:58:52,019:INFO:Creating metrics dataframe
2024-05-10 14:58:52,020:INFO:Uploading results into container
2024-05-10 14:58:52,021:INFO:Uploading model into container now
2024-05-10 14:58:52,021:INFO:_master_model_container: 1
2024-05-10 14:58:52,021:INFO:_display_container: 2
2024-05-10 14:58:52,021:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:58:52,021:INFO:create_model() successfully completed......................................
2024-05-10 14:58:52,126:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:52,126:INFO:Creating metrics dataframe
2024-05-10 14:58:52,131:INFO:Initializing Lasso Regression
2024-05-10 14:58:52,131:INFO:Total runtime is 0.005787010987599691 minutes
2024-05-10 14:58:52,134:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:52,134:INFO:Initializing create_model()
2024-05-10 14:58:52,135:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:52,135:INFO:Checking exceptions
2024-05-10 14:58:52,135:INFO:Importing libraries
2024-05-10 14:58:52,135:INFO:Copying training dataset
2024-05-10 14:58:52,138:INFO:Defining folds
2024-05-10 14:58:52,138:INFO:Declaring metric variables
2024-05-10 14:58:52,141:INFO:Importing untrained model
2024-05-10 14:58:52,143:INFO:Lasso Regression Imported successfully
2024-05-10 14:58:52,150:INFO:Starting cross validation
2024-05-10 14:58:52,155:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:52,350:INFO:Calculating mean and std
2024-05-10 14:58:52,350:INFO:Creating metrics dataframe
2024-05-10 14:58:52,352:INFO:Uploading results into container
2024-05-10 14:58:52,352:INFO:Uploading model into container now
2024-05-10 14:58:52,353:INFO:_master_model_container: 2
2024-05-10 14:58:52,353:INFO:_display_container: 2
2024-05-10 14:58:52,353:INFO:Lasso(random_state=123)
2024-05-10 14:58:52,353:INFO:create_model() successfully completed......................................
2024-05-10 14:58:52,460:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:52,460:INFO:Creating metrics dataframe
2024-05-10 14:58:52,464:INFO:Initializing Ridge Regression
2024-05-10 14:58:52,464:INFO:Total runtime is 0.01133945385615031 minutes
2024-05-10 14:58:52,466:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:52,466:INFO:Initializing create_model()
2024-05-10 14:58:52,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:52,467:INFO:Checking exceptions
2024-05-10 14:58:52,467:INFO:Importing libraries
2024-05-10 14:58:52,467:INFO:Copying training dataset
2024-05-10 14:58:52,468:INFO:Defining folds
2024-05-10 14:58:52,468:INFO:Declaring metric variables
2024-05-10 14:58:52,470:INFO:Importing untrained model
2024-05-10 14:58:52,472:INFO:Ridge Regression Imported successfully
2024-05-10 14:58:52,475:INFO:Starting cross validation
2024-05-10 14:58:52,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:52,679:INFO:Calculating mean and std
2024-05-10 14:58:52,680:INFO:Creating metrics dataframe
2024-05-10 14:58:52,682:INFO:Uploading results into container
2024-05-10 14:58:52,682:INFO:Uploading model into container now
2024-05-10 14:58:52,683:INFO:_master_model_container: 3
2024-05-10 14:58:52,683:INFO:_display_container: 2
2024-05-10 14:58:52,683:INFO:Ridge(random_state=123)
2024-05-10 14:58:52,683:INFO:create_model() successfully completed......................................
2024-05-10 14:58:52,792:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:52,792:INFO:Creating metrics dataframe
2024-05-10 14:58:52,797:INFO:Initializing Elastic Net
2024-05-10 14:58:52,797:INFO:Total runtime is 0.016884779930114745 minutes
2024-05-10 14:58:52,799:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:52,799:INFO:Initializing create_model()
2024-05-10 14:58:52,799:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:52,799:INFO:Checking exceptions
2024-05-10 14:58:52,799:INFO:Importing libraries
2024-05-10 14:58:52,799:INFO:Copying training dataset
2024-05-10 14:58:52,801:INFO:Defining folds
2024-05-10 14:58:52,801:INFO:Declaring metric variables
2024-05-10 14:58:52,803:INFO:Importing untrained model
2024-05-10 14:58:52,805:INFO:Elastic Net Imported successfully
2024-05-10 14:58:52,808:INFO:Starting cross validation
2024-05-10 14:58:52,813:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:53,012:INFO:Calculating mean and std
2024-05-10 14:58:53,014:INFO:Creating metrics dataframe
2024-05-10 14:58:53,016:INFO:Uploading results into container
2024-05-10 14:58:53,017:INFO:Uploading model into container now
2024-05-10 14:58:53,017:INFO:_master_model_container: 4
2024-05-10 14:58:53,017:INFO:_display_container: 2
2024-05-10 14:58:53,017:INFO:ElasticNet(random_state=123)
2024-05-10 14:58:53,017:INFO:create_model() successfully completed......................................
2024-05-10 14:58:53,124:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:53,125:INFO:Creating metrics dataframe
2024-05-10 14:58:53,129:INFO:Initializing Least Angle Regression
2024-05-10 14:58:53,129:INFO:Total runtime is 0.02242533763249715 minutes
2024-05-10 14:58:53,131:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:53,132:INFO:Initializing create_model()
2024-05-10 14:58:53,132:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:53,132:INFO:Checking exceptions
2024-05-10 14:58:53,132:INFO:Importing libraries
2024-05-10 14:58:53,132:INFO:Copying training dataset
2024-05-10 14:58:53,134:INFO:Defining folds
2024-05-10 14:58:53,134:INFO:Declaring metric variables
2024-05-10 14:58:53,136:INFO:Importing untrained model
2024-05-10 14:58:53,138:INFO:Least Angle Regression Imported successfully
2024-05-10 14:58:53,142:INFO:Starting cross validation
2024-05-10 14:58:53,147:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:53,344:INFO:Calculating mean and std
2024-05-10 14:58:53,344:INFO:Creating metrics dataframe
2024-05-10 14:58:53,346:INFO:Uploading results into container
2024-05-10 14:58:53,346:INFO:Uploading model into container now
2024-05-10 14:58:53,347:INFO:_master_model_container: 5
2024-05-10 14:58:53,347:INFO:_display_container: 2
2024-05-10 14:58:53,347:INFO:Lars(random_state=123)
2024-05-10 14:58:53,347:INFO:create_model() successfully completed......................................
2024-05-10 14:58:53,453:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:53,453:INFO:Creating metrics dataframe
2024-05-10 14:58:53,457:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:58:53,457:INFO:Total runtime is 0.027895069122314452 minutes
2024-05-10 14:58:53,459:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:53,459:INFO:Initializing create_model()
2024-05-10 14:58:53,459:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:53,459:INFO:Checking exceptions
2024-05-10 14:58:53,459:INFO:Importing libraries
2024-05-10 14:58:53,459:INFO:Copying training dataset
2024-05-10 14:58:53,462:INFO:Defining folds
2024-05-10 14:58:53,462:INFO:Declaring metric variables
2024-05-10 14:58:53,464:INFO:Importing untrained model
2024-05-10 14:58:53,466:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:58:53,472:INFO:Starting cross validation
2024-05-10 14:58:53,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:53,674:INFO:Calculating mean and std
2024-05-10 14:58:53,675:INFO:Creating metrics dataframe
2024-05-10 14:58:53,676:INFO:Uploading results into container
2024-05-10 14:58:53,676:INFO:Uploading model into container now
2024-05-10 14:58:53,676:INFO:_master_model_container: 6
2024-05-10 14:58:53,677:INFO:_display_container: 2
2024-05-10 14:58:53,677:INFO:LassoLars(random_state=123)
2024-05-10 14:58:53,677:INFO:create_model() successfully completed......................................
2024-05-10 14:58:53,785:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:53,785:INFO:Creating metrics dataframe
2024-05-10 14:58:53,790:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:58:53,790:INFO:Total runtime is 0.0334364374478658 minutes
2024-05-10 14:58:53,792:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:53,792:INFO:Initializing create_model()
2024-05-10 14:58:53,792:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:53,792:INFO:Checking exceptions
2024-05-10 14:58:53,792:INFO:Importing libraries
2024-05-10 14:58:53,792:INFO:Copying training dataset
2024-05-10 14:58:53,794:INFO:Defining folds
2024-05-10 14:58:53,794:INFO:Declaring metric variables
2024-05-10 14:58:53,797:INFO:Importing untrained model
2024-05-10 14:58:53,800:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:58:53,803:INFO:Starting cross validation
2024-05-10 14:58:53,808:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:53,995:INFO:Calculating mean and std
2024-05-10 14:58:53,996:INFO:Creating metrics dataframe
2024-05-10 14:58:53,998:INFO:Uploading results into container
2024-05-10 14:58:53,999:INFO:Uploading model into container now
2024-05-10 14:58:54,000:INFO:_master_model_container: 7
2024-05-10 14:58:54,000:INFO:_display_container: 2
2024-05-10 14:58:54,000:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:58:54,000:INFO:create_model() successfully completed......................................
2024-05-10 14:58:54,104:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:54,104:INFO:Creating metrics dataframe
2024-05-10 14:58:54,109:INFO:Initializing Bayesian Ridge
2024-05-10 14:58:54,109:INFO:Total runtime is 0.0387594978014628 minutes
2024-05-10 14:58:54,111:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:54,112:INFO:Initializing create_model()
2024-05-10 14:58:54,112:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:54,112:INFO:Checking exceptions
2024-05-10 14:58:54,112:INFO:Importing libraries
2024-05-10 14:58:54,112:INFO:Copying training dataset
2024-05-10 14:58:54,115:INFO:Defining folds
2024-05-10 14:58:54,116:INFO:Declaring metric variables
2024-05-10 14:58:54,117:INFO:Importing untrained model
2024-05-10 14:58:54,119:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:58:54,123:INFO:Starting cross validation
2024-05-10 14:58:54,127:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:54,320:INFO:Calculating mean and std
2024-05-10 14:58:54,321:INFO:Creating metrics dataframe
2024-05-10 14:58:54,324:INFO:Uploading results into container
2024-05-10 14:58:54,324:INFO:Uploading model into container now
2024-05-10 14:58:54,325:INFO:_master_model_container: 8
2024-05-10 14:58:54,325:INFO:_display_container: 2
2024-05-10 14:58:54,326:INFO:BayesianRidge()
2024-05-10 14:58:54,326:INFO:create_model() successfully completed......................................
2024-05-10 14:58:54,442:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:54,442:INFO:Creating metrics dataframe
2024-05-10 14:58:54,446:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:58:54,447:INFO:Total runtime is 0.044382592042287186 minutes
2024-05-10 14:58:54,449:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:54,449:INFO:Initializing create_model()
2024-05-10 14:58:54,449:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:54,449:INFO:Checking exceptions
2024-05-10 14:58:54,449:INFO:Importing libraries
2024-05-10 14:58:54,449:INFO:Copying training dataset
2024-05-10 14:58:54,452:INFO:Defining folds
2024-05-10 14:58:54,452:INFO:Declaring metric variables
2024-05-10 14:58:54,454:INFO:Importing untrained model
2024-05-10 14:58:54,456:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:58:54,459:INFO:Starting cross validation
2024-05-10 14:58:54,464:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:54,646:INFO:Calculating mean and std
2024-05-10 14:58:54,646:INFO:Creating metrics dataframe
2024-05-10 14:58:54,649:INFO:Uploading results into container
2024-05-10 14:58:54,650:INFO:Uploading model into container now
2024-05-10 14:58:54,650:INFO:_master_model_container: 9
2024-05-10 14:58:54,650:INFO:_display_container: 2
2024-05-10 14:58:54,651:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:58:54,651:INFO:create_model() successfully completed......................................
2024-05-10 14:58:54,755:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:54,755:INFO:Creating metrics dataframe
2024-05-10 14:58:54,760:INFO:Initializing Huber Regressor
2024-05-10 14:58:54,760:INFO:Total runtime is 0.04960999886194865 minutes
2024-05-10 14:58:54,762:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:54,763:INFO:Initializing create_model()
2024-05-10 14:58:54,763:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:54,763:INFO:Checking exceptions
2024-05-10 14:58:54,763:INFO:Importing libraries
2024-05-10 14:58:54,763:INFO:Copying training dataset
2024-05-10 14:58:54,766:INFO:Defining folds
2024-05-10 14:58:54,766:INFO:Declaring metric variables
2024-05-10 14:58:54,768:INFO:Importing untrained model
2024-05-10 14:58:54,770:INFO:Huber Regressor Imported successfully
2024-05-10 14:58:54,773:INFO:Starting cross validation
2024-05-10 14:58:54,778:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:54,894:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,902:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,906:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,942:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,950:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,951:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,954:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,968:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,968:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,975:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 14:58:54,982:INFO:Calculating mean and std
2024-05-10 14:58:54,983:INFO:Creating metrics dataframe
2024-05-10 14:58:54,984:INFO:Uploading results into container
2024-05-10 14:58:54,985:INFO:Uploading model into container now
2024-05-10 14:58:54,985:INFO:_master_model_container: 10
2024-05-10 14:58:54,985:INFO:_display_container: 2
2024-05-10 14:58:54,985:INFO:HuberRegressor()
2024-05-10 14:58:54,985:INFO:create_model() successfully completed......................................
2024-05-10 14:58:55,093:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:55,093:INFO:Creating metrics dataframe
2024-05-10 14:58:55,098:INFO:Initializing K Neighbors Regressor
2024-05-10 14:58:55,099:INFO:Total runtime is 0.05524845918019612 minutes
2024-05-10 14:58:55,100:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:55,101:INFO:Initializing create_model()
2024-05-10 14:58:55,101:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:55,101:INFO:Checking exceptions
2024-05-10 14:58:55,101:INFO:Importing libraries
2024-05-10 14:58:55,101:INFO:Copying training dataset
2024-05-10 14:58:55,103:INFO:Defining folds
2024-05-10 14:58:55,103:INFO:Declaring metric variables
2024-05-10 14:58:55,106:INFO:Importing untrained model
2024-05-10 14:58:55,108:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:58:55,112:INFO:Starting cross validation
2024-05-10 14:58:55,117:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:55,307:INFO:Calculating mean and std
2024-05-10 14:58:55,308:INFO:Creating metrics dataframe
2024-05-10 14:58:55,309:INFO:Uploading results into container
2024-05-10 14:58:55,309:INFO:Uploading model into container now
2024-05-10 14:58:55,310:INFO:_master_model_container: 11
2024-05-10 14:58:55,310:INFO:_display_container: 2
2024-05-10 14:58:55,310:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:58:55,310:INFO:create_model() successfully completed......................................
2024-05-10 14:58:55,414:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:55,414:INFO:Creating metrics dataframe
2024-05-10 14:58:55,419:INFO:Initializing Decision Tree Regressor
2024-05-10 14:58:55,420:INFO:Total runtime is 0.060598369439442946 minutes
2024-05-10 14:58:55,421:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:55,422:INFO:Initializing create_model()
2024-05-10 14:58:55,422:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:55,422:INFO:Checking exceptions
2024-05-10 14:58:55,422:INFO:Importing libraries
2024-05-10 14:58:55,422:INFO:Copying training dataset
2024-05-10 14:58:55,424:INFO:Defining folds
2024-05-10 14:58:55,424:INFO:Declaring metric variables
2024-05-10 14:58:55,426:INFO:Importing untrained model
2024-05-10 14:58:55,428:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:58:55,431:INFO:Starting cross validation
2024-05-10 14:58:55,436:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:55,628:INFO:Calculating mean and std
2024-05-10 14:58:55,628:INFO:Creating metrics dataframe
2024-05-10 14:58:55,629:INFO:Uploading results into container
2024-05-10 14:58:55,630:INFO:Uploading model into container now
2024-05-10 14:58:55,630:INFO:_master_model_container: 12
2024-05-10 14:58:55,630:INFO:_display_container: 2
2024-05-10 14:58:55,631:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:58:55,631:INFO:create_model() successfully completed......................................
2024-05-10 14:58:55,736:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:55,736:INFO:Creating metrics dataframe
2024-05-10 14:58:55,742:INFO:Initializing Random Forest Regressor
2024-05-10 14:58:55,742:INFO:Total runtime is 0.06596852938334147 minutes
2024-05-10 14:58:55,743:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:55,744:INFO:Initializing create_model()
2024-05-10 14:58:55,744:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:55,744:INFO:Checking exceptions
2024-05-10 14:58:55,744:INFO:Importing libraries
2024-05-10 14:58:55,744:INFO:Copying training dataset
2024-05-10 14:58:55,746:INFO:Defining folds
2024-05-10 14:58:55,746:INFO:Declaring metric variables
2024-05-10 14:58:55,748:INFO:Importing untrained model
2024-05-10 14:58:55,750:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:58:55,754:INFO:Starting cross validation
2024-05-10 14:58:55,758:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:56,260:INFO:Calculating mean and std
2024-05-10 14:58:56,261:INFO:Creating metrics dataframe
2024-05-10 14:58:56,263:INFO:Uploading results into container
2024-05-10 14:58:56,263:INFO:Uploading model into container now
2024-05-10 14:58:56,263:INFO:_master_model_container: 13
2024-05-10 14:58:56,263:INFO:_display_container: 2
2024-05-10 14:58:56,264:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:56,264:INFO:create_model() successfully completed......................................
2024-05-10 14:58:56,368:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:56,368:INFO:Creating metrics dataframe
2024-05-10 14:58:56,373:INFO:Initializing Extra Trees Regressor
2024-05-10 14:58:56,373:INFO:Total runtime is 0.07649567127227783 minutes
2024-05-10 14:58:56,376:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:56,376:INFO:Initializing create_model()
2024-05-10 14:58:56,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:56,376:INFO:Checking exceptions
2024-05-10 14:58:56,376:INFO:Importing libraries
2024-05-10 14:58:56,376:INFO:Copying training dataset
2024-05-10 14:58:56,379:INFO:Defining folds
2024-05-10 14:58:56,379:INFO:Declaring metric variables
2024-05-10 14:58:56,381:INFO:Importing untrained model
2024-05-10 14:58:56,384:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:58:56,388:INFO:Starting cross validation
2024-05-10 14:58:56,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:56,741:INFO:Calculating mean and std
2024-05-10 14:58:56,742:INFO:Creating metrics dataframe
2024-05-10 14:58:56,744:INFO:Uploading results into container
2024-05-10 14:58:56,745:INFO:Uploading model into container now
2024-05-10 14:58:56,745:INFO:_master_model_container: 14
2024-05-10 14:58:56,745:INFO:_display_container: 2
2024-05-10 14:58:56,746:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:56,746:INFO:create_model() successfully completed......................................
2024-05-10 14:58:56,849:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:56,849:INFO:Creating metrics dataframe
2024-05-10 14:58:56,855:INFO:Initializing AdaBoost Regressor
2024-05-10 14:58:56,855:INFO:Total runtime is 0.08451852003733316 minutes
2024-05-10 14:58:56,856:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:56,857:INFO:Initializing create_model()
2024-05-10 14:58:56,857:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:56,857:INFO:Checking exceptions
2024-05-10 14:58:56,857:INFO:Importing libraries
2024-05-10 14:58:56,857:INFO:Copying training dataset
2024-05-10 14:58:56,859:INFO:Defining folds
2024-05-10 14:58:56,859:INFO:Declaring metric variables
2024-05-10 14:58:56,862:INFO:Importing untrained model
2024-05-10 14:58:56,864:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:58:56,867:INFO:Starting cross validation
2024-05-10 14:58:56,871:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:57,198:INFO:Calculating mean and std
2024-05-10 14:58:57,198:INFO:Creating metrics dataframe
2024-05-10 14:58:57,200:INFO:Uploading results into container
2024-05-10 14:58:57,200:INFO:Uploading model into container now
2024-05-10 14:58:57,200:INFO:_master_model_container: 15
2024-05-10 14:58:57,200:INFO:_display_container: 2
2024-05-10 14:58:57,201:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:58:57,201:INFO:create_model() successfully completed......................................
2024-05-10 14:58:57,302:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:57,302:INFO:Creating metrics dataframe
2024-05-10 14:58:57,306:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:58:57,307:INFO:Total runtime is 0.09204905827840168 minutes
2024-05-10 14:58:57,309:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:57,309:INFO:Initializing create_model()
2024-05-10 14:58:57,309:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:57,309:INFO:Checking exceptions
2024-05-10 14:58:57,309:INFO:Importing libraries
2024-05-10 14:58:57,309:INFO:Copying training dataset
2024-05-10 14:58:57,312:INFO:Defining folds
2024-05-10 14:58:57,312:INFO:Declaring metric variables
2024-05-10 14:58:57,314:INFO:Importing untrained model
2024-05-10 14:58:57,317:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:58:57,320:INFO:Starting cross validation
2024-05-10 14:58:57,325:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:57,727:INFO:Calculating mean and std
2024-05-10 14:58:57,728:INFO:Creating metrics dataframe
2024-05-10 14:58:57,729:INFO:Uploading results into container
2024-05-10 14:58:57,730:INFO:Uploading model into container now
2024-05-10 14:58:57,730:INFO:_master_model_container: 16
2024-05-10 14:58:57,730:INFO:_display_container: 2
2024-05-10 14:58:57,730:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:58:57,730:INFO:create_model() successfully completed......................................
2024-05-10 14:58:57,838:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:57,838:INFO:Creating metrics dataframe
2024-05-10 14:58:57,845:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:58:57,845:INFO:Total runtime is 0.1010197599728902 minutes
2024-05-10 14:58:57,847:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:57,848:INFO:Initializing create_model()
2024-05-10 14:58:57,848:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:57,848:INFO:Checking exceptions
2024-05-10 14:58:57,848:INFO:Importing libraries
2024-05-10 14:58:57,848:INFO:Copying training dataset
2024-05-10 14:58:57,851:INFO:Defining folds
2024-05-10 14:58:57,851:INFO:Declaring metric variables
2024-05-10 14:58:57,853:INFO:Importing untrained model
2024-05-10 14:58:57,856:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:58:57,859:INFO:Starting cross validation
2024-05-10 14:58:57,865:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:58,634:INFO:Calculating mean and std
2024-05-10 14:58:58,635:INFO:Creating metrics dataframe
2024-05-10 14:58:58,637:INFO:Uploading results into container
2024-05-10 14:58:58,637:INFO:Uploading model into container now
2024-05-10 14:58:58,637:INFO:_master_model_container: 17
2024-05-10 14:58:58,637:INFO:_display_container: 2
2024-05-10 14:58:58,637:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:58,637:INFO:create_model() successfully completed......................................
2024-05-10 14:58:58,741:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:58,741:INFO:Creating metrics dataframe
2024-05-10 14:58:58,747:INFO:Initializing Dummy Regressor
2024-05-10 14:58:58,747:INFO:Total runtime is 0.11605146725972491 minutes
2024-05-10 14:58:58,749:INFO:SubProcess create_model() called ==================================
2024-05-10 14:58:58,749:INFO:Initializing create_model()
2024-05-10 14:58:58,749:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4dd01850>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:58,749:INFO:Checking exceptions
2024-05-10 14:58:58,750:INFO:Importing libraries
2024-05-10 14:58:58,750:INFO:Copying training dataset
2024-05-10 14:58:58,752:INFO:Defining folds
2024-05-10 14:58:58,752:INFO:Declaring metric variables
2024-05-10 14:58:58,754:INFO:Importing untrained model
2024-05-10 14:58:58,757:INFO:Dummy Regressor Imported successfully
2024-05-10 14:58:58,762:INFO:Starting cross validation
2024-05-10 14:58:58,768:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:58:58,951:INFO:Calculating mean and std
2024-05-10 14:58:58,951:INFO:Creating metrics dataframe
2024-05-10 14:58:58,952:INFO:Uploading results into container
2024-05-10 14:58:58,953:INFO:Uploading model into container now
2024-05-10 14:58:58,953:INFO:_master_model_container: 18
2024-05-10 14:58:58,953:INFO:_display_container: 2
2024-05-10 14:58:58,953:INFO:DummyRegressor()
2024-05-10 14:58:58,953:INFO:create_model() successfully completed......................................
2024-05-10 14:58:59,058:INFO:SubProcess create_model() end ==================================
2024-05-10 14:58:59,058:INFO:Creating metrics dataframe
2024-05-10 14:58:59,065:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:58:59,070:INFO:Initializing create_model()
2024-05-10 14:58:59,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:58:59,070:INFO:Checking exceptions
2024-05-10 14:58:59,072:INFO:Importing libraries
2024-05-10 14:58:59,072:INFO:Copying training dataset
2024-05-10 14:58:59,073:INFO:Defining folds
2024-05-10 14:58:59,074:INFO:Declaring metric variables
2024-05-10 14:58:59,074:INFO:Importing untrained model
2024-05-10 14:58:59,074:INFO:Declaring custom model
2024-05-10 14:58:59,074:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:58:59,078:INFO:Cross validation set to False
2024-05-10 14:58:59,078:INFO:Fitting Model
2024-05-10 14:58:59,212:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:59,212:INFO:create_model() successfully completed......................................
2024-05-10 14:58:59,330:INFO:_master_model_container: 18
2024-05-10 14:58:59,330:INFO:_display_container: 2
2024-05-10 14:58:59,330:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:58:59,330:INFO:compare_models() successfully completed......................................
2024-05-10 14:58:59,331:INFO:Initializing tune_model()
2024-05-10 14:58:59,331:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>)
2024-05-10 14:58:59,331:INFO:Checking exceptions
2024-05-10 14:58:59,340:INFO:Copying training dataset
2024-05-10 14:58:59,341:INFO:Checking base model
2024-05-10 14:58:59,342:INFO:Base model : Extra Trees Regressor
2024-05-10 14:58:59,344:INFO:Declaring metric variables
2024-05-10 14:58:59,346:INFO:Defining Hyperparameters
2024-05-10 14:58:59,483:INFO:Tuning with n_jobs=-1
2024-05-10 14:58:59,483:INFO:Initializing RandomizedSearchCV
2024-05-10 14:59:02,583:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 14:59:02,583:INFO:Hyperparameter search completed
2024-05-10 14:59:02,583:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:02,584:INFO:Initializing create_model()
2024-05-10 14:59:02,584:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32d49e50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 14:59:02,584:INFO:Checking exceptions
2024-05-10 14:59:02,584:INFO:Importing libraries
2024-05-10 14:59:02,584:INFO:Copying training dataset
2024-05-10 14:59:02,586:INFO:Defining folds
2024-05-10 14:59:02,586:INFO:Declaring metric variables
2024-05-10 14:59:02,588:INFO:Importing untrained model
2024-05-10 14:59:02,588:INFO:Declaring custom model
2024-05-10 14:59:02,590:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:59:02,594:INFO:Starting cross validation
2024-05-10 14:59:02,600:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:02,999:INFO:Calculating mean and std
2024-05-10 14:59:03,000:INFO:Creating metrics dataframe
2024-05-10 14:59:03,003:INFO:Finalizing model
2024-05-10 14:59:03,193:INFO:Uploading results into container
2024-05-10 14:59:03,194:INFO:Uploading model into container now
2024-05-10 14:59:03,194:INFO:_master_model_container: 19
2024-05-10 14:59:03,194:INFO:_display_container: 3
2024-05-10 14:59:03,195:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 14:59:03,195:INFO:create_model() successfully completed......................................
2024-05-10 14:59:03,299:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:03,300:INFO:choose_better activated
2024-05-10 14:59:03,302:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:03,302:INFO:Initializing create_model()
2024-05-10 14:59:03,302:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:03,303:INFO:Checking exceptions
2024-05-10 14:59:03,304:INFO:Importing libraries
2024-05-10 14:59:03,304:INFO:Copying training dataset
2024-05-10 14:59:03,305:INFO:Defining folds
2024-05-10 14:59:03,305:INFO:Declaring metric variables
2024-05-10 14:59:03,306:INFO:Importing untrained model
2024-05-10 14:59:03,306:INFO:Declaring custom model
2024-05-10 14:59:03,306:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:59:03,306:INFO:Starting cross validation
2024-05-10 14:59:03,310:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:03,641:INFO:Calculating mean and std
2024-05-10 14:59:03,642:INFO:Creating metrics dataframe
2024-05-10 14:59:03,643:INFO:Finalizing model
2024-05-10 14:59:03,776:INFO:Uploading results into container
2024-05-10 14:59:03,777:INFO:Uploading model into container now
2024-05-10 14:59:03,777:INFO:_master_model_container: 20
2024-05-10 14:59:03,778:INFO:_display_container: 4
2024-05-10 14:59:03,778:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:59:03,778:INFO:create_model() successfully completed......................................
2024-05-10 14:59:03,882:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:03,883:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.7239
2024-05-10 14:59:03,883:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.7
2024-05-10 14:59:03,883:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 14:59:03,884:INFO:choose_better completed
2024-05-10 14:59:03,884:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 14:59:03,889:INFO:_master_model_container: 20
2024-05-10 14:59:03,889:INFO:_display_container: 3
2024-05-10 14:59:03,889:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:59:03,889:INFO:tune_model() successfully completed......................................
2024-05-10 14:59:03,995:INFO:Initializing evaluate_model()
2024-05-10 14:59:03,995:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:59:04,002:INFO:Initializing plot_model()
2024-05-10 14:59:04,002:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, system=True)
2024-05-10 14:59:04,002:INFO:Checking exceptions
2024-05-10 14:59:04,012:INFO:Preloading libraries
2024-05-10 14:59:04,018:INFO:Copying training dataset
2024-05-10 14:59:04,018:INFO:Plot type: pipeline
2024-05-10 14:59:04,096:INFO:Visual Rendered Successfully
2024-05-10 14:59:04,203:INFO:plot_model() successfully completed......................................
2024-05-10 14:59:07,403:INFO:Initializing plot_model()
2024-05-10 14:59:07,404:INFO:plot_model(plot=error, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, system=True)
2024-05-10 14:59:07,404:INFO:Checking exceptions
2024-05-10 14:59:07,418:INFO:Preloading libraries
2024-05-10 14:59:07,428:INFO:Copying training dataset
2024-05-10 14:59:07,428:INFO:Plot type: error
2024-05-10 14:59:07,699:INFO:Fitting Model
2024-05-10 14:59:07,699:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:59:07,699:INFO:Scoring test/hold-out set
2024-05-10 14:59:07,826:INFO:Visual Rendered Successfully
2024-05-10 14:59:07,929:INFO:plot_model() successfully completed......................................
2024-05-10 14:59:08,373:INFO:Initializing plot_model()
2024-05-10 14:59:08,373:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de2c5e0>, system=True)
2024-05-10 14:59:08,373:INFO:Checking exceptions
2024-05-10 14:59:08,387:INFO:Preloading libraries
2024-05-10 14:59:08,394:INFO:Copying training dataset
2024-05-10 14:59:08,394:INFO:Plot type: residuals
2024-05-10 14:59:08,536:INFO:Fitting Model
2024-05-10 14:59:08,536:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 14:59:08,576:INFO:Scoring test/hold-out set
2024-05-10 14:59:08,783:INFO:Visual Rendered Successfully
2024-05-10 14:59:08,895:INFO:plot_model() successfully completed......................................
2024-05-10 14:59:30,817:INFO:PyCaret RegressionExperiment
2024-05-10 14:59:30,817:INFO:Logging name: reg-default-name
2024-05-10 14:59:30,817:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 14:59:30,817:INFO:version 3.3.2
2024-05-10 14:59:30,817:INFO:Initializing setup()
2024-05-10 14:59:30,817:INFO:self.USI: 302b
2024-05-10 14:59:30,817:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 14:59:30,817:INFO:Checking environment
2024-05-10 14:59:30,817:INFO:python_version: 3.9.18
2024-05-10 14:59:30,817:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 14:59:30,817:INFO:machine: x86_64
2024-05-10 14:59:30,817:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:59:30,817:INFO:Memory: svmem(total=16429797376, available=5749149696, percent=65.0, used=9558888448, free=3620315136, active=7008239616, inactive=4381167616, buffers=171270144, cached=3079323648, shared=775217152, slab=740024320)
2024-05-10 14:59:30,818:INFO:Physical Core: 12
2024-05-10 14:59:30,818:INFO:Logical Core: 16
2024-05-10 14:59:30,818:INFO:Checking libraries
2024-05-10 14:59:30,818:INFO:System:
2024-05-10 14:59:30,818:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 14:59:30,818:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 14:59:30,818:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 14:59:30,818:INFO:PyCaret required dependencies:
2024-05-10 14:59:30,818:INFO:                 pip: 23.3.1
2024-05-10 14:59:30,818:INFO:          setuptools: 68.2.2
2024-05-10 14:59:30,818:INFO:             pycaret: 3.3.2
2024-05-10 14:59:30,818:INFO:             IPython: 8.15.0
2024-05-10 14:59:30,818:INFO:          ipywidgets: 7.6.5
2024-05-10 14:59:30,818:INFO:                tqdm: 4.65.0
2024-05-10 14:59:30,818:INFO:               numpy: 1.26.4
2024-05-10 14:59:30,818:INFO:              pandas: 2.1.4
2024-05-10 14:59:30,818:INFO:              jinja2: 3.1.3
2024-05-10 14:59:30,818:INFO:               scipy: 1.11.4
2024-05-10 14:59:30,818:INFO:              joblib: 1.2.0
2024-05-10 14:59:30,818:INFO:             sklearn: 1.4.2
2024-05-10 14:59:30,818:INFO:                pyod: 1.1.3
2024-05-10 14:59:30,818:INFO:            imblearn: 0.12.2
2024-05-10 14:59:30,818:INFO:   category_encoders: 2.6.3
2024-05-10 14:59:30,818:INFO:            lightgbm: 4.3.0
2024-05-10 14:59:30,818:INFO:               numba: 0.59.1
2024-05-10 14:59:30,818:INFO:            requests: 2.31.0
2024-05-10 14:59:30,818:INFO:          matplotlib: 3.7.5
2024-05-10 14:59:30,818:INFO:          scikitplot: 0.3.7
2024-05-10 14:59:30,818:INFO:         yellowbrick: 1.5
2024-05-10 14:59:30,818:INFO:              plotly: 5.19.0
2024-05-10 14:59:30,818:INFO:    plotly-resampler: Not installed
2024-05-10 14:59:30,818:INFO:             kaleido: 0.2.1
2024-05-10 14:59:30,818:INFO:           schemdraw: 0.15
2024-05-10 14:59:30,818:INFO:         statsmodels: 0.14.0
2024-05-10 14:59:30,818:INFO:              sktime: 0.26.0
2024-05-10 14:59:30,818:INFO:               tbats: 1.1.3
2024-05-10 14:59:30,818:INFO:            pmdarima: 2.0.4
2024-05-10 14:59:30,818:INFO:              psutil: 5.9.0
2024-05-10 14:59:30,818:INFO:          markupsafe: 2.1.3
2024-05-10 14:59:30,818:INFO:             pickle5: Not installed
2024-05-10 14:59:30,818:INFO:         cloudpickle: 2.2.1
2024-05-10 14:59:30,818:INFO:         deprecation: 2.1.0
2024-05-10 14:59:30,818:INFO:              xxhash: 3.4.1
2024-05-10 14:59:30,818:INFO:           wurlitzer: 3.0.2
2024-05-10 14:59:30,818:INFO:PyCaret optional dependencies:
2024-05-10 14:59:30,818:INFO:                shap: Not installed
2024-05-10 14:59:30,818:INFO:           interpret: Not installed
2024-05-10 14:59:30,818:INFO:                umap: Not installed
2024-05-10 14:59:30,818:INFO:     ydata_profiling: Not installed
2024-05-10 14:59:30,818:INFO:  explainerdashboard: Not installed
2024-05-10 14:59:30,818:INFO:             autoviz: Not installed
2024-05-10 14:59:30,818:INFO:           fairlearn: Not installed
2024-05-10 14:59:30,818:INFO:          deepchecks: Not installed
2024-05-10 14:59:30,818:INFO:             xgboost: Not installed
2024-05-10 14:59:30,818:INFO:            catboost: Not installed
2024-05-10 14:59:30,819:INFO:              kmodes: Not installed
2024-05-10 14:59:30,819:INFO:             mlxtend: Not installed
2024-05-10 14:59:30,819:INFO:       statsforecast: Not installed
2024-05-10 14:59:30,819:INFO:        tune_sklearn: Not installed
2024-05-10 14:59:30,819:INFO:                 ray: Not installed
2024-05-10 14:59:30,819:INFO:            hyperopt: Not installed
2024-05-10 14:59:30,819:INFO:              optuna: Not installed
2024-05-10 14:59:30,819:INFO:               skopt: Not installed
2024-05-10 14:59:30,819:INFO:              mlflow: Not installed
2024-05-10 14:59:30,819:INFO:              gradio: Not installed
2024-05-10 14:59:30,819:INFO:             fastapi: Not installed
2024-05-10 14:59:30,819:INFO:             uvicorn: Not installed
2024-05-10 14:59:30,819:INFO:              m2cgen: Not installed
2024-05-10 14:59:30,819:INFO:           evidently: Not installed
2024-05-10 14:59:30,819:INFO:               fugue: Not installed
2024-05-10 14:59:30,819:INFO:           streamlit: 1.32.0
2024-05-10 14:59:30,819:INFO:             prophet: Not installed
2024-05-10 14:59:30,819:INFO:None
2024-05-10 14:59:30,819:INFO:Set up data.
2024-05-10 14:59:30,821:INFO:Set up folding strategy.
2024-05-10 14:59:30,821:INFO:Set up train/test split.
2024-05-10 14:59:30,823:INFO:Set up index.
2024-05-10 14:59:30,823:INFO:Assigning column types.
2024-05-10 14:59:30,825:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 14:59:30,825:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,827:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,829:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,854:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,872:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,873:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:30,873:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:30,873:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,875:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,877:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,901:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,919:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,920:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:30,920:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:30,920:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 14:59:30,922:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,924:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,948:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,968:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,968:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:30,968:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:30,970:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,972:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:59:30,997:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,016:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,017:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 14:59:31,021:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,047:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,066:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,066:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,067:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,071:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,095:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,116:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,117:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,117:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,117:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 14:59:31,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,165:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,165:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,165:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,195:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,214:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,214:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,214:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,214:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 14:59:31,243:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,263:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,263:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,291:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 14:59:31,314:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,314:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,314:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 14:59:31,362:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,362:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,411:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,411:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,412:INFO:Preparing preprocessing pipeline...
2024-05-10 14:59:31,412:INFO:Set up simple imputation.
2024-05-10 14:59:31,412:INFO:Set up polynomial features.
2024-05-10 14:59:31,412:INFO:Set up removing outliers.
2024-05-10 14:59:31,412:INFO:Set up feature normalization.
2024-05-10 14:59:31,412:INFO:Set up column name cleaning.
2024-05-10 14:59:31,501:INFO:Finished creating preprocessing pipeline.
2024-05-10 14:59:31,504:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 14:59:31,504:INFO:Creating final display dataframe.
2024-05-10 14:59:31,825:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 3)
4        Transformed data shape          (579, 6)
5   Transformed train set shape          (399, 6)
6    Transformed test set shape          (180, 6)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              302b
2024-05-10 14:59:31,883:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,943:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,943:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 14:59:31,943:INFO:setup() successfully completed in 1.13s...............
2024-05-10 14:59:31,943:INFO:Initializing compare_models()
2024-05-10 14:59:31,943:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 14:59:31,943:INFO:Checking exceptions
2024-05-10 14:59:31,944:INFO:Preparing display monitor
2024-05-10 14:59:31,958:INFO:Initializing Linear Regression
2024-05-10 14:59:31,959:INFO:Total runtime is 3.055731455485026e-06 minutes
2024-05-10 14:59:31,961:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:31,961:INFO:Initializing create_model()
2024-05-10 14:59:31,961:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:31,961:INFO:Checking exceptions
2024-05-10 14:59:31,961:INFO:Importing libraries
2024-05-10 14:59:31,961:INFO:Copying training dataset
2024-05-10 14:59:31,963:INFO:Defining folds
2024-05-10 14:59:31,963:INFO:Declaring metric variables
2024-05-10 14:59:31,966:INFO:Importing untrained model
2024-05-10 14:59:31,968:INFO:Linear Regression Imported successfully
2024-05-10 14:59:31,973:INFO:Starting cross validation
2024-05-10 14:59:31,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:32,169:INFO:Calculating mean and std
2024-05-10 14:59:32,170:INFO:Creating metrics dataframe
2024-05-10 14:59:32,171:INFO:Uploading results into container
2024-05-10 14:59:32,172:INFO:Uploading model into container now
2024-05-10 14:59:32,172:INFO:_master_model_container: 1
2024-05-10 14:59:32,172:INFO:_display_container: 2
2024-05-10 14:59:32,172:INFO:LinearRegression(n_jobs=-1)
2024-05-10 14:59:32,172:INFO:create_model() successfully completed......................................
2024-05-10 14:59:32,273:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:32,273:INFO:Creating metrics dataframe
2024-05-10 14:59:32,276:INFO:Initializing Lasso Regression
2024-05-10 14:59:32,276:INFO:Total runtime is 0.005299194653828938 minutes
2024-05-10 14:59:32,278:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:32,278:INFO:Initializing create_model()
2024-05-10 14:59:32,279:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:32,279:INFO:Checking exceptions
2024-05-10 14:59:32,279:INFO:Importing libraries
2024-05-10 14:59:32,279:INFO:Copying training dataset
2024-05-10 14:59:32,281:INFO:Defining folds
2024-05-10 14:59:32,281:INFO:Declaring metric variables
2024-05-10 14:59:32,283:INFO:Importing untrained model
2024-05-10 14:59:32,285:INFO:Lasso Regression Imported successfully
2024-05-10 14:59:32,288:INFO:Starting cross validation
2024-05-10 14:59:32,293:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:32,475:INFO:Calculating mean and std
2024-05-10 14:59:32,475:INFO:Creating metrics dataframe
2024-05-10 14:59:32,477:INFO:Uploading results into container
2024-05-10 14:59:32,477:INFO:Uploading model into container now
2024-05-10 14:59:32,478:INFO:_master_model_container: 2
2024-05-10 14:59:32,478:INFO:_display_container: 2
2024-05-10 14:59:32,478:INFO:Lasso(random_state=123)
2024-05-10 14:59:32,478:INFO:create_model() successfully completed......................................
2024-05-10 14:59:32,579:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:32,579:INFO:Creating metrics dataframe
2024-05-10 14:59:32,583:INFO:Initializing Ridge Regression
2024-05-10 14:59:32,583:INFO:Total runtime is 0.01040897766749064 minutes
2024-05-10 14:59:32,585:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:32,585:INFO:Initializing create_model()
2024-05-10 14:59:32,585:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:32,585:INFO:Checking exceptions
2024-05-10 14:59:32,585:INFO:Importing libraries
2024-05-10 14:59:32,585:INFO:Copying training dataset
2024-05-10 14:59:32,588:INFO:Defining folds
2024-05-10 14:59:32,588:INFO:Declaring metric variables
2024-05-10 14:59:32,590:INFO:Importing untrained model
2024-05-10 14:59:32,592:INFO:Ridge Regression Imported successfully
2024-05-10 14:59:32,595:INFO:Starting cross validation
2024-05-10 14:59:32,601:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:32,785:INFO:Calculating mean and std
2024-05-10 14:59:32,785:INFO:Creating metrics dataframe
2024-05-10 14:59:32,787:INFO:Uploading results into container
2024-05-10 14:59:32,787:INFO:Uploading model into container now
2024-05-10 14:59:32,787:INFO:_master_model_container: 3
2024-05-10 14:59:32,787:INFO:_display_container: 2
2024-05-10 14:59:32,787:INFO:Ridge(random_state=123)
2024-05-10 14:59:32,787:INFO:create_model() successfully completed......................................
2024-05-10 14:59:32,891:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:32,891:INFO:Creating metrics dataframe
2024-05-10 14:59:32,896:INFO:Initializing Elastic Net
2024-05-10 14:59:32,896:INFO:Total runtime is 0.015620120366414386 minutes
2024-05-10 14:59:32,898:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:32,898:INFO:Initializing create_model()
2024-05-10 14:59:32,898:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:32,898:INFO:Checking exceptions
2024-05-10 14:59:32,898:INFO:Importing libraries
2024-05-10 14:59:32,898:INFO:Copying training dataset
2024-05-10 14:59:32,900:INFO:Defining folds
2024-05-10 14:59:32,901:INFO:Declaring metric variables
2024-05-10 14:59:32,902:INFO:Importing untrained model
2024-05-10 14:59:32,904:INFO:Elastic Net Imported successfully
2024-05-10 14:59:32,907:INFO:Starting cross validation
2024-05-10 14:59:32,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:33,103:INFO:Calculating mean and std
2024-05-10 14:59:33,103:INFO:Creating metrics dataframe
2024-05-10 14:59:33,105:INFO:Uploading results into container
2024-05-10 14:59:33,105:INFO:Uploading model into container now
2024-05-10 14:59:33,105:INFO:_master_model_container: 4
2024-05-10 14:59:33,105:INFO:_display_container: 2
2024-05-10 14:59:33,106:INFO:ElasticNet(random_state=123)
2024-05-10 14:59:33,106:INFO:create_model() successfully completed......................................
2024-05-10 14:59:33,210:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:33,210:INFO:Creating metrics dataframe
2024-05-10 14:59:33,215:INFO:Initializing Least Angle Regression
2024-05-10 14:59:33,215:INFO:Total runtime is 0.02094008127848307 minutes
2024-05-10 14:59:33,217:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:33,217:INFO:Initializing create_model()
2024-05-10 14:59:33,217:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:33,217:INFO:Checking exceptions
2024-05-10 14:59:33,217:INFO:Importing libraries
2024-05-10 14:59:33,217:INFO:Copying training dataset
2024-05-10 14:59:33,219:INFO:Defining folds
2024-05-10 14:59:33,219:INFO:Declaring metric variables
2024-05-10 14:59:33,221:INFO:Importing untrained model
2024-05-10 14:59:33,223:INFO:Least Angle Regression Imported successfully
2024-05-10 14:59:33,226:INFO:Starting cross validation
2024-05-10 14:59:33,231:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:33,430:INFO:Calculating mean and std
2024-05-10 14:59:33,430:INFO:Creating metrics dataframe
2024-05-10 14:59:33,432:INFO:Uploading results into container
2024-05-10 14:59:33,432:INFO:Uploading model into container now
2024-05-10 14:59:33,432:INFO:_master_model_container: 5
2024-05-10 14:59:33,432:INFO:_display_container: 2
2024-05-10 14:59:33,433:INFO:Lars(random_state=123)
2024-05-10 14:59:33,433:INFO:create_model() successfully completed......................................
2024-05-10 14:59:33,537:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:33,537:INFO:Creating metrics dataframe
2024-05-10 14:59:33,541:INFO:Initializing Lasso Least Angle Regression
2024-05-10 14:59:33,541:INFO:Total runtime is 0.026377375920613604 minutes
2024-05-10 14:59:33,543:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:33,543:INFO:Initializing create_model()
2024-05-10 14:59:33,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:33,543:INFO:Checking exceptions
2024-05-10 14:59:33,543:INFO:Importing libraries
2024-05-10 14:59:33,543:INFO:Copying training dataset
2024-05-10 14:59:33,545:INFO:Defining folds
2024-05-10 14:59:33,545:INFO:Declaring metric variables
2024-05-10 14:59:33,548:INFO:Importing untrained model
2024-05-10 14:59:33,550:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 14:59:33,554:INFO:Starting cross validation
2024-05-10 14:59:33,558:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:33,745:INFO:Calculating mean and std
2024-05-10 14:59:33,746:INFO:Creating metrics dataframe
2024-05-10 14:59:33,748:INFO:Uploading results into container
2024-05-10 14:59:33,749:INFO:Uploading model into container now
2024-05-10 14:59:33,750:INFO:_master_model_container: 6
2024-05-10 14:59:33,750:INFO:_display_container: 2
2024-05-10 14:59:33,750:INFO:LassoLars(random_state=123)
2024-05-10 14:59:33,750:INFO:create_model() successfully completed......................................
2024-05-10 14:59:33,855:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:33,855:INFO:Creating metrics dataframe
2024-05-10 14:59:33,860:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 14:59:33,860:INFO:Total runtime is 0.03168718020121256 minutes
2024-05-10 14:59:33,861:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:33,862:INFO:Initializing create_model()
2024-05-10 14:59:33,862:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:33,862:INFO:Checking exceptions
2024-05-10 14:59:33,862:INFO:Importing libraries
2024-05-10 14:59:33,862:INFO:Copying training dataset
2024-05-10 14:59:33,865:INFO:Defining folds
2024-05-10 14:59:33,865:INFO:Declaring metric variables
2024-05-10 14:59:33,867:INFO:Importing untrained model
2024-05-10 14:59:33,870:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 14:59:33,873:INFO:Starting cross validation
2024-05-10 14:59:33,877:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:34,067:INFO:Calculating mean and std
2024-05-10 14:59:34,067:INFO:Creating metrics dataframe
2024-05-10 14:59:34,068:INFO:Uploading results into container
2024-05-10 14:59:34,069:INFO:Uploading model into container now
2024-05-10 14:59:34,069:INFO:_master_model_container: 7
2024-05-10 14:59:34,069:INFO:_display_container: 2
2024-05-10 14:59:34,069:INFO:OrthogonalMatchingPursuit()
2024-05-10 14:59:34,069:INFO:create_model() successfully completed......................................
2024-05-10 14:59:34,176:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:34,176:INFO:Creating metrics dataframe
2024-05-10 14:59:34,182:INFO:Initializing Bayesian Ridge
2024-05-10 14:59:34,182:INFO:Total runtime is 0.03705820639928182 minutes
2024-05-10 14:59:34,184:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:34,184:INFO:Initializing create_model()
2024-05-10 14:59:34,184:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:34,184:INFO:Checking exceptions
2024-05-10 14:59:34,184:INFO:Importing libraries
2024-05-10 14:59:34,184:INFO:Copying training dataset
2024-05-10 14:59:34,186:INFO:Defining folds
2024-05-10 14:59:34,187:INFO:Declaring metric variables
2024-05-10 14:59:34,188:INFO:Importing untrained model
2024-05-10 14:59:34,190:INFO:Bayesian Ridge Imported successfully
2024-05-10 14:59:34,193:INFO:Starting cross validation
2024-05-10 14:59:34,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:34,389:INFO:Calculating mean and std
2024-05-10 14:59:34,390:INFO:Creating metrics dataframe
2024-05-10 14:59:34,391:INFO:Uploading results into container
2024-05-10 14:59:34,392:INFO:Uploading model into container now
2024-05-10 14:59:34,392:INFO:_master_model_container: 8
2024-05-10 14:59:34,392:INFO:_display_container: 2
2024-05-10 14:59:34,392:INFO:BayesianRidge()
2024-05-10 14:59:34,392:INFO:create_model() successfully completed......................................
2024-05-10 14:59:34,497:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:34,497:INFO:Creating metrics dataframe
2024-05-10 14:59:34,502:INFO:Initializing Passive Aggressive Regressor
2024-05-10 14:59:34,502:INFO:Total runtime is 0.04239969253540039 minutes
2024-05-10 14:59:34,504:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:34,505:INFO:Initializing create_model()
2024-05-10 14:59:34,505:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:34,505:INFO:Checking exceptions
2024-05-10 14:59:34,505:INFO:Importing libraries
2024-05-10 14:59:34,505:INFO:Copying training dataset
2024-05-10 14:59:34,507:INFO:Defining folds
2024-05-10 14:59:34,507:INFO:Declaring metric variables
2024-05-10 14:59:34,509:INFO:Importing untrained model
2024-05-10 14:59:34,511:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 14:59:34,515:INFO:Starting cross validation
2024-05-10 14:59:34,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:34,701:INFO:Calculating mean and std
2024-05-10 14:59:34,702:INFO:Creating metrics dataframe
2024-05-10 14:59:34,703:INFO:Uploading results into container
2024-05-10 14:59:34,703:INFO:Uploading model into container now
2024-05-10 14:59:34,704:INFO:_master_model_container: 9
2024-05-10 14:59:34,704:INFO:_display_container: 2
2024-05-10 14:59:34,704:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 14:59:34,704:INFO:create_model() successfully completed......................................
2024-05-10 14:59:34,809:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:34,809:INFO:Creating metrics dataframe
2024-05-10 14:59:34,814:INFO:Initializing Huber Regressor
2024-05-10 14:59:34,814:INFO:Total runtime is 0.04758969942728679 minutes
2024-05-10 14:59:34,816:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:34,816:INFO:Initializing create_model()
2024-05-10 14:59:34,816:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:34,816:INFO:Checking exceptions
2024-05-10 14:59:34,816:INFO:Importing libraries
2024-05-10 14:59:34,816:INFO:Copying training dataset
2024-05-10 14:59:34,818:INFO:Defining folds
2024-05-10 14:59:34,819:INFO:Declaring metric variables
2024-05-10 14:59:34,820:INFO:Importing untrained model
2024-05-10 14:59:34,822:INFO:Huber Regressor Imported successfully
2024-05-10 14:59:34,825:INFO:Starting cross validation
2024-05-10 14:59:34,830:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:35,026:INFO:Calculating mean and std
2024-05-10 14:59:35,027:INFO:Creating metrics dataframe
2024-05-10 14:59:35,028:INFO:Uploading results into container
2024-05-10 14:59:35,029:INFO:Uploading model into container now
2024-05-10 14:59:35,029:INFO:_master_model_container: 10
2024-05-10 14:59:35,029:INFO:_display_container: 2
2024-05-10 14:59:35,030:INFO:HuberRegressor()
2024-05-10 14:59:35,030:INFO:create_model() successfully completed......................................
2024-05-10 14:59:35,137:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:35,137:INFO:Creating metrics dataframe
2024-05-10 14:59:35,142:INFO:Initializing K Neighbors Regressor
2024-05-10 14:59:35,143:INFO:Total runtime is 0.053068923950195315 minutes
2024-05-10 14:59:35,144:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:35,144:INFO:Initializing create_model()
2024-05-10 14:59:35,144:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:35,144:INFO:Checking exceptions
2024-05-10 14:59:35,144:INFO:Importing libraries
2024-05-10 14:59:35,144:INFO:Copying training dataset
2024-05-10 14:59:35,147:INFO:Defining folds
2024-05-10 14:59:35,147:INFO:Declaring metric variables
2024-05-10 14:59:35,149:INFO:Importing untrained model
2024-05-10 14:59:35,151:INFO:K Neighbors Regressor Imported successfully
2024-05-10 14:59:35,155:INFO:Starting cross validation
2024-05-10 14:59:35,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:35,350:INFO:Calculating mean and std
2024-05-10 14:59:35,350:INFO:Creating metrics dataframe
2024-05-10 14:59:35,352:INFO:Uploading results into container
2024-05-10 14:59:35,352:INFO:Uploading model into container now
2024-05-10 14:59:35,353:INFO:_master_model_container: 11
2024-05-10 14:59:35,353:INFO:_display_container: 2
2024-05-10 14:59:35,353:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 14:59:35,353:INFO:create_model() successfully completed......................................
2024-05-10 14:59:35,457:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:35,457:INFO:Creating metrics dataframe
2024-05-10 14:59:35,462:INFO:Initializing Decision Tree Regressor
2024-05-10 14:59:35,462:INFO:Total runtime is 0.0583865761756897 minutes
2024-05-10 14:59:35,464:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:35,464:INFO:Initializing create_model()
2024-05-10 14:59:35,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:35,464:INFO:Checking exceptions
2024-05-10 14:59:35,464:INFO:Importing libraries
2024-05-10 14:59:35,464:INFO:Copying training dataset
2024-05-10 14:59:35,467:INFO:Defining folds
2024-05-10 14:59:35,467:INFO:Declaring metric variables
2024-05-10 14:59:35,469:INFO:Importing untrained model
2024-05-10 14:59:35,471:INFO:Decision Tree Regressor Imported successfully
2024-05-10 14:59:35,474:INFO:Starting cross validation
2024-05-10 14:59:35,478:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:35,691:INFO:Calculating mean and std
2024-05-10 14:59:35,692:INFO:Creating metrics dataframe
2024-05-10 14:59:35,693:INFO:Uploading results into container
2024-05-10 14:59:35,694:INFO:Uploading model into container now
2024-05-10 14:59:35,694:INFO:_master_model_container: 12
2024-05-10 14:59:35,694:INFO:_display_container: 2
2024-05-10 14:59:35,694:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 14:59:35,694:INFO:create_model() successfully completed......................................
2024-05-10 14:59:35,800:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:35,800:INFO:Creating metrics dataframe
2024-05-10 14:59:35,806:INFO:Initializing Random Forest Regressor
2024-05-10 14:59:35,806:INFO:Total runtime is 0.06413238843282064 minutes
2024-05-10 14:59:35,808:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:35,808:INFO:Initializing create_model()
2024-05-10 14:59:35,808:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:35,808:INFO:Checking exceptions
2024-05-10 14:59:35,808:INFO:Importing libraries
2024-05-10 14:59:35,808:INFO:Copying training dataset
2024-05-10 14:59:35,810:INFO:Defining folds
2024-05-10 14:59:35,810:INFO:Declaring metric variables
2024-05-10 14:59:35,813:INFO:Importing untrained model
2024-05-10 14:59:35,815:INFO:Random Forest Regressor Imported successfully
2024-05-10 14:59:35,819:INFO:Starting cross validation
2024-05-10 14:59:35,823:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:36,198:INFO:Calculating mean and std
2024-05-10 14:59:36,199:INFO:Creating metrics dataframe
2024-05-10 14:59:36,201:INFO:Uploading results into container
2024-05-10 14:59:36,201:INFO:Uploading model into container now
2024-05-10 14:59:36,201:INFO:_master_model_container: 13
2024-05-10 14:59:36,201:INFO:_display_container: 2
2024-05-10 14:59:36,202:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:59:36,202:INFO:create_model() successfully completed......................................
2024-05-10 14:59:36,305:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:36,306:INFO:Creating metrics dataframe
2024-05-10 14:59:36,311:INFO:Initializing Extra Trees Regressor
2024-05-10 14:59:36,311:INFO:Total runtime is 0.07253814538319905 minutes
2024-05-10 14:59:36,313:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:36,313:INFO:Initializing create_model()
2024-05-10 14:59:36,313:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:36,313:INFO:Checking exceptions
2024-05-10 14:59:36,313:INFO:Importing libraries
2024-05-10 14:59:36,313:INFO:Copying training dataset
2024-05-10 14:59:36,316:INFO:Defining folds
2024-05-10 14:59:36,317:INFO:Declaring metric variables
2024-05-10 14:59:36,319:INFO:Importing untrained model
2024-05-10 14:59:36,321:INFO:Extra Trees Regressor Imported successfully
2024-05-10 14:59:36,324:INFO:Starting cross validation
2024-05-10 14:59:36,329:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:36,663:INFO:Calculating mean and std
2024-05-10 14:59:36,664:INFO:Creating metrics dataframe
2024-05-10 14:59:36,665:INFO:Uploading results into container
2024-05-10 14:59:36,666:INFO:Uploading model into container now
2024-05-10 14:59:36,666:INFO:_master_model_container: 14
2024-05-10 14:59:36,666:INFO:_display_container: 2
2024-05-10 14:59:36,666:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:59:36,666:INFO:create_model() successfully completed......................................
2024-05-10 14:59:36,772:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:36,772:INFO:Creating metrics dataframe
2024-05-10 14:59:36,778:INFO:Initializing AdaBoost Regressor
2024-05-10 14:59:36,778:INFO:Total runtime is 0.08032703399658203 minutes
2024-05-10 14:59:36,780:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:36,780:INFO:Initializing create_model()
2024-05-10 14:59:36,781:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:36,781:INFO:Checking exceptions
2024-05-10 14:59:36,781:INFO:Importing libraries
2024-05-10 14:59:36,781:INFO:Copying training dataset
2024-05-10 14:59:36,783:INFO:Defining folds
2024-05-10 14:59:36,783:INFO:Declaring metric variables
2024-05-10 14:59:36,785:INFO:Importing untrained model
2024-05-10 14:59:36,787:INFO:AdaBoost Regressor Imported successfully
2024-05-10 14:59:36,790:INFO:Starting cross validation
2024-05-10 14:59:36,795:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:37,025:INFO:Calculating mean and std
2024-05-10 14:59:37,026:INFO:Creating metrics dataframe
2024-05-10 14:59:37,027:INFO:Uploading results into container
2024-05-10 14:59:37,027:INFO:Uploading model into container now
2024-05-10 14:59:37,027:INFO:_master_model_container: 15
2024-05-10 14:59:37,027:INFO:_display_container: 2
2024-05-10 14:59:37,028:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 14:59:37,028:INFO:create_model() successfully completed......................................
2024-05-10 14:59:37,135:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:37,135:INFO:Creating metrics dataframe
2024-05-10 14:59:37,141:INFO:Initializing Gradient Boosting Regressor
2024-05-10 14:59:37,141:INFO:Total runtime is 0.08637474377950033 minutes
2024-05-10 14:59:37,143:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:37,143:INFO:Initializing create_model()
2024-05-10 14:59:37,143:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:37,143:INFO:Checking exceptions
2024-05-10 14:59:37,143:INFO:Importing libraries
2024-05-10 14:59:37,143:INFO:Copying training dataset
2024-05-10 14:59:37,145:INFO:Defining folds
2024-05-10 14:59:37,145:INFO:Declaring metric variables
2024-05-10 14:59:37,147:INFO:Importing untrained model
2024-05-10 14:59:37,150:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 14:59:37,153:INFO:Starting cross validation
2024-05-10 14:59:37,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:37,466:INFO:Calculating mean and std
2024-05-10 14:59:37,467:INFO:Creating metrics dataframe
2024-05-10 14:59:37,468:INFO:Uploading results into container
2024-05-10 14:59:37,469:INFO:Uploading model into container now
2024-05-10 14:59:37,469:INFO:_master_model_container: 16
2024-05-10 14:59:37,469:INFO:_display_container: 2
2024-05-10 14:59:37,469:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 14:59:37,469:INFO:create_model() successfully completed......................................
2024-05-10 14:59:37,572:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:37,572:INFO:Creating metrics dataframe
2024-05-10 14:59:37,577:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 14:59:37,577:INFO:Total runtime is 0.09363942941029867 minutes
2024-05-10 14:59:37,578:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:37,579:INFO:Initializing create_model()
2024-05-10 14:59:37,579:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:37,579:INFO:Checking exceptions
2024-05-10 14:59:37,579:INFO:Importing libraries
2024-05-10 14:59:37,579:INFO:Copying training dataset
2024-05-10 14:59:37,581:INFO:Defining folds
2024-05-10 14:59:37,581:INFO:Declaring metric variables
2024-05-10 14:59:37,584:INFO:Importing untrained model
2024-05-10 14:59:37,586:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:59:37,589:INFO:Starting cross validation
2024-05-10 14:59:37,594:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:38,324:INFO:Calculating mean and std
2024-05-10 14:59:38,326:INFO:Creating metrics dataframe
2024-05-10 14:59:38,327:INFO:Uploading results into container
2024-05-10 14:59:38,328:INFO:Uploading model into container now
2024-05-10 14:59:38,328:INFO:_master_model_container: 17
2024-05-10 14:59:38,328:INFO:_display_container: 2
2024-05-10 14:59:38,329:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:59:38,329:INFO:create_model() successfully completed......................................
2024-05-10 14:59:38,434:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:38,434:INFO:Creating metrics dataframe
2024-05-10 14:59:38,440:INFO:Initializing Dummy Regressor
2024-05-10 14:59:38,440:INFO:Total runtime is 0.10802005529403687 minutes
2024-05-10 14:59:38,441:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:38,442:INFO:Initializing create_model()
2024-05-10 14:59:38,442:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d577c15e0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:38,442:INFO:Checking exceptions
2024-05-10 14:59:38,442:INFO:Importing libraries
2024-05-10 14:59:38,442:INFO:Copying training dataset
2024-05-10 14:59:38,444:INFO:Defining folds
2024-05-10 14:59:38,444:INFO:Declaring metric variables
2024-05-10 14:59:38,446:INFO:Importing untrained model
2024-05-10 14:59:38,449:INFO:Dummy Regressor Imported successfully
2024-05-10 14:59:38,454:INFO:Starting cross validation
2024-05-10 14:59:38,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:38,646:INFO:Calculating mean and std
2024-05-10 14:59:38,647:INFO:Creating metrics dataframe
2024-05-10 14:59:38,649:INFO:Uploading results into container
2024-05-10 14:59:38,649:INFO:Uploading model into container now
2024-05-10 14:59:38,649:INFO:_master_model_container: 18
2024-05-10 14:59:38,649:INFO:_display_container: 2
2024-05-10 14:59:38,649:INFO:DummyRegressor()
2024-05-10 14:59:38,649:INFO:create_model() successfully completed......................................
2024-05-10 14:59:38,756:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:38,756:INFO:Creating metrics dataframe
2024-05-10 14:59:38,763:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 14:59:38,769:INFO:Initializing create_model()
2024-05-10 14:59:38,769:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:38,769:INFO:Checking exceptions
2024-05-10 14:59:38,770:INFO:Importing libraries
2024-05-10 14:59:38,770:INFO:Copying training dataset
2024-05-10 14:59:38,772:INFO:Defining folds
2024-05-10 14:59:38,772:INFO:Declaring metric variables
2024-05-10 14:59:38,772:INFO:Importing untrained model
2024-05-10 14:59:38,772:INFO:Declaring custom model
2024-05-10 14:59:38,773:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:59:38,776:INFO:Cross validation set to False
2024-05-10 14:59:38,776:INFO:Fitting Model
2024-05-10 14:59:38,851:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-10 14:59:38,852:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000891 seconds.
2024-05-10 14:59:38,852:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-10 14:59:38,852:INFO:[LightGBM] [Info] Total Bins 564
2024-05-10 14:59:38,853:INFO:[LightGBM] [Info] Number of data points in the train set: 399, number of used features: 5
2024-05-10 14:59:38,853:INFO:[LightGBM] [Info] Start training from score 8.417540
2024-05-10 14:59:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,863:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,866:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,881:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,901:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,908:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,909:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,910:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,911:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,912:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,914:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,916:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,917:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,918:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,919:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,920:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,921:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,922:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,923:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,924:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,925:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,926:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,927:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,928:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,929:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,930:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,932:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,933:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,935:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,937:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,938:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,940:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,941:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,942:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,943:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,944:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,945:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,946:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,948:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,950:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,951:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,952:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,953:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,954:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,955:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,956:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,957:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,958:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,959:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,960:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:38,962:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:59:38,962:INFO:create_model() successfully completed......................................
2024-05-10 14:59:39,115:INFO:_master_model_container: 18
2024-05-10 14:59:39,115:INFO:_display_container: 2
2024-05-10 14:59:39,115:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:59:39,115:INFO:compare_models() successfully completed......................................
2024-05-10 14:59:39,116:INFO:Initializing tune_model()
2024-05-10 14:59:39,116:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>)
2024-05-10 14:59:39,116:INFO:Checking exceptions
2024-05-10 14:59:39,124:INFO:Copying training dataset
2024-05-10 14:59:39,126:INFO:Checking base model
2024-05-10 14:59:39,126:INFO:Base model : Light Gradient Boosting Machine
2024-05-10 14:59:39,129:INFO:Declaring metric variables
2024-05-10 14:59:39,131:INFO:Defining Hyperparameters
2024-05-10 14:59:39,247:INFO:Tuning with n_jobs=-1
2024-05-10 14:59:39,248:INFO:Initializing RandomizedSearchCV
2024-05-10 14:59:41,917:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-05-10 14:59:41,917:INFO:Hyperparameter search completed
2024-05-10 14:59:41,917:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:41,918:INFO:Initializing create_model()
2024-05-10 14:59:41,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df84a90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-05-10 14:59:41,918:INFO:Checking exceptions
2024-05-10 14:59:41,918:INFO:Importing libraries
2024-05-10 14:59:41,918:INFO:Copying training dataset
2024-05-10 14:59:41,920:INFO:Defining folds
2024-05-10 14:59:41,920:INFO:Declaring metric variables
2024-05-10 14:59:41,922:INFO:Importing untrained model
2024-05-10 14:59:41,922:INFO:Declaring custom model
2024-05-10 14:59:41,924:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:59:41,928:INFO:Starting cross validation
2024-05-10 14:59:41,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:42,184:INFO:Calculating mean and std
2024-05-10 14:59:42,185:INFO:Creating metrics dataframe
2024-05-10 14:59:42,189:INFO:Finalizing model
2024-05-10 14:59:42,272:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 14:59:42,272:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 14:59:42,272:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 14:59:42,273:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-10 14:59:42,274:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 14:59:42,274:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 14:59:42,274:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 14:59:42,274:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000735 seconds.
2024-05-10 14:59:42,274:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-10 14:59:42,275:INFO:[LightGBM] [Info] Total Bins 564
2024-05-10 14:59:42,275:INFO:[LightGBM] [Info] Number of data points in the train set: 399, number of used features: 5
2024-05-10 14:59:42,275:INFO:[LightGBM] [Info] Start training from score 8.417540
2024-05-10 14:59:42,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,281:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,283:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,287:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,288:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,289:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,290:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,291:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,292:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:42,293:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 14:59:42,297:INFO:Uploading results into container
2024-05-10 14:59:42,298:INFO:Uploading model into container now
2024-05-10 14:59:42,299:INFO:_master_model_container: 19
2024-05-10 14:59:42,299:INFO:_display_container: 3
2024-05-10 14:59:42,299:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1)
2024-05-10 14:59:42,299:INFO:create_model() successfully completed......................................
2024-05-10 14:59:42,416:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:42,416:INFO:choose_better activated
2024-05-10 14:59:42,419:INFO:SubProcess create_model() called ==================================
2024-05-10 14:59:42,419:INFO:Initializing create_model()
2024-05-10 14:59:42,420:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 14:59:42,420:INFO:Checking exceptions
2024-05-10 14:59:42,421:INFO:Importing libraries
2024-05-10 14:59:42,421:INFO:Copying training dataset
2024-05-10 14:59:42,423:INFO:Defining folds
2024-05-10 14:59:42,424:INFO:Declaring metric variables
2024-05-10 14:59:42,424:INFO:Importing untrained model
2024-05-10 14:59:42,424:INFO:Declaring custom model
2024-05-10 14:59:42,424:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 14:59:42,424:INFO:Starting cross validation
2024-05-10 14:59:42,429:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 14:59:43,161:INFO:Calculating mean and std
2024-05-10 14:59:43,161:INFO:Creating metrics dataframe
2024-05-10 14:59:43,162:INFO:Finalizing model
2024-05-10 14:59:43,247:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-10 14:59:43,249:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001041 seconds.
2024-05-10 14:59:43,249:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-10 14:59:43,249:INFO:[LightGBM] [Info] Total Bins 564
2024-05-10 14:59:43,249:INFO:[LightGBM] [Info] Number of data points in the train set: 399, number of used features: 5
2024-05-10 14:59:43,249:INFO:[LightGBM] [Info] Start training from score 8.417540
2024-05-10 14:59:43,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,257:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,258:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,259:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,260:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,261:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,262:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,264:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,265:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,267:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,269:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,270:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,271:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,272:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,273:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,274:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,275:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,276:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,277:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,278:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,279:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,280:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,282:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,284:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,285:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,286:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,288:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,289:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,290:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,291:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,293:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,294:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,295:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,296:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,297:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,299:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,301:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,302:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,303:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,304:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,306:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,307:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,308:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,309:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,310:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,311:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,312:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,315:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,317:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,319:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,320:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,321:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,322:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,323:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,324:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,325:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,326:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,327:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,328:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,329:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,331:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,333:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,335:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,336:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,337:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,338:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,340:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,341:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,342:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,343:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,344:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,345:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,346:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,348:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,350:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,352:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,353:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,355:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,356:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,357:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,358:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,359:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,360:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,361:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,362:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,363:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,365:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,367:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,369:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,370:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 14:59:43,372:INFO:Uploading results into container
2024-05-10 14:59:43,373:INFO:Uploading model into container now
2024-05-10 14:59:43,373:INFO:_master_model_container: 20
2024-05-10 14:59:43,373:INFO:_display_container: 4
2024-05-10 14:59:43,373:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 14:59:43,373:INFO:create_model() successfully completed......................................
2024-05-10 14:59:43,483:INFO:SubProcess create_model() end ==================================
2024-05-10 14:59:43,483:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.6391
2024-05-10 14:59:43,484:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1) result for R2 is 0.6434
2024-05-10 14:59:43,484:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1) is best model
2024-05-10 14:59:43,484:INFO:choose_better completed
2024-05-10 14:59:43,489:INFO:_master_model_container: 20
2024-05-10 14:59:43,489:INFO:_display_container: 3
2024-05-10 14:59:43,489:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1)
2024-05-10 14:59:43,489:INFO:tune_model() successfully completed......................................
2024-05-10 14:59:43,599:INFO:Initializing evaluate_model()
2024-05-10 14:59:43,599:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 14:59:43,606:INFO:Initializing plot_model()
2024-05-10 14:59:43,606:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, system=True)
2024-05-10 14:59:43,606:INFO:Checking exceptions
2024-05-10 14:59:43,607:INFO:Preloading libraries
2024-05-10 14:59:43,608:INFO:Copying training dataset
2024-05-10 14:59:43,608:INFO:Plot type: pipeline
2024-05-10 14:59:43,692:INFO:Visual Rendered Successfully
2024-05-10 14:59:43,804:INFO:plot_model() successfully completed......................................
2024-05-10 14:59:48,014:INFO:Initializing plot_model()
2024-05-10 14:59:48,014:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4de307f0>, system=True)
2024-05-10 14:59:48,014:INFO:Checking exceptions
2024-05-10 14:59:48,017:INFO:Preloading libraries
2024-05-10 14:59:48,019:INFO:Copying training dataset
2024-05-10 14:59:48,019:INFO:Plot type: residuals
2024-05-10 14:59:48,358:INFO:Fitting Model
2024-05-10 14:59:48,359:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 14:59:48,359:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 14:59:48,359:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 14:59:48,360:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 14:59:48,361:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 14:59:48,361:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 14:59:48,377:INFO:Scoring test/hold-out set
2024-05-10 14:59:48,377:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 14:59:48,377:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 14:59:48,377:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 14:59:48,378:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 14:59:48,378:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 14:59:48,378:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 14:59:48,553:INFO:Visual Rendered Successfully
2024-05-10 14:59:48,661:INFO:plot_model() successfully completed......................................
2024-05-10 15:00:01,978:INFO:PyCaret RegressionExperiment
2024-05-10 15:00:01,978:INFO:Logging name: reg-default-name
2024-05-10 15:00:01,978:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 15:00:01,978:INFO:version 3.3.2
2024-05-10 15:00:01,978:INFO:Initializing setup()
2024-05-10 15:00:01,978:INFO:self.USI: 0878
2024-05-10 15:00:01,978:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 15:00:01,978:INFO:Checking environment
2024-05-10 15:00:01,978:INFO:python_version: 3.9.18
2024-05-10 15:00:01,978:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 15:00:01,978:INFO:machine: x86_64
2024-05-10 15:00:01,978:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:00:01,978:INFO:Memory: svmem(total=16429797376, available=5730848768, percent=65.1, used=9590239232, free=3600900096, active=7035211776, inactive=4381708288, buffers=171655168, cached=3067002880, shared=762167296, slab=740126720)
2024-05-10 15:00:01,978:INFO:Physical Core: 12
2024-05-10 15:00:01,978:INFO:Logical Core: 16
2024-05-10 15:00:01,978:INFO:Checking libraries
2024-05-10 15:00:01,978:INFO:System:
2024-05-10 15:00:01,978:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 15:00:01,978:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 15:00:01,978:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:00:01,978:INFO:PyCaret required dependencies:
2024-05-10 15:00:01,979:INFO:                 pip: 23.3.1
2024-05-10 15:00:01,979:INFO:          setuptools: 68.2.2
2024-05-10 15:00:01,979:INFO:             pycaret: 3.3.2
2024-05-10 15:00:01,979:INFO:             IPython: 8.15.0
2024-05-10 15:00:01,979:INFO:          ipywidgets: 7.6.5
2024-05-10 15:00:01,979:INFO:                tqdm: 4.65.0
2024-05-10 15:00:01,979:INFO:               numpy: 1.26.4
2024-05-10 15:00:01,979:INFO:              pandas: 2.1.4
2024-05-10 15:00:01,979:INFO:              jinja2: 3.1.3
2024-05-10 15:00:01,979:INFO:               scipy: 1.11.4
2024-05-10 15:00:01,979:INFO:              joblib: 1.2.0
2024-05-10 15:00:01,979:INFO:             sklearn: 1.4.2
2024-05-10 15:00:01,979:INFO:                pyod: 1.1.3
2024-05-10 15:00:01,979:INFO:            imblearn: 0.12.2
2024-05-10 15:00:01,979:INFO:   category_encoders: 2.6.3
2024-05-10 15:00:01,979:INFO:            lightgbm: 4.3.0
2024-05-10 15:00:01,979:INFO:               numba: 0.59.1
2024-05-10 15:00:01,979:INFO:            requests: 2.31.0
2024-05-10 15:00:01,979:INFO:          matplotlib: 3.7.5
2024-05-10 15:00:01,979:INFO:          scikitplot: 0.3.7
2024-05-10 15:00:01,979:INFO:         yellowbrick: 1.5
2024-05-10 15:00:01,979:INFO:              plotly: 5.19.0
2024-05-10 15:00:01,979:INFO:    plotly-resampler: Not installed
2024-05-10 15:00:01,979:INFO:             kaleido: 0.2.1
2024-05-10 15:00:01,979:INFO:           schemdraw: 0.15
2024-05-10 15:00:01,979:INFO:         statsmodels: 0.14.0
2024-05-10 15:00:01,979:INFO:              sktime: 0.26.0
2024-05-10 15:00:01,979:INFO:               tbats: 1.1.3
2024-05-10 15:00:01,979:INFO:            pmdarima: 2.0.4
2024-05-10 15:00:01,979:INFO:              psutil: 5.9.0
2024-05-10 15:00:01,979:INFO:          markupsafe: 2.1.3
2024-05-10 15:00:01,979:INFO:             pickle5: Not installed
2024-05-10 15:00:01,979:INFO:         cloudpickle: 2.2.1
2024-05-10 15:00:01,979:INFO:         deprecation: 2.1.0
2024-05-10 15:00:01,979:INFO:              xxhash: 3.4.1
2024-05-10 15:00:01,979:INFO:           wurlitzer: 3.0.2
2024-05-10 15:00:01,979:INFO:PyCaret optional dependencies:
2024-05-10 15:00:01,979:INFO:                shap: Not installed
2024-05-10 15:00:01,979:INFO:           interpret: Not installed
2024-05-10 15:00:01,979:INFO:                umap: Not installed
2024-05-10 15:00:01,979:INFO:     ydata_profiling: Not installed
2024-05-10 15:00:01,979:INFO:  explainerdashboard: Not installed
2024-05-10 15:00:01,979:INFO:             autoviz: Not installed
2024-05-10 15:00:01,979:INFO:           fairlearn: Not installed
2024-05-10 15:00:01,979:INFO:          deepchecks: Not installed
2024-05-10 15:00:01,979:INFO:             xgboost: Not installed
2024-05-10 15:00:01,979:INFO:            catboost: Not installed
2024-05-10 15:00:01,979:INFO:              kmodes: Not installed
2024-05-10 15:00:01,979:INFO:             mlxtend: Not installed
2024-05-10 15:00:01,979:INFO:       statsforecast: Not installed
2024-05-10 15:00:01,979:INFO:        tune_sklearn: Not installed
2024-05-10 15:00:01,979:INFO:                 ray: Not installed
2024-05-10 15:00:01,979:INFO:            hyperopt: Not installed
2024-05-10 15:00:01,979:INFO:              optuna: Not installed
2024-05-10 15:00:01,979:INFO:               skopt: Not installed
2024-05-10 15:00:01,979:INFO:              mlflow: Not installed
2024-05-10 15:00:01,979:INFO:              gradio: Not installed
2024-05-10 15:00:01,979:INFO:             fastapi: Not installed
2024-05-10 15:00:01,979:INFO:             uvicorn: Not installed
2024-05-10 15:00:01,979:INFO:              m2cgen: Not installed
2024-05-10 15:00:01,979:INFO:           evidently: Not installed
2024-05-10 15:00:01,979:INFO:               fugue: Not installed
2024-05-10 15:00:01,979:INFO:           streamlit: 1.32.0
2024-05-10 15:00:01,979:INFO:             prophet: Not installed
2024-05-10 15:00:01,979:INFO:None
2024-05-10 15:00:01,979:INFO:Set up data.
2024-05-10 15:00:01,982:INFO:Set up folding strategy.
2024-05-10 15:00:01,982:INFO:Set up train/test split.
2024-05-10 15:00:01,984:INFO:Set up index.
2024-05-10 15:00:01,984:INFO:Assigning column types.
2024-05-10 15:00:01,985:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 15:00:01,985:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 15:00:01,988:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:00:01,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,016:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,034:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,035:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,037:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,039:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,063:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,082:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,082:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,083:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 15:00:02,085:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,087:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,111:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,130:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,130:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,133:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,135:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,179:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,179:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,179:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 15:00:02,183:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,208:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,230:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,255:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,276:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,277:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,277:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,277:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 15:00:02,306:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,326:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,326:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,326:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,356:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,375:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,375:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,376:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,376:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 15:00:02,405:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,426:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,454:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:02,473:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,473:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,473:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 15:00:02,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:02,573:INFO:Preparing preprocessing pipeline...
2024-05-10 15:00:02,573:INFO:Set up simple imputation.
2024-05-10 15:00:02,573:INFO:Set up polynomial features.
2024-05-10 15:00:02,573:INFO:Set up removing outliers.
2024-05-10 15:00:02,573:INFO:Set up feature normalization.
2024-05-10 15:00:02,574:INFO:Set up column name cleaning.
2024-05-10 15:00:02,667:INFO:Finished creating preprocessing pipeline.
2024-05-10 15:00:02,670:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_co2(ppm)',
                                             'average_illumination(lux)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 15:00:02,670:INFO:Creating final display dataframe.
2024-05-10 15:00:02,986:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 3)
4        Transformed data shape          (579, 6)
5   Transformed train set shape          (399, 6)
6    Transformed test set shape          (180, 6)
7              Numeric features                 2
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              0878
2024-05-10 15:00:03,071:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:03,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:03,121:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:03,122:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:03,122:INFO:setup() successfully completed in 1.15s...............
2024-05-10 15:00:03,122:INFO:Initializing compare_models()
2024-05-10 15:00:03,122:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 15:00:03,122:INFO:Checking exceptions
2024-05-10 15:00:03,123:INFO:Preparing display monitor
2024-05-10 15:00:03,138:INFO:Initializing Linear Regression
2024-05-10 15:00:03,138:INFO:Total runtime is 2.5431315104166665e-06 minutes
2024-05-10 15:00:03,139:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:03,140:INFO:Initializing create_model()
2024-05-10 15:00:03,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:03,140:INFO:Checking exceptions
2024-05-10 15:00:03,140:INFO:Importing libraries
2024-05-10 15:00:03,140:INFO:Copying training dataset
2024-05-10 15:00:03,142:INFO:Defining folds
2024-05-10 15:00:03,142:INFO:Declaring metric variables
2024-05-10 15:00:03,143:INFO:Importing untrained model
2024-05-10 15:00:03,145:INFO:Linear Regression Imported successfully
2024-05-10 15:00:03,150:INFO:Starting cross validation
2024-05-10 15:00:03,156:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:03,344:INFO:Calculating mean and std
2024-05-10 15:00:03,344:INFO:Creating metrics dataframe
2024-05-10 15:00:03,346:INFO:Uploading results into container
2024-05-10 15:00:03,346:INFO:Uploading model into container now
2024-05-10 15:00:03,347:INFO:_master_model_container: 1
2024-05-10 15:00:03,347:INFO:_display_container: 2
2024-05-10 15:00:03,347:INFO:LinearRegression(n_jobs=-1)
2024-05-10 15:00:03,347:INFO:create_model() successfully completed......................................
2024-05-10 15:00:03,455:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:03,455:INFO:Creating metrics dataframe
2024-05-10 15:00:03,459:INFO:Initializing Lasso Regression
2024-05-10 15:00:03,459:INFO:Total runtime is 0.005353717009226482 minutes
2024-05-10 15:00:03,460:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:03,461:INFO:Initializing create_model()
2024-05-10 15:00:03,461:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:03,461:INFO:Checking exceptions
2024-05-10 15:00:03,461:INFO:Importing libraries
2024-05-10 15:00:03,461:INFO:Copying training dataset
2024-05-10 15:00:03,463:INFO:Defining folds
2024-05-10 15:00:03,463:INFO:Declaring metric variables
2024-05-10 15:00:03,465:INFO:Importing untrained model
2024-05-10 15:00:03,467:INFO:Lasso Regression Imported successfully
2024-05-10 15:00:03,470:INFO:Starting cross validation
2024-05-10 15:00:03,475:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:03,653:INFO:Calculating mean and std
2024-05-10 15:00:03,653:INFO:Creating metrics dataframe
2024-05-10 15:00:03,654:INFO:Uploading results into container
2024-05-10 15:00:03,655:INFO:Uploading model into container now
2024-05-10 15:00:03,655:INFO:_master_model_container: 2
2024-05-10 15:00:03,655:INFO:_display_container: 2
2024-05-10 15:00:03,655:INFO:Lasso(random_state=123)
2024-05-10 15:00:03,655:INFO:create_model() successfully completed......................................
2024-05-10 15:00:03,759:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:03,759:INFO:Creating metrics dataframe
2024-05-10 15:00:03,764:INFO:Initializing Ridge Regression
2024-05-10 15:00:03,764:INFO:Total runtime is 0.010437365372975668 minutes
2024-05-10 15:00:03,766:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:03,766:INFO:Initializing create_model()
2024-05-10 15:00:03,766:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:03,766:INFO:Checking exceptions
2024-05-10 15:00:03,766:INFO:Importing libraries
2024-05-10 15:00:03,766:INFO:Copying training dataset
2024-05-10 15:00:03,768:INFO:Defining folds
2024-05-10 15:00:03,768:INFO:Declaring metric variables
2024-05-10 15:00:03,770:INFO:Importing untrained model
2024-05-10 15:00:03,772:INFO:Ridge Regression Imported successfully
2024-05-10 15:00:03,775:INFO:Starting cross validation
2024-05-10 15:00:03,779:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:03,970:INFO:Calculating mean and std
2024-05-10 15:00:03,971:INFO:Creating metrics dataframe
2024-05-10 15:00:03,972:INFO:Uploading results into container
2024-05-10 15:00:03,972:INFO:Uploading model into container now
2024-05-10 15:00:03,973:INFO:_master_model_container: 3
2024-05-10 15:00:03,973:INFO:_display_container: 2
2024-05-10 15:00:03,973:INFO:Ridge(random_state=123)
2024-05-10 15:00:03,973:INFO:create_model() successfully completed......................................
2024-05-10 15:00:04,078:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:04,078:INFO:Creating metrics dataframe
2024-05-10 15:00:04,083:INFO:Initializing Elastic Net
2024-05-10 15:00:04,083:INFO:Total runtime is 0.015753304958343508 minutes
2024-05-10 15:00:04,085:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:04,085:INFO:Initializing create_model()
2024-05-10 15:00:04,085:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:04,085:INFO:Checking exceptions
2024-05-10 15:00:04,085:INFO:Importing libraries
2024-05-10 15:00:04,085:INFO:Copying training dataset
2024-05-10 15:00:04,087:INFO:Defining folds
2024-05-10 15:00:04,087:INFO:Declaring metric variables
2024-05-10 15:00:04,089:INFO:Importing untrained model
2024-05-10 15:00:04,090:INFO:Elastic Net Imported successfully
2024-05-10 15:00:04,093:INFO:Starting cross validation
2024-05-10 15:00:04,098:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:04,288:INFO:Calculating mean and std
2024-05-10 15:00:04,289:INFO:Creating metrics dataframe
2024-05-10 15:00:04,291:INFO:Uploading results into container
2024-05-10 15:00:04,291:INFO:Uploading model into container now
2024-05-10 15:00:04,292:INFO:_master_model_container: 4
2024-05-10 15:00:04,292:INFO:_display_container: 2
2024-05-10 15:00:04,292:INFO:ElasticNet(random_state=123)
2024-05-10 15:00:04,292:INFO:create_model() successfully completed......................................
2024-05-10 15:00:04,402:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:04,402:INFO:Creating metrics dataframe
2024-05-10 15:00:04,407:INFO:Initializing Least Angle Regression
2024-05-10 15:00:04,407:INFO:Total runtime is 0.021156708399454754 minutes
2024-05-10 15:00:04,409:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:04,409:INFO:Initializing create_model()
2024-05-10 15:00:04,410:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:04,410:INFO:Checking exceptions
2024-05-10 15:00:04,410:INFO:Importing libraries
2024-05-10 15:00:04,410:INFO:Copying training dataset
2024-05-10 15:00:04,412:INFO:Defining folds
2024-05-10 15:00:04,413:INFO:Declaring metric variables
2024-05-10 15:00:04,415:INFO:Importing untrained model
2024-05-10 15:00:04,417:INFO:Least Angle Regression Imported successfully
2024-05-10 15:00:04,421:INFO:Starting cross validation
2024-05-10 15:00:04,425:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:04,624:INFO:Calculating mean and std
2024-05-10 15:00:04,625:INFO:Creating metrics dataframe
2024-05-10 15:00:04,627:INFO:Uploading results into container
2024-05-10 15:00:04,628:INFO:Uploading model into container now
2024-05-10 15:00:04,628:INFO:_master_model_container: 5
2024-05-10 15:00:04,628:INFO:_display_container: 2
2024-05-10 15:00:04,629:INFO:Lars(random_state=123)
2024-05-10 15:00:04,629:INFO:create_model() successfully completed......................................
2024-05-10 15:00:04,735:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:04,735:INFO:Creating metrics dataframe
2024-05-10 15:00:04,740:INFO:Initializing Lasso Least Angle Regression
2024-05-10 15:00:04,740:INFO:Total runtime is 0.026708519458770754 minutes
2024-05-10 15:00:04,742:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:04,742:INFO:Initializing create_model()
2024-05-10 15:00:04,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:04,742:INFO:Checking exceptions
2024-05-10 15:00:04,742:INFO:Importing libraries
2024-05-10 15:00:04,742:INFO:Copying training dataset
2024-05-10 15:00:04,744:INFO:Defining folds
2024-05-10 15:00:04,745:INFO:Declaring metric variables
2024-05-10 15:00:04,747:INFO:Importing untrained model
2024-05-10 15:00:04,749:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 15:00:04,753:INFO:Starting cross validation
2024-05-10 15:00:04,757:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:04,945:INFO:Calculating mean and std
2024-05-10 15:00:04,945:INFO:Creating metrics dataframe
2024-05-10 15:00:04,947:INFO:Uploading results into container
2024-05-10 15:00:04,947:INFO:Uploading model into container now
2024-05-10 15:00:04,948:INFO:_master_model_container: 6
2024-05-10 15:00:04,948:INFO:_display_container: 2
2024-05-10 15:00:04,948:INFO:LassoLars(random_state=123)
2024-05-10 15:00:04,948:INFO:create_model() successfully completed......................................
2024-05-10 15:00:05,054:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:05,054:INFO:Creating metrics dataframe
2024-05-10 15:00:05,059:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 15:00:05,059:INFO:Total runtime is 0.03202190399169922 minutes
2024-05-10 15:00:05,061:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:05,061:INFO:Initializing create_model()
2024-05-10 15:00:05,061:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:05,061:INFO:Checking exceptions
2024-05-10 15:00:05,061:INFO:Importing libraries
2024-05-10 15:00:05,061:INFO:Copying training dataset
2024-05-10 15:00:05,063:INFO:Defining folds
2024-05-10 15:00:05,063:INFO:Declaring metric variables
2024-05-10 15:00:05,065:INFO:Importing untrained model
2024-05-10 15:00:05,068:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 15:00:05,072:INFO:Starting cross validation
2024-05-10 15:00:05,076:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:05,256:INFO:Calculating mean and std
2024-05-10 15:00:05,257:INFO:Creating metrics dataframe
2024-05-10 15:00:05,258:INFO:Uploading results into container
2024-05-10 15:00:05,258:INFO:Uploading model into container now
2024-05-10 15:00:05,259:INFO:_master_model_container: 7
2024-05-10 15:00:05,259:INFO:_display_container: 2
2024-05-10 15:00:05,259:INFO:OrthogonalMatchingPursuit()
2024-05-10 15:00:05,259:INFO:create_model() successfully completed......................................
2024-05-10 15:00:05,365:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:05,365:INFO:Creating metrics dataframe
2024-05-10 15:00:05,370:INFO:Initializing Bayesian Ridge
2024-05-10 15:00:05,370:INFO:Total runtime is 0.03720246950785319 minutes
2024-05-10 15:00:05,372:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:05,372:INFO:Initializing create_model()
2024-05-10 15:00:05,372:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:05,372:INFO:Checking exceptions
2024-05-10 15:00:05,372:INFO:Importing libraries
2024-05-10 15:00:05,372:INFO:Copying training dataset
2024-05-10 15:00:05,375:INFO:Defining folds
2024-05-10 15:00:05,375:INFO:Declaring metric variables
2024-05-10 15:00:05,377:INFO:Importing untrained model
2024-05-10 15:00:05,379:INFO:Bayesian Ridge Imported successfully
2024-05-10 15:00:05,383:INFO:Starting cross validation
2024-05-10 15:00:05,388:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:05,576:INFO:Calculating mean and std
2024-05-10 15:00:05,577:INFO:Creating metrics dataframe
2024-05-10 15:00:05,578:INFO:Uploading results into container
2024-05-10 15:00:05,578:INFO:Uploading model into container now
2024-05-10 15:00:05,578:INFO:_master_model_container: 8
2024-05-10 15:00:05,578:INFO:_display_container: 2
2024-05-10 15:00:05,578:INFO:BayesianRidge()
2024-05-10 15:00:05,578:INFO:create_model() successfully completed......................................
2024-05-10 15:00:05,685:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:05,685:INFO:Creating metrics dataframe
2024-05-10 15:00:05,690:INFO:Initializing Passive Aggressive Regressor
2024-05-10 15:00:05,690:INFO:Total runtime is 0.042544039090474446 minutes
2024-05-10 15:00:05,692:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:05,692:INFO:Initializing create_model()
2024-05-10 15:00:05,692:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:05,692:INFO:Checking exceptions
2024-05-10 15:00:05,692:INFO:Importing libraries
2024-05-10 15:00:05,692:INFO:Copying training dataset
2024-05-10 15:00:05,695:INFO:Defining folds
2024-05-10 15:00:05,695:INFO:Declaring metric variables
2024-05-10 15:00:05,697:INFO:Importing untrained model
2024-05-10 15:00:05,699:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 15:00:05,703:INFO:Starting cross validation
2024-05-10 15:00:05,707:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:05,886:INFO:Calculating mean and std
2024-05-10 15:00:05,886:INFO:Creating metrics dataframe
2024-05-10 15:00:05,888:INFO:Uploading results into container
2024-05-10 15:00:05,888:INFO:Uploading model into container now
2024-05-10 15:00:05,888:INFO:_master_model_container: 9
2024-05-10 15:00:05,889:INFO:_display_container: 2
2024-05-10 15:00:05,889:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 15:00:05,889:INFO:create_model() successfully completed......................................
2024-05-10 15:00:05,994:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:05,994:INFO:Creating metrics dataframe
2024-05-10 15:00:05,999:INFO:Initializing Huber Regressor
2024-05-10 15:00:05,999:INFO:Total runtime is 0.0476971427599589 minutes
2024-05-10 15:00:06,001:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:06,001:INFO:Initializing create_model()
2024-05-10 15:00:06,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:06,002:INFO:Checking exceptions
2024-05-10 15:00:06,002:INFO:Importing libraries
2024-05-10 15:00:06,002:INFO:Copying training dataset
2024-05-10 15:00:06,004:INFO:Defining folds
2024-05-10 15:00:06,004:INFO:Declaring metric variables
2024-05-10 15:00:06,005:INFO:Importing untrained model
2024-05-10 15:00:06,007:INFO:Huber Regressor Imported successfully
2024-05-10 15:00:06,010:INFO:Starting cross validation
2024-05-10 15:00:06,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:06,242:INFO:Calculating mean and std
2024-05-10 15:00:06,243:INFO:Creating metrics dataframe
2024-05-10 15:00:06,244:INFO:Uploading results into container
2024-05-10 15:00:06,244:INFO:Uploading model into container now
2024-05-10 15:00:06,244:INFO:_master_model_container: 10
2024-05-10 15:00:06,244:INFO:_display_container: 2
2024-05-10 15:00:06,244:INFO:HuberRegressor()
2024-05-10 15:00:06,244:INFO:create_model() successfully completed......................................
2024-05-10 15:00:06,350:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:06,350:INFO:Creating metrics dataframe
2024-05-10 15:00:06,356:INFO:Initializing K Neighbors Regressor
2024-05-10 15:00:06,356:INFO:Total runtime is 0.053639133771260575 minutes
2024-05-10 15:00:06,358:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:06,358:INFO:Initializing create_model()
2024-05-10 15:00:06,358:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:06,358:INFO:Checking exceptions
2024-05-10 15:00:06,358:INFO:Importing libraries
2024-05-10 15:00:06,358:INFO:Copying training dataset
2024-05-10 15:00:06,360:INFO:Defining folds
2024-05-10 15:00:06,360:INFO:Declaring metric variables
2024-05-10 15:00:06,362:INFO:Importing untrained model
2024-05-10 15:00:06,364:INFO:K Neighbors Regressor Imported successfully
2024-05-10 15:00:06,367:INFO:Starting cross validation
2024-05-10 15:00:06,372:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:06,570:INFO:Calculating mean and std
2024-05-10 15:00:06,570:INFO:Creating metrics dataframe
2024-05-10 15:00:06,572:INFO:Uploading results into container
2024-05-10 15:00:06,572:INFO:Uploading model into container now
2024-05-10 15:00:06,572:INFO:_master_model_container: 11
2024-05-10 15:00:06,572:INFO:_display_container: 2
2024-05-10 15:00:06,573:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 15:00:06,573:INFO:create_model() successfully completed......................................
2024-05-10 15:00:06,680:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:06,680:INFO:Creating metrics dataframe
2024-05-10 15:00:06,686:INFO:Initializing Decision Tree Regressor
2024-05-10 15:00:06,686:INFO:Total runtime is 0.05913423299789428 minutes
2024-05-10 15:00:06,687:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:06,687:INFO:Initializing create_model()
2024-05-10 15:00:06,688:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:06,688:INFO:Checking exceptions
2024-05-10 15:00:06,688:INFO:Importing libraries
2024-05-10 15:00:06,688:INFO:Copying training dataset
2024-05-10 15:00:06,690:INFO:Defining folds
2024-05-10 15:00:06,690:INFO:Declaring metric variables
2024-05-10 15:00:06,691:INFO:Importing untrained model
2024-05-10 15:00:06,693:INFO:Decision Tree Regressor Imported successfully
2024-05-10 15:00:06,697:INFO:Starting cross validation
2024-05-10 15:00:06,704:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:06,889:INFO:Calculating mean and std
2024-05-10 15:00:06,889:INFO:Creating metrics dataframe
2024-05-10 15:00:06,891:INFO:Uploading results into container
2024-05-10 15:00:06,891:INFO:Uploading model into container now
2024-05-10 15:00:06,891:INFO:_master_model_container: 12
2024-05-10 15:00:06,892:INFO:_display_container: 2
2024-05-10 15:00:06,892:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 15:00:06,892:INFO:create_model() successfully completed......................................
2024-05-10 15:00:07,009:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:07,009:INFO:Creating metrics dataframe
2024-05-10 15:00:07,015:INFO:Initializing Random Forest Regressor
2024-05-10 15:00:07,015:INFO:Total runtime is 0.06462373336156209 minutes
2024-05-10 15:00:07,018:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:07,018:INFO:Initializing create_model()
2024-05-10 15:00:07,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:07,018:INFO:Checking exceptions
2024-05-10 15:00:07,018:INFO:Importing libraries
2024-05-10 15:00:07,019:INFO:Copying training dataset
2024-05-10 15:00:07,022:INFO:Defining folds
2024-05-10 15:00:07,022:INFO:Declaring metric variables
2024-05-10 15:00:07,026:INFO:Importing untrained model
2024-05-10 15:00:07,030:INFO:Random Forest Regressor Imported successfully
2024-05-10 15:00:07,037:INFO:Starting cross validation
2024-05-10 15:00:07,041:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:07,417:INFO:Calculating mean and std
2024-05-10 15:00:07,418:INFO:Creating metrics dataframe
2024-05-10 15:00:07,421:INFO:Uploading results into container
2024-05-10 15:00:07,421:INFO:Uploading model into container now
2024-05-10 15:00:07,421:INFO:_master_model_container: 13
2024-05-10 15:00:07,422:INFO:_display_container: 2
2024-05-10 15:00:07,422:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:07,422:INFO:create_model() successfully completed......................................
2024-05-10 15:00:07,526:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:07,526:INFO:Creating metrics dataframe
2024-05-10 15:00:07,531:INFO:Initializing Extra Trees Regressor
2024-05-10 15:00:07,531:INFO:Total runtime is 0.0732282797495524 minutes
2024-05-10 15:00:07,533:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:07,534:INFO:Initializing create_model()
2024-05-10 15:00:07,534:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:07,534:INFO:Checking exceptions
2024-05-10 15:00:07,534:INFO:Importing libraries
2024-05-10 15:00:07,534:INFO:Copying training dataset
2024-05-10 15:00:07,536:INFO:Defining folds
2024-05-10 15:00:07,536:INFO:Declaring metric variables
2024-05-10 15:00:07,538:INFO:Importing untrained model
2024-05-10 15:00:07,540:INFO:Extra Trees Regressor Imported successfully
2024-05-10 15:00:07,543:INFO:Starting cross validation
2024-05-10 15:00:07,547:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:07,893:INFO:Calculating mean and std
2024-05-10 15:00:07,894:INFO:Creating metrics dataframe
2024-05-10 15:00:07,895:INFO:Uploading results into container
2024-05-10 15:00:07,896:INFO:Uploading model into container now
2024-05-10 15:00:07,896:INFO:_master_model_container: 14
2024-05-10 15:00:07,896:INFO:_display_container: 2
2024-05-10 15:00:07,896:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:07,896:INFO:create_model() successfully completed......................................
2024-05-10 15:00:08,009:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:08,009:INFO:Creating metrics dataframe
2024-05-10 15:00:08,015:INFO:Initializing AdaBoost Regressor
2024-05-10 15:00:08,015:INFO:Total runtime is 0.08129333655039468 minutes
2024-05-10 15:00:08,017:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:08,017:INFO:Initializing create_model()
2024-05-10 15:00:08,017:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:08,017:INFO:Checking exceptions
2024-05-10 15:00:08,017:INFO:Importing libraries
2024-05-10 15:00:08,017:INFO:Copying training dataset
2024-05-10 15:00:08,020:INFO:Defining folds
2024-05-10 15:00:08,020:INFO:Declaring metric variables
2024-05-10 15:00:08,022:INFO:Importing untrained model
2024-05-10 15:00:08,024:INFO:AdaBoost Regressor Imported successfully
2024-05-10 15:00:08,027:INFO:Starting cross validation
2024-05-10 15:00:08,031:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:08,253:INFO:Calculating mean and std
2024-05-10 15:00:08,254:INFO:Creating metrics dataframe
2024-05-10 15:00:08,255:INFO:Uploading results into container
2024-05-10 15:00:08,256:INFO:Uploading model into container now
2024-05-10 15:00:08,256:INFO:_master_model_container: 15
2024-05-10 15:00:08,256:INFO:_display_container: 2
2024-05-10 15:00:08,256:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 15:00:08,256:INFO:create_model() successfully completed......................................
2024-05-10 15:00:08,359:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:08,359:INFO:Creating metrics dataframe
2024-05-10 15:00:08,364:INFO:Initializing Gradient Boosting Regressor
2024-05-10 15:00:08,364:INFO:Total runtime is 0.087114147345225 minutes
2024-05-10 15:00:08,366:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:08,366:INFO:Initializing create_model()
2024-05-10 15:00:08,366:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:08,366:INFO:Checking exceptions
2024-05-10 15:00:08,366:INFO:Importing libraries
2024-05-10 15:00:08,367:INFO:Copying training dataset
2024-05-10 15:00:08,369:INFO:Defining folds
2024-05-10 15:00:08,369:INFO:Declaring metric variables
2024-05-10 15:00:08,371:INFO:Importing untrained model
2024-05-10 15:00:08,373:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 15:00:08,376:INFO:Starting cross validation
2024-05-10 15:00:08,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:08,667:INFO:Calculating mean and std
2024-05-10 15:00:08,668:INFO:Creating metrics dataframe
2024-05-10 15:00:08,670:INFO:Uploading results into container
2024-05-10 15:00:08,670:INFO:Uploading model into container now
2024-05-10 15:00:08,671:INFO:_master_model_container: 16
2024-05-10 15:00:08,671:INFO:_display_container: 2
2024-05-10 15:00:08,671:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 15:00:08,671:INFO:create_model() successfully completed......................................
2024-05-10 15:00:08,777:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:08,777:INFO:Creating metrics dataframe
2024-05-10 15:00:08,783:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 15:00:08,783:INFO:Total runtime is 0.09408662319183349 minutes
2024-05-10 15:00:08,785:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:08,785:INFO:Initializing create_model()
2024-05-10 15:00:08,785:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:08,785:INFO:Checking exceptions
2024-05-10 15:00:08,785:INFO:Importing libraries
2024-05-10 15:00:08,785:INFO:Copying training dataset
2024-05-10 15:00:08,787:INFO:Defining folds
2024-05-10 15:00:08,787:INFO:Declaring metric variables
2024-05-10 15:00:08,789:INFO:Importing untrained model
2024-05-10 15:00:08,791:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 15:00:08,794:INFO:Starting cross validation
2024-05-10 15:00:08,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:09,533:INFO:Calculating mean and std
2024-05-10 15:00:09,534:INFO:Creating metrics dataframe
2024-05-10 15:00:09,536:INFO:Uploading results into container
2024-05-10 15:00:09,536:INFO:Uploading model into container now
2024-05-10 15:00:09,537:INFO:_master_model_container: 17
2024-05-10 15:00:09,537:INFO:_display_container: 2
2024-05-10 15:00:09,537:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:09,537:INFO:create_model() successfully completed......................................
2024-05-10 15:00:09,644:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:09,644:INFO:Creating metrics dataframe
2024-05-10 15:00:09,649:INFO:Initializing Dummy Regressor
2024-05-10 15:00:09,649:INFO:Total runtime is 0.10853206316630044 minutes
2024-05-10 15:00:09,651:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:09,651:INFO:Initializing create_model()
2024-05-10 15:00:09,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d31d0d3a0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:09,651:INFO:Checking exceptions
2024-05-10 15:00:09,651:INFO:Importing libraries
2024-05-10 15:00:09,652:INFO:Copying training dataset
2024-05-10 15:00:09,654:INFO:Defining folds
2024-05-10 15:00:09,654:INFO:Declaring metric variables
2024-05-10 15:00:09,656:INFO:Importing untrained model
2024-05-10 15:00:09,658:INFO:Dummy Regressor Imported successfully
2024-05-10 15:00:09,663:INFO:Starting cross validation
2024-05-10 15:00:09,669:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:09,853:INFO:Calculating mean and std
2024-05-10 15:00:09,854:INFO:Creating metrics dataframe
2024-05-10 15:00:09,855:INFO:Uploading results into container
2024-05-10 15:00:09,856:INFO:Uploading model into container now
2024-05-10 15:00:09,856:INFO:_master_model_container: 18
2024-05-10 15:00:09,856:INFO:_display_container: 2
2024-05-10 15:00:09,856:INFO:DummyRegressor()
2024-05-10 15:00:09,856:INFO:create_model() successfully completed......................................
2024-05-10 15:00:09,964:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:09,964:INFO:Creating metrics dataframe
2024-05-10 15:00:09,971:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 15:00:09,975:INFO:Initializing create_model()
2024-05-10 15:00:09,975:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:09,975:INFO:Checking exceptions
2024-05-10 15:00:09,976:INFO:Importing libraries
2024-05-10 15:00:09,976:INFO:Copying training dataset
2024-05-10 15:00:09,978:INFO:Defining folds
2024-05-10 15:00:09,978:INFO:Declaring metric variables
2024-05-10 15:00:09,978:INFO:Importing untrained model
2024-05-10 15:00:09,978:INFO:Declaring custom model
2024-05-10 15:00:09,978:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 15:00:09,983:INFO:Cross validation set to False
2024-05-10 15:00:09,983:INFO:Fitting Model
2024-05-10 15:00:10,058:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-10 15:00:10,059:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000783 seconds.
2024-05-10 15:00:10,059:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-10 15:00:10,059:INFO:[LightGBM] [Info] Total Bins 564
2024-05-10 15:00:10,060:INFO:[LightGBM] [Info] Number of data points in the train set: 399, number of used features: 5
2024-05-10 15:00:10,060:INFO:[LightGBM] [Info] Start training from score 8.417540
2024-05-10 15:00:10,062:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,063:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,064:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,065:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,067:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,068:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,069:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,070:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,071:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,072:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,073:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,074:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,075:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,076:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,077:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,078:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,079:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,080:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,081:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,082:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,084:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,085:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,087:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,088:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,089:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,090:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,091:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,092:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,093:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,094:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,095:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,097:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,098:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,100:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,101:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,102:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,103:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,104:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,105:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,106:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,107:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,108:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,109:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,110:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,111:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,112:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,113:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,114:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,115:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,117:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,118:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,119:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,120:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,121:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,122:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,123:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,124:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,125:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,126:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,127:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,128:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,129:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,130:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,131:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,133:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,134:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,135:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,136:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,137:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,138:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,139:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,140:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,141:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,142:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,143:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,144:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,145:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,147:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,148:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,149:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,151:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,152:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,153:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,154:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,155:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,156:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,157:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,158:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,159:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,160:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,161:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,162:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,163:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,165:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,166:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,167:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,168:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:10,170:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:10,170:INFO:create_model() successfully completed......................................
2024-05-10 15:00:10,298:INFO:_master_model_container: 18
2024-05-10 15:00:10,298:INFO:_display_container: 2
2024-05-10 15:00:10,299:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:10,299:INFO:compare_models() successfully completed......................................
2024-05-10 15:00:10,300:INFO:Initializing tune_model()
2024-05-10 15:00:10,300:INFO:tune_model(estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>)
2024-05-10 15:00:10,300:INFO:Checking exceptions
2024-05-10 15:00:10,317:INFO:Copying training dataset
2024-05-10 15:00:10,318:INFO:Checking base model
2024-05-10 15:00:10,319:INFO:Base model : Light Gradient Boosting Machine
2024-05-10 15:00:10,322:INFO:Declaring metric variables
2024-05-10 15:00:10,326:INFO:Defining Hyperparameters
2024-05-10 15:00:10,445:INFO:Tuning with n_jobs=-1
2024-05-10 15:00:10,445:INFO:Initializing RandomizedSearchCV
2024-05-10 15:00:13,080:INFO:best_params: {'actual_estimator__reg_lambda': 0.1, 'actual_estimator__reg_alpha': 0.0005, 'actual_estimator__num_leaves': 90, 'actual_estimator__n_estimators': 90, 'actual_estimator__min_split_gain': 0.4, 'actual_estimator__min_child_samples': 66, 'actual_estimator__learning_rate': 0.1, 'actual_estimator__feature_fraction': 0.5, 'actual_estimator__bagging_freq': 6, 'actual_estimator__bagging_fraction': 0.7}
2024-05-10 15:00:13,080:INFO:Hyperparameter search completed
2024-05-10 15:00:13,080:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:13,081:INFO:Initializing create_model()
2024-05-10 15:00:13,081:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32ab5040>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'reg_lambda': 0.1, 'reg_alpha': 0.0005, 'num_leaves': 90, 'n_estimators': 90, 'min_split_gain': 0.4, 'min_child_samples': 66, 'learning_rate': 0.1, 'feature_fraction': 0.5, 'bagging_freq': 6, 'bagging_fraction': 0.7})
2024-05-10 15:00:13,081:INFO:Checking exceptions
2024-05-10 15:00:13,081:INFO:Importing libraries
2024-05-10 15:00:13,081:INFO:Copying training dataset
2024-05-10 15:00:13,085:INFO:Defining folds
2024-05-10 15:00:13,085:INFO:Declaring metric variables
2024-05-10 15:00:13,087:INFO:Importing untrained model
2024-05-10 15:00:13,087:INFO:Declaring custom model
2024-05-10 15:00:13,091:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 15:00:13,095:INFO:Starting cross validation
2024-05-10 15:00:13,101:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:13,350:INFO:Calculating mean and std
2024-05-10 15:00:13,351:INFO:Creating metrics dataframe
2024-05-10 15:00:13,354:INFO:Finalizing model
2024-05-10 15:00:13,436:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 15:00:13,436:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 15:00:13,436:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 15:00:13,437:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-10 15:00:13,437:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 15:00:13,437:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 15:00:13,437:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 15:00:13,438:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000960 seconds.
2024-05-10 15:00:13,438:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-10 15:00:13,439:INFO:[LightGBM] [Info] Total Bins 564
2024-05-10 15:00:13,439:INFO:[LightGBM] [Info] Number of data points in the train set: 399, number of used features: 5
2024-05-10 15:00:13,439:INFO:[LightGBM] [Info] Start training from score 8.417540
2024-05-10 15:00:13,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,447:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,449:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,451:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,455:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,457:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,458:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,460:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:13,461:INFO:[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements
2024-05-10 15:00:13,466:INFO:Uploading results into container
2024-05-10 15:00:13,467:INFO:Uploading model into container now
2024-05-10 15:00:13,467:INFO:_master_model_container: 19
2024-05-10 15:00:13,467:INFO:_display_container: 3
2024-05-10 15:00:13,468:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1)
2024-05-10 15:00:13,468:INFO:create_model() successfully completed......................................
2024-05-10 15:00:13,575:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:13,575:INFO:choose_better activated
2024-05-10 15:00:13,578:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:13,578:INFO:Initializing create_model()
2024-05-10 15:00:13,578:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:13,578:INFO:Checking exceptions
2024-05-10 15:00:13,579:INFO:Importing libraries
2024-05-10 15:00:13,579:INFO:Copying training dataset
2024-05-10 15:00:13,581:INFO:Defining folds
2024-05-10 15:00:13,581:INFO:Declaring metric variables
2024-05-10 15:00:13,582:INFO:Importing untrained model
2024-05-10 15:00:13,582:INFO:Declaring custom model
2024-05-10 15:00:13,582:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 15:00:13,582:INFO:Starting cross validation
2024-05-10 15:00:13,586:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:14,299:INFO:Calculating mean and std
2024-05-10 15:00:14,300:INFO:Creating metrics dataframe
2024-05-10 15:00:14,301:INFO:Finalizing model
2024-05-10 15:00:14,379:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2024-05-10 15:00:14,380:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001087 seconds.
2024-05-10 15:00:14,380:INFO:You can set `force_col_wise=true` to remove the overhead.
2024-05-10 15:00:14,380:INFO:[LightGBM] [Info] Total Bins 564
2024-05-10 15:00:14,381:INFO:[LightGBM] [Info] Number of data points in the train set: 399, number of used features: 5
2024-05-10 15:00:14,381:INFO:[LightGBM] [Info] Start training from score 8.417540
2024-05-10 15:00:14,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,391:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,395:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,409:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,411:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,436:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,441:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,442:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,443:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,444:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,445:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,446:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,448:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,450:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,452:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,453:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,454:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,456:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,457:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,458:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,459:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,460:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,461:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,462:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,463:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,465:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,466:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,467:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,468:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,469:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,470:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,471:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,472:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,473:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,474:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,475:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,476:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,477:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,478:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,479:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,480:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,482:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,483:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,485:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,486:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,487:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,488:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2024-05-10 15:00:14,490:INFO:Uploading results into container
2024-05-10 15:00:14,490:INFO:Uploading model into container now
2024-05-10 15:00:14,490:INFO:_master_model_container: 20
2024-05-10 15:00:14,490:INFO:_display_container: 4
2024-05-10 15:00:14,491:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:14,491:INFO:create_model() successfully completed......................................
2024-05-10 15:00:14,597:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:14,598:INFO:LGBMRegressor(n_jobs=-1, random_state=123) result for R2 is 0.6391
2024-05-10 15:00:14,599:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1) result for R2 is 0.6434
2024-05-10 15:00:14,599:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1) is best model
2024-05-10 15:00:14,599:INFO:choose_better completed
2024-05-10 15:00:14,605:INFO:_master_model_container: 20
2024-05-10 15:00:14,605:INFO:_display_container: 3
2024-05-10 15:00:14,606:INFO:LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1)
2024-05-10 15:00:14,606:INFO:tune_model() successfully completed......................................
2024-05-10 15:00:14,715:INFO:Initializing evaluate_model()
2024-05-10 15:00:14,715:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 15:00:14,721:INFO:Initializing plot_model()
2024-05-10 15:00:14,721:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, system=True)
2024-05-10 15:00:14,721:INFO:Checking exceptions
2024-05-10 15:00:14,722:INFO:Preloading libraries
2024-05-10 15:00:14,723:INFO:Copying training dataset
2024-05-10 15:00:14,723:INFO:Plot type: pipeline
2024-05-10 15:00:14,816:INFO:Visual Rendered Successfully
2024-05-10 15:00:14,926:INFO:plot_model() successfully completed......................................
2024-05-10 15:00:21,418:INFO:Initializing plot_model()
2024-05-10 15:00:21,419:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=LGBMRegressor(bagging_fraction=0.7, bagging_freq=6, feature_fraction=0.5,
              min_child_samples=66, min_split_gain=0.4, n_estimators=90,
              n_jobs=-1, num_leaves=90, random_state=123, reg_alpha=0.0005,
              reg_lambda=0.1), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4dbc1a00>, system=True)
2024-05-10 15:00:21,419:INFO:Checking exceptions
2024-05-10 15:00:21,420:INFO:Preloading libraries
2024-05-10 15:00:21,421:INFO:Copying training dataset
2024-05-10 15:00:21,421:INFO:Plot type: residuals
2024-05-10 15:00:21,761:INFO:Fitting Model
2024-05-10 15:00:21,761:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 15:00:21,761:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 15:00:21,761:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 15:00:21,763:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 15:00:21,763:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 15:00:21,763:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 15:00:21,779:INFO:Scoring test/hold-out set
2024-05-10 15:00:21,779:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 15:00:21,780:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 15:00:21,780:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 15:00:21,781:INFO:[LightGBM] [Warning] feature_fraction is set=0.5, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.5
2024-05-10 15:00:21,781:INFO:[LightGBM] [Warning] bagging_freq is set=6, subsample_freq=0 will be ignored. Current value: bagging_freq=6
2024-05-10 15:00:21,781:INFO:[LightGBM] [Warning] bagging_fraction is set=0.7, subsample=1.0 will be ignored. Current value: bagging_fraction=0.7
2024-05-10 15:00:21,959:INFO:Visual Rendered Successfully
2024-05-10 15:00:22,083:INFO:plot_model() successfully completed......................................
2024-05-10 15:00:32,448:INFO:PyCaret RegressionExperiment
2024-05-10 15:00:32,448:INFO:Logging name: reg-default-name
2024-05-10 15:00:32,448:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 15:00:32,448:INFO:version 3.3.2
2024-05-10 15:00:32,448:INFO:Initializing setup()
2024-05-10 15:00:32,448:INFO:self.USI: ee6f
2024-05-10 15:00:32,448:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 15:00:32,448:INFO:Checking environment
2024-05-10 15:00:32,448:INFO:python_version: 3.9.18
2024-05-10 15:00:32,448:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 15:00:32,448:INFO:machine: x86_64
2024-05-10 15:00:32,448:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:00:32,448:INFO:Memory: svmem(total=16429797376, available=5612589056, percent=65.8, used=9672654848, free=3482058752, active=7121977344, inactive=4382289920, buffers=172032000, cached=3103051776, shared=798011392, slab=740294656)
2024-05-10 15:00:32,449:INFO:Physical Core: 12
2024-05-10 15:00:32,449:INFO:Logical Core: 16
2024-05-10 15:00:32,449:INFO:Checking libraries
2024-05-10 15:00:32,449:INFO:System:
2024-05-10 15:00:32,449:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 15:00:32,449:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 15:00:32,449:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:00:32,449:INFO:PyCaret required dependencies:
2024-05-10 15:00:32,449:INFO:                 pip: 23.3.1
2024-05-10 15:00:32,449:INFO:          setuptools: 68.2.2
2024-05-10 15:00:32,449:INFO:             pycaret: 3.3.2
2024-05-10 15:00:32,449:INFO:             IPython: 8.15.0
2024-05-10 15:00:32,449:INFO:          ipywidgets: 7.6.5
2024-05-10 15:00:32,449:INFO:                tqdm: 4.65.0
2024-05-10 15:00:32,449:INFO:               numpy: 1.26.4
2024-05-10 15:00:32,449:INFO:              pandas: 2.1.4
2024-05-10 15:00:32,449:INFO:              jinja2: 3.1.3
2024-05-10 15:00:32,449:INFO:               scipy: 1.11.4
2024-05-10 15:00:32,449:INFO:              joblib: 1.2.0
2024-05-10 15:00:32,449:INFO:             sklearn: 1.4.2
2024-05-10 15:00:32,449:INFO:                pyod: 1.1.3
2024-05-10 15:00:32,449:INFO:            imblearn: 0.12.2
2024-05-10 15:00:32,449:INFO:   category_encoders: 2.6.3
2024-05-10 15:00:32,449:INFO:            lightgbm: 4.3.0
2024-05-10 15:00:32,449:INFO:               numba: 0.59.1
2024-05-10 15:00:32,449:INFO:            requests: 2.31.0
2024-05-10 15:00:32,449:INFO:          matplotlib: 3.7.5
2024-05-10 15:00:32,449:INFO:          scikitplot: 0.3.7
2024-05-10 15:00:32,449:INFO:         yellowbrick: 1.5
2024-05-10 15:00:32,449:INFO:              plotly: 5.19.0
2024-05-10 15:00:32,449:INFO:    plotly-resampler: Not installed
2024-05-10 15:00:32,449:INFO:             kaleido: 0.2.1
2024-05-10 15:00:32,449:INFO:           schemdraw: 0.15
2024-05-10 15:00:32,449:INFO:         statsmodels: 0.14.0
2024-05-10 15:00:32,449:INFO:              sktime: 0.26.0
2024-05-10 15:00:32,449:INFO:               tbats: 1.1.3
2024-05-10 15:00:32,449:INFO:            pmdarima: 2.0.4
2024-05-10 15:00:32,449:INFO:              psutil: 5.9.0
2024-05-10 15:00:32,449:INFO:          markupsafe: 2.1.3
2024-05-10 15:00:32,449:INFO:             pickle5: Not installed
2024-05-10 15:00:32,449:INFO:         cloudpickle: 2.2.1
2024-05-10 15:00:32,449:INFO:         deprecation: 2.1.0
2024-05-10 15:00:32,449:INFO:              xxhash: 3.4.1
2024-05-10 15:00:32,449:INFO:           wurlitzer: 3.0.2
2024-05-10 15:00:32,449:INFO:PyCaret optional dependencies:
2024-05-10 15:00:32,449:INFO:                shap: Not installed
2024-05-10 15:00:32,449:INFO:           interpret: Not installed
2024-05-10 15:00:32,449:INFO:                umap: Not installed
2024-05-10 15:00:32,449:INFO:     ydata_profiling: Not installed
2024-05-10 15:00:32,449:INFO:  explainerdashboard: Not installed
2024-05-10 15:00:32,449:INFO:             autoviz: Not installed
2024-05-10 15:00:32,449:INFO:           fairlearn: Not installed
2024-05-10 15:00:32,449:INFO:          deepchecks: Not installed
2024-05-10 15:00:32,449:INFO:             xgboost: Not installed
2024-05-10 15:00:32,449:INFO:            catboost: Not installed
2024-05-10 15:00:32,449:INFO:              kmodes: Not installed
2024-05-10 15:00:32,449:INFO:             mlxtend: Not installed
2024-05-10 15:00:32,450:INFO:       statsforecast: Not installed
2024-05-10 15:00:32,450:INFO:        tune_sklearn: Not installed
2024-05-10 15:00:32,450:INFO:                 ray: Not installed
2024-05-10 15:00:32,450:INFO:            hyperopt: Not installed
2024-05-10 15:00:32,450:INFO:              optuna: Not installed
2024-05-10 15:00:32,450:INFO:               skopt: Not installed
2024-05-10 15:00:32,450:INFO:              mlflow: Not installed
2024-05-10 15:00:32,450:INFO:              gradio: Not installed
2024-05-10 15:00:32,450:INFO:             fastapi: Not installed
2024-05-10 15:00:32,450:INFO:             uvicorn: Not installed
2024-05-10 15:00:32,450:INFO:              m2cgen: Not installed
2024-05-10 15:00:32,450:INFO:           evidently: Not installed
2024-05-10 15:00:32,450:INFO:               fugue: Not installed
2024-05-10 15:00:32,450:INFO:           streamlit: 1.32.0
2024-05-10 15:00:32,450:INFO:             prophet: Not installed
2024-05-10 15:00:32,450:INFO:None
2024-05-10 15:00:32,450:INFO:Set up data.
2024-05-10 15:00:32,452:INFO:Set up folding strategy.
2024-05-10 15:00:32,452:INFO:Set up train/test split.
2024-05-10 15:00:32,454:INFO:Set up index.
2024-05-10 15:00:32,454:INFO:Assigning column types.
2024-05-10 15:00:32,456:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 15:00:32,456:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,458:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,460:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,494:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,512:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,513:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,513:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,513:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,515:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,517:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,542:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,561:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,562:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,562:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 15:00:32,564:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,566:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,591:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,611:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,613:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,615:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,641:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,661:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,662:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,662:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 15:00:32,666:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,692:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,713:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,717:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,744:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,763:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,764:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,764:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,764:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 15:00:32,793:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,813:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,813:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,844:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,863:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,863:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,863:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,863:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 15:00:32,893:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,914:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,914:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,944:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:00:32,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:32,966:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 15:00:33,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:33,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:33,072:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:33,072:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:33,072:INFO:Preparing preprocessing pipeline...
2024-05-10 15:00:33,072:INFO:Set up simple imputation.
2024-05-10 15:00:33,072:INFO:Set up polynomial features.
2024-05-10 15:00:33,072:INFO:Set up removing outliers.
2024-05-10 15:00:33,072:INFO:Set up feature normalization.
2024-05-10 15:00:33,073:INFO:Set up column name cleaning.
2024-05-10 15:00:33,160:INFO:Finished creating preprocessing pipeline.
2024-05-10 15:00:33,164:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 15:00:33,164:INFO:Creating final display dataframe.
2024-05-10 15:00:33,534:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 4)
4        Transformed data shape         (579, 10)
5   Transformed train set shape         (399, 10)
6    Transformed test set shape         (180, 10)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              ee6f
2024-05-10 15:00:33,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:33,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:33,637:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:33,637:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:00:33,637:INFO:setup() successfully completed in 1.19s...............
2024-05-10 15:00:33,637:INFO:Initializing compare_models()
2024-05-10 15:00:33,637:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 15:00:33,638:INFO:Checking exceptions
2024-05-10 15:00:33,638:INFO:Preparing display monitor
2024-05-10 15:00:33,652:INFO:Initializing Linear Regression
2024-05-10 15:00:33,653:INFO:Total runtime is 3.3736228942871095e-06 minutes
2024-05-10 15:00:33,654:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:33,655:INFO:Initializing create_model()
2024-05-10 15:00:33,655:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:33,655:INFO:Checking exceptions
2024-05-10 15:00:33,655:INFO:Importing libraries
2024-05-10 15:00:33,655:INFO:Copying training dataset
2024-05-10 15:00:33,657:INFO:Defining folds
2024-05-10 15:00:33,657:INFO:Declaring metric variables
2024-05-10 15:00:33,659:INFO:Importing untrained model
2024-05-10 15:00:33,660:INFO:Linear Regression Imported successfully
2024-05-10 15:00:33,665:INFO:Starting cross validation
2024-05-10 15:00:33,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:33,881:INFO:Calculating mean and std
2024-05-10 15:00:33,881:INFO:Creating metrics dataframe
2024-05-10 15:00:33,883:INFO:Uploading results into container
2024-05-10 15:00:33,884:INFO:Uploading model into container now
2024-05-10 15:00:33,884:INFO:_master_model_container: 1
2024-05-10 15:00:33,884:INFO:_display_container: 2
2024-05-10 15:00:33,884:INFO:LinearRegression(n_jobs=-1)
2024-05-10 15:00:33,884:INFO:create_model() successfully completed......................................
2024-05-10 15:00:34,000:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:34,000:INFO:Creating metrics dataframe
2024-05-10 15:00:34,004:INFO:Initializing Lasso Regression
2024-05-10 15:00:34,005:INFO:Total runtime is 0.005869118372599284 minutes
2024-05-10 15:00:34,006:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:34,006:INFO:Initializing create_model()
2024-05-10 15:00:34,007:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:34,007:INFO:Checking exceptions
2024-05-10 15:00:34,007:INFO:Importing libraries
2024-05-10 15:00:34,007:INFO:Copying training dataset
2024-05-10 15:00:34,009:INFO:Defining folds
2024-05-10 15:00:34,009:INFO:Declaring metric variables
2024-05-10 15:00:34,011:INFO:Importing untrained model
2024-05-10 15:00:34,013:INFO:Lasso Regression Imported successfully
2024-05-10 15:00:34,019:INFO:Starting cross validation
2024-05-10 15:00:34,024:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:34,220:INFO:Calculating mean and std
2024-05-10 15:00:34,220:INFO:Creating metrics dataframe
2024-05-10 15:00:34,222:INFO:Uploading results into container
2024-05-10 15:00:34,222:INFO:Uploading model into container now
2024-05-10 15:00:34,223:INFO:_master_model_container: 2
2024-05-10 15:00:34,223:INFO:_display_container: 2
2024-05-10 15:00:34,223:INFO:Lasso(random_state=123)
2024-05-10 15:00:34,223:INFO:create_model() successfully completed......................................
2024-05-10 15:00:34,336:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:34,336:INFO:Creating metrics dataframe
2024-05-10 15:00:34,340:INFO:Initializing Ridge Regression
2024-05-10 15:00:34,340:INFO:Total runtime is 0.01146105130513509 minutes
2024-05-10 15:00:34,342:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:34,342:INFO:Initializing create_model()
2024-05-10 15:00:34,342:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:34,342:INFO:Checking exceptions
2024-05-10 15:00:34,342:INFO:Importing libraries
2024-05-10 15:00:34,342:INFO:Copying training dataset
2024-05-10 15:00:34,344:INFO:Defining folds
2024-05-10 15:00:34,344:INFO:Declaring metric variables
2024-05-10 15:00:34,346:INFO:Importing untrained model
2024-05-10 15:00:34,348:INFO:Ridge Regression Imported successfully
2024-05-10 15:00:34,352:INFO:Starting cross validation
2024-05-10 15:00:34,356:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:34,545:INFO:Calculating mean and std
2024-05-10 15:00:34,545:INFO:Creating metrics dataframe
2024-05-10 15:00:34,547:INFO:Uploading results into container
2024-05-10 15:00:34,547:INFO:Uploading model into container now
2024-05-10 15:00:34,547:INFO:_master_model_container: 3
2024-05-10 15:00:34,547:INFO:_display_container: 2
2024-05-10 15:00:34,548:INFO:Ridge(random_state=123)
2024-05-10 15:00:34,548:INFO:create_model() successfully completed......................................
2024-05-10 15:00:34,666:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:34,666:INFO:Creating metrics dataframe
2024-05-10 15:00:34,670:INFO:Initializing Elastic Net
2024-05-10 15:00:34,670:INFO:Total runtime is 0.016966915130615233 minutes
2024-05-10 15:00:34,672:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:34,672:INFO:Initializing create_model()
2024-05-10 15:00:34,672:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:34,672:INFO:Checking exceptions
2024-05-10 15:00:34,672:INFO:Importing libraries
2024-05-10 15:00:34,673:INFO:Copying training dataset
2024-05-10 15:00:34,675:INFO:Defining folds
2024-05-10 15:00:34,675:INFO:Declaring metric variables
2024-05-10 15:00:34,676:INFO:Importing untrained model
2024-05-10 15:00:34,678:INFO:Elastic Net Imported successfully
2024-05-10 15:00:34,682:INFO:Starting cross validation
2024-05-10 15:00:34,688:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:34,878:INFO:Calculating mean and std
2024-05-10 15:00:34,879:INFO:Creating metrics dataframe
2024-05-10 15:00:34,880:INFO:Uploading results into container
2024-05-10 15:00:34,880:INFO:Uploading model into container now
2024-05-10 15:00:34,881:INFO:_master_model_container: 4
2024-05-10 15:00:34,881:INFO:_display_container: 2
2024-05-10 15:00:34,881:INFO:ElasticNet(random_state=123)
2024-05-10 15:00:34,881:INFO:create_model() successfully completed......................................
2024-05-10 15:00:34,994:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:34,995:INFO:Creating metrics dataframe
2024-05-10 15:00:35,000:INFO:Initializing Least Angle Regression
2024-05-10 15:00:35,000:INFO:Total runtime is 0.022456204891204833 minutes
2024-05-10 15:00:35,002:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:35,002:INFO:Initializing create_model()
2024-05-10 15:00:35,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:35,002:INFO:Checking exceptions
2024-05-10 15:00:35,002:INFO:Importing libraries
2024-05-10 15:00:35,002:INFO:Copying training dataset
2024-05-10 15:00:35,004:INFO:Defining folds
2024-05-10 15:00:35,004:INFO:Declaring metric variables
2024-05-10 15:00:35,006:INFO:Importing untrained model
2024-05-10 15:00:35,008:INFO:Least Angle Regression Imported successfully
2024-05-10 15:00:35,011:INFO:Starting cross validation
2024-05-10 15:00:35,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:35,205:INFO:Calculating mean and std
2024-05-10 15:00:35,205:INFO:Creating metrics dataframe
2024-05-10 15:00:35,207:INFO:Uploading results into container
2024-05-10 15:00:35,207:INFO:Uploading model into container now
2024-05-10 15:00:35,207:INFO:_master_model_container: 5
2024-05-10 15:00:35,207:INFO:_display_container: 2
2024-05-10 15:00:35,208:INFO:Lars(random_state=123)
2024-05-10 15:00:35,208:INFO:create_model() successfully completed......................................
2024-05-10 15:00:35,314:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:35,314:INFO:Creating metrics dataframe
2024-05-10 15:00:35,319:INFO:Initializing Lasso Least Angle Regression
2024-05-10 15:00:35,319:INFO:Total runtime is 0.027774699529012042 minutes
2024-05-10 15:00:35,321:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:35,321:INFO:Initializing create_model()
2024-05-10 15:00:35,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:35,321:INFO:Checking exceptions
2024-05-10 15:00:35,321:INFO:Importing libraries
2024-05-10 15:00:35,321:INFO:Copying training dataset
2024-05-10 15:00:35,323:INFO:Defining folds
2024-05-10 15:00:35,323:INFO:Declaring metric variables
2024-05-10 15:00:35,324:INFO:Importing untrained model
2024-05-10 15:00:35,326:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 15:00:35,329:INFO:Starting cross validation
2024-05-10 15:00:35,335:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:35,516:INFO:Calculating mean and std
2024-05-10 15:00:35,517:INFO:Creating metrics dataframe
2024-05-10 15:00:35,519:INFO:Uploading results into container
2024-05-10 15:00:35,519:INFO:Uploading model into container now
2024-05-10 15:00:35,520:INFO:_master_model_container: 6
2024-05-10 15:00:35,520:INFO:_display_container: 2
2024-05-10 15:00:35,520:INFO:LassoLars(random_state=123)
2024-05-10 15:00:35,520:INFO:create_model() successfully completed......................................
2024-05-10 15:00:35,626:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:35,626:INFO:Creating metrics dataframe
2024-05-10 15:00:35,631:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 15:00:35,632:INFO:Total runtime is 0.03298577864964803 minutes
2024-05-10 15:00:35,634:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:35,634:INFO:Initializing create_model()
2024-05-10 15:00:35,634:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:35,634:INFO:Checking exceptions
2024-05-10 15:00:35,634:INFO:Importing libraries
2024-05-10 15:00:35,634:INFO:Copying training dataset
2024-05-10 15:00:35,636:INFO:Defining folds
2024-05-10 15:00:35,636:INFO:Declaring metric variables
2024-05-10 15:00:35,638:INFO:Importing untrained model
2024-05-10 15:00:35,640:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 15:00:35,643:INFO:Starting cross validation
2024-05-10 15:00:35,649:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:35,834:INFO:Calculating mean and std
2024-05-10 15:00:35,835:INFO:Creating metrics dataframe
2024-05-10 15:00:35,836:INFO:Uploading results into container
2024-05-10 15:00:35,837:INFO:Uploading model into container now
2024-05-10 15:00:35,837:INFO:_master_model_container: 7
2024-05-10 15:00:35,837:INFO:_display_container: 2
2024-05-10 15:00:35,837:INFO:OrthogonalMatchingPursuit()
2024-05-10 15:00:35,837:INFO:create_model() successfully completed......................................
2024-05-10 15:00:35,945:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:35,945:INFO:Creating metrics dataframe
2024-05-10 15:00:35,950:INFO:Initializing Bayesian Ridge
2024-05-10 15:00:35,950:INFO:Total runtime is 0.03829479614893595 minutes
2024-05-10 15:00:35,952:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:35,952:INFO:Initializing create_model()
2024-05-10 15:00:35,952:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:35,952:INFO:Checking exceptions
2024-05-10 15:00:35,952:INFO:Importing libraries
2024-05-10 15:00:35,952:INFO:Copying training dataset
2024-05-10 15:00:35,955:INFO:Defining folds
2024-05-10 15:00:35,955:INFO:Declaring metric variables
2024-05-10 15:00:35,957:INFO:Importing untrained model
2024-05-10 15:00:35,959:INFO:Bayesian Ridge Imported successfully
2024-05-10 15:00:35,962:INFO:Starting cross validation
2024-05-10 15:00:35,968:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:36,155:INFO:Calculating mean and std
2024-05-10 15:00:36,156:INFO:Creating metrics dataframe
2024-05-10 15:00:36,157:INFO:Uploading results into container
2024-05-10 15:00:36,157:INFO:Uploading model into container now
2024-05-10 15:00:36,157:INFO:_master_model_container: 8
2024-05-10 15:00:36,157:INFO:_display_container: 2
2024-05-10 15:00:36,158:INFO:BayesianRidge()
2024-05-10 15:00:36,158:INFO:create_model() successfully completed......................................
2024-05-10 15:00:36,267:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:36,267:INFO:Creating metrics dataframe
2024-05-10 15:00:36,272:INFO:Initializing Passive Aggressive Regressor
2024-05-10 15:00:36,272:INFO:Total runtime is 0.043667614459991455 minutes
2024-05-10 15:00:36,274:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:36,275:INFO:Initializing create_model()
2024-05-10 15:00:36,275:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:36,275:INFO:Checking exceptions
2024-05-10 15:00:36,275:INFO:Importing libraries
2024-05-10 15:00:36,275:INFO:Copying training dataset
2024-05-10 15:00:36,277:INFO:Defining folds
2024-05-10 15:00:36,277:INFO:Declaring metric variables
2024-05-10 15:00:36,278:INFO:Importing untrained model
2024-05-10 15:00:36,281:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 15:00:36,288:INFO:Starting cross validation
2024-05-10 15:00:36,297:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:36,502:INFO:Calculating mean and std
2024-05-10 15:00:36,503:INFO:Creating metrics dataframe
2024-05-10 15:00:36,504:INFO:Uploading results into container
2024-05-10 15:00:36,505:INFO:Uploading model into container now
2024-05-10 15:00:36,505:INFO:_master_model_container: 9
2024-05-10 15:00:36,505:INFO:_display_container: 2
2024-05-10 15:00:36,505:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 15:00:36,505:INFO:create_model() successfully completed......................................
2024-05-10 15:00:36,613:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:36,613:INFO:Creating metrics dataframe
2024-05-10 15:00:36,619:INFO:Initializing Huber Regressor
2024-05-10 15:00:36,619:INFO:Total runtime is 0.049440268675486246 minutes
2024-05-10 15:00:36,621:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:36,621:INFO:Initializing create_model()
2024-05-10 15:00:36,621:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:36,621:INFO:Checking exceptions
2024-05-10 15:00:36,621:INFO:Importing libraries
2024-05-10 15:00:36,621:INFO:Copying training dataset
2024-05-10 15:00:36,623:INFO:Defining folds
2024-05-10 15:00:36,623:INFO:Declaring metric variables
2024-05-10 15:00:36,625:INFO:Importing untrained model
2024-05-10 15:00:36,627:INFO:Huber Regressor Imported successfully
2024-05-10 15:00:36,630:INFO:Starting cross validation
2024-05-10 15:00:36,636:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:36,761:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,784:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,794:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,814:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,830:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,845:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,852:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,856:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,860:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:00:36,873:INFO:Calculating mean and std
2024-05-10 15:00:36,874:INFO:Creating metrics dataframe
2024-05-10 15:00:36,876:INFO:Uploading results into container
2024-05-10 15:00:36,877:INFO:Uploading model into container now
2024-05-10 15:00:36,877:INFO:_master_model_container: 10
2024-05-10 15:00:36,877:INFO:_display_container: 2
2024-05-10 15:00:36,877:INFO:HuberRegressor()
2024-05-10 15:00:36,878:INFO:create_model() successfully completed......................................
2024-05-10 15:00:36,985:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:36,985:INFO:Creating metrics dataframe
2024-05-10 15:00:36,990:INFO:Initializing K Neighbors Regressor
2024-05-10 15:00:36,990:INFO:Total runtime is 0.055623487631479895 minutes
2024-05-10 15:00:36,992:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:36,992:INFO:Initializing create_model()
2024-05-10 15:00:36,992:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:36,992:INFO:Checking exceptions
2024-05-10 15:00:36,992:INFO:Importing libraries
2024-05-10 15:00:36,992:INFO:Copying training dataset
2024-05-10 15:00:36,994:INFO:Defining folds
2024-05-10 15:00:36,994:INFO:Declaring metric variables
2024-05-10 15:00:36,996:INFO:Importing untrained model
2024-05-10 15:00:36,999:INFO:K Neighbors Regressor Imported successfully
2024-05-10 15:00:37,003:INFO:Starting cross validation
2024-05-10 15:00:37,008:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:37,208:INFO:Calculating mean and std
2024-05-10 15:00:37,209:INFO:Creating metrics dataframe
2024-05-10 15:00:37,210:INFO:Uploading results into container
2024-05-10 15:00:37,211:INFO:Uploading model into container now
2024-05-10 15:00:37,211:INFO:_master_model_container: 11
2024-05-10 15:00:37,211:INFO:_display_container: 2
2024-05-10 15:00:37,211:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 15:00:37,212:INFO:create_model() successfully completed......................................
2024-05-10 15:00:37,318:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:37,318:INFO:Creating metrics dataframe
2024-05-10 15:00:37,323:INFO:Initializing Decision Tree Regressor
2024-05-10 15:00:37,323:INFO:Total runtime is 0.061170895894368485 minutes
2024-05-10 15:00:37,325:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:37,325:INFO:Initializing create_model()
2024-05-10 15:00:37,325:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:37,325:INFO:Checking exceptions
2024-05-10 15:00:37,325:INFO:Importing libraries
2024-05-10 15:00:37,325:INFO:Copying training dataset
2024-05-10 15:00:37,327:INFO:Defining folds
2024-05-10 15:00:37,327:INFO:Declaring metric variables
2024-05-10 15:00:37,329:INFO:Importing untrained model
2024-05-10 15:00:37,332:INFO:Decision Tree Regressor Imported successfully
2024-05-10 15:00:37,336:INFO:Starting cross validation
2024-05-10 15:00:37,340:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:37,547:INFO:Calculating mean and std
2024-05-10 15:00:37,548:INFO:Creating metrics dataframe
2024-05-10 15:00:37,550:INFO:Uploading results into container
2024-05-10 15:00:37,551:INFO:Uploading model into container now
2024-05-10 15:00:37,551:INFO:_master_model_container: 12
2024-05-10 15:00:37,551:INFO:_display_container: 2
2024-05-10 15:00:37,552:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 15:00:37,552:INFO:create_model() successfully completed......................................
2024-05-10 15:00:37,662:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:37,662:INFO:Creating metrics dataframe
2024-05-10 15:00:37,668:INFO:Initializing Random Forest Regressor
2024-05-10 15:00:37,668:INFO:Total runtime is 0.06693061192830403 minutes
2024-05-10 15:00:37,670:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:37,670:INFO:Initializing create_model()
2024-05-10 15:00:37,670:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:37,670:INFO:Checking exceptions
2024-05-10 15:00:37,670:INFO:Importing libraries
2024-05-10 15:00:37,670:INFO:Copying training dataset
2024-05-10 15:00:37,673:INFO:Defining folds
2024-05-10 15:00:37,673:INFO:Declaring metric variables
2024-05-10 15:00:37,675:INFO:Importing untrained model
2024-05-10 15:00:37,678:INFO:Random Forest Regressor Imported successfully
2024-05-10 15:00:37,683:INFO:Starting cross validation
2024-05-10 15:00:37,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:38,149:INFO:Calculating mean and std
2024-05-10 15:00:38,149:INFO:Creating metrics dataframe
2024-05-10 15:00:38,151:INFO:Uploading results into container
2024-05-10 15:00:38,151:INFO:Uploading model into container now
2024-05-10 15:00:38,151:INFO:_master_model_container: 13
2024-05-10 15:00:38,151:INFO:_display_container: 2
2024-05-10 15:00:38,152:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:38,152:INFO:create_model() successfully completed......................................
2024-05-10 15:00:38,257:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:38,257:INFO:Creating metrics dataframe
2024-05-10 15:00:38,263:INFO:Initializing Extra Trees Regressor
2024-05-10 15:00:38,263:INFO:Total runtime is 0.0768374482790629 minutes
2024-05-10 15:00:38,265:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:38,265:INFO:Initializing create_model()
2024-05-10 15:00:38,265:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:38,265:INFO:Checking exceptions
2024-05-10 15:00:38,265:INFO:Importing libraries
2024-05-10 15:00:38,265:INFO:Copying training dataset
2024-05-10 15:00:38,268:INFO:Defining folds
2024-05-10 15:00:38,268:INFO:Declaring metric variables
2024-05-10 15:00:38,270:INFO:Importing untrained model
2024-05-10 15:00:38,272:INFO:Extra Trees Regressor Imported successfully
2024-05-10 15:00:38,276:INFO:Starting cross validation
2024-05-10 15:00:38,280:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:38,596:INFO:Calculating mean and std
2024-05-10 15:00:38,597:INFO:Creating metrics dataframe
2024-05-10 15:00:38,600:INFO:Uploading results into container
2024-05-10 15:00:38,600:INFO:Uploading model into container now
2024-05-10 15:00:38,600:INFO:_master_model_container: 14
2024-05-10 15:00:38,601:INFO:_display_container: 2
2024-05-10 15:00:38,601:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:38,601:INFO:create_model() successfully completed......................................
2024-05-10 15:00:38,709:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:38,709:INFO:Creating metrics dataframe
2024-05-10 15:00:38,714:INFO:Initializing AdaBoost Regressor
2024-05-10 15:00:38,714:INFO:Total runtime is 0.08436583280563353 minutes
2024-05-10 15:00:38,717:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:38,717:INFO:Initializing create_model()
2024-05-10 15:00:38,717:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:38,717:INFO:Checking exceptions
2024-05-10 15:00:38,717:INFO:Importing libraries
2024-05-10 15:00:38,717:INFO:Copying training dataset
2024-05-10 15:00:38,719:INFO:Defining folds
2024-05-10 15:00:38,720:INFO:Declaring metric variables
2024-05-10 15:00:38,721:INFO:Importing untrained model
2024-05-10 15:00:38,723:INFO:AdaBoost Regressor Imported successfully
2024-05-10 15:00:38,727:INFO:Starting cross validation
2024-05-10 15:00:38,731:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:38,963:INFO:Calculating mean and std
2024-05-10 15:00:38,964:INFO:Creating metrics dataframe
2024-05-10 15:00:38,965:INFO:Uploading results into container
2024-05-10 15:00:38,966:INFO:Uploading model into container now
2024-05-10 15:00:38,966:INFO:_master_model_container: 15
2024-05-10 15:00:38,966:INFO:_display_container: 2
2024-05-10 15:00:38,966:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 15:00:38,967:INFO:create_model() successfully completed......................................
2024-05-10 15:00:39,075:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:39,075:INFO:Creating metrics dataframe
2024-05-10 15:00:39,081:INFO:Initializing Gradient Boosting Regressor
2024-05-10 15:00:39,081:INFO:Total runtime is 0.09047606388727823 minutes
2024-05-10 15:00:39,083:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:39,083:INFO:Initializing create_model()
2024-05-10 15:00:39,083:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:39,083:INFO:Checking exceptions
2024-05-10 15:00:39,083:INFO:Importing libraries
2024-05-10 15:00:39,083:INFO:Copying training dataset
2024-05-10 15:00:39,086:INFO:Defining folds
2024-05-10 15:00:39,086:INFO:Declaring metric variables
2024-05-10 15:00:39,088:INFO:Importing untrained model
2024-05-10 15:00:39,091:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 15:00:39,097:INFO:Starting cross validation
2024-05-10 15:00:39,109:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:39,457:INFO:Calculating mean and std
2024-05-10 15:00:39,458:INFO:Creating metrics dataframe
2024-05-10 15:00:39,460:INFO:Uploading results into container
2024-05-10 15:00:39,460:INFO:Uploading model into container now
2024-05-10 15:00:39,461:INFO:_master_model_container: 16
2024-05-10 15:00:39,461:INFO:_display_container: 2
2024-05-10 15:00:39,461:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 15:00:39,461:INFO:create_model() successfully completed......................................
2024-05-10 15:00:39,566:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:39,566:INFO:Creating metrics dataframe
2024-05-10 15:00:39,571:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 15:00:39,572:INFO:Total runtime is 0.09865160783131917 minutes
2024-05-10 15:00:39,573:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:39,573:INFO:Initializing create_model()
2024-05-10 15:00:39,574:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:39,574:INFO:Checking exceptions
2024-05-10 15:00:39,574:INFO:Importing libraries
2024-05-10 15:00:39,574:INFO:Copying training dataset
2024-05-10 15:00:39,576:INFO:Defining folds
2024-05-10 15:00:39,576:INFO:Declaring metric variables
2024-05-10 15:00:39,578:INFO:Importing untrained model
2024-05-10 15:00:39,579:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 15:00:39,583:INFO:Starting cross validation
2024-05-10 15:00:39,588:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:40,317:INFO:Calculating mean and std
2024-05-10 15:00:40,318:INFO:Creating metrics dataframe
2024-05-10 15:00:40,319:INFO:Uploading results into container
2024-05-10 15:00:40,320:INFO:Uploading model into container now
2024-05-10 15:00:40,320:INFO:_master_model_container: 17
2024-05-10 15:00:40,320:INFO:_display_container: 2
2024-05-10 15:00:40,321:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:40,321:INFO:create_model() successfully completed......................................
2024-05-10 15:00:40,428:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:40,428:INFO:Creating metrics dataframe
2024-05-10 15:00:40,434:INFO:Initializing Dummy Regressor
2024-05-10 15:00:40,434:INFO:Total runtime is 0.11302432219187418 minutes
2024-05-10 15:00:40,436:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:40,436:INFO:Initializing create_model()
2024-05-10 15:00:40,436:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d317e3070>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:40,436:INFO:Checking exceptions
2024-05-10 15:00:40,436:INFO:Importing libraries
2024-05-10 15:00:40,436:INFO:Copying training dataset
2024-05-10 15:00:40,438:INFO:Defining folds
2024-05-10 15:00:40,438:INFO:Declaring metric variables
2024-05-10 15:00:40,440:INFO:Importing untrained model
2024-05-10 15:00:40,442:INFO:Dummy Regressor Imported successfully
2024-05-10 15:00:40,446:INFO:Starting cross validation
2024-05-10 15:00:40,451:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:40,638:INFO:Calculating mean and std
2024-05-10 15:00:40,639:INFO:Creating metrics dataframe
2024-05-10 15:00:40,640:INFO:Uploading results into container
2024-05-10 15:00:40,641:INFO:Uploading model into container now
2024-05-10 15:00:40,641:INFO:_master_model_container: 18
2024-05-10 15:00:40,641:INFO:_display_container: 2
2024-05-10 15:00:40,641:INFO:DummyRegressor()
2024-05-10 15:00:40,642:INFO:create_model() successfully completed......................................
2024-05-10 15:00:40,746:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:40,746:INFO:Creating metrics dataframe
2024-05-10 15:00:40,752:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 15:00:40,756:INFO:Initializing create_model()
2024-05-10 15:00:40,757:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:40,757:INFO:Checking exceptions
2024-05-10 15:00:40,757:INFO:Importing libraries
2024-05-10 15:00:40,757:INFO:Copying training dataset
2024-05-10 15:00:40,759:INFO:Defining folds
2024-05-10 15:00:40,759:INFO:Declaring metric variables
2024-05-10 15:00:40,759:INFO:Importing untrained model
2024-05-10 15:00:40,759:INFO:Declaring custom model
2024-05-10 15:00:40,760:INFO:Random Forest Regressor Imported successfully
2024-05-10 15:00:40,763:INFO:Cross validation set to False
2024-05-10 15:00:40,763:INFO:Fitting Model
2024-05-10 15:00:40,929:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:40,929:INFO:create_model() successfully completed......................................
2024-05-10 15:00:41,049:INFO:_master_model_container: 18
2024-05-10 15:00:41,049:INFO:_display_container: 2
2024-05-10 15:00:41,049:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:41,049:INFO:compare_models() successfully completed......................................
2024-05-10 15:00:41,050:INFO:Initializing tune_model()
2024-05-10 15:00:41,050:INFO:tune_model(estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>)
2024-05-10 15:00:41,050:INFO:Checking exceptions
2024-05-10 15:00:41,059:INFO:Copying training dataset
2024-05-10 15:00:41,060:INFO:Checking base model
2024-05-10 15:00:41,060:INFO:Base model : Random Forest Regressor
2024-05-10 15:00:41,063:INFO:Declaring metric variables
2024-05-10 15:00:41,065:INFO:Defining Hyperparameters
2024-05-10 15:00:41,184:INFO:Tuning with n_jobs=-1
2024-05-10 15:00:41,184:INFO:Initializing RandomizedSearchCV
2024-05-10 15:00:44,899:INFO:best_params: {'actual_estimator__n_estimators': 290, 'actual_estimator__min_samples_split': 2, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0002, 'actual_estimator__max_features': 'log2', 'actual_estimator__max_depth': 6, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': True}
2024-05-10 15:00:44,899:INFO:Hyperparameter search completed
2024-05-10 15:00:44,900:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:44,900:INFO:Initializing create_model()
2024-05-10 15:00:44,900:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d32c73a00>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 290, 'min_samples_split': 2, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0002, 'max_features': 'log2', 'max_depth': 6, 'criterion': 'squared_error', 'bootstrap': True})
2024-05-10 15:00:44,900:INFO:Checking exceptions
2024-05-10 15:00:44,900:INFO:Importing libraries
2024-05-10 15:00:44,900:INFO:Copying training dataset
2024-05-10 15:00:44,902:INFO:Defining folds
2024-05-10 15:00:44,902:INFO:Declaring metric variables
2024-05-10 15:00:44,905:INFO:Importing untrained model
2024-05-10 15:00:44,905:INFO:Declaring custom model
2024-05-10 15:00:44,908:INFO:Random Forest Regressor Imported successfully
2024-05-10 15:00:44,914:INFO:Starting cross validation
2024-05-10 15:00:44,921:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:45,536:INFO:Calculating mean and std
2024-05-10 15:00:45,537:INFO:Creating metrics dataframe
2024-05-10 15:00:45,541:INFO:Finalizing model
2024-05-10 15:00:45,944:INFO:Uploading results into container
2024-05-10 15:00:45,945:INFO:Uploading model into container now
2024-05-10 15:00:45,945:INFO:_master_model_container: 19
2024-05-10 15:00:45,945:INFO:_display_container: 3
2024-05-10 15:00:45,946:INFO:RandomForestRegressor(max_depth=6, max_features='log2',
                      min_impurity_decrease=0.0002, min_samples_leaf=2,
                      n_estimators=290, n_jobs=-1, random_state=123)
2024-05-10 15:00:45,946:INFO:create_model() successfully completed......................................
2024-05-10 15:00:46,055:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:46,055:INFO:choose_better activated
2024-05-10 15:00:46,058:INFO:SubProcess create_model() called ==================================
2024-05-10 15:00:46,058:INFO:Initializing create_model()
2024-05-10 15:00:46,058:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:00:46,058:INFO:Checking exceptions
2024-05-10 15:00:46,059:INFO:Importing libraries
2024-05-10 15:00:46,059:INFO:Copying training dataset
2024-05-10 15:00:46,061:INFO:Defining folds
2024-05-10 15:00:46,061:INFO:Declaring metric variables
2024-05-10 15:00:46,061:INFO:Importing untrained model
2024-05-10 15:00:46,061:INFO:Declaring custom model
2024-05-10 15:00:46,062:INFO:Random Forest Regressor Imported successfully
2024-05-10 15:00:46,062:INFO:Starting cross validation
2024-05-10 15:00:46,066:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:00:46,492:INFO:Calculating mean and std
2024-05-10 15:00:46,493:INFO:Creating metrics dataframe
2024-05-10 15:00:46,494:INFO:Finalizing model
2024-05-10 15:00:46,665:INFO:Uploading results into container
2024-05-10 15:00:46,666:INFO:Uploading model into container now
2024-05-10 15:00:46,666:INFO:_master_model_container: 20
2024-05-10 15:00:46,666:INFO:_display_container: 4
2024-05-10 15:00:46,666:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:46,667:INFO:create_model() successfully completed......................................
2024-05-10 15:00:46,773:INFO:SubProcess create_model() end ==================================
2024-05-10 15:00:46,773:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) result for R2 is 0.675
2024-05-10 15:00:46,774:INFO:RandomForestRegressor(max_depth=6, max_features='log2',
                      min_impurity_decrease=0.0002, min_samples_leaf=2,
                      n_estimators=290, n_jobs=-1, random_state=123) result for R2 is 0.6665
2024-05-10 15:00:46,774:INFO:RandomForestRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 15:00:46,774:INFO:choose_better completed
2024-05-10 15:00:46,774:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 15:00:46,780:INFO:_master_model_container: 20
2024-05-10 15:00:46,780:INFO:_display_container: 3
2024-05-10 15:00:46,780:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:00:46,780:INFO:tune_model() successfully completed......................................
2024-05-10 15:00:46,891:INFO:Initializing evaluate_model()
2024-05-10 15:00:46,891:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 15:00:46,898:INFO:Initializing plot_model()
2024-05-10 15:00:46,898:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, system=True)
2024-05-10 15:00:46,898:INFO:Checking exceptions
2024-05-10 15:00:46,911:INFO:Preloading libraries
2024-05-10 15:00:46,917:INFO:Copying training dataset
2024-05-10 15:00:46,917:INFO:Plot type: pipeline
2024-05-10 15:00:47,004:INFO:Visual Rendered Successfully
2024-05-10 15:00:47,116:INFO:plot_model() successfully completed......................................
2024-05-10 15:00:49,276:INFO:Initializing plot_model()
2024-05-10 15:00:49,276:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=RandomForestRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d4da47460>, system=True)
2024-05-10 15:00:49,276:INFO:Checking exceptions
2024-05-10 15:00:49,288:INFO:Preloading libraries
2024-05-10 15:00:49,294:INFO:Copying training dataset
2024-05-10 15:00:49,294:INFO:Plot type: residuals
2024-05-10 15:00:49,433:INFO:Fitting Model
2024-05-10 15:00:49,433:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but RandomForestRegressor was fitted with feature names
  warnings.warn(

2024-05-10 15:00:49,476:INFO:Scoring test/hold-out set
2024-05-10 15:00:49,676:INFO:Visual Rendered Successfully
2024-05-10 15:00:49,794:INFO:plot_model() successfully completed......................................
2024-05-10 15:09:05,472:INFO:PyCaret RegressionExperiment
2024-05-10 15:09:05,472:INFO:Logging name: reg-default-name
2024-05-10 15:09:05,472:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 15:09:05,472:INFO:version 3.3.2
2024-05-10 15:09:05,472:INFO:Initializing setup()
2024-05-10 15:09:05,472:INFO:self.USI: d4b9
2024-05-10 15:09:05,472:INFO:self._variable_keys: {'gpu_param', 'pipeline', '_ml_usecase', 'html_param', 'target_param', 'idx', 'log_plots_param', '_available_plots', 'y_train', 'USI', 'exp_name_log', 'logging_param', 'memory', 'X_train', 'y', 'fold_generator', 'exp_id', 'fold_shuffle_param', 'X', 'n_jobs_param', 'X_test', 'gpu_n_jobs_param', 'y_test', 'fold_groups_param', 'seed', 'transform_target_param', 'data'}
2024-05-10 15:09:05,472:INFO:Checking environment
2024-05-10 15:09:05,472:INFO:python_version: 3.9.18
2024-05-10 15:09:05,472:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 15:09:05,472:INFO:machine: x86_64
2024-05-10 15:09:05,472:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:09:05,472:INFO:Memory: svmem(total=16429797376, available=8459218944, percent=48.5, used=6856798208, free=6284374016, active=4378460160, inactive=4380835840, buffers=193470464, cached=3095154688, shared=767238144, slab=733532160)
2024-05-10 15:09:05,473:INFO:Physical Core: 12
2024-05-10 15:09:05,473:INFO:Logical Core: 16
2024-05-10 15:09:05,473:INFO:Checking libraries
2024-05-10 15:09:05,473:INFO:System:
2024-05-10 15:09:05,473:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 15:09:05,473:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 15:09:05,473:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:09:05,473:INFO:PyCaret required dependencies:
2024-05-10 15:09:05,473:INFO:                 pip: 23.3.1
2024-05-10 15:09:05,473:INFO:          setuptools: 68.2.2
2024-05-10 15:09:05,473:INFO:             pycaret: 3.3.2
2024-05-10 15:09:05,473:INFO:             IPython: 8.15.0
2024-05-10 15:09:05,473:INFO:          ipywidgets: 7.6.5
2024-05-10 15:09:05,473:INFO:                tqdm: 4.65.0
2024-05-10 15:09:05,473:INFO:               numpy: 1.26.4
2024-05-10 15:09:05,473:INFO:              pandas: 2.1.4
2024-05-10 15:09:05,473:INFO:              jinja2: 3.1.3
2024-05-10 15:09:05,473:INFO:               scipy: 1.11.4
2024-05-10 15:09:05,473:INFO:              joblib: 1.2.0
2024-05-10 15:09:05,473:INFO:             sklearn: 1.4.2
2024-05-10 15:09:05,473:INFO:                pyod: 1.1.3
2024-05-10 15:09:05,473:INFO:            imblearn: 0.12.2
2024-05-10 15:09:05,473:INFO:   category_encoders: 2.6.3
2024-05-10 15:09:05,473:INFO:            lightgbm: 4.3.0
2024-05-10 15:09:05,473:INFO:               numba: 0.59.1
2024-05-10 15:09:05,473:INFO:            requests: 2.31.0
2024-05-10 15:09:05,473:INFO:          matplotlib: 3.7.5
2024-05-10 15:09:05,473:INFO:          scikitplot: 0.3.7
2024-05-10 15:09:05,473:INFO:         yellowbrick: 1.5
2024-05-10 15:09:05,473:INFO:              plotly: 5.19.0
2024-05-10 15:09:05,473:INFO:    plotly-resampler: Not installed
2024-05-10 15:09:05,473:INFO:             kaleido: 0.2.1
2024-05-10 15:09:05,473:INFO:           schemdraw: 0.15
2024-05-10 15:09:05,473:INFO:         statsmodels: 0.14.0
2024-05-10 15:09:05,473:INFO:              sktime: 0.26.0
2024-05-10 15:09:05,473:INFO:               tbats: 1.1.3
2024-05-10 15:09:05,473:INFO:            pmdarima: 2.0.4
2024-05-10 15:09:05,473:INFO:              psutil: 5.9.0
2024-05-10 15:09:05,473:INFO:          markupsafe: 2.1.3
2024-05-10 15:09:05,473:INFO:             pickle5: Not installed
2024-05-10 15:09:05,473:INFO:         cloudpickle: 2.2.1
2024-05-10 15:09:05,473:INFO:         deprecation: 2.1.0
2024-05-10 15:09:05,473:INFO:              xxhash: 3.4.1
2024-05-10 15:09:05,473:INFO:           wurlitzer: 3.0.2
2024-05-10 15:09:05,473:INFO:PyCaret optional dependencies:
2024-05-10 15:09:05,473:INFO:                shap: Not installed
2024-05-10 15:09:05,473:INFO:           interpret: Not installed
2024-05-10 15:09:05,473:INFO:                umap: Not installed
2024-05-10 15:09:05,473:INFO:     ydata_profiling: Not installed
2024-05-10 15:09:05,473:INFO:  explainerdashboard: Not installed
2024-05-10 15:09:05,473:INFO:             autoviz: Not installed
2024-05-10 15:09:05,473:INFO:           fairlearn: Not installed
2024-05-10 15:09:05,473:INFO:          deepchecks: Not installed
2024-05-10 15:09:05,473:INFO:             xgboost: Not installed
2024-05-10 15:09:05,473:INFO:            catboost: Not installed
2024-05-10 15:09:05,473:INFO:              kmodes: Not installed
2024-05-10 15:09:05,473:INFO:             mlxtend: Not installed
2024-05-10 15:09:05,473:INFO:       statsforecast: Not installed
2024-05-10 15:09:05,473:INFO:        tune_sklearn: Not installed
2024-05-10 15:09:05,473:INFO:                 ray: Not installed
2024-05-10 15:09:05,473:INFO:            hyperopt: Not installed
2024-05-10 15:09:05,473:INFO:              optuna: Not installed
2024-05-10 15:09:05,473:INFO:               skopt: Not installed
2024-05-10 15:09:05,473:INFO:              mlflow: Not installed
2024-05-10 15:09:05,474:INFO:              gradio: Not installed
2024-05-10 15:09:05,474:INFO:             fastapi: Not installed
2024-05-10 15:09:05,474:INFO:             uvicorn: Not installed
2024-05-10 15:09:05,474:INFO:              m2cgen: Not installed
2024-05-10 15:09:05,474:INFO:           evidently: Not installed
2024-05-10 15:09:05,474:INFO:               fugue: Not installed
2024-05-10 15:09:05,474:INFO:           streamlit: 1.32.0
2024-05-10 15:09:05,474:INFO:             prophet: Not installed
2024-05-10 15:09:05,474:INFO:None
2024-05-10 15:09:05,474:INFO:Set up data.
2024-05-10 15:09:05,478:INFO:Set up folding strategy.
2024-05-10 15:09:05,478:INFO:Set up train/test split.
2024-05-10 15:09:05,480:INFO:Set up index.
2024-05-10 15:09:05,481:INFO:Assigning column types.
2024-05-10 15:09:05,484:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 15:09:05,484:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,492:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,500:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,547:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,566:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,567:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,567:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,567:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,570:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,571:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,596:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,623:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,623:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,623:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,623:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 15:09:05,625:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,652:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,672:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,672:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,672:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,675:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,677:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,702:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,721:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,722:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,722:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,722:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 15:09:05,726:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,756:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,777:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,781:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,808:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,828:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,828:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,828:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,828:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 15:09:05,859:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,879:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,880:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,880:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,910:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,928:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,929:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,929:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,929:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 15:09:05,957:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:05,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:05,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,008:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 15:09:06,028:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,028:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,029:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 15:09:06,081:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,081:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,133:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,133:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,133:INFO:Preparing preprocessing pipeline...
2024-05-10 15:09:06,133:INFO:Set up simple imputation.
2024-05-10 15:09:06,134:INFO:Set up polynomial features.
2024-05-10 15:09:06,134:INFO:Set up removing outliers.
2024-05-10 15:09:06,134:INFO:Set up feature normalization.
2024-05-10 15:09:06,134:INFO:Set up column name cleaning.
2024-05-10 15:09:06,223:INFO:Finished creating preprocessing pipeline.
2024-05-10 15:09:06,227:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('polynomial_features',
                 TransformerWrapper(transformer=PolynomialFeatures(include_bias=False))),
                ('remove_outliers',
                 TransformerWrapper(transformer=RemoveOutliers(random_state=123))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 15:09:06,227:INFO:Creating final display dataframe.
2024-05-10 15:09:06,554:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 4)
4        Transformed data shape         (585, 10)
5   Transformed train set shape         (285, 10)
6    Transformed test set shape         (300, 10)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12          Polynomial features              True
13            Polynomial degree                 2
14              Remove outliers              True
15           Outliers threshold              0.05
16                    Normalize              True
17             Normalize method            zscore
18               Fold Generator             KFold
19                  Fold Number                10
20                     CPU Jobs                -1
21                      Use GPU             False
22               Log Experiment             False
23              Experiment Name  reg-default-name
24                          USI              d4b9
2024-05-10 15:09:06,610:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,610:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,661:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,662:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:09:06,662:INFO:setup() successfully completed in 1.19s...............
2024-05-10 15:09:06,662:INFO:Initializing compare_models()
2024-05-10 15:09:06,662:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 15:09:06,662:INFO:Checking exceptions
2024-05-10 15:09:06,663:INFO:Preparing display monitor
2024-05-10 15:09:06,677:INFO:Initializing Linear Regression
2024-05-10 15:09:06,677:INFO:Total runtime is 2.4358431498209636e-06 minutes
2024-05-10 15:09:06,679:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:06,679:INFO:Initializing create_model()
2024-05-10 15:09:06,679:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:06,679:INFO:Checking exceptions
2024-05-10 15:09:06,679:INFO:Importing libraries
2024-05-10 15:09:06,679:INFO:Copying training dataset
2024-05-10 15:09:06,681:INFO:Defining folds
2024-05-10 15:09:06,681:INFO:Declaring metric variables
2024-05-10 15:09:06,683:INFO:Importing untrained model
2024-05-10 15:09:06,685:INFO:Linear Regression Imported successfully
2024-05-10 15:09:06,689:INFO:Starting cross validation
2024-05-10 15:09:06,694:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:09,185:INFO:Calculating mean and std
2024-05-10 15:09:09,187:INFO:Creating metrics dataframe
2024-05-10 15:09:09,190:INFO:Uploading results into container
2024-05-10 15:09:09,191:INFO:Uploading model into container now
2024-05-10 15:09:09,191:INFO:_master_model_container: 1
2024-05-10 15:09:09,191:INFO:_display_container: 2
2024-05-10 15:09:09,192:INFO:LinearRegression(n_jobs=-1)
2024-05-10 15:09:09,192:INFO:create_model() successfully completed......................................
2024-05-10 15:09:09,317:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:09,317:INFO:Creating metrics dataframe
2024-05-10 15:09:09,321:INFO:Initializing Lasso Regression
2024-05-10 15:09:09,321:INFO:Total runtime is 0.04407310883204142 minutes
2024-05-10 15:09:09,323:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:09,324:INFO:Initializing create_model()
2024-05-10 15:09:09,324:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:09,324:INFO:Checking exceptions
2024-05-10 15:09:09,324:INFO:Importing libraries
2024-05-10 15:09:09,324:INFO:Copying training dataset
2024-05-10 15:09:09,326:INFO:Defining folds
2024-05-10 15:09:09,326:INFO:Declaring metric variables
2024-05-10 15:09:09,328:INFO:Importing untrained model
2024-05-10 15:09:09,330:INFO:Lasso Regression Imported successfully
2024-05-10 15:09:09,334:INFO:Starting cross validation
2024-05-10 15:09:09,341:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:11,053:INFO:Calculating mean and std
2024-05-10 15:09:11,054:INFO:Creating metrics dataframe
2024-05-10 15:09:11,056:INFO:Uploading results into container
2024-05-10 15:09:11,056:INFO:Uploading model into container now
2024-05-10 15:09:11,056:INFO:_master_model_container: 2
2024-05-10 15:09:11,056:INFO:_display_container: 2
2024-05-10 15:09:11,057:INFO:Lasso(random_state=123)
2024-05-10 15:09:11,057:INFO:create_model() successfully completed......................................
2024-05-10 15:09:11,169:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:11,169:INFO:Creating metrics dataframe
2024-05-10 15:09:11,173:INFO:Initializing Ridge Regression
2024-05-10 15:09:11,174:INFO:Total runtime is 0.07494155565897623 minutes
2024-05-10 15:09:11,175:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:11,175:INFO:Initializing create_model()
2024-05-10 15:09:11,175:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:11,175:INFO:Checking exceptions
2024-05-10 15:09:11,176:INFO:Importing libraries
2024-05-10 15:09:11,176:INFO:Copying training dataset
2024-05-10 15:09:11,177:INFO:Defining folds
2024-05-10 15:09:11,178:INFO:Declaring metric variables
2024-05-10 15:09:11,179:INFO:Importing untrained model
2024-05-10 15:09:11,181:INFO:Ridge Regression Imported successfully
2024-05-10 15:09:11,184:INFO:Starting cross validation
2024-05-10 15:09:11,188:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:11,373:INFO:Calculating mean and std
2024-05-10 15:09:11,373:INFO:Creating metrics dataframe
2024-05-10 15:09:11,375:INFO:Uploading results into container
2024-05-10 15:09:11,375:INFO:Uploading model into container now
2024-05-10 15:09:11,376:INFO:_master_model_container: 3
2024-05-10 15:09:11,376:INFO:_display_container: 2
2024-05-10 15:09:11,376:INFO:Ridge(random_state=123)
2024-05-10 15:09:11,376:INFO:create_model() successfully completed......................................
2024-05-10 15:09:11,485:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:11,486:INFO:Creating metrics dataframe
2024-05-10 15:09:11,491:INFO:Initializing Elastic Net
2024-05-10 15:09:11,491:INFO:Total runtime is 0.08022651274998982 minutes
2024-05-10 15:09:11,492:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:11,493:INFO:Initializing create_model()
2024-05-10 15:09:11,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:11,493:INFO:Checking exceptions
2024-05-10 15:09:11,493:INFO:Importing libraries
2024-05-10 15:09:11,493:INFO:Copying training dataset
2024-05-10 15:09:11,495:INFO:Defining folds
2024-05-10 15:09:11,495:INFO:Declaring metric variables
2024-05-10 15:09:11,497:INFO:Importing untrained model
2024-05-10 15:09:11,499:INFO:Elastic Net Imported successfully
2024-05-10 15:09:11,502:INFO:Starting cross validation
2024-05-10 15:09:11,507:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:11,699:INFO:Calculating mean and std
2024-05-10 15:09:11,700:INFO:Creating metrics dataframe
2024-05-10 15:09:11,701:INFO:Uploading results into container
2024-05-10 15:09:11,702:INFO:Uploading model into container now
2024-05-10 15:09:11,702:INFO:_master_model_container: 4
2024-05-10 15:09:11,702:INFO:_display_container: 2
2024-05-10 15:09:11,702:INFO:ElasticNet(random_state=123)
2024-05-10 15:09:11,702:INFO:create_model() successfully completed......................................
2024-05-10 15:09:11,811:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:11,811:INFO:Creating metrics dataframe
2024-05-10 15:09:11,815:INFO:Initializing Least Angle Regression
2024-05-10 15:09:11,815:INFO:Total runtime is 0.08563684622446695 minutes
2024-05-10 15:09:11,817:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:11,817:INFO:Initializing create_model()
2024-05-10 15:09:11,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:11,817:INFO:Checking exceptions
2024-05-10 15:09:11,817:INFO:Importing libraries
2024-05-10 15:09:11,817:INFO:Copying training dataset
2024-05-10 15:09:11,820:INFO:Defining folds
2024-05-10 15:09:11,820:INFO:Declaring metric variables
2024-05-10 15:09:11,822:INFO:Importing untrained model
2024-05-10 15:09:11,824:INFO:Least Angle Regression Imported successfully
2024-05-10 15:09:11,828:INFO:Starting cross validation
2024-05-10 15:09:11,833:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:12,018:INFO:Calculating mean and std
2024-05-10 15:09:12,019:INFO:Creating metrics dataframe
2024-05-10 15:09:12,021:INFO:Uploading results into container
2024-05-10 15:09:12,022:INFO:Uploading model into container now
2024-05-10 15:09:12,022:INFO:_master_model_container: 5
2024-05-10 15:09:12,022:INFO:_display_container: 2
2024-05-10 15:09:12,022:INFO:Lars(random_state=123)
2024-05-10 15:09:12,022:INFO:create_model() successfully completed......................................
2024-05-10 15:09:12,131:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:12,131:INFO:Creating metrics dataframe
2024-05-10 15:09:12,135:INFO:Initializing Lasso Least Angle Regression
2024-05-10 15:09:12,136:INFO:Total runtime is 0.09097439050674437 minutes
2024-05-10 15:09:12,138:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:12,138:INFO:Initializing create_model()
2024-05-10 15:09:12,138:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:12,138:INFO:Checking exceptions
2024-05-10 15:09:12,138:INFO:Importing libraries
2024-05-10 15:09:12,138:INFO:Copying training dataset
2024-05-10 15:09:12,142:INFO:Defining folds
2024-05-10 15:09:12,142:INFO:Declaring metric variables
2024-05-10 15:09:12,145:INFO:Importing untrained model
2024-05-10 15:09:12,148:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 15:09:12,153:INFO:Starting cross validation
2024-05-10 15:09:12,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:12,345:INFO:Calculating mean and std
2024-05-10 15:09:12,346:INFO:Creating metrics dataframe
2024-05-10 15:09:12,348:INFO:Uploading results into container
2024-05-10 15:09:12,348:INFO:Uploading model into container now
2024-05-10 15:09:12,348:INFO:_master_model_container: 6
2024-05-10 15:09:12,349:INFO:_display_container: 2
2024-05-10 15:09:12,349:INFO:LassoLars(random_state=123)
2024-05-10 15:09:12,349:INFO:create_model() successfully completed......................................
2024-05-10 15:09:12,458:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:12,458:INFO:Creating metrics dataframe
2024-05-10 15:09:12,462:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 15:09:12,462:INFO:Total runtime is 0.09642119805018105 minutes
2024-05-10 15:09:12,464:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:12,464:INFO:Initializing create_model()
2024-05-10 15:09:12,464:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:12,464:INFO:Checking exceptions
2024-05-10 15:09:12,464:INFO:Importing libraries
2024-05-10 15:09:12,464:INFO:Copying training dataset
2024-05-10 15:09:12,466:INFO:Defining folds
2024-05-10 15:09:12,466:INFO:Declaring metric variables
2024-05-10 15:09:12,468:INFO:Importing untrained model
2024-05-10 15:09:12,471:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 15:09:12,476:INFO:Starting cross validation
2024-05-10 15:09:12,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:12,670:INFO:Calculating mean and std
2024-05-10 15:09:12,670:INFO:Creating metrics dataframe
2024-05-10 15:09:12,672:INFO:Uploading results into container
2024-05-10 15:09:12,672:INFO:Uploading model into container now
2024-05-10 15:09:12,673:INFO:_master_model_container: 7
2024-05-10 15:09:12,673:INFO:_display_container: 2
2024-05-10 15:09:12,673:INFO:OrthogonalMatchingPursuit()
2024-05-10 15:09:12,673:INFO:create_model() successfully completed......................................
2024-05-10 15:09:12,778:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:12,778:INFO:Creating metrics dataframe
2024-05-10 15:09:12,782:INFO:Initializing Bayesian Ridge
2024-05-10 15:09:12,782:INFO:Total runtime is 0.10175243616104124 minutes
2024-05-10 15:09:12,784:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:12,784:INFO:Initializing create_model()
2024-05-10 15:09:12,784:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:12,784:INFO:Checking exceptions
2024-05-10 15:09:12,784:INFO:Importing libraries
2024-05-10 15:09:12,784:INFO:Copying training dataset
2024-05-10 15:09:12,787:INFO:Defining folds
2024-05-10 15:09:12,787:INFO:Declaring metric variables
2024-05-10 15:09:12,790:INFO:Importing untrained model
2024-05-10 15:09:12,792:INFO:Bayesian Ridge Imported successfully
2024-05-10 15:09:12,795:INFO:Starting cross validation
2024-05-10 15:09:12,799:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:12,994:INFO:Calculating mean and std
2024-05-10 15:09:12,995:INFO:Creating metrics dataframe
2024-05-10 15:09:12,996:INFO:Uploading results into container
2024-05-10 15:09:12,997:INFO:Uploading model into container now
2024-05-10 15:09:12,997:INFO:_master_model_container: 8
2024-05-10 15:09:12,997:INFO:_display_container: 2
2024-05-10 15:09:12,998:INFO:BayesianRidge()
2024-05-10 15:09:12,998:INFO:create_model() successfully completed......................................
2024-05-10 15:09:13,106:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:13,106:INFO:Creating metrics dataframe
2024-05-10 15:09:13,111:INFO:Initializing Passive Aggressive Regressor
2024-05-10 15:09:13,111:INFO:Total runtime is 0.10723734299341835 minutes
2024-05-10 15:09:13,113:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:13,113:INFO:Initializing create_model()
2024-05-10 15:09:13,113:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:13,113:INFO:Checking exceptions
2024-05-10 15:09:13,113:INFO:Importing libraries
2024-05-10 15:09:13,113:INFO:Copying training dataset
2024-05-10 15:09:13,115:INFO:Defining folds
2024-05-10 15:09:13,115:INFO:Declaring metric variables
2024-05-10 15:09:13,117:INFO:Importing untrained model
2024-05-10 15:09:13,121:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 15:09:13,128:INFO:Starting cross validation
2024-05-10 15:09:13,140:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:13,345:INFO:Calculating mean and std
2024-05-10 15:09:13,346:INFO:Creating metrics dataframe
2024-05-10 15:09:13,348:INFO:Uploading results into container
2024-05-10 15:09:13,348:INFO:Uploading model into container now
2024-05-10 15:09:13,349:INFO:_master_model_container: 9
2024-05-10 15:09:13,349:INFO:_display_container: 2
2024-05-10 15:09:13,349:INFO:PassiveAggressiveRegressor(random_state=123)
2024-05-10 15:09:13,349:INFO:create_model() successfully completed......................................
2024-05-10 15:09:13,461:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:13,461:INFO:Creating metrics dataframe
2024-05-10 15:09:13,465:INFO:Initializing Huber Regressor
2024-05-10 15:09:13,465:INFO:Total runtime is 0.11313502788543699 minutes
2024-05-10 15:09:13,467:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:13,467:INFO:Initializing create_model()
2024-05-10 15:09:13,467:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:13,467:INFO:Checking exceptions
2024-05-10 15:09:13,467:INFO:Importing libraries
2024-05-10 15:09:13,467:INFO:Copying training dataset
2024-05-10 15:09:13,470:INFO:Defining folds
2024-05-10 15:09:13,470:INFO:Declaring metric variables
2024-05-10 15:09:13,472:INFO:Importing untrained model
2024-05-10 15:09:13,476:INFO:Huber Regressor Imported successfully
2024-05-10 15:09:13,481:INFO:Starting cross validation
2024-05-10 15:09:13,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:13,603:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,621:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,641:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,651:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,657:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,665:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,675:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,684:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,688:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,688:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/linear_model/_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-05-10 15:09:13,696:INFO:Calculating mean and std
2024-05-10 15:09:13,697:INFO:Creating metrics dataframe
2024-05-10 15:09:13,700:INFO:Uploading results into container
2024-05-10 15:09:13,700:INFO:Uploading model into container now
2024-05-10 15:09:13,700:INFO:_master_model_container: 10
2024-05-10 15:09:13,701:INFO:_display_container: 2
2024-05-10 15:09:13,701:INFO:HuberRegressor()
2024-05-10 15:09:13,701:INFO:create_model() successfully completed......................................
2024-05-10 15:09:13,809:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:13,809:INFO:Creating metrics dataframe
2024-05-10 15:09:13,814:INFO:Initializing K Neighbors Regressor
2024-05-10 15:09:13,814:INFO:Total runtime is 0.11895676056543983 minutes
2024-05-10 15:09:13,816:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:13,816:INFO:Initializing create_model()
2024-05-10 15:09:13,817:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:13,817:INFO:Checking exceptions
2024-05-10 15:09:13,817:INFO:Importing libraries
2024-05-10 15:09:13,817:INFO:Copying training dataset
2024-05-10 15:09:13,819:INFO:Defining folds
2024-05-10 15:09:13,819:INFO:Declaring metric variables
2024-05-10 15:09:13,821:INFO:Importing untrained model
2024-05-10 15:09:13,824:INFO:K Neighbors Regressor Imported successfully
2024-05-10 15:09:13,828:INFO:Starting cross validation
2024-05-10 15:09:13,832:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:14,023:INFO:Calculating mean and std
2024-05-10 15:09:14,024:INFO:Creating metrics dataframe
2024-05-10 15:09:14,025:INFO:Uploading results into container
2024-05-10 15:09:14,025:INFO:Uploading model into container now
2024-05-10 15:09:14,026:INFO:_master_model_container: 11
2024-05-10 15:09:14,026:INFO:_display_container: 2
2024-05-10 15:09:14,026:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 15:09:14,026:INFO:create_model() successfully completed......................................
2024-05-10 15:09:14,138:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:14,138:INFO:Creating metrics dataframe
2024-05-10 15:09:14,143:INFO:Initializing Decision Tree Regressor
2024-05-10 15:09:14,143:INFO:Total runtime is 0.12443590958913164 minutes
2024-05-10 15:09:14,145:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:14,145:INFO:Initializing create_model()
2024-05-10 15:09:14,145:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:14,145:INFO:Checking exceptions
2024-05-10 15:09:14,145:INFO:Importing libraries
2024-05-10 15:09:14,145:INFO:Copying training dataset
2024-05-10 15:09:14,147:INFO:Defining folds
2024-05-10 15:09:14,148:INFO:Declaring metric variables
2024-05-10 15:09:14,149:INFO:Importing untrained model
2024-05-10 15:09:14,151:INFO:Decision Tree Regressor Imported successfully
2024-05-10 15:09:14,155:INFO:Starting cross validation
2024-05-10 15:09:14,160:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:14,352:INFO:Calculating mean and std
2024-05-10 15:09:14,353:INFO:Creating metrics dataframe
2024-05-10 15:09:14,354:INFO:Uploading results into container
2024-05-10 15:09:14,354:INFO:Uploading model into container now
2024-05-10 15:09:14,355:INFO:_master_model_container: 12
2024-05-10 15:09:14,355:INFO:_display_container: 2
2024-05-10 15:09:14,355:INFO:DecisionTreeRegressor(random_state=123)
2024-05-10 15:09:14,355:INFO:create_model() successfully completed......................................
2024-05-10 15:09:14,465:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:14,465:INFO:Creating metrics dataframe
2024-05-10 15:09:14,471:INFO:Initializing Random Forest Regressor
2024-05-10 15:09:14,471:INFO:Total runtime is 0.12989343007405596 minutes
2024-05-10 15:09:14,473:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:14,473:INFO:Initializing create_model()
2024-05-10 15:09:14,473:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:14,473:INFO:Checking exceptions
2024-05-10 15:09:14,473:INFO:Importing libraries
2024-05-10 15:09:14,473:INFO:Copying training dataset
2024-05-10 15:09:14,475:INFO:Defining folds
2024-05-10 15:09:14,476:INFO:Declaring metric variables
2024-05-10 15:09:14,477:INFO:Importing untrained model
2024-05-10 15:09:14,479:INFO:Random Forest Regressor Imported successfully
2024-05-10 15:09:14,482:INFO:Starting cross validation
2024-05-10 15:09:14,487:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:14,875:INFO:Calculating mean and std
2024-05-10 15:09:14,875:INFO:Creating metrics dataframe
2024-05-10 15:09:14,877:INFO:Uploading results into container
2024-05-10 15:09:14,877:INFO:Uploading model into container now
2024-05-10 15:09:14,877:INFO:_master_model_container: 13
2024-05-10 15:09:14,878:INFO:_display_container: 2
2024-05-10 15:09:14,878:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:09:14,878:INFO:create_model() successfully completed......................................
2024-05-10 15:09:14,988:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:14,988:INFO:Creating metrics dataframe
2024-05-10 15:09:14,993:INFO:Initializing Extra Trees Regressor
2024-05-10 15:09:14,993:INFO:Total runtime is 0.13859574000040686 minutes
2024-05-10 15:09:14,995:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:14,995:INFO:Initializing create_model()
2024-05-10 15:09:14,995:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:14,995:INFO:Checking exceptions
2024-05-10 15:09:14,995:INFO:Importing libraries
2024-05-10 15:09:14,995:INFO:Copying training dataset
2024-05-10 15:09:14,999:INFO:Defining folds
2024-05-10 15:09:14,999:INFO:Declaring metric variables
2024-05-10 15:09:15,001:INFO:Importing untrained model
2024-05-10 15:09:15,003:INFO:Extra Trees Regressor Imported successfully
2024-05-10 15:09:15,009:INFO:Starting cross validation
2024-05-10 15:09:15,016:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:15,317:INFO:Calculating mean and std
2024-05-10 15:09:15,318:INFO:Creating metrics dataframe
2024-05-10 15:09:15,320:INFO:Uploading results into container
2024-05-10 15:09:15,321:INFO:Uploading model into container now
2024-05-10 15:09:15,322:INFO:_master_model_container: 14
2024-05-10 15:09:15,322:INFO:_display_container: 2
2024-05-10 15:09:15,322:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:09:15,322:INFO:create_model() successfully completed......................................
2024-05-10 15:09:15,429:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:15,429:INFO:Creating metrics dataframe
2024-05-10 15:09:15,434:INFO:Initializing AdaBoost Regressor
2024-05-10 15:09:15,434:INFO:Total runtime is 0.14595324595769243 minutes
2024-05-10 15:09:15,436:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:15,437:INFO:Initializing create_model()
2024-05-10 15:09:15,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:15,437:INFO:Checking exceptions
2024-05-10 15:09:15,437:INFO:Importing libraries
2024-05-10 15:09:15,437:INFO:Copying training dataset
2024-05-10 15:09:15,439:INFO:Defining folds
2024-05-10 15:09:15,440:INFO:Declaring metric variables
2024-05-10 15:09:15,442:INFO:Importing untrained model
2024-05-10 15:09:15,444:INFO:AdaBoost Regressor Imported successfully
2024-05-10 15:09:15,449:INFO:Starting cross validation
2024-05-10 15:09:15,454:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:15,708:INFO:Calculating mean and std
2024-05-10 15:09:15,708:INFO:Creating metrics dataframe
2024-05-10 15:09:15,709:INFO:Uploading results into container
2024-05-10 15:09:15,710:INFO:Uploading model into container now
2024-05-10 15:09:15,710:INFO:_master_model_container: 15
2024-05-10 15:09:15,710:INFO:_display_container: 2
2024-05-10 15:09:15,710:INFO:AdaBoostRegressor(random_state=123)
2024-05-10 15:09:15,710:INFO:create_model() successfully completed......................................
2024-05-10 15:09:15,818:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:15,818:INFO:Creating metrics dataframe
2024-05-10 15:09:15,824:INFO:Initializing Gradient Boosting Regressor
2024-05-10 15:09:15,824:INFO:Total runtime is 0.15244895219802854 minutes
2024-05-10 15:09:15,826:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:15,826:INFO:Initializing create_model()
2024-05-10 15:09:15,826:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:15,826:INFO:Checking exceptions
2024-05-10 15:09:15,826:INFO:Importing libraries
2024-05-10 15:09:15,826:INFO:Copying training dataset
2024-05-10 15:09:15,829:INFO:Defining folds
2024-05-10 15:09:15,829:INFO:Declaring metric variables
2024-05-10 15:09:15,831:INFO:Importing untrained model
2024-05-10 15:09:15,833:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 15:09:15,843:INFO:Starting cross validation
2024-05-10 15:09:15,854:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:16,172:INFO:Calculating mean and std
2024-05-10 15:09:16,173:INFO:Creating metrics dataframe
2024-05-10 15:09:16,174:INFO:Uploading results into container
2024-05-10 15:09:16,175:INFO:Uploading model into container now
2024-05-10 15:09:16,175:INFO:_master_model_container: 16
2024-05-10 15:09:16,175:INFO:_display_container: 2
2024-05-10 15:09:16,175:INFO:GradientBoostingRegressor(random_state=123)
2024-05-10 15:09:16,175:INFO:create_model() successfully completed......................................
2024-05-10 15:09:16,286:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:16,286:INFO:Creating metrics dataframe
2024-05-10 15:09:16,292:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 15:09:16,292:INFO:Total runtime is 0.16024332841237382 minutes
2024-05-10 15:09:16,294:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:16,294:INFO:Initializing create_model()
2024-05-10 15:09:16,294:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:16,294:INFO:Checking exceptions
2024-05-10 15:09:16,294:INFO:Importing libraries
2024-05-10 15:09:16,294:INFO:Copying training dataset
2024-05-10 15:09:16,298:INFO:Defining folds
2024-05-10 15:09:16,298:INFO:Declaring metric variables
2024-05-10 15:09:16,301:INFO:Importing untrained model
2024-05-10 15:09:16,304:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 15:09:16,308:INFO:Starting cross validation
2024-05-10 15:09:16,313:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:16,922:INFO:Calculating mean and std
2024-05-10 15:09:16,923:INFO:Creating metrics dataframe
2024-05-10 15:09:16,924:INFO:Uploading results into container
2024-05-10 15:09:16,925:INFO:Uploading model into container now
2024-05-10 15:09:16,925:INFO:_master_model_container: 17
2024-05-10 15:09:16,925:INFO:_display_container: 2
2024-05-10 15:09:16,925:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:09:16,925:INFO:create_model() successfully completed......................................
2024-05-10 15:09:17,033:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:17,033:INFO:Creating metrics dataframe
2024-05-10 15:09:17,039:INFO:Initializing Dummy Regressor
2024-05-10 15:09:17,040:INFO:Total runtime is 0.1727083007494608 minutes
2024-05-10 15:09:17,041:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:17,041:INFO:Initializing create_model()
2024-05-10 15:09:17,041:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df3feb0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:17,041:INFO:Checking exceptions
2024-05-10 15:09:17,041:INFO:Importing libraries
2024-05-10 15:09:17,041:INFO:Copying training dataset
2024-05-10 15:09:17,044:INFO:Defining folds
2024-05-10 15:09:17,044:INFO:Declaring metric variables
2024-05-10 15:09:17,045:INFO:Importing untrained model
2024-05-10 15:09:17,047:INFO:Dummy Regressor Imported successfully
2024-05-10 15:09:17,050:INFO:Starting cross validation
2024-05-10 15:09:17,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:17,251:INFO:Calculating mean and std
2024-05-10 15:09:17,252:INFO:Creating metrics dataframe
2024-05-10 15:09:17,254:INFO:Uploading results into container
2024-05-10 15:09:17,254:INFO:Uploading model into container now
2024-05-10 15:09:17,255:INFO:_master_model_container: 18
2024-05-10 15:09:17,255:INFO:_display_container: 2
2024-05-10 15:09:17,255:INFO:DummyRegressor()
2024-05-10 15:09:17,255:INFO:create_model() successfully completed......................................
2024-05-10 15:09:17,364:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:17,364:INFO:Creating metrics dataframe
2024-05-10 15:09:17,370:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/pycaret/internal/pycaret_experiment/supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-05-10 15:09:17,375:INFO:Initializing create_model()
2024-05-10 15:09:17,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:17,376:INFO:Checking exceptions
2024-05-10 15:09:17,377:INFO:Importing libraries
2024-05-10 15:09:17,377:INFO:Copying training dataset
2024-05-10 15:09:17,379:INFO:Defining folds
2024-05-10 15:09:17,379:INFO:Declaring metric variables
2024-05-10 15:09:17,379:INFO:Importing untrained model
2024-05-10 15:09:17,379:INFO:Declaring custom model
2024-05-10 15:09:17,379:INFO:Extra Trees Regressor Imported successfully
2024-05-10 15:09:17,383:INFO:Cross validation set to False
2024-05-10 15:09:17,383:INFO:Fitting Model
2024-05-10 15:09:17,511:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:09:17,511:INFO:create_model() successfully completed......................................
2024-05-10 15:09:17,635:INFO:_master_model_container: 18
2024-05-10 15:09:17,635:INFO:_display_container: 2
2024-05-10 15:09:17,636:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:09:17,636:INFO:compare_models() successfully completed......................................
2024-05-10 15:09:17,637:INFO:Initializing tune_model()
2024-05-10 15:09:17,637:INFO:tune_model(estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, round=4, n_iter=10, custom_grid=None, optimize=R2, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>)
2024-05-10 15:09:17,637:INFO:Checking exceptions
2024-05-10 15:09:17,647:INFO:Copying training dataset
2024-05-10 15:09:17,648:INFO:Checking base model
2024-05-10 15:09:17,648:INFO:Base model : Extra Trees Regressor
2024-05-10 15:09:17,650:INFO:Declaring metric variables
2024-05-10 15:09:17,652:INFO:Defining Hyperparameters
2024-05-10 15:09:17,773:INFO:Tuning with n_jobs=-1
2024-05-10 15:09:17,774:INFO:Initializing RandomizedSearchCV
2024-05-10 15:09:20,915:INFO:best_params: {'actual_estimator__n_estimators': 240, 'actual_estimator__min_samples_split': 5, 'actual_estimator__min_samples_leaf': 2, 'actual_estimator__min_impurity_decrease': 0.0001, 'actual_estimator__max_features': 'sqrt', 'actual_estimator__max_depth': 8, 'actual_estimator__criterion': 'squared_error', 'actual_estimator__bootstrap': False}
2024-05-10 15:09:20,916:INFO:Hyperparameter search completed
2024-05-10 15:09:20,916:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:20,916:INFO:Initializing create_model()
2024-05-10 15:09:20,916:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x701d4df92e20>, model_only=True, return_train_score=False, error_score=0.0, kwargs={'n_estimators': 240, 'min_samples_split': 5, 'min_samples_leaf': 2, 'min_impurity_decrease': 0.0001, 'max_features': 'sqrt', 'max_depth': 8, 'criterion': 'squared_error', 'bootstrap': False})
2024-05-10 15:09:20,916:INFO:Checking exceptions
2024-05-10 15:09:20,916:INFO:Importing libraries
2024-05-10 15:09:20,916:INFO:Copying training dataset
2024-05-10 15:09:20,919:INFO:Defining folds
2024-05-10 15:09:20,919:INFO:Declaring metric variables
2024-05-10 15:09:20,923:INFO:Importing untrained model
2024-05-10 15:09:20,923:INFO:Declaring custom model
2024-05-10 15:09:20,925:INFO:Extra Trees Regressor Imported successfully
2024-05-10 15:09:20,929:INFO:Starting cross validation
2024-05-10 15:09:20,934:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:21,347:INFO:Calculating mean and std
2024-05-10 15:09:21,348:INFO:Creating metrics dataframe
2024-05-10 15:09:21,351:INFO:Finalizing model
2024-05-10 15:09:21,543:INFO:Uploading results into container
2024-05-10 15:09:21,544:INFO:Uploading model into container now
2024-05-10 15:09:21,544:INFO:_master_model_container: 19
2024-05-10 15:09:21,544:INFO:_display_container: 3
2024-05-10 15:09:21,544:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123)
2024-05-10 15:09:21,544:INFO:create_model() successfully completed......................................
2024-05-10 15:09:21,654:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:21,654:INFO:choose_better activated
2024-05-10 15:09:21,657:INFO:SubProcess create_model() called ==================================
2024-05-10 15:09:21,657:INFO:Initializing create_model()
2024-05-10 15:09:21,657:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 15:09:21,657:INFO:Checking exceptions
2024-05-10 15:09:21,658:INFO:Importing libraries
2024-05-10 15:09:21,658:INFO:Copying training dataset
2024-05-10 15:09:21,660:INFO:Defining folds
2024-05-10 15:09:21,660:INFO:Declaring metric variables
2024-05-10 15:09:21,660:INFO:Importing untrained model
2024-05-10 15:09:21,660:INFO:Declaring custom model
2024-05-10 15:09:21,661:INFO:Extra Trees Regressor Imported successfully
2024-05-10 15:09:21,661:INFO:Starting cross validation
2024-05-10 15:09:21,665:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 15:09:21,981:INFO:Calculating mean and std
2024-05-10 15:09:21,981:INFO:Creating metrics dataframe
2024-05-10 15:09:21,982:INFO:Finalizing model
2024-05-10 15:09:22,111:INFO:Uploading results into container
2024-05-10 15:09:22,112:INFO:Uploading model into container now
2024-05-10 15:09:22,112:INFO:_master_model_container: 20
2024-05-10 15:09:22,112:INFO:_display_container: 4
2024-05-10 15:09:22,112:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:09:22,113:INFO:create_model() successfully completed......................................
2024-05-10 15:09:22,222:INFO:SubProcess create_model() end ==================================
2024-05-10 15:09:22,223:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) result for R2 is 0.6563
2024-05-10 15:09:22,223:INFO:ExtraTreesRegressor(max_depth=8, max_features='sqrt',
                    min_impurity_decrease=0.0001, min_samples_leaf=2,
                    min_samples_split=5, n_estimators=240, n_jobs=-1,
                    random_state=123) result for R2 is 0.6499
2024-05-10 15:09:22,223:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123) is best model
2024-05-10 15:09:22,223:INFO:choose_better completed
2024-05-10 15:09:22,223:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2024-05-10 15:09:22,229:INFO:_master_model_container: 20
2024-05-10 15:09:22,230:INFO:_display_container: 3
2024-05-10 15:09:22,230:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2024-05-10 15:09:22,230:INFO:tune_model() successfully completed......................................
2024-05-10 15:09:22,341:INFO:Initializing evaluate_model()
2024-05-10 15:09:22,341:INFO:evaluate_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None)
2024-05-10 15:09:22,347:INFO:Initializing plot_model()
2024-05-10 15:09:22,348:INFO:plot_model(plot=pipeline, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, system=True)
2024-05-10 15:09:22,348:INFO:Checking exceptions
2024-05-10 15:09:22,357:INFO:Preloading libraries
2024-05-10 15:09:22,363:INFO:Copying training dataset
2024-05-10 15:09:22,363:INFO:Plot type: pipeline
2024-05-10 15:09:22,448:INFO:Visual Rendered Successfully
2024-05-10 15:09:22,560:INFO:plot_model() successfully completed......................................
2024-05-10 15:09:25,125:INFO:Initializing plot_model()
2024-05-10 15:09:25,126:INFO:plot_model(plot=residuals, fold=KFold(n_splits=10, random_state=None, shuffle=False), verbose=False, display=None, display_format=None, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.regression.oop.RegressionExperiment object at 0x701d31d4ee20>, system=True)
2024-05-10 15:09:25,126:INFO:Checking exceptions
2024-05-10 15:09:25,139:INFO:Preloading libraries
2024-05-10 15:09:25,144:INFO:Copying training dataset
2024-05-10 15:09:25,144:INFO:Plot type: residuals
2024-05-10 15:09:25,437:INFO:Fitting Model
2024-05-10 15:09:25,437:WARNING:/home/nhnacademy/anaconda3/envs/smoothing/lib/python3.9/site-packages/sklearn/base.py:493: UserWarning: X does not have valid feature names, but ExtraTreesRegressor was fitted with feature names
  warnings.warn(

2024-05-10 15:09:25,477:INFO:Scoring test/hold-out set
2024-05-10 15:09:25,694:INFO:Visual Rendered Successfully
2024-05-10 15:09:25,803:INFO:plot_model() successfully completed......................................
2024-05-10 15:26:37,205:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:33:57,113:INFO:PyCaret TSForecastingExperiment
2024-05-10 15:33:57,113:INFO:Logging name: ts-default-name
2024-05-10 15:33:57,113:INFO:ML Usecase: MLUsecase.TIME_SERIES
2024-05-10 15:33:57,113:INFO:version 3.3.2
2024-05-10 15:33:57,113:INFO:Initializing setup()
2024-05-10 15:33:57,113:INFO:self.USI: 6897
2024-05-10 15:33:57,113:INFO:self._variable_keys: {'y_train_transformed', 'significant_sps', 'seed', 'model_engines', '_ml_usecase', '_available_plots', 'gpu_n_jobs_param', 'exogenous_present', 'data', 'y', 'approach_type', 'enforce_pi', 'n_jobs_param', 'logging_param', 'seasonality_present', 'y_train', 'memory', 'X', 'y_transformed', 'log_plots_param', 'enforce_exogenous', 'html_param', 'X_transformed', 'X_train_transformed', 'X_test_transformed', 'gpu_param', 'primary_sp_to_use', 'exp_name_log', 'significant_sps_no_harmonics', 'index_type', 'fold_param', 'strictly_positive', 'pipeline', 'candidate_sps', 'all_sps_to_use', 'X_test', 'y_test_transformed', 'idx', 'y_test', 'fh', 'USI', 'X_train', 'exp_id', 'fold_generator'}
2024-05-10 15:33:57,113:INFO:Checking environment
2024-05-10 15:33:57,113:INFO:python_version: 3.9.18
2024-05-10 15:33:57,113:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 15:33:57,113:INFO:machine: x86_64
2024-05-10 15:33:57,114:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:33:57,114:INFO:Memory: svmem(total=16429797376, available=7879204864, percent=52.0, used=7364890624, free=5624741888, active=4940279808, inactive=4411846656, buffers=207867904, cached=3232296960, shared=839159808, slab=733986816)
2024-05-10 15:33:57,114:INFO:Physical Core: 12
2024-05-10 15:33:57,114:INFO:Logical Core: 16
2024-05-10 15:33:57,114:INFO:Checking libraries
2024-05-10 15:33:57,114:INFO:System:
2024-05-10 15:33:57,114:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 15:33:57,114:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 15:33:57,114:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:33:57,114:INFO:PyCaret required dependencies:
2024-05-10 15:33:57,114:INFO:                 pip: 23.3.1
2024-05-10 15:33:57,114:INFO:          setuptools: 68.2.2
2024-05-10 15:33:57,114:INFO:             pycaret: 3.3.2
2024-05-10 15:33:57,114:INFO:             IPython: 8.15.0
2024-05-10 15:33:57,114:INFO:          ipywidgets: 7.6.5
2024-05-10 15:33:57,114:INFO:                tqdm: 4.65.0
2024-05-10 15:33:57,114:INFO:               numpy: 1.26.4
2024-05-10 15:33:57,114:INFO:              pandas: 2.1.4
2024-05-10 15:33:57,114:INFO:              jinja2: 3.1.3
2024-05-10 15:33:57,114:INFO:               scipy: 1.11.4
2024-05-10 15:33:57,114:INFO:              joblib: 1.2.0
2024-05-10 15:33:57,115:INFO:             sklearn: 1.4.2
2024-05-10 15:33:57,115:INFO:                pyod: 1.1.3
2024-05-10 15:33:57,115:INFO:            imblearn: 0.12.2
2024-05-10 15:33:57,115:INFO:   category_encoders: 2.6.3
2024-05-10 15:33:57,115:INFO:            lightgbm: 4.3.0
2024-05-10 15:33:57,115:INFO:               numba: 0.59.1
2024-05-10 15:33:57,115:INFO:            requests: 2.31.0
2024-05-10 15:33:57,115:INFO:          matplotlib: 3.7.5
2024-05-10 15:33:57,115:INFO:          scikitplot: 0.3.7
2024-05-10 15:33:57,115:INFO:         yellowbrick: 1.5
2024-05-10 15:33:57,115:INFO:              plotly: 5.19.0
2024-05-10 15:33:57,115:INFO:    plotly-resampler: Not installed
2024-05-10 15:33:57,115:INFO:             kaleido: 0.2.1
2024-05-10 15:33:57,115:INFO:           schemdraw: 0.15
2024-05-10 15:33:57,115:INFO:         statsmodels: 0.14.0
2024-05-10 15:33:57,115:INFO:              sktime: 0.26.0
2024-05-10 15:33:57,115:INFO:               tbats: 1.1.3
2024-05-10 15:33:57,115:INFO:            pmdarima: 2.0.4
2024-05-10 15:33:57,115:INFO:              psutil: 5.9.0
2024-05-10 15:33:57,115:INFO:          markupsafe: 2.1.3
2024-05-10 15:33:57,115:INFO:             pickle5: Not installed
2024-05-10 15:33:57,115:INFO:         cloudpickle: 2.2.1
2024-05-10 15:33:57,115:INFO:         deprecation: 2.1.0
2024-05-10 15:33:57,115:INFO:              xxhash: 3.4.1
2024-05-10 15:33:57,115:INFO:           wurlitzer: 3.0.2
2024-05-10 15:33:57,115:INFO:PyCaret optional dependencies:
2024-05-10 15:33:57,115:INFO:                shap: Not installed
2024-05-10 15:33:57,115:INFO:           interpret: Not installed
2024-05-10 15:33:57,115:INFO:                umap: Not installed
2024-05-10 15:33:57,115:INFO:     ydata_profiling: Not installed
2024-05-10 15:33:57,115:INFO:  explainerdashboard: Not installed
2024-05-10 15:33:57,115:INFO:             autoviz: Not installed
2024-05-10 15:33:57,115:INFO:           fairlearn: Not installed
2024-05-10 15:33:57,115:INFO:          deepchecks: Not installed
2024-05-10 15:33:57,115:INFO:             xgboost: Not installed
2024-05-10 15:33:57,115:INFO:            catboost: Not installed
2024-05-10 15:33:57,115:INFO:              kmodes: Not installed
2024-05-10 15:33:57,115:INFO:             mlxtend: Not installed
2024-05-10 15:33:57,115:INFO:       statsforecast: Not installed
2024-05-10 15:33:57,115:INFO:        tune_sklearn: Not installed
2024-05-10 15:33:57,115:INFO:                 ray: Not installed
2024-05-10 15:33:57,115:INFO:            hyperopt: Not installed
2024-05-10 15:33:57,115:INFO:              optuna: Not installed
2024-05-10 15:33:57,115:INFO:               skopt: Not installed
2024-05-10 15:33:57,115:INFO:              mlflow: Not installed
2024-05-10 15:33:57,115:INFO:              gradio: Not installed
2024-05-10 15:33:57,115:INFO:             fastapi: Not installed
2024-05-10 15:33:57,115:INFO:             uvicorn: Not installed
2024-05-10 15:33:57,115:INFO:              m2cgen: Not installed
2024-05-10 15:33:57,115:INFO:           evidently: Not installed
2024-05-10 15:33:57,115:INFO:               fugue: Not installed
2024-05-10 15:33:57,115:INFO:           streamlit: 1.32.0
2024-05-10 15:33:57,115:INFO:             prophet: Not installed
2024-05-10 15:33:57,115:INFO:None
2024-05-10 15:34:11,562:INFO:PyCaret TSForecastingExperiment
2024-05-10 15:34:11,562:INFO:Logging name: ts-default-name
2024-05-10 15:34:11,562:INFO:ML Usecase: MLUsecase.TIME_SERIES
2024-05-10 15:34:11,562:INFO:version 3.3.2
2024-05-10 15:34:11,563:INFO:Initializing setup()
2024-05-10 15:34:11,563:INFO:self.USI: 5173
2024-05-10 15:34:11,563:INFO:self._variable_keys: {'y_train_transformed', 'significant_sps', 'seed', 'model_engines', '_ml_usecase', '_available_plots', 'gpu_n_jobs_param', 'exogenous_present', 'data', 'y', 'approach_type', 'enforce_pi', 'n_jobs_param', 'logging_param', 'seasonality_present', 'y_train', 'memory', 'X', 'y_transformed', 'log_plots_param', 'enforce_exogenous', 'html_param', 'X_transformed', 'X_train_transformed', 'X_test_transformed', 'gpu_param', 'primary_sp_to_use', 'exp_name_log', 'significant_sps_no_harmonics', 'index_type', 'fold_param', 'strictly_positive', 'pipeline', 'candidate_sps', 'all_sps_to_use', 'X_test', 'y_test_transformed', 'idx', 'y_test', 'fh', 'USI', 'X_train', 'exp_id', 'fold_generator'}
2024-05-10 15:34:11,563:INFO:Checking environment
2024-05-10 15:34:11,563:INFO:python_version: 3.9.18
2024-05-10 15:34:11,563:INFO:python_build: ('main', 'Sep 11 2023 13:41:44')
2024-05-10 15:34:11,563:INFO:machine: x86_64
2024-05-10 15:34:11,563:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:34:11,563:INFO:Memory: svmem(total=16429797376, available=7851679744, percent=52.2, used=7394045952, free=5597048832, active=4962435072, inactive=4412014592, buffers=207990784, cached=3230711808, shared=837529600, slab=733958144)
2024-05-10 15:34:11,563:INFO:Physical Core: 12
2024-05-10 15:34:11,563:INFO:Logical Core: 16
2024-05-10 15:34:11,563:INFO:Checking libraries
2024-05-10 15:34:11,564:INFO:System:
2024-05-10 15:34:11,564:INFO:    python: 3.9.18 (main, Sep 11 2023, 13:41:44)  [GCC 11.2.0]
2024-05-10 15:34:11,564:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing/bin/python
2024-05-10 15:34:11,564:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 15:34:11,564:INFO:PyCaret required dependencies:
2024-05-10 15:34:11,564:INFO:                 pip: 23.3.1
2024-05-10 15:34:11,564:INFO:          setuptools: 68.2.2
2024-05-10 15:34:11,564:INFO:             pycaret: 3.3.2
2024-05-10 15:34:11,564:INFO:             IPython: 8.15.0
2024-05-10 15:34:11,564:INFO:          ipywidgets: 7.6.5
2024-05-10 15:34:11,564:INFO:                tqdm: 4.65.0
2024-05-10 15:34:11,564:INFO:               numpy: 1.26.4
2024-05-10 15:34:11,564:INFO:              pandas: 2.1.4
2024-05-10 15:34:11,564:INFO:              jinja2: 3.1.3
2024-05-10 15:34:11,564:INFO:               scipy: 1.11.4
2024-05-10 15:34:11,564:INFO:              joblib: 1.2.0
2024-05-10 15:34:11,564:INFO:             sklearn: 1.4.2
2024-05-10 15:34:11,564:INFO:                pyod: 1.1.3
2024-05-10 15:34:11,564:INFO:            imblearn: 0.12.2
2024-05-10 15:34:11,564:INFO:   category_encoders: 2.6.3
2024-05-10 15:34:11,564:INFO:            lightgbm: 4.3.0
2024-05-10 15:34:11,564:INFO:               numba: 0.59.1
2024-05-10 15:34:11,564:INFO:            requests: 2.31.0
2024-05-10 15:34:11,564:INFO:          matplotlib: 3.7.5
2024-05-10 15:34:11,564:INFO:          scikitplot: 0.3.7
2024-05-10 15:34:11,564:INFO:         yellowbrick: 1.5
2024-05-10 15:34:11,564:INFO:              plotly: 5.19.0
2024-05-10 15:34:11,564:INFO:    plotly-resampler: Not installed
2024-05-10 15:34:11,564:INFO:             kaleido: 0.2.1
2024-05-10 15:34:11,565:INFO:           schemdraw: 0.15
2024-05-10 15:34:11,565:INFO:         statsmodels: 0.14.0
2024-05-10 15:34:11,565:INFO:              sktime: 0.26.0
2024-05-10 15:34:11,565:INFO:               tbats: 1.1.3
2024-05-10 15:34:11,565:INFO:            pmdarima: 2.0.4
2024-05-10 15:34:11,565:INFO:              psutil: 5.9.0
2024-05-10 15:34:11,565:INFO:          markupsafe: 2.1.3
2024-05-10 15:34:11,565:INFO:             pickle5: Not installed
2024-05-10 15:34:11,565:INFO:         cloudpickle: 2.2.1
2024-05-10 15:34:11,565:INFO:         deprecation: 2.1.0
2024-05-10 15:34:11,565:INFO:              xxhash: 3.4.1
2024-05-10 15:34:11,565:INFO:           wurlitzer: 3.0.2
2024-05-10 15:34:11,565:INFO:PyCaret optional dependencies:
2024-05-10 15:34:11,565:INFO:                shap: Not installed
2024-05-10 15:34:11,565:INFO:           interpret: Not installed
2024-05-10 15:34:11,565:INFO:                umap: Not installed
2024-05-10 15:34:11,565:INFO:     ydata_profiling: Not installed
2024-05-10 15:34:11,565:INFO:  explainerdashboard: Not installed
2024-05-10 15:34:11,565:INFO:             autoviz: Not installed
2024-05-10 15:34:11,566:INFO:           fairlearn: Not installed
2024-05-10 15:34:11,566:INFO:          deepchecks: Not installed
2024-05-10 15:34:11,566:INFO:             xgboost: Not installed
2024-05-10 15:34:11,566:INFO:            catboost: Not installed
2024-05-10 15:34:11,566:INFO:              kmodes: Not installed
2024-05-10 15:34:11,566:INFO:             mlxtend: Not installed
2024-05-10 15:34:11,566:INFO:       statsforecast: Not installed
2024-05-10 15:34:11,566:INFO:        tune_sklearn: Not installed
2024-05-10 15:34:11,566:INFO:                 ray: Not installed
2024-05-10 15:34:11,566:INFO:            hyperopt: Not installed
2024-05-10 15:34:11,566:INFO:              optuna: Not installed
2024-05-10 15:34:11,567:INFO:               skopt: Not installed
2024-05-10 15:34:11,567:INFO:              mlflow: Not installed
2024-05-10 15:34:11,567:INFO:              gradio: Not installed
2024-05-10 15:34:11,567:INFO:             fastapi: Not installed
2024-05-10 15:34:11,567:INFO:             uvicorn: Not installed
2024-05-10 15:34:11,567:INFO:              m2cgen: Not installed
2024-05-10 15:34:11,567:INFO:           evidently: Not installed
2024-05-10 15:34:11,567:INFO:               fugue: Not installed
2024-05-10 15:34:11,567:INFO:           streamlit: 1.32.0
2024-05-10 15:34:11,567:INFO:             prophet: Not installed
2024-05-10 15:34:11,567:INFO:None
2024-05-10 15:34:11,577:INFO:Set Forecast Horizon.
2024-05-10 15:34:11,577:INFO:Set up Train-Test Splits.
2024-05-10 15:34:11,591:INFO:Preparing preprocessing pipeline...
2024-05-10 15:34:11,591:INFO:Set up imputation for Target variable(s).
2024-05-10 15:34:11,591:INFO:Set up imputation for Exogenous variable(s).
2024-05-10 15:34:11,679:INFO:Finished creating preprocessing pipeline.
2024-05-10 15:34:11,686:INFO:Pipeline: ForecastingPipeline(steps=[('transformer_exogenous',
                            TransformerPipeline(steps=[('numerical_imputer',
                                                        Imputer(random_state=42))])),
                           ('forecaster',
                            TransformedTargetForecaster(steps=[('transformer_target',
                                                                TransformerPipeline(steps=[('numerical_imputer',
                                                                                            Imputer(random_state=42))])),
                                                               ('model',
                                                                DummyForecaster())]))])
2024-05-10 15:34:11,686:INFO:Set up Seasonal Period.
2024-05-10 15:34:11,694:INFO:Setting the seasonal component type - 'add' or 'mul'.
2024-05-10 15:34:11,694:INFO:Checking if data is strictly positive.
2024-05-10 15:34:11,726:INFO:Creating final display dataframe.
2024-05-10 15:34:11,746:INFO:Setup Display Container:                                           Description  \
0                                          session_id   
1                                              Target   
2                                            Approach   
3                                 Exogenous Variables   
4                                 Original data shape   
5                              Transformed data shape   
6                         Transformed train set shape   
7                          Transformed test set shape   
8                            Rows with missing values   
9                                      Fold Generator   
10                                        Fold Number   
11                        Enforce Prediction Interval   
12                    Splits used for hyperparameters   
13                    User Defined Seasonal Period(s)   
14                            Ignore Seasonality Test   
15                         Seasonality Detection Algo   
16                             Max Period to Consider   
17                          Seasonal Period(s) Tested   
18                     Significant Seasonal Period(s)   
19   Significant Seasonal Period(s) without Harmonics   
20                                   Remove Harmonics   
21                             Harmonics Order Method   
22                           Num Seasonalities to Use   
23                           All Seasonalities to Use   
24                                Primary Seasonality   
25                                Seasonality Present   
26                                   Seasonality Type   
27                           Target Strictly Positive   
28                                 Target White Noise   
29                                      Recommended d   
30                             Recommended Seasonal D   
31                                         Preprocess   
32                      Numerical Imputation (Target)   
33                            Transformation (Target)   
34                                   Scaling (Target)   
35  Feature Engineering (Target) - Reduced Regression   
36                   Numerical Imputation (Exogenous)   
37                         Transformation (Exogenous)   
38                                Scaling (Exogenous)   
39                                           CPU Jobs   
40                                            Use GPU   
41                                     Log Experiment   
42                                    Experiment Name   
43                                                USI   

                                                Value  
0                                                  42  
1                                    socket_power(Wh)  
2                                          Univariate  
3                                             Present  
4                                            (600, 4)  
5                                            (600, 4)  
6                                            (552, 4)  
7                                             (48, 4)  
8                                                0.0%  
9                             ExpandingWindowSplitter  
10                                                  3  
11                                              False  
12                                                all  
13                                               None  
14                                              False  
15                                               auto  
16                                                 60  
17  [2, 3, 24, 23, 25, 4, 22, 26, 21, 5, 48, 20, 2...  
18  [2, 3, 24, 23, 25, 4, 22, 26, 21, 5, 48, 20, 2...  
19   [48, 46, 25, 22, 26, 21, 20, 27, 47, 49, 28, 19]  
20                                              False  
21                                       harmonic_max  
22                                                  1  
23                                                [2]  
24                                                  2  
25                                               True  
26                                                mul  
27                                               True  
28                                                 No  
29                                                  0  
30                                                  0  
31                                               True  
32                                              drift  
33                                               None  
34                                               None  
35                                              False  
36                                              drift  
37                                               None  
38                                               None  
39                                                 -1  
40                                              False  
41                                              False  
42                                    ts-default-name  
43                                               5173  
2024-05-10 15:34:11,751:INFO:Engine successfully changes for model 'auto_arima' to 'pmdarima'.
2024-05-10 15:34:11,770:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,770:INFO:Engine for model 'lr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,770:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,770:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,771:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,771:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,771:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,771:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,773:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,774:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,775:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,775:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,775:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,775:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,775:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,776:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,776:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,776:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,776:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,776:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,778:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,778:INFO:Engine for model 'lr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,778:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,779:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,779:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,779:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,779:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,779:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,781:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,783:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,784:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,784:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,784:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,784:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,784:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,785:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,785:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,785:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,785:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,785:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,785:INFO:Engine successfully changes for model 'lr_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,787:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,787:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,788:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,788:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,788:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,788:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,788:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,789:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,791:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,791:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,791:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,791:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,791:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,792:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,792:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,792:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,792:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,794:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,794:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,794:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,794:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,795:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,795:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,795:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,796:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,797:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,798:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,798:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,798:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,798:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,798:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,799:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,799:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,799:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,799:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,799:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,799:INFO:Engine successfully changes for model 'en_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,801:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,801:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,802:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,802:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,802:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,802:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,803:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,804:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,804:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,805:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,805:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,805:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,805:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,805:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,805:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,805:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,805:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,807:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,807:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,808:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,808:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,808:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,808:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,809:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,810:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,810:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,810:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,811:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,811:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,811:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,811:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,811:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,811:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,811:INFO:Engine successfully changes for model 'ridge_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,813:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,813:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,813:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,814:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,814:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,815:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,816:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,816:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,816:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,816:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,816:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,817:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,817:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,817:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,817:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,817:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,817:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,819:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,820:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,820:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,820:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,820:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,822:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,823:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,824:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,824:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,824:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,824:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,824:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,824:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,824:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,824:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,825:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,825:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,825:INFO:Engine successfully changes for model 'lasso_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,826:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,827:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,827:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,827:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,828:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,829:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,830:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,830:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,830:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,830:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,830:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,830:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,830:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,831:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,831:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,831:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,832:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,833:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,833:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,833:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,834:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,835:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,836:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,836:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,836:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,836:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,836:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,836:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,836:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,836:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,837:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,837:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,837:INFO:Engine successfully changes for model 'lar_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,838:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,839:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,839:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,839:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,840:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,841:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,841:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,842:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,842:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,842:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,842:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,842:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,842:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,842:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,843:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,843:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,845:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,845:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,845:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,845:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,847:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,848:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,848:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,848:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,849:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,849:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,849:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,849:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,849:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,849:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,850:INFO:Engine successfully changes for model 'llar_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,851:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,852:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,852:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,853:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,855:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,855:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,855:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,855:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,855:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,856:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,856:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,856:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,856:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,856:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,858:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,859:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,859:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,860:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,861:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,861:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,861:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,862:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,862:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,862:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,862:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,862:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,862:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,862:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,862:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,862:INFO:Engine successfully changes for model 'br_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,864:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,865:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,866:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,867:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,867:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,867:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,868:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,868:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,868:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,868:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,868:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,868:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,868:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,870:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,871:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,872:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,873:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,874:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,874:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,874:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,874:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,874:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,874:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,874:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,875:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,875:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,875:INFO:Engine successfully changes for model 'huber_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,877:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,879:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,880:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,880:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,880:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,880:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,880:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,881:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,881:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,881:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,881:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,881:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,881:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,883:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,885:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,887:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,887:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,887:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,887:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,887:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,888:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,888:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,888:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,888:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,888:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,888:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,888:INFO:Engine successfully changes for model 'par_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,890:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,892:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,893:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,894:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,894:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,894:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,894:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,894:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,894:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,894:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,894:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,895:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,896:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,898:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,899:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,900:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,900:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,900:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,900:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,901:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,901:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,901:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,901:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,901:INFO:Engine successfully changes for model 'omp_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,903:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,905:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,906:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,906:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,906:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,906:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,906:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,907:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,907:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,907:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,907:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,907:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,909:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,912:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,912:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,912:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,912:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,912:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,912:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,913:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,913:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,913:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,913:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,913:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,913:INFO:Engine successfully changes for model 'knn_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,915:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,918:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,918:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,918:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,918:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,918:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,918:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,918:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,919:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,919:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,920:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,923:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,924:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,924:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,924:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,924:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,924:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,924:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,924:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,924:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,924:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,925:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,925:INFO:Engine successfully changes for model 'dt_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,926:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,930:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,930:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,930:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,930:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,930:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,930:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,931:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,931:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,932:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,936:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,936:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,936:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,936:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,936:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,936:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,936:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,936:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,936:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,937:INFO:Engine successfully changes for model 'rf_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,938:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,941:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,942:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,942:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,942:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,942:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,942:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,942:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,944:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,948:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,948:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,949:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,949:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,949:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,949:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,949:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,949:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,949:INFO:Engine successfully changes for model 'et_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,951:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,954:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,954:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,954:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,954:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,954:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,955:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,955:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,956:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,960:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,960:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,960:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,960:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,960:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,960:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,960:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,961:INFO:Engine successfully changes for model 'gbr_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,962:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,966:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,966:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,966:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,966:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,966:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,968:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,972:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,972:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,972:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,972:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,972:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,972:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,972:INFO:Engine successfully changes for model 'ada_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,974:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,978:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,978:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,978:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,978:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,980:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,985:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,985:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,985:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,985:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,985:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,985:INFO:Engine successfully changes for model 'xgboost_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,987:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,991:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,991:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,991:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,991:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,993:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:11,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,997:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,997:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,997:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:11,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,997:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:11,997:INFO:Engine successfully changes for model 'lightgbm_cds_dt' to 'sklearn'.
2024-05-10 15:34:11,999:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:12,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,003:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,003:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:12,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,003:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,005:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:12,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,009:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 15:34:12,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,009:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,009:INFO:Engine successfully changes for model 'catboost_cds_dt' to 'sklearn'.
2024-05-10 15:34:12,011:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:12,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,015:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,017:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:12,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,021:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,022:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:12,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,026:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,028:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 15:34:12,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,032:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,033:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 15:34:12,033:INFO:setup() successfully completed in 0.47s...............
2024-05-10 15:35:15,428:INFO:Visual Rendered Successfully
2024-05-10 15:36:44,462:INFO:Visual Rendered Successfully
2024-05-10 16:45:34,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 16:45:34,398:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 16:45:34,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 16:45:34,399:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-05-10 16:45:47,016:INFO:PyCaret RegressionExperiment
2024-05-10 16:45:47,016:INFO:Logging name: reg-default-name
2024-05-10 16:45:47,016:INFO:ML Usecase: MLUsecase.REGRESSION
2024-05-10 16:45:47,016:INFO:version 3.3.2
2024-05-10 16:45:47,016:INFO:Initializing setup()
2024-05-10 16:45:47,016:INFO:self.USI: b6c4
2024-05-10 16:45:47,016:INFO:self._variable_keys: {'USI', 'data', 'y_train', 'gpu_param', 'html_param', 'y_test', 'gpu_n_jobs_param', 'fold_groups_param', 'memory', 'transform_target_param', 'seed', 'exp_name_log', 'X_train', 'fold_generator', 'n_jobs_param', 'log_plots_param', 'y', 'fold_shuffle_param', 'logging_param', 'X', 'X_test', '_ml_usecase', 'idx', 'exp_id', 'pipeline', 'target_param', '_available_plots'}
2024-05-10 16:45:47,016:INFO:Checking environment
2024-05-10 16:45:47,016:INFO:python_version: 3.9.19
2024-05-10 16:45:47,016:INFO:python_build: ('main', 'May  6 2024 19:43:03')
2024-05-10 16:45:47,016:INFO:machine: x86_64
2024-05-10 16:45:47,016:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 16:45:47,016:INFO:Memory: svmem(total=16429797376, available=9112248320, percent=44.5, used=6198099968, free=1432596480, active=5368995840, inactive=7697321984, buffers=528400384, cached=8270700544, shared=772907008, slab=1068589056)
2024-05-10 16:45:47,017:INFO:Physical Core: 12
2024-05-10 16:45:47,017:INFO:Logical Core: 16
2024-05-10 16:45:47,017:INFO:Checking libraries
2024-05-10 16:45:47,017:INFO:System:
2024-05-10 16:45:47,017:INFO:    python: 3.9.19 (main, May  6 2024, 19:43:03)  [GCC 11.2.0]
2024-05-10 16:45:47,017:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing_ml/bin/python
2024-05-10 16:45:47,017:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 16:45:47,017:INFO:PyCaret required dependencies:
2024-05-10 16:45:47,032:INFO:                 pip: 24.0
2024-05-10 16:45:47,033:INFO:          setuptools: 69.5.1
2024-05-10 16:45:47,033:INFO:             pycaret: 3.3.2
2024-05-10 16:45:47,033:INFO:             IPython: 8.12.0
2024-05-10 16:45:47,033:INFO:          ipywidgets: 8.1.2
2024-05-10 16:45:47,033:INFO:                tqdm: 4.66.4
2024-05-10 16:45:47,033:INFO:               numpy: 1.26.4
2024-05-10 16:45:47,033:INFO:              pandas: 2.1.4
2024-05-10 16:45:47,033:INFO:              jinja2: 3.1.4
2024-05-10 16:45:47,033:INFO:               scipy: 1.11.4
2024-05-10 16:45:47,033:INFO:              joblib: 1.3.2
2024-05-10 16:45:47,033:INFO:             sklearn: 1.4.2
2024-05-10 16:45:47,033:INFO:                pyod: 1.1.3
2024-05-10 16:45:47,033:INFO:            imblearn: 0.12.2
2024-05-10 16:45:47,033:INFO:   category_encoders: 2.6.3
2024-05-10 16:45:47,033:INFO:            lightgbm: 4.3.0
2024-05-10 16:45:47,033:INFO:               numba: 0.59.1
2024-05-10 16:45:47,033:INFO:            requests: 2.31.0
2024-05-10 16:45:47,033:INFO:          matplotlib: 3.7.5
2024-05-10 16:45:47,033:INFO:          scikitplot: 0.3.7
2024-05-10 16:45:47,033:INFO:         yellowbrick: 1.5
2024-05-10 16:45:47,033:INFO:              plotly: 5.22.0
2024-05-10 16:45:47,033:INFO:    plotly-resampler: Not installed
2024-05-10 16:45:47,033:INFO:             kaleido: 0.2.1
2024-05-10 16:45:47,033:INFO:           schemdraw: 0.15
2024-05-10 16:45:47,033:INFO:         statsmodels: 0.14.2
2024-05-10 16:45:47,033:INFO:              sktime: 0.26.0
2024-05-10 16:45:47,033:INFO:               tbats: 1.1.3
2024-05-10 16:45:47,033:INFO:            pmdarima: 2.0.4
2024-05-10 16:45:47,033:INFO:              psutil: 5.9.0
2024-05-10 16:45:47,033:INFO:          markupsafe: 2.1.5
2024-05-10 16:45:47,033:INFO:             pickle5: Not installed
2024-05-10 16:45:47,033:INFO:         cloudpickle: 3.0.0
2024-05-10 16:45:47,033:INFO:         deprecation: 2.1.0
2024-05-10 16:45:47,033:INFO:              xxhash: 3.4.1
2024-05-10 16:45:47,033:INFO:           wurlitzer: 3.1.0
2024-05-10 16:45:47,033:INFO:PyCaret optional dependencies:
2024-05-10 16:45:47,040:INFO:                shap: Not installed
2024-05-10 16:45:47,040:INFO:           interpret: Not installed
2024-05-10 16:45:47,040:INFO:                umap: Not installed
2024-05-10 16:45:47,040:INFO:     ydata_profiling: Not installed
2024-05-10 16:45:47,040:INFO:  explainerdashboard: Not installed
2024-05-10 16:45:47,040:INFO:             autoviz: Not installed
2024-05-10 16:45:47,040:INFO:           fairlearn: Not installed
2024-05-10 16:45:47,040:INFO:          deepchecks: Not installed
2024-05-10 16:45:47,040:INFO:             xgboost: Not installed
2024-05-10 16:45:47,040:INFO:            catboost: Not installed
2024-05-10 16:45:47,040:INFO:              kmodes: Not installed
2024-05-10 16:45:47,040:INFO:             mlxtend: Not installed
2024-05-10 16:45:47,040:INFO:       statsforecast: Not installed
2024-05-10 16:45:47,040:INFO:        tune_sklearn: Not installed
2024-05-10 16:45:47,040:INFO:                 ray: Not installed
2024-05-10 16:45:47,040:INFO:            hyperopt: Not installed
2024-05-10 16:45:47,040:INFO:              optuna: Not installed
2024-05-10 16:45:47,040:INFO:               skopt: Not installed
2024-05-10 16:45:47,040:INFO:              mlflow: Not installed
2024-05-10 16:45:47,040:INFO:              gradio: Not installed
2024-05-10 16:45:47,040:INFO:             fastapi: Not installed
2024-05-10 16:45:47,040:INFO:             uvicorn: Not installed
2024-05-10 16:45:47,040:INFO:              m2cgen: Not installed
2024-05-10 16:45:47,040:INFO:           evidently: Not installed
2024-05-10 16:45:47,040:INFO:               fugue: Not installed
2024-05-10 16:45:47,040:INFO:           streamlit: Not installed
2024-05-10 16:45:47,040:INFO:             prophet: Not installed
2024-05-10 16:45:47,040:INFO:None
2024-05-10 16:45:47,040:INFO:Set up data.
2024-05-10 16:45:47,043:INFO:Set up folding strategy.
2024-05-10 16:45:47,043:INFO:Set up train/test split.
2024-05-10 16:45:47,045:INFO:Set up index.
2024-05-10 16:45:47,045:INFO:Assigning column types.
2024-05-10 16:45:47,046:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-05-10 16:45:47,046:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,049:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,051:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,079:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,098:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,099:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,101:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,102:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,129:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,149:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,149:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,150:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-05-10 16:45:47,152:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,154:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,181:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,201:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,204:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,206:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,233:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,256:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,257:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-05-10 16:45:47,261:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,288:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,309:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,310:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,310:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,314:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,342:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,363:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,363:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,363:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,363:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-05-10 16:45:47,396:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,417:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,417:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,448:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,469:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,470:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,470:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,470:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-05-10 16:45:47,501:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-05-10 16:45:47,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,577:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-05-10 16:45:47,629:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,629:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,684:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,684:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,685:INFO:Preparing preprocessing pipeline...
2024-05-10 16:45:47,685:INFO:Set up simple imputation.
2024-05-10 16:45:47,685:INFO:Set up feature normalization.
2024-05-10 16:45:47,686:INFO:Set up column name cleaning.
2024-05-10 16:45:47,700:INFO:Finished creating preprocessing pipeline.
2024-05-10 16:45:47,703:INFO:Pipeline: Pipeline(memory=FastMemory(location=/tmp/joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['average_humidity(%)',
                                             'average_co2(ppm)',
                                             'average_illumination(lux)'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('normalize', TransformerWrapper(transformer=StandardScaler())),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2024-05-10 16:45:47,703:INFO:Creating final display dataframe.
2024-05-10 16:45:47,746:INFO:Setup _display_container:                     Description             Value
0                    Session id                 1
1                        Target  socket_power(Wh)
2                   Target type        Regression
3           Original data shape          (600, 4)
4        Transformed data shape          (600, 4)
5   Transformed train set shape          (420, 4)
6    Transformed test set shape          (180, 4)
7              Numeric features                 3
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12                    Normalize              True
13             Normalize method            zscore
14               Fold Generator             KFold
15                  Fold Number                10
16                     CPU Jobs                -1
17                      Use GPU             False
18               Log Experiment             False
19              Experiment Name  reg-default-name
20                          USI              b6c4
2024-05-10 16:45:47,805:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,806:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,855:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,855:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 16:45:47,856:INFO:setup() successfully completed in 0.84s...............
2024-05-10 16:45:47,856:INFO:Initializing compare_models()
2024-05-10 16:45:47,856:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-05-10 16:45:47,856:INFO:Checking exceptions
2024-05-10 16:45:47,857:INFO:Preparing display monitor
2024-05-10 16:45:47,868:INFO:Initializing Linear Regression
2024-05-10 16:45:47,868:INFO:Total runtime is 1.438458760579427e-06 minutes
2024-05-10 16:45:47,870:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:47,870:INFO:Initializing create_model()
2024-05-10 16:45:47,870:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:47,870:INFO:Checking exceptions
2024-05-10 16:45:47,870:INFO:Importing libraries
2024-05-10 16:45:47,870:INFO:Copying training dataset
2024-05-10 16:45:47,872:INFO:Defining folds
2024-05-10 16:45:47,872:INFO:Declaring metric variables
2024-05-10 16:45:47,874:INFO:Importing untrained model
2024-05-10 16:45:47,877:INFO:Linear Regression Imported successfully
2024-05-10 16:45:47,882:INFO:Starting cross validation
2024-05-10 16:45:47,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:49,556:INFO:Calculating mean and std
2024-05-10 16:45:49,558:INFO:Creating metrics dataframe
2024-05-10 16:45:49,560:INFO:Uploading results into container
2024-05-10 16:45:49,561:INFO:Uploading model into container now
2024-05-10 16:45:49,562:INFO:_master_model_container: 1
2024-05-10 16:45:49,562:INFO:_display_container: 2
2024-05-10 16:45:49,562:INFO:LinearRegression(n_jobs=-1)
2024-05-10 16:45:49,562:INFO:create_model() successfully completed......................................
2024-05-10 16:45:49,632:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:49,632:INFO:Creating metrics dataframe
2024-05-10 16:45:49,636:INFO:Initializing Lasso Regression
2024-05-10 16:45:49,636:INFO:Total runtime is 0.029461562633514404 minutes
2024-05-10 16:45:49,638:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:49,638:INFO:Initializing create_model()
2024-05-10 16:45:49,638:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:49,638:INFO:Checking exceptions
2024-05-10 16:45:49,638:INFO:Importing libraries
2024-05-10 16:45:49,638:INFO:Copying training dataset
2024-05-10 16:45:49,640:INFO:Defining folds
2024-05-10 16:45:49,640:INFO:Declaring metric variables
2024-05-10 16:45:49,641:INFO:Importing untrained model
2024-05-10 16:45:49,643:INFO:Lasso Regression Imported successfully
2024-05-10 16:45:49,647:INFO:Starting cross validation
2024-05-10 16:45:49,648:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:50,718:INFO:Calculating mean and std
2024-05-10 16:45:50,719:INFO:Creating metrics dataframe
2024-05-10 16:45:50,721:INFO:Uploading results into container
2024-05-10 16:45:50,721:INFO:Uploading model into container now
2024-05-10 16:45:50,722:INFO:_master_model_container: 2
2024-05-10 16:45:50,722:INFO:_display_container: 2
2024-05-10 16:45:50,722:INFO:Lasso(random_state=1)
2024-05-10 16:45:50,722:INFO:create_model() successfully completed......................................
2024-05-10 16:45:50,786:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:50,787:INFO:Creating metrics dataframe
2024-05-10 16:45:50,791:INFO:Initializing Ridge Regression
2024-05-10 16:45:50,791:INFO:Total runtime is 0.04870671431223551 minutes
2024-05-10 16:45:50,793:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:50,793:INFO:Initializing create_model()
2024-05-10 16:45:50,793:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:50,793:INFO:Checking exceptions
2024-05-10 16:45:50,793:INFO:Importing libraries
2024-05-10 16:45:50,793:INFO:Copying training dataset
2024-05-10 16:45:50,796:INFO:Defining folds
2024-05-10 16:45:50,796:INFO:Declaring metric variables
2024-05-10 16:45:50,797:INFO:Importing untrained model
2024-05-10 16:45:50,799:INFO:Ridge Regression Imported successfully
2024-05-10 16:45:50,803:INFO:Starting cross validation
2024-05-10 16:45:50,803:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:50,854:INFO:Calculating mean and std
2024-05-10 16:45:50,855:INFO:Creating metrics dataframe
2024-05-10 16:45:50,857:INFO:Uploading results into container
2024-05-10 16:45:50,857:INFO:Uploading model into container now
2024-05-10 16:45:50,858:INFO:_master_model_container: 3
2024-05-10 16:45:50,858:INFO:_display_container: 2
2024-05-10 16:45:50,858:INFO:Ridge(random_state=1)
2024-05-10 16:45:50,858:INFO:create_model() successfully completed......................................
2024-05-10 16:45:50,917:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:50,918:INFO:Creating metrics dataframe
2024-05-10 16:45:50,922:INFO:Initializing Elastic Net
2024-05-10 16:45:50,922:INFO:Total runtime is 0.050889110565185545 minutes
2024-05-10 16:45:50,923:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:50,924:INFO:Initializing create_model()
2024-05-10 16:45:50,924:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:50,924:INFO:Checking exceptions
2024-05-10 16:45:50,924:INFO:Importing libraries
2024-05-10 16:45:50,924:INFO:Copying training dataset
2024-05-10 16:45:50,926:INFO:Defining folds
2024-05-10 16:45:50,926:INFO:Declaring metric variables
2024-05-10 16:45:50,929:INFO:Importing untrained model
2024-05-10 16:45:50,931:INFO:Elastic Net Imported successfully
2024-05-10 16:45:50,936:INFO:Starting cross validation
2024-05-10 16:45:50,938:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:51,005:INFO:Calculating mean and std
2024-05-10 16:45:51,006:INFO:Creating metrics dataframe
2024-05-10 16:45:51,007:INFO:Uploading results into container
2024-05-10 16:45:51,008:INFO:Uploading model into container now
2024-05-10 16:45:51,008:INFO:_master_model_container: 4
2024-05-10 16:45:51,008:INFO:_display_container: 2
2024-05-10 16:45:51,009:INFO:ElasticNet(random_state=1)
2024-05-10 16:45:51,009:INFO:create_model() successfully completed......................................
2024-05-10 16:45:51,067:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:51,067:INFO:Creating metrics dataframe
2024-05-10 16:45:51,071:INFO:Initializing Least Angle Regression
2024-05-10 16:45:51,071:INFO:Total runtime is 0.053378132979075114 minutes
2024-05-10 16:45:51,073:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:51,073:INFO:Initializing create_model()
2024-05-10 16:45:51,073:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:51,073:INFO:Checking exceptions
2024-05-10 16:45:51,073:INFO:Importing libraries
2024-05-10 16:45:51,073:INFO:Copying training dataset
2024-05-10 16:45:51,075:INFO:Defining folds
2024-05-10 16:45:51,076:INFO:Declaring metric variables
2024-05-10 16:45:51,077:INFO:Importing untrained model
2024-05-10 16:45:51,080:INFO:Least Angle Regression Imported successfully
2024-05-10 16:45:51,083:INFO:Starting cross validation
2024-05-10 16:45:51,083:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:51,138:INFO:Calculating mean and std
2024-05-10 16:45:51,139:INFO:Creating metrics dataframe
2024-05-10 16:45:51,140:INFO:Uploading results into container
2024-05-10 16:45:51,141:INFO:Uploading model into container now
2024-05-10 16:45:51,141:INFO:_master_model_container: 5
2024-05-10 16:45:51,141:INFO:_display_container: 2
2024-05-10 16:45:51,141:INFO:Lars(random_state=1)
2024-05-10 16:45:51,141:INFO:create_model() successfully completed......................................
2024-05-10 16:45:51,200:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:51,200:INFO:Creating metrics dataframe
2024-05-10 16:45:51,205:INFO:Initializing Lasso Least Angle Regression
2024-05-10 16:45:51,205:INFO:Total runtime is 0.055609254042307536 minutes
2024-05-10 16:45:51,207:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:51,207:INFO:Initializing create_model()
2024-05-10 16:45:51,207:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:51,207:INFO:Checking exceptions
2024-05-10 16:45:51,207:INFO:Importing libraries
2024-05-10 16:45:51,207:INFO:Copying training dataset
2024-05-10 16:45:51,209:INFO:Defining folds
2024-05-10 16:45:51,209:INFO:Declaring metric variables
2024-05-10 16:45:51,211:INFO:Importing untrained model
2024-05-10 16:45:51,214:INFO:Lasso Least Angle Regression Imported successfully
2024-05-10 16:45:51,218:INFO:Starting cross validation
2024-05-10 16:45:51,219:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:51,278:INFO:Calculating mean and std
2024-05-10 16:45:51,279:INFO:Creating metrics dataframe
2024-05-10 16:45:51,280:INFO:Uploading results into container
2024-05-10 16:45:51,281:INFO:Uploading model into container now
2024-05-10 16:45:51,281:INFO:_master_model_container: 6
2024-05-10 16:45:51,281:INFO:_display_container: 2
2024-05-10 16:45:51,281:INFO:LassoLars(random_state=1)
2024-05-10 16:45:51,281:INFO:create_model() successfully completed......................................
2024-05-10 16:45:51,338:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:51,338:INFO:Creating metrics dataframe
2024-05-10 16:45:51,343:INFO:Initializing Orthogonal Matching Pursuit
2024-05-10 16:45:51,343:INFO:Total runtime is 0.05790778001149496 minutes
2024-05-10 16:45:51,345:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:51,346:INFO:Initializing create_model()
2024-05-10 16:45:51,346:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:51,346:INFO:Checking exceptions
2024-05-10 16:45:51,346:INFO:Importing libraries
2024-05-10 16:45:51,346:INFO:Copying training dataset
2024-05-10 16:45:51,348:INFO:Defining folds
2024-05-10 16:45:51,348:INFO:Declaring metric variables
2024-05-10 16:45:51,350:INFO:Importing untrained model
2024-05-10 16:45:51,352:INFO:Orthogonal Matching Pursuit Imported successfully
2024-05-10 16:45:51,355:INFO:Starting cross validation
2024-05-10 16:45:51,356:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:51,406:INFO:Calculating mean and std
2024-05-10 16:45:51,407:INFO:Creating metrics dataframe
2024-05-10 16:45:51,408:INFO:Uploading results into container
2024-05-10 16:45:51,408:INFO:Uploading model into container now
2024-05-10 16:45:51,409:INFO:_master_model_container: 7
2024-05-10 16:45:51,409:INFO:_display_container: 2
2024-05-10 16:45:51,409:INFO:OrthogonalMatchingPursuit()
2024-05-10 16:45:51,409:INFO:create_model() successfully completed......................................
2024-05-10 16:45:51,466:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:51,466:INFO:Creating metrics dataframe
2024-05-10 16:45:51,470:INFO:Initializing Bayesian Ridge
2024-05-10 16:45:51,470:INFO:Total runtime is 0.06003501415252686 minutes
2024-05-10 16:45:51,472:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:51,472:INFO:Initializing create_model()
2024-05-10 16:45:51,472:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:51,472:INFO:Checking exceptions
2024-05-10 16:45:51,472:INFO:Importing libraries
2024-05-10 16:45:51,472:INFO:Copying training dataset
2024-05-10 16:45:51,474:INFO:Defining folds
2024-05-10 16:45:51,475:INFO:Declaring metric variables
2024-05-10 16:45:51,476:INFO:Importing untrained model
2024-05-10 16:45:51,479:INFO:Bayesian Ridge Imported successfully
2024-05-10 16:45:51,482:INFO:Starting cross validation
2024-05-10 16:45:51,482:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:51,539:INFO:Calculating mean and std
2024-05-10 16:45:51,540:INFO:Creating metrics dataframe
2024-05-10 16:45:51,541:INFO:Uploading results into container
2024-05-10 16:45:51,542:INFO:Uploading model into container now
2024-05-10 16:45:51,542:INFO:_master_model_container: 8
2024-05-10 16:45:51,542:INFO:_display_container: 2
2024-05-10 16:45:51,542:INFO:BayesianRidge()
2024-05-10 16:45:51,542:INFO:create_model() successfully completed......................................
2024-05-10 16:45:51,598:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:51,598:INFO:Creating metrics dataframe
2024-05-10 16:45:51,602:INFO:Initializing Passive Aggressive Regressor
2024-05-10 16:45:51,603:INFO:Total runtime is 0.062235923608144124 minutes
2024-05-10 16:45:51,604:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:51,604:INFO:Initializing create_model()
2024-05-10 16:45:51,604:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:51,604:INFO:Checking exceptions
2024-05-10 16:45:51,604:INFO:Importing libraries
2024-05-10 16:45:51,605:INFO:Copying training dataset
2024-05-10 16:45:51,606:INFO:Defining folds
2024-05-10 16:45:51,606:INFO:Declaring metric variables
2024-05-10 16:45:51,608:INFO:Importing untrained model
2024-05-10 16:45:51,610:INFO:Passive Aggressive Regressor Imported successfully
2024-05-10 16:45:51,613:INFO:Starting cross validation
2024-05-10 16:45:51,614:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:51,665:INFO:Calculating mean and std
2024-05-10 16:45:51,666:INFO:Creating metrics dataframe
2024-05-10 16:45:51,668:INFO:Uploading results into container
2024-05-10 16:45:51,668:INFO:Uploading model into container now
2024-05-10 16:45:51,669:INFO:_master_model_container: 9
2024-05-10 16:45:51,669:INFO:_display_container: 2
2024-05-10 16:45:51,669:INFO:PassiveAggressiveRegressor(random_state=1)
2024-05-10 16:45:51,669:INFO:create_model() successfully completed......................................
2024-05-10 16:45:51,725:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:51,725:INFO:Creating metrics dataframe
2024-05-10 16:45:51,730:INFO:Initializing Huber Regressor
2024-05-10 16:45:51,730:INFO:Total runtime is 0.0643657088279724 minutes
2024-05-10 16:45:51,732:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:51,732:INFO:Initializing create_model()
2024-05-10 16:45:51,732:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:51,732:INFO:Checking exceptions
2024-05-10 16:45:51,733:INFO:Importing libraries
2024-05-10 16:45:51,733:INFO:Copying training dataset
2024-05-10 16:45:51,734:INFO:Defining folds
2024-05-10 16:45:51,734:INFO:Declaring metric variables
2024-05-10 16:45:51,736:INFO:Importing untrained model
2024-05-10 16:45:51,738:INFO:Huber Regressor Imported successfully
2024-05-10 16:45:51,741:INFO:Starting cross validation
2024-05-10 16:45:51,742:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:51,804:INFO:Calculating mean and std
2024-05-10 16:45:51,804:INFO:Creating metrics dataframe
2024-05-10 16:45:51,805:INFO:Uploading results into container
2024-05-10 16:45:51,806:INFO:Uploading model into container now
2024-05-10 16:45:51,806:INFO:_master_model_container: 10
2024-05-10 16:45:51,806:INFO:_display_container: 2
2024-05-10 16:45:51,806:INFO:HuberRegressor()
2024-05-10 16:45:51,806:INFO:create_model() successfully completed......................................
2024-05-10 16:45:51,865:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:51,865:INFO:Creating metrics dataframe
2024-05-10 16:45:51,870:INFO:Initializing K Neighbors Regressor
2024-05-10 16:45:51,870:INFO:Total runtime is 0.06669856707255045 minutes
2024-05-10 16:45:51,872:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:51,872:INFO:Initializing create_model()
2024-05-10 16:45:51,872:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:51,872:INFO:Checking exceptions
2024-05-10 16:45:51,872:INFO:Importing libraries
2024-05-10 16:45:51,872:INFO:Copying training dataset
2024-05-10 16:45:51,874:INFO:Defining folds
2024-05-10 16:45:51,874:INFO:Declaring metric variables
2024-05-10 16:45:51,876:INFO:Importing untrained model
2024-05-10 16:45:51,877:INFO:K Neighbors Regressor Imported successfully
2024-05-10 16:45:51,881:INFO:Starting cross validation
2024-05-10 16:45:51,881:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:51,956:INFO:Calculating mean and std
2024-05-10 16:45:51,957:INFO:Creating metrics dataframe
2024-05-10 16:45:51,958:INFO:Uploading results into container
2024-05-10 16:45:51,958:INFO:Uploading model into container now
2024-05-10 16:45:51,959:INFO:_master_model_container: 11
2024-05-10 16:45:51,959:INFO:_display_container: 2
2024-05-10 16:45:51,959:INFO:KNeighborsRegressor(n_jobs=-1)
2024-05-10 16:45:51,959:INFO:create_model() successfully completed......................................
2024-05-10 16:45:52,016:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:52,016:INFO:Creating metrics dataframe
2024-05-10 16:45:52,021:INFO:Initializing Decision Tree Regressor
2024-05-10 16:45:52,021:INFO:Total runtime is 0.06921748320261636 minutes
2024-05-10 16:45:52,023:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:52,023:INFO:Initializing create_model()
2024-05-10 16:45:52,023:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:52,023:INFO:Checking exceptions
2024-05-10 16:45:52,023:INFO:Importing libraries
2024-05-10 16:45:52,023:INFO:Copying training dataset
2024-05-10 16:45:52,025:INFO:Defining folds
2024-05-10 16:45:52,025:INFO:Declaring metric variables
2024-05-10 16:45:52,027:INFO:Importing untrained model
2024-05-10 16:45:52,029:INFO:Decision Tree Regressor Imported successfully
2024-05-10 16:45:52,033:INFO:Starting cross validation
2024-05-10 16:45:52,034:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:52,091:INFO:Calculating mean and std
2024-05-10 16:45:52,092:INFO:Creating metrics dataframe
2024-05-10 16:45:52,095:INFO:Uploading results into container
2024-05-10 16:45:52,095:INFO:Uploading model into container now
2024-05-10 16:45:52,096:INFO:_master_model_container: 12
2024-05-10 16:45:52,096:INFO:_display_container: 2
2024-05-10 16:45:52,096:INFO:DecisionTreeRegressor(random_state=1)
2024-05-10 16:45:52,096:INFO:create_model() successfully completed......................................
2024-05-10 16:45:52,152:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:52,152:INFO:Creating metrics dataframe
2024-05-10 16:45:52,157:INFO:Initializing Random Forest Regressor
2024-05-10 16:45:52,157:INFO:Total runtime is 0.07148394584655761 minutes
2024-05-10 16:45:52,159:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:52,160:INFO:Initializing create_model()
2024-05-10 16:45:52,160:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:52,160:INFO:Checking exceptions
2024-05-10 16:45:52,160:INFO:Importing libraries
2024-05-10 16:45:52,160:INFO:Copying training dataset
2024-05-10 16:45:52,164:INFO:Defining folds
2024-05-10 16:45:52,164:INFO:Declaring metric variables
2024-05-10 16:45:52,165:INFO:Importing untrained model
2024-05-10 16:45:52,167:INFO:Random Forest Regressor Imported successfully
2024-05-10 16:45:52,170:INFO:Starting cross validation
2024-05-10 16:45:52,170:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:52,428:INFO:Calculating mean and std
2024-05-10 16:45:52,429:INFO:Creating metrics dataframe
2024-05-10 16:45:52,431:INFO:Uploading results into container
2024-05-10 16:45:52,431:INFO:Uploading model into container now
2024-05-10 16:45:52,431:INFO:_master_model_container: 13
2024-05-10 16:45:52,431:INFO:_display_container: 2
2024-05-10 16:45:52,431:INFO:RandomForestRegressor(n_jobs=-1, random_state=1)
2024-05-10 16:45:52,432:INFO:create_model() successfully completed......................................
2024-05-10 16:45:52,488:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:52,488:INFO:Creating metrics dataframe
2024-05-10 16:45:52,493:INFO:Initializing Extra Trees Regressor
2024-05-10 16:45:52,493:INFO:Total runtime is 0.07707321246465046 minutes
2024-05-10 16:45:52,495:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:52,495:INFO:Initializing create_model()
2024-05-10 16:45:52,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:52,495:INFO:Checking exceptions
2024-05-10 16:45:52,495:INFO:Importing libraries
2024-05-10 16:45:52,495:INFO:Copying training dataset
2024-05-10 16:45:52,497:INFO:Defining folds
2024-05-10 16:45:52,497:INFO:Declaring metric variables
2024-05-10 16:45:52,499:INFO:Importing untrained model
2024-05-10 16:45:52,501:INFO:Extra Trees Regressor Imported successfully
2024-05-10 16:45:52,503:INFO:Starting cross validation
2024-05-10 16:45:52,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:52,684:INFO:Calculating mean and std
2024-05-10 16:45:52,685:INFO:Creating metrics dataframe
2024-05-10 16:45:52,687:INFO:Uploading results into container
2024-05-10 16:45:52,687:INFO:Uploading model into container now
2024-05-10 16:45:52,688:INFO:_master_model_container: 14
2024-05-10 16:45:52,688:INFO:_display_container: 2
2024-05-10 16:45:52,688:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=1)
2024-05-10 16:45:52,688:INFO:create_model() successfully completed......................................
2024-05-10 16:45:52,745:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:52,745:INFO:Creating metrics dataframe
2024-05-10 16:45:52,751:INFO:Initializing AdaBoost Regressor
2024-05-10 16:45:52,751:INFO:Total runtime is 0.08137236436208088 minutes
2024-05-10 16:45:52,752:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:52,753:INFO:Initializing create_model()
2024-05-10 16:45:52,753:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:52,753:INFO:Checking exceptions
2024-05-10 16:45:52,753:INFO:Importing libraries
2024-05-10 16:45:52,753:INFO:Copying training dataset
2024-05-10 16:45:52,754:INFO:Defining folds
2024-05-10 16:45:52,754:INFO:Declaring metric variables
2024-05-10 16:45:52,756:INFO:Importing untrained model
2024-05-10 16:45:52,757:INFO:AdaBoost Regressor Imported successfully
2024-05-10 16:45:52,760:INFO:Starting cross validation
2024-05-10 16:45:52,761:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:52,878:INFO:Calculating mean and std
2024-05-10 16:45:52,880:INFO:Creating metrics dataframe
2024-05-10 16:45:52,881:INFO:Uploading results into container
2024-05-10 16:45:52,881:INFO:Uploading model into container now
2024-05-10 16:45:52,882:INFO:_master_model_container: 15
2024-05-10 16:45:52,882:INFO:_display_container: 2
2024-05-10 16:45:52,882:INFO:AdaBoostRegressor(random_state=1)
2024-05-10 16:45:52,882:INFO:create_model() successfully completed......................................
2024-05-10 16:45:52,938:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:52,939:INFO:Creating metrics dataframe
2024-05-10 16:45:52,944:INFO:Initializing Gradient Boosting Regressor
2024-05-10 16:45:52,944:INFO:Total runtime is 0.08459764719009398 minutes
2024-05-10 16:45:52,946:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:52,947:INFO:Initializing create_model()
2024-05-10 16:45:52,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:52,947:INFO:Checking exceptions
2024-05-10 16:45:52,947:INFO:Importing libraries
2024-05-10 16:45:52,947:INFO:Copying training dataset
2024-05-10 16:45:52,949:INFO:Defining folds
2024-05-10 16:45:52,949:INFO:Declaring metric variables
2024-05-10 16:45:52,950:INFO:Importing untrained model
2024-05-10 16:45:52,952:INFO:Gradient Boosting Regressor Imported successfully
2024-05-10 16:45:52,955:INFO:Starting cross validation
2024-05-10 16:45:52,955:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 16:45:53,094:INFO:Calculating mean and std
2024-05-10 16:45:53,095:INFO:Creating metrics dataframe
2024-05-10 16:45:53,097:INFO:Uploading results into container
2024-05-10 16:45:53,097:INFO:Uploading model into container now
2024-05-10 16:45:53,097:INFO:_master_model_container: 16
2024-05-10 16:45:53,097:INFO:_display_container: 2
2024-05-10 16:45:53,098:INFO:GradientBoostingRegressor(random_state=1)
2024-05-10 16:45:53,098:INFO:create_model() successfully completed......................................
2024-05-10 16:45:53,155:INFO:SubProcess create_model() end ==================================
2024-05-10 16:45:53,155:INFO:Creating metrics dataframe
2024-05-10 16:45:53,161:INFO:Initializing Light Gradient Boosting Machine
2024-05-10 16:45:53,161:INFO:Total runtime is 0.08821122646331786 minutes
2024-05-10 16:45:53,163:INFO:SubProcess create_model() called ==================================
2024-05-10 16:45:53,163:INFO:Initializing create_model()
2024-05-10 16:45:53,163:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x752299d51d90>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x752298bd2d90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-05-10 16:45:53,163:INFO:Checking exceptions
2024-05-10 16:45:53,163:INFO:Importing libraries
2024-05-10 16:45:53,163:INFO:Copying training dataset
2024-05-10 16:45:53,165:INFO:Defining folds
2024-05-10 16:45:53,165:INFO:Declaring metric variables
2024-05-10 16:45:53,166:INFO:Importing untrained model
2024-05-10 16:45:53,168:INFO:Light Gradient Boosting Machine Imported successfully
2024-05-10 16:45:53,171:INFO:Starting cross validation
2024-05-10 16:45:53,172:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-05-10 17:18:06,179:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,323:INFO:PyCaret TSForecastingExperiment
2024-05-10 17:18:06,323:INFO:Logging name: ts-default-name
2024-05-10 17:18:06,323:INFO:ML Usecase: MLUsecase.TIME_SERIES
2024-05-10 17:18:06,323:INFO:version 3.3.2
2024-05-10 17:18:06,323:INFO:Initializing setup()
2024-05-10 17:18:06,323:INFO:self.USI: c837
2024-05-10 17:18:06,324:INFO:self._variable_keys: {'data', 'primary_sp_to_use', 'exp_name_log', 'exogenous_present', 'gpu_n_jobs_param', 'X_test', 'fh', 'significant_sps_no_harmonics', 'y_test', 'memory', 'X_transformed', 'significant_sps', 'gpu_param', 'log_plots_param', 'idx', '_available_plots', 'enforce_pi', 'y_train_transformed', 'fold_param', 'y_test_transformed', 'strictly_positive', 'seed', 'X', 'model_engines', 'all_sps_to_use', 'seasonality_present', 'pipeline', 'y_transformed', 'logging_param', 'y_train', 'fold_generator', 'USI', 'exp_id', 'approach_type', 'enforce_exogenous', 'n_jobs_param', 'y', 'html_param', 'X_test_transformed', 'X_train_transformed', 'X_train', 'index_type', 'candidate_sps', '_ml_usecase'}
2024-05-10 17:18:06,324:INFO:Checking environment
2024-05-10 17:18:06,324:INFO:python_version: 3.9.19
2024-05-10 17:18:06,324:INFO:python_build: ('main', 'May  6 2024 19:43:03')
2024-05-10 17:18:06,324:INFO:machine: x86_64
2024-05-10 17:18:06,324:INFO:platform: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 17:18:06,324:INFO:Memory: svmem(total=16429797376, available=8563421184, percent=47.9, used=6615269376, free=1532268544, active=6563766272, inactive=6485508096, buffers=240443392, cached=8041816064, shared=904503296, slab=1066663936)
2024-05-10 17:18:06,324:INFO:Physical Core: 12
2024-05-10 17:18:06,324:INFO:Logical Core: 16
2024-05-10 17:18:06,324:INFO:Checking libraries
2024-05-10 17:18:06,324:INFO:System:
2024-05-10 17:18:06,324:INFO:    python: 3.9.19 (main, May  6 2024, 19:43:03)  [GCC 11.2.0]
2024-05-10 17:18:06,324:INFO:executable: /home/nhnacademy/anaconda3/envs/smoothing_ml/bin/python
2024-05-10 17:18:06,324:INFO:   machine: Linux-6.5.0-28-generic-x86_64-with-glibc2.35
2024-05-10 17:18:06,324:INFO:PyCaret required dependencies:
2024-05-10 17:18:06,324:INFO:                 pip: 24.0
2024-05-10 17:18:06,324:INFO:          setuptools: 69.5.1
2024-05-10 17:18:06,324:INFO:             pycaret: 3.3.2
2024-05-10 17:18:06,324:INFO:             IPython: 8.12.0
2024-05-10 17:18:06,324:INFO:          ipywidgets: 8.1.2
2024-05-10 17:18:06,324:INFO:                tqdm: 4.66.4
2024-05-10 17:18:06,324:INFO:               numpy: 1.26.4
2024-05-10 17:18:06,324:INFO:              pandas: 2.1.4
2024-05-10 17:18:06,324:INFO:              jinja2: 3.1.4
2024-05-10 17:18:06,324:INFO:               scipy: 1.11.4
2024-05-10 17:18:06,324:INFO:              joblib: 1.3.2
2024-05-10 17:18:06,324:INFO:             sklearn: 1.4.2
2024-05-10 17:18:06,324:INFO:                pyod: 1.1.3
2024-05-10 17:18:06,324:INFO:            imblearn: 0.12.2
2024-05-10 17:18:06,325:INFO:   category_encoders: 2.6.3
2024-05-10 17:18:06,325:INFO:            lightgbm: 4.3.0
2024-05-10 17:18:06,325:INFO:               numba: 0.59.1
2024-05-10 17:18:06,325:INFO:            requests: 2.31.0
2024-05-10 17:18:06,325:INFO:          matplotlib: 3.7.5
2024-05-10 17:18:06,325:INFO:          scikitplot: 0.3.7
2024-05-10 17:18:06,325:INFO:         yellowbrick: 1.5
2024-05-10 17:18:06,325:INFO:              plotly: 5.22.0
2024-05-10 17:18:06,325:INFO:    plotly-resampler: Not installed
2024-05-10 17:18:06,325:INFO:             kaleido: 0.2.1
2024-05-10 17:18:06,325:INFO:           schemdraw: 0.15
2024-05-10 17:18:06,325:INFO:         statsmodels: 0.14.2
2024-05-10 17:18:06,325:INFO:              sktime: 0.26.0
2024-05-10 17:18:06,325:INFO:               tbats: 1.1.3
2024-05-10 17:18:06,325:INFO:            pmdarima: 2.0.4
2024-05-10 17:18:06,325:INFO:              psutil: 5.9.0
2024-05-10 17:18:06,325:INFO:          markupsafe: 2.1.5
2024-05-10 17:18:06,325:INFO:             pickle5: Not installed
2024-05-10 17:18:06,325:INFO:         cloudpickle: 3.0.0
2024-05-10 17:18:06,325:INFO:         deprecation: 2.1.0
2024-05-10 17:18:06,325:INFO:              xxhash: 3.4.1
2024-05-10 17:18:06,325:INFO:           wurlitzer: 3.1.0
2024-05-10 17:18:06,325:INFO:PyCaret optional dependencies:
2024-05-10 17:18:06,325:INFO:                shap: Not installed
2024-05-10 17:18:06,325:INFO:           interpret: Not installed
2024-05-10 17:18:06,325:INFO:                umap: Not installed
2024-05-10 17:18:06,325:INFO:     ydata_profiling: Not installed
2024-05-10 17:18:06,325:INFO:  explainerdashboard: Not installed
2024-05-10 17:18:06,325:INFO:             autoviz: Not installed
2024-05-10 17:18:06,325:INFO:           fairlearn: Not installed
2024-05-10 17:18:06,325:INFO:          deepchecks: Not installed
2024-05-10 17:18:06,325:INFO:             xgboost: Not installed
2024-05-10 17:18:06,325:INFO:            catboost: Not installed
2024-05-10 17:18:06,325:INFO:              kmodes: Not installed
2024-05-10 17:18:06,325:INFO:             mlxtend: Not installed
2024-05-10 17:18:06,325:INFO:       statsforecast: Not installed
2024-05-10 17:18:06,325:INFO:        tune_sklearn: Not installed
2024-05-10 17:18:06,325:INFO:                 ray: Not installed
2024-05-10 17:18:06,325:INFO:            hyperopt: Not installed
2024-05-10 17:18:06,325:INFO:              optuna: Not installed
2024-05-10 17:18:06,325:INFO:               skopt: Not installed
2024-05-10 17:18:06,325:INFO:              mlflow: Not installed
2024-05-10 17:18:06,325:INFO:              gradio: Not installed
2024-05-10 17:18:06,325:INFO:             fastapi: Not installed
2024-05-10 17:18:06,325:INFO:             uvicorn: Not installed
2024-05-10 17:18:06,325:INFO:              m2cgen: Not installed
2024-05-10 17:18:06,325:INFO:           evidently: Not installed
2024-05-10 17:18:06,325:INFO:               fugue: Not installed
2024-05-10 17:18:06,325:INFO:           streamlit: Not installed
2024-05-10 17:18:06,325:INFO:             prophet: Not installed
2024-05-10 17:18:06,325:INFO:None
2024-05-10 17:18:06,328:INFO:Set Forecast Horizon.
2024-05-10 17:18:06,328:INFO:Set up Train-Test Splits.
2024-05-10 17:18:06,333:INFO:Preparing preprocessing pipeline...
2024-05-10 17:18:06,333:INFO:Set up imputation for Target variable(s).
2024-05-10 17:18:06,333:INFO:Set up imputation for Exogenous variable(s).
2024-05-10 17:18:06,390:INFO:Finished creating preprocessing pipeline.
2024-05-10 17:18:06,395:INFO:Pipeline: ForecastingPipeline(steps=[('transformer_exogenous',
                            TransformerPipeline(steps=[('numerical_imputer',
                                                        Imputer(random_state=42))])),
                           ('forecaster',
                            TransformedTargetForecaster(steps=[('transformer_target',
                                                                TransformerPipeline(steps=[('numerical_imputer',
                                                                                            Imputer(random_state=42))])),
                                                               ('model',
                                                                DummyForecaster())]))])
2024-05-10 17:18:06,395:INFO:Set up Seasonal Period.
2024-05-10 17:18:06,400:INFO:Setting the seasonal component type - 'add' or 'mul'.
2024-05-10 17:18:06,400:INFO:Checking if data is strictly positive.
2024-05-10 17:18:06,424:INFO:Creating final display dataframe.
2024-05-10 17:18:06,444:INFO:Setup Display Container:                                           Description  \
0                                          session_id   
1                                              Target   
2                                            Approach   
3                                 Exogenous Variables   
4                                 Original data shape   
5                              Transformed data shape   
6                         Transformed train set shape   
7                          Transformed test set shape   
8                            Rows with missing values   
9                                      Fold Generator   
10                                        Fold Number   
11                        Enforce Prediction Interval   
12                    Splits used for hyperparameters   
13                    User Defined Seasonal Period(s)   
14                            Ignore Seasonality Test   
15                         Seasonality Detection Algo   
16                             Max Period to Consider   
17                          Seasonal Period(s) Tested   
18                     Significant Seasonal Period(s)   
19   Significant Seasonal Period(s) without Harmonics   
20                                   Remove Harmonics   
21                             Harmonics Order Method   
22                           Num Seasonalities to Use   
23                           All Seasonalities to Use   
24                                Primary Seasonality   
25                                Seasonality Present   
26                                   Seasonality Type   
27                           Target Strictly Positive   
28                                 Target White Noise   
29                                      Recommended d   
30                             Recommended Seasonal D   
31                                         Preprocess   
32                      Numerical Imputation (Target)   
33                            Transformation (Target)   
34                                   Scaling (Target)   
35  Feature Engineering (Target) - Reduced Regression   
36                   Numerical Imputation (Exogenous)   
37                         Transformation (Exogenous)   
38                                Scaling (Exogenous)   
39                                           CPU Jobs   
40                                            Use GPU   
41                                     Log Experiment   
42                                    Experiment Name   
43                                                USI   

                                                Value  
0                                                  42  
1                                    socket_power(Wh)  
2                                          Univariate  
3                                             Present  
4                                            (600, 4)  
5                                            (600, 4)  
6                                            (552, 4)  
7                                             (48, 4)  
8                                                0.0%  
9                             ExpandingWindowSplitter  
10                                                  3  
11                                              False  
12                                                all  
13                                               None  
14                                              False  
15                                               auto  
16                                                 60  
17  [2, 3, 24, 23, 25, 4, 22, 26, 21, 5, 48, 20, 2...  
18  [2, 3, 24, 23, 25, 4, 22, 26, 21, 5, 48, 20, 2...  
19   [48, 46, 25, 22, 26, 21, 20, 27, 47, 49, 28, 19]  
20                                              False  
21                                       harmonic_max  
22                                                  1  
23                                                [2]  
24                                                  2  
25                                               True  
26                                                mul  
27                                               True  
28                                                 No  
29                                                  0  
30                                                  0  
31                                               True  
32                                              drift  
33                                               None  
34                                               None  
35                                              False  
36                                              drift  
37                                               None  
38                                               None  
39                                                 -1  
40                                              False  
41                                              False  
42                                    ts-default-name  
43                                               c837  
2024-05-10 17:18:06,453:INFO:Engine successfully changes for model 'auto_arima' to 'pmdarima'.
2024-05-10 17:18:06,474:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,474:INFO:Engine for model 'lr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,475:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,475:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,475:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,476:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,476:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,477:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,479:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,481:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,481:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,482:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,482:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,483:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,483:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,484:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,484:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,485:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,489:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,489:INFO:Engine for model 'lr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,489:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,490:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,490:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,490:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,491:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,491:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,493:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,495:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,495:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,496:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,496:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,497:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,497:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,497:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,498:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,498:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,498:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,499:INFO:Engine successfully changes for model 'lr_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,503:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,504:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,504:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,504:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,505:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,505:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,506:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,508:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,509:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,510:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,510:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,511:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,511:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,511:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,512:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,512:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,512:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,512:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,512:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,516:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,517:INFO:Engine for model 'en_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,517:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,518:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,518:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,519:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,519:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,521:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,523:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,524:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,524:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,524:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,525:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,525:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,526:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,526:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,526:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,526:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,526:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,526:INFO:Engine successfully changes for model 'en_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,528:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,528:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,529:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,529:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,529:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,529:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,530:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,532:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,532:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,532:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,532:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,533:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,533:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,533:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,533:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,533:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,533:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,533:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,535:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,536:INFO:Engine for model 'ridge_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,536:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,536:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,536:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,536:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,538:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,539:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,539:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,539:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,540:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,540:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,540:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,540:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,540:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,540:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,541:INFO:Engine successfully changes for model 'ridge_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,542:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,543:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,543:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,543:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,543:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,544:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,545:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,546:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,546:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,546:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,546:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,546:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,547:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,547:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,547:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,547:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,549:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,549:INFO:Engine for model 'lasso_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,550:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,550:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,550:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,552:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,553:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,553:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,553:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,554:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,554:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,554:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,554:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,554:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,554:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,554:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,554:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,555:INFO:Engine successfully changes for model 'lasso_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,556:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,557:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,557:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,557:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,559:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,560:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,560:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,560:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,561:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,561:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,561:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,561:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,561:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,562:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,562:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,563:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,564:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,564:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,565:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,566:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,567:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,568:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,568:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,568:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,568:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,568:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,569:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,569:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,569:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,569:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,569:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,569:INFO:Engine successfully changes for model 'lar_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,571:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,572:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,572:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,572:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,573:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,574:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,575:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,575:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,575:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,575:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,575:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,576:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,576:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,576:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,576:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,576:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,578:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,579:INFO:Engine for model 'llar_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,579:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,579:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,580:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,582:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,582:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,582:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,582:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,583:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,583:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,583:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,583:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,583:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,584:INFO:Engine successfully changes for model 'llar_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,585:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,586:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,586:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,588:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,589:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,590:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,590:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,590:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,590:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,590:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,590:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,591:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,591:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,591:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,591:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,593:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,594:INFO:Engine for model 'br_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,594:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,595:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,596:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,597:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,597:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,597:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,597:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,597:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,597:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,597:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,598:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,598:INFO:Engine successfully changes for model 'br_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,600:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,601:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,603:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,604:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,604:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,604:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,604:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,605:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,605:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,605:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,605:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,605:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,607:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,608:INFO:Engine for model 'huber_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,609:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,611:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,611:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,611:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,611:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,611:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,612:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,612:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,612:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,612:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,612:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,612:INFO:Engine successfully changes for model 'huber_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,614:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,616:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,618:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,618:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,618:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,618:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,619:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,619:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,619:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,619:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,619:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,619:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,619:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,621:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,623:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,625:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,625:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,625:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,625:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,626:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,626:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,626:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,626:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,626:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,626:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,626:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,626:INFO:Engine successfully changes for model 'par_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,628:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,630:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,631:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,631:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,631:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,632:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,632:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,632:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,632:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,632:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,632:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,633:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,633:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,635:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,639:INFO:Engine for model 'omp_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,641:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,641:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,642:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,642:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,642:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,643:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,643:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,643:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,643:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,644:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,644:INFO:Engine successfully changes for model 'omp_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,646:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,650:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,651:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,651:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,651:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,652:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,652:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,652:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,652:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,652:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,652:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,652:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,655:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,658:INFO:Engine for model 'knn_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,658:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,658:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,659:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,659:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,659:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,659:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,659:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,659:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,659:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,659:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,659:INFO:Engine successfully changes for model 'knn_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,661:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,664:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,664:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,664:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,665:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,665:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,665:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,665:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,665:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,668:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,672:INFO:Engine for model 'dt_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,672:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,672:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,673:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,673:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,673:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,673:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,673:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,673:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,673:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,673:INFO:Engine successfully changes for model 'dt_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,675:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,678:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,678:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,678:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,679:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,679:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,679:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,679:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,679:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,679:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,681:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,686:INFO:Engine for model 'rf_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,686:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,686:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,686:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,686:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,686:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,686:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,687:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,687:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,687:INFO:Engine successfully changes for model 'rf_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,689:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,692:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,692:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,693:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,693:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,693:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,693:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,693:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,693:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,695:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,698:INFO:Engine for model 'et_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,699:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,699:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,699:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,699:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,699:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,700:INFO:Engine successfully changes for model 'et_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,702:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,707:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,707:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,707:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,707:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,707:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,707:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,707:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,709:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,713:INFO:Engine for model 'gbr_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,713:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,713:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,713:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,713:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,713:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,713:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,714:INFO:Engine successfully changes for model 'gbr_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,715:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,721:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,721:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,721:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,721:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,723:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,727:INFO:Engine for model 'ada_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,727:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,727:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,727:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,727:INFO:Engine successfully changes for model 'ada_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,729:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,733:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,733:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,733:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,733:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,736:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,740:INFO:Engine for model 'xgboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,740:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,740:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,741:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,741:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,741:INFO:Engine successfully changes for model 'xgboost_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,742:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,746:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,746:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,746:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,748:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,752:INFO:Engine for model 'lightgbm_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,753:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,753:INFO:Engine successfully changes for model 'lightgbm_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,755:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,759:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,761:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,765:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,765:INFO:Engine for model 'catboost_cds_dt' has not been set explicitly, hence returning None.
2024-05-10 17:18:06,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,765:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,765:INFO:Engine successfully changes for model 'catboost_cds_dt' to 'sklearn'.
2024-05-10 17:18:06,768:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,775:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,779:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,779:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,780:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,781:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,786:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,786:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,788:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2024-05-10 17:18:06,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,793:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,793:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-05-10 17:18:06,793:INFO:setup() successfully completed in 0.48s...............
