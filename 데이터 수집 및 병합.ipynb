{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## InfluxDB 연결 설정\n",
    "InfluxDB 연결 정보 설정 및 장비 맵핑"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:05:08.600049Z",
     "start_time": "2024-05-02T01:05:06.340624Z"
    }
   },
   "source": [
    "%pip install influxdb_client"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: influxdb_client in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (1.42.0)\r\n",
      "Requirement already satisfied: reactivex>=4.0.4 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (4.0.4)\r\n",
      "Requirement already satisfied: certifi>=14.05.14 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (2024.2.2)\r\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (2.8.2)\r\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (68.0.0)\r\n",
      "Requirement already satisfied: urllib3>=1.26.0 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from influxdb_client) (1.26.16)\r\n",
      "Requirement already satisfied: six>=1.5 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.5.3->influxdb_client) (1.16.0)\r\n",
      "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.1 in /home/nhnacademy/anaconda3/lib/python3.9/site-packages (from reactivex>=4.0.4->influxdb_client) (4.7.1)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:05:08.790989Z",
     "start_time": "2024-05-02T01:05:08.604297Z"
    }
   },
   "source": [
    "import os\n",
    "import pytz\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from datetime import datetime, timedelta\n",
    "from datetime import datetime, timedelta\n",
    "from influxdb_client import InfluxDBClient"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T05:56:36.824721Z",
     "start_time": "2024-05-02T05:56:36.820535Z"
    }
   },
   "source": [
    "# InfluxDB 설정 정보\n",
    "url = \"http://133.186.144.22:8086\"\n",
    "token = \"r3Ecro-rJQ82UpyNScnHXYDZ3KaE45AzweCXz6QIv2jeo7eOP4hL4-A9uKvkAVQDg_xavWorGUGZn7MI_sPCwg==\"\n",
    "org = \"smoothing\"\n",
    "\n",
    "# Device ID와 위치를 매핑\n",
    "location_mapping = {\n",
    "    '24e124126d152919': 'indoor',\n",
    "    '24e124126d152969': 'bottom_right_corner',\n",
    "    '24e124128c067999': 'indoor',\n",
    "    '24e124785c389818': 'bottom_left_corner',\n",
    "    '24e124785c421885': 'top_right_corner'\n",
    "}\n",
    "\n",
    "# 한국 시간대 설정\n",
    "korea_tz = pytz.timezone('Asia/Seoul')\n",
    "\n",
    "# 실행 시점의 날짜를 기준으로 전날의 날짜를 계산\n",
    "today_kst = datetime.now(korea_tz)\n",
    "yesterday_kst = today_kst - timedelta(days=1)\n",
    "\n",
    "# 전날의 시작과 끝 시간을 한국 시간대로 설정\n",
    "start_time_kst = korea_tz.localize(datetime(yesterday_kst.year, yesterday_kst.month, yesterday_kst.day, 0, 0, 0))\n",
    "end_time_kst = start_time_kst + timedelta(days=1)\n",
    "\n",
    "# UTC로 시간 변환\n",
    "start_time_utc = start_time_kst.astimezone(pytz.utc)\n",
    "end_time_utc = end_time_kst.astimezone(pytz.utc)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T07:23:45.552471Z",
     "start_time": "2024-05-02T07:23:45.538389Z"
    }
   },
   "source": [
    "def create_client(url, token, org):\n",
    "    \"\"\"\n",
    "    Influx DB 연결 Client를 생성합니다.\n",
    "    \n",
    "    :param url: InfluxDB 연결 주소\n",
    "    :param token: InfluxDB 토큰\n",
    "    :param org:  InfluxDB 조직\n",
    "    :return: InfluxDBClient\n",
    "    \"\"\"\n",
    "    return InfluxDBClient(url=url, token=token, org=org)\n",
    "\n",
    "def query_to_dataframe(client, query, field = \"location\"):\n",
    "    \"\"\"\n",
    "    구성된 쿼리를 실행하고 전달받은 데이터를 Dataframe으로 만듭니다.\n",
    "    \n",
    "    :param field: 기본값 location\n",
    "    :param client: InfluxDBClient\n",
    "    :param query: 요청할 쿼리\n",
    "    :return: DataFrame \n",
    "    \"\"\"\n",
    "    result = client.query_api().query(query=query)\n",
    "    results = []\n",
    "    \n",
    "    for table in result:\n",
    "        for record in table.records:\n",
    "            results.append({\n",
    "                \"time\": record.get_time(),\n",
    "                \"value\": record.get_value(),\n",
    "                \"place\": record.values.get(\"place\"),\n",
    "                \"location\": record.values.get(field),\n",
    "                \"device\": record.values.get(\"device\")\n",
    "            })\n",
    "    \n",
    "    df = pd.DataFrame(results)\n",
    "    df['time'] = df['time'].astype(str).str.replace(r'\\+00:00$', '', regex=True)\n",
    "    return df\n",
    "\n",
    "def save_csv(df, file_pattern, directory):\n",
    "    \n",
    "    \"\"\"\n",
    "    DataFrame을 CSV로 변환하여 저장합니다.\n",
    "    \n",
    "    :param df: DataFrame\n",
    "    :param file_pattern: 파일 이름 패턴\n",
    "    :param directory: 저장할 위치\n",
    "    \"\"\"\n",
    "    # 파일 경로를 확인 하고 없다면 생성 합니다.\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "        \n",
    "    previous_date = datetime.now() - timedelta(days=1)\n",
    "    filename = f\"{directory}{previous_date.strftime(file_pattern)}\"\n",
    "    df.to_csv(filename, index=False)\n",
    "        \n",
    "def update_location(df):\n",
    "    \"\"\"\n",
    "    환경 센서 Data에서 Device ID를 확인 하여 'location' 열을 업데이트 합니다.\n",
    "    \n",
    "    :param df: 환경 센서 DataFrame\n",
    "    :return: 'location' 열을 업데이트한 DataFrame\n",
    "    \"\"\"\n",
    "    df['location'] = df['device'].map(location_mapping)\n",
    "    return df\n",
    "\n",
    "def merge_data(directory_path):\n",
    "    \"\"\"\n",
    "    CSV 파일들을 하나의 DataFrame으로 병합하고 정렬 합니다.\n",
    "    \n",
    "    :param directory_path: 파일 경로 \n",
    "    :return: 병합된 DataFrame\n",
    "    \"\"\"\n",
    "    # 파일 내의 모든 CSV 파일 목록을 생성\n",
    "    csv_files = [file for file in os.listdir(directory_path) if file.endswith('.csv')]\n",
    "\n",
    "    # 모든 CSV 파일을 DataFrame으로 읽어와 하나로 병합\n",
    "    data_frames = []\n",
    "    for file in csv_files:\n",
    "        file_path = os.path.join(directory_path, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        df['time'] = pd.to_datetime(df['time'])\n",
    "        data_frames.append(df)\n",
    "\n",
    "    merged_df = pd.concat(data_frames, ignore_index=True)\n",
    "\n",
    "    # 해당 컬럼들로 재구성\n",
    "    columns_to_keep = ['time', 'value', 'place', 'location']\n",
    "    filtered_df = merged_df[columns_to_keep]\n",
    "\n",
    "    # 'place', 'time' 으로 정렬\n",
    "    sorted_df = filtered_df.sort_values(['place', 'time'])\n",
    "\n",
    "    return sorted_df\n",
    "\n",
    "def df_hourly_calculate(dataframe, change_column_name, calculate):\n",
    "    \"\"\"\n",
    "    DataFrame에서 value를 시간별로 calculate 함수에 따라 계산합니다.\n",
    "    계산 후 value 컬럼을 지정한 이름으로 변경합니다.\n",
    "        \n",
    "    :param dataframe: 계산할 DataFrame\n",
    "    :param change_column_name: 계산 후 value 컬럼을 지정한 이름으로 변경\n",
    "    :param calculate: 문자열 형태로 계산할 함수명 ('sum', 'mean', 'diff' 등)\n",
    "    :return: 시간별 계산된 DataFrame\n",
    "    \"\"\"\n",
    "    # 시간 컬럼이 datetime형태인지 확인하고 설정후 Index로 설정\n",
    "    if not pd.api.types.is_datetime64_any_dtype(dataframe.index):\n",
    "        dataframe['time'] = pd.to_datetime(dataframe['time'])\n",
    "        dataframe.set_index('time', inplace=True)\n",
    "\n",
    "    # 시간별로 그룹화하여 마지막 값을 선택 (누적값의 경우)\n",
    "    if calculate == 'diff':\n",
    "        # 누적값의 마지막 값을 시간별로 선택하고 차분 계산\n",
    "        result = dataframe['value'].resample('H').last().diff().rename(change_column_name)\n",
    "    else:\n",
    "        # 기타 계산\n",
    "        result = dataframe.resample('H').agg({'value': calculate}).rename(columns={'value': change_column_name})\n",
    "\n",
    "    # Null 값 채우기 (forward fill)\n",
    "    result.fillna(method='bfill', inplace=True)\n",
    "\n",
    "    return result\n",
    "\n",
    "def merge_dataframes(df_list):\n",
    "    \"\"\"\n",
    "    여러 DataFrame을 병합합니다. \n",
    "    \n",
    "    :param df_list: 병합할 DataFrame 리스트\n",
    "    :return: 병합된 DataFrame\n",
    "    \"\"\"\n",
    "    merged_df = df_list[0]\n",
    "    for df in df_list[1:]:\n",
    "        merged_df = pd.merge(merged_df, df, left_index=True, right_index=True, how='outer', validate=None)\n",
    "    return merged_df\n",
    "\n",
    "def calculate_attendance(dataframe):\n",
    "    # time 컬럼을 datetime 타입으로 변환\n",
    "    dataframe['time'] = pd.to_datetime(dataframe['time'])\n",
    "\n",
    "    # 시간대별로 그룹화 (시간, 분, 초까지 모두 고려)\n",
    "    grouped = dataframe.groupby(['time', 'location'])['value'].sum().unstack().fillna(0)\n",
    "\n",
    "    # 입장과 퇴장 데이터 분리\n",
    "    grouped['in'] = grouped.filter(like='_in').sum(axis=1)\n",
    "    grouped['out'] = grouped.filter(like='_out').sum(axis=1)\n",
    "\n",
    "    # 순 입장 인원 계산 (재실 인원)\n",
    "    grouped['net'] = grouped['in'] - grouped['out']\n",
    "\n",
    "    # 누적 재실 인원 계산\n",
    "    cumulative = 0  # 초기값 설정\n",
    "    cumulative_results = []  # 누적 결과를 저장할 리스트\n",
    "    for net in grouped['net']:\n",
    "        cumulative += net\n",
    "        if cumulative < 0:\n",
    "            cumulative = 0  # 음수는 0으로 처리\n",
    "        cumulative_results.append(cumulative)\n",
    "\n",
    "    grouped['cumulative'] = cumulative_results\n",
    "\n",
    "    return grouped[['in', 'out', 'cumulative']]"
   ],
   "outputs": [],
   "execution_count": 65
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T07:01:00.890831Z",
     "start_time": "2024-05-02T07:00:59.604400Z"
    }
   },
   "source": [
    "# DB 연결 및 쿼리 실행\n",
    "client = create_client(url, token, org)\n",
    "\n",
    "# 전력(W) 조회(class a : main) Flux 쿼리\n",
    "query_power_total_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"w\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"total\")\n",
    "  |> filter(fn: (r) => r[\"location\"] == \"main\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 전력 사용량 조회(class a : main) Flux 쿼리\n",
    "query_power_usage_total_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"powermetrics_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"phase\"] == \"kwh\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"description\"] == \"sum\")\n",
    "  |> filter(fn: (r) => r[\"location\"] == \"main\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 온도 조회 Flux 쿼리\n",
    "query_temperature_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"temperature\")\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 이산화탄소 조회 Flux 쿼리\n",
    "query_co2_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"co2\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 조도 조회 Flux 쿼리\n",
    "query_illumination_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"illumination\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 습도 조회 Flux 쿼리\n",
    "query_humidity_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"environmentalsensors_data\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"measurement\"] == \"humidity\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"location\", \"device\"])\n",
    "'''\n",
    "\n",
    "# 이동 감지 카운터 조회 Flux 쿼리\n",
    "query_counter_data = f'''\n",
    "import \"experimental\"\n",
    "from(bucket: \"milesight\")\n",
    "  |> range(start: {start_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')}, stop: {end_time_utc.strftime('%Y-%m-%dT%H:%M:%SZ')})\n",
    "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
    "  |> filter(fn: (r) => r[\"_field\"] == \"line_periodic_data_1_out\" or r[\"_field\"] == \"line_periodic_data_1_in\")\n",
    "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
    "  |> map(fn: (r) => ({{r with _time: experimental.addDuration(d: 9h, to: r._time)}}))\n",
    "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"_field\", \"device\"])\n",
    "'''\n",
    "\n",
    "print(query_counter_data)\n",
    "\n",
    "# 전력 CSV 생성\n",
    "df_power = query_to_dataframe(client, query_power_total_data)\n",
    "print(df_power.head(2))\n",
    "save_csv(df_power, \"%m_%d_power_total_data.csv\", \"all_data/power/total/\")\n",
    "\n",
    "# 전력 사용량 CSV 생성\n",
    "df_power_usage = query_to_dataframe(client, query_power_usage_total_data)\n",
    "save_csv(df_power_usage, \"%m_%d_power_usage_total_data.csv\", \"all_data/power_usage/total/\")\n",
    "print(df_power_usage.head(2))\n",
    "\n",
    "# 온도 CSV 생성\n",
    "df_temperature = query_to_dataframe(client, query_temperature_data)\n",
    "df_temperature_fix = update_location(df_temperature)\n",
    "print(df_temperature_fix.head(2))\n",
    "save_csv(df_temperature_fix, \"%m_%d_temperature_data.csv\", \"all_data/temperature/total/\")\n",
    "\n",
    "# co2 CSV 생성\n",
    "df_co2 = query_to_dataframe(client, query_co2_data)\n",
    "df_co2_fix = update_location(df_co2)\n",
    "print(df_co2_fix.head(2))\n",
    "save_csv(df_co2_fix, \"%m_%d_co2_data.csv\", \"all_data/co2/\")\n",
    "\n",
    "# 조도 CSV 생성\n",
    "df_illumination = query_to_dataframe(client, query_illumination_data)\n",
    "update_location(df_illumination)\n",
    "print(df_illumination.head(2))\n",
    "save_csv(df_illumination, \"%m_%d_illumination_data.csv\", \"all_data/illumination/\")\n",
    "\n",
    "# 습도 CSV 생성\n",
    "df_humidity = query_to_dataframe(client, query_humidity_data)\n",
    "update_location(df_humidity)\n",
    "print(df_humidity.head(2))\n",
    "save_csv(df_humidity, \"%m_%d_humidity_data.csv\", \"all_data/humidity/\")\n",
    "\n",
    "# 이동 감지 카운터 CSV 생성\n",
    "df_counter = query_to_dataframe(client, query_counter_data, \"_field\")\n",
    "print(df_counter.head(2))\n",
    "save_csv(df_counter, \"%m_%d_counter_data.csv\", \"all_data/counter/total/\")\n",
    "\n",
    "# 연결 Client 종료\n",
    "client.close()"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import \"experimental\"\n",
      "from(bucket: \"milesight\")\n",
      "  |> range(start: 2024-04-30T15:00:00Z, stop: 2024-05-01T15:00:00Z)\n",
      "  |> filter(fn: (r) => r[\"place\"] == \"class_a\")\n",
      "  |> filter(fn: (r) => r[\"_field\"] == \"line_periodic_data_1_out\" or r[\"_field\"] == \"line_periodic_data_1_in\")\n",
      "  |> aggregateWindow(every: 2m, fn: mean, createEmpty: false)\n",
      "  |> map(fn: (r) => ({r with _time: experimental.addDuration(d: 9h, to: r._time)}))\n",
      "  |> keep(columns: [\"_time\", \"_value\", \"place\", \"_field\", \"device\"])\n",
      "\n",
      "                  time   value    place location     device\n",
      "0  2024-05-01 00:02:00  5012.5  class_a     main  gems-3500\n",
      "1  2024-05-01 00:04:00  4723.0  class_a     main  gems-3500\n",
      "                  time   value    place location     device\n",
      "0  2024-05-01 00:02:00  759.45  class_a     main  gems-3500\n",
      "1  2024-05-01 00:04:00  759.65  class_a     main  gems-3500\n",
      "                  time  value    place             location            device\n",
      "0  2024-05-01 00:02:00   23.1  class_a  bottom_right_corner  24e124126d152969\n",
      "1  2024-05-01 00:04:00   23.1  class_a  bottom_right_corner  24e124126d152969\n",
      "                  time  value    place location            device\n",
      "0  2024-05-01 00:02:00  546.5  class_a   indoor  24e124128c067999\n",
      "1  2024-05-01 00:04:00  544.5  class_a   indoor  24e124128c067999\n",
      "                  time  value    place location            device\n",
      "0  2024-05-01 00:02:00   69.0  class_a   indoor  24e124128c067999\n",
      "1  2024-05-01 00:04:00   69.0  class_a   indoor  24e124128c067999\n",
      "                  time  value    place             location            device\n",
      "0  2024-05-01 00:02:00   49.0  class_a  bottom_right_corner  24e124126d152969\n",
      "1  2024-05-01 00:04:00   48.5  class_a  bottom_right_corner  24e124126d152969\n",
      "                  time  value    place                 location device\n",
      "0  2024-05-01 01:00:00    0.0  class_a  line_periodic_data_1_in  vs133\n",
      "1  2024-05-01 02:00:00    0.0  class_a  line_periodic_data_1_in  vs133\n"
     ]
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T07:27:16.467316Z",
     "start_time": "2024-05-02T07:27:16.190942Z"
    }
   },
   "source": [
    "power_path = 'all_data/power/total'\n",
    "power_total_df = merge_data(power_path)\n",
    "print(power_total_df.head(2), \"\\n\")\n",
    "\n",
    "power_usage_path = 'all_data/power_usage/total'\n",
    "power_usage_total_df = merge_data(power_usage_path)\n",
    "print(power_usage_total_df.head(2), \"\\n\")\n",
    "\n",
    "temperature_path = 'all_data/temperature'\n",
    "temperature_total_df = merge_data(temperature_path)\n",
    "print(temperature_total_df.head(2), \"\\n\")\n",
    "\n",
    "co2_path = 'all_data/co2'\n",
    "co2_total_df = merge_data(co2_path)\n",
    "print(co2_total_df.head(2), \"\\n\")\n",
    "\n",
    "illumination_path = 'all_data/illumination'\n",
    "illumination_total_df = merge_data(illumination_path)\n",
    "print(illumination_total_df.head(2), \"\\n\")\n",
    "\n",
    "humidity_path = 'all_data/humidity'\n",
    "humidity_total_df = merge_data(humidity_path)\n",
    "print(humidity_total_df.head(2), \"\\n\")\n",
    "\n",
    "counter_path = 'all_data/counter/total'\n",
    "counter_total_df = merge_data(counter_path)\n",
    "print(counter_total_df.head(2), \"\\n\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    time  value    place location\n",
      "9345 2024-04-15 00:02:00  152.0  class_a     main\n",
      "9346 2024-04-15 00:04:00  150.5  class_a     main \n",
      "\n",
      "                    time  value    place location\n",
      "5743 2024-04-15 00:02:00  264.7  class_a     main\n",
      "5744 2024-04-15 00:04:00  264.7  class_a     main \n",
      "\n",
      "                     time  value    place             location\n",
      "24282 2024-04-15 00:02:00   24.0  class_a  bottom_right_corner\n",
      "24986 2024-04-15 00:02:00   24.6  class_a               indoor \n",
      "\n",
      "                     time  value    place location\n",
      "10059 2024-04-15 00:02:00  658.0  class_a   indoor\n",
      "10060 2024-04-15 00:04:00  659.0  class_a   indoor \n",
      "\n",
      "                    time  value    place             location\n",
      "8618 2024-04-15 00:02:00   49.5  class_a  bottom_right_corner\n",
      "9322 2024-04-15 00:02:00   45.5  class_a               indoor \n",
      "\n",
      "                     time  value    place             location\n",
      "21416 2024-04-15 00:02:00   49.5  class_a  bottom_right_corner\n",
      "22120 2024-04-15 00:02:00   45.5  class_a               indoor \n",
      "\n",
      "                  time  value    place                  location\n",
      "0  2024-05-01 01:00:00    0.0  class_a   line_periodic_data_1_in\n",
      "23 2024-05-01 01:00:00    0.0  class_a  line_periodic_data_1_out \n",
      "\n"
     ]
    }
   ],
   "execution_count": 68
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T07:27:20.089779Z",
     "start_time": "2024-05-02T07:27:20.020859Z"
    }
   },
   "source": [
    "temperature_total_df = df_hourly_calculate(temperature_total_df, \"average_temperature(°C)\", \"mean\")\n",
    "humidity_total_df = df_hourly_calculate(humidity_total_df, \"average_humidity(%)\", \"mean\")\n",
    "co2_total_df = df_hourly_calculate(co2_total_df, \"average_co2(ppm)\", \"mean\")\n",
    "illumination_total_df = df_hourly_calculate(illumination_total_df, \"average_illumination(lux)\", \"mean\")\n",
    "counter_total_df = calculate_attendance(counter_total_df)"
   ],
   "outputs": [],
   "execution_count": 69
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T07:27:22.013239Z",
     "start_time": "2024-05-02T07:27:21.991061Z"
    }
   },
   "source": [
    "# 데이터프레임 병합\n",
    "total_environment_data_df = merge_dataframes([counter_total_df, temperature_total_df, humidity_total_df, co2_total_df, illumination_total_df])\n",
    "\n",
    "# 결과 확인\n",
    "print(total_environment_data_df)\n",
    "\n",
    "# 인덱스를 일반 컬럼으로 변경\n",
    "final_df1 = total_environment_data_df.reset_index()\n",
    "\n",
    "# CSV 파일로 저장\n",
    "final_df1.to_csv('all_data/class_a_environmental_sensor.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       in   out  cumulative  average_temperature(°C)  \\\n",
      "time                                                                   \n",
      "2024-04-15 00:00:00   NaN   NaN         NaN                23.918247   \n",
      "2024-04-15 01:00:00   NaN   NaN         NaN                23.331073   \n",
      "2024-04-15 02:00:00   NaN   NaN         NaN                23.240556   \n",
      "2024-04-15 03:00:00   NaN   NaN         NaN                23.148472   \n",
      "2024-04-15 04:00:00   NaN   NaN         NaN                22.955322   \n",
      "...                   ...   ...         ...                      ...   \n",
      "2024-05-01 20:00:00  11.0  11.0         0.0                23.611667   \n",
      "2024-05-01 21:00:00  15.0   9.0         6.0                23.312037   \n",
      "2024-05-01 22:00:00   9.0  10.0         5.0                23.214962   \n",
      "2024-05-01 23:00:00   0.0   0.0         5.0                23.116479   \n",
      "2024-05-02 00:00:00   0.0   0.0         5.0                23.016667   \n",
      "\n",
      "                     average_humidity(%)  average_co2(ppm)  \\\n",
      "time                                                         \n",
      "2024-04-15 00:00:00            47.913075        634.270115   \n",
      "2024-04-15 01:00:00            48.881356        611.783333   \n",
      "2024-04-15 02:00:00            48.548611        591.683333   \n",
      "2024-04-15 03:00:00            48.346528        581.433333   \n",
      "2024-04-15 04:00:00            48.401261        570.238889   \n",
      "...                                  ...               ...   \n",
      "2024-05-01 20:00:00            38.694444        619.944444   \n",
      "2024-05-01 21:00:00            39.969444        684.833333   \n",
      "2024-05-01 22:00:00            39.918561        676.661111   \n",
      "2024-05-01 23:00:00            39.639513        584.022222   \n",
      "2024-05-02 00:00:00            38.833333        541.000000   \n",
      "\n",
      "                     average_illumination(lux)  \n",
      "time                                            \n",
      "2024-04-15 00:00:00                  47.913075  \n",
      "2024-04-15 01:00:00                  48.881356  \n",
      "2024-04-15 02:00:00                  48.548611  \n",
      "2024-04-15 03:00:00                  48.346528  \n",
      "2024-04-15 04:00:00                  48.401261  \n",
      "...                                        ...  \n",
      "2024-05-01 20:00:00                  68.333333  \n",
      "2024-05-01 21:00:00                  68.433333  \n",
      "2024-05-01 22:00:00                  66.822222  \n",
      "2024-05-01 23:00:00                  65.777778  \n",
      "2024-05-02 00:00:00                  65.000000  \n",
      "\n",
      "[409 rows x 7 columns]\n"
     ]
    }
   ],
   "execution_count": 70
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:05:10.561050Z",
     "start_time": "2024-05-02T01:05:10.537306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 전체 전력/전력량\n",
    "power_total_df = df_hourly_calculate(power_total_df, \"total_power(Wh)\", \"sum\")\n",
    "power_usage_total_df = df_hourly_calculate(power_usage_total_df, 'total_power_usage(Kwh)', 'diff')\n",
    "\n",
    "# 실내기 전력/전력량\n",
    "\n",
    "# 실외기 전력/전력량\n",
    "\n",
    "# 자동문 전력/전력량\n"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-02T01:05:10.571686Z",
     "start_time": "2024-05-02T01:05:10.562412Z"
    }
   },
   "cell_type": "code",
   "source": [
    "total_power_data_df = merge_dataframes([power_total_df, power_usage_total_df])\n",
    "print(total_power_data_df)\n",
    "final_df2 = total_power_data_df.reset_index()\n",
    "final_df2.to_csv('all_data/class_a_power_sensor.csv', index=False)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     total_power(Wh)  total_power_usage(Kwh)\n",
      "time                                                        \n",
      "2024-04-15 00:00:00           2234.5                    0.20\n",
      "2024-04-15 01:00:00           6152.5                    0.20\n",
      "2024-04-15 02:00:00           5315.5                    0.20\n",
      "2024-04-15 03:00:00           3457.5                    0.10\n",
      "2024-04-15 04:00:00           6012.5                    0.20\n",
      "...                              ...                     ...\n",
      "2024-05-01 20:00:00          31287.5                    1.00\n",
      "2024-05-01 21:00:00          17475.5                    0.50\n",
      "2024-05-01 22:00:00          16100.5                    0.50\n",
      "2024-05-01 23:00:00          17601.5                    0.50\n",
      "2024-05-02 00:00:00            961.0                    0.05\n",
      "\n",
      "[409 rows x 2 columns]\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smoothing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
